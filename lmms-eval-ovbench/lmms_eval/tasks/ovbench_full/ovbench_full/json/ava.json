[
    {
        "middle_frame_timestamp": 945.0,
        "question": "Are there still 2 people in the current frame now?",
        "answer": "No",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "1j20qq1JyX4",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 50.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 966.0,
        "question": "What action is the person at the location [0.02, 0.14, 0.99, 0.99] in the image performing?",
        "answer": "stand, talk to (e.g., self, a person, a group)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "1j20qq1JyX4",
        "candidates": [
            "stand, carry/hold (an object), watch (a person)",
            "stand, talk to (e.g., self, a person, a group)",
            "sit, talk to (e.g., self, a person, a group)",
            "stand, carry/hold (an object)"
        ],
        "start": 0.0,
        "end": 71.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1081.0,
        "question": "Where was the person currently performing the walk in the scene 8 seconds ago?",
        "answer": "[0.33, 0.29, 0.45, 0.66]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "1j20qq1JyX4",
        "candidates": [
            "[0.23, 0.14, 0.36, 0.48]",
            "[0.12, 0.30, 0.46, 1.00]",
            "[0.42, 0.45, 0.73, 0.89]",
            "[0.33, 0.29, 0.45, 0.66]"
        ],
        "start": 0.0,
        "end": 186.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1085.0,
        "question": "Are there still 1 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "1j20qq1JyX4",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 190.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1122.0,
        "question": "What action is the person at the location [0.13, 0.25, 0.39, 0.97] in the image performing?",
        "answer": "stand, carry/hold (an object), watch (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "1j20qq1JyX4",
        "candidates": [
            "stand, listen to (a person), watch (a person)",
            "sit, talk to (e.g., self, a person, a group)",
            "walk, carry/hold (an object)",
            "stand, carry/hold (an object), watch (a person)"
        ],
        "start": 0.0,
        "end": 227.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1268.0,
        "question": "Where is the person currently performing the talk to (e.g., self, a person, a group) located in the picture?",
        "answer": "[0.14, 0.03, 0.95, 1.00]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "1j20qq1JyX4",
        "candidates": [
            "[0.07, 0.22, 0.62, 0.99]",
            "[0.14, 0.03, 0.95, 1.00]",
            "[0.44, 0.32, 0.95, 0.85]",
            "[0.00, 0.32, 1.00, 1.00]"
        ],
        "start": 0.0,
        "end": 373.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1298.0,
        "question": "Are there still 1 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "1j20qq1JyX4",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 403.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1310.0,
        "question": "Where was the person currently performing the carry/hold (an object) in the scene 8 seconds ago?",
        "answer": "[0.00, 0.11, 1.00, 0.99]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "1j20qq1JyX4",
        "candidates": [
            "[0.10, 0.12, 0.76, 0.70]",
            "[0.00, 0.11, 1.00, 0.99]",
            "[0.39, 0.04, 0.89, 0.70]",
            "[0.00, 0.22, 0.72, 1.00]"
        ],
        "start": 0.0,
        "end": 415.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1415.0,
        "question": "What action is the person at the location [0.12, 0.39, 0.34, 0.82] in the image performing?",
        "answer": "sit, talk to (e.g., self, a person, a group)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "1j20qq1JyX4",
        "candidates": [
            "stand, carry/hold (an object), watch (a person)",
            "sit, talk to (e.g., self, a person, a group)",
            "stand, carry/hold (an object)",
            "walk, carry/hold (an object), talk to (e.g., self, a person, a group), watch (a person)"
        ],
        "start": 0.0,
        "end": 520.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1441.0,
        "question": "Are there still 2 people in the current frame now?",
        "answer": "No",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "1j20qq1JyX4",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 546.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1480.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.15, 0.01, 0.89, 0.98]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "1j20qq1JyX4",
        "candidates": [
            "[0.00, 0.01, 0.61, 1.00]",
            "[0.10, 0.30, 0.72, 1.00]",
            "[0.61, 0.10, 0.87, 0.65]",
            "[0.15, 0.01, 0.89, 0.98]"
        ],
        "start": 0.0,
        "end": 585.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1579.0,
        "question": "Are there still 1 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "1j20qq1JyX4",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 684.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1648.0,
        "question": "What action is the person at the location [0.12, 0.30, 0.46, 1.00] in the image performing?",
        "answer": "stand, listen to (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "1j20qq1JyX4",
        "candidates": [
            "stand, listen to (a person), watch (a person)",
            "stand, carry/hold (an object), talk to (e.g., self, a person, a group)",
            "stand, listen to (a person)",
            "sit, listen to (a person), watch (a person)"
        ],
        "start": 0.0,
        "end": 753.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1656.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.12, 0.30, 0.46, 1.00]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "1j20qq1JyX4",
        "candidates": [
            "[0.08, 0.43, 0.17, 0.86]",
            "[0.00, 0.26, 0.48, 0.71]",
            "[0.38, 0.21, 0.55, 0.96]",
            "[0.12, 0.30, 0.46, 1.00]"
        ],
        "start": 0.0,
        "end": 761.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1716.0,
        "question": "Where was the person currently performing the bend/bow (at the waist) in the scene 8 seconds ago?",
        "answer": "[0.03, 0.04, 0.99, 0.99]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "1j20qq1JyX4",
        "candidates": [
            "[0.03, 0.04, 0.99, 0.99]",
            "[0.00, 0.32, 0.88, 1.00]",
            "[0.18, 0.33, 1.00, 1.00]",
            "[0.12, 0.29, 0.45, 0.99]"
        ],
        "start": 0.0,
        "end": 821.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1751.0,
        "question": "What action is the person currently in the [0.05, 0.13, 0.99, 0.98] location likely to do next?",
        "answer": "bend/bow (at the waist)",
        "sub_answer_type": "FuturePrediction-1",
        "answer_type": "FuturePrediction",
        "video": "1j20qq1JyX4",
        "candidates": [
            "drink",
            "sail boat",
            "bend/bow (at the waist)",
            "walk and talk to (e.g., self, a person, a group)"
        ],
        "start": 0.0,
        "end": 856.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 921.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.62, 0.41, 0.96, 0.99]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "2PpxiG0WU18",
        "candidates": [
            "[0.62, 0.41, 0.96, 0.99]",
            "[0.33, 0.68, 0.97, 0.88]",
            "[0.91, 0.48, 1.00, 0.90]",
            "[0.52, 0.12, 0.94, 0.97]"
        ],
        "start": 0.0,
        "end": 26.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 965.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "ride (e.g., a bike, a car, a horse) -> talk to (e.g., self, a person, a group)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "2PpxiG0WU18",
        "candidates": [
            "answer phone -> ride (e.g., a bike, a car, a horse)",
            "shoot -> ride (e.g., a bike, a car, a horse)",
            "ride (e.g., a bike, a car, a horse) -> talk to (e.g., self, a person, a group)",
            "hand shake -> talk to (e.g., self, a person, a group)"
        ],
        "start": 0.0,
        "end": 70.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 984.0,
        "question": "Where is the person currently performing the drive (e.g., a car, a truck) located in the picture?",
        "answer": "[0.05, 0.14, 0.66, 0.96]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "2PpxiG0WU18",
        "candidates": [
            "[0.05, 0.14, 0.66, 0.96]",
            "[0.00, 0.17, 0.43, 0.79]",
            "[0.24, 0.15, 0.83, 0.91]",
            "[0.00, 0.38, 0.81, 1.00]"
        ],
        "start": 0.0,
        "end": 89.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 991.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "drive (e.g., a car, a truck) -> talk to (e.g., self, a person, a group) -> ride (e.g., a bike, a car, a horse)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "2PpxiG0WU18",
        "candidates": [
            "drive (e.g., a car, a truck) -> talk to (e.g., self, a person, a group) -> ride (e.g., a bike, a car, a horse)",
            "lift (a person) -> talk to (e.g., self, a person, a group) -> drive (e.g., a car, a truck)",
            "climb (e.g., a mountain) -> drive (e.g., a car, a truck) -> talk to (e.g., self, a person, a group)",
            "smoke -> talk to (e.g., self, a person, a group) -> ride (e.g., a bike, a car, a horse)"
        ],
        "start": 0.0,
        "end": 96.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1004.0,
        "question": "Is the person currently in the [0.47, 0.10, 0.96, 1.00] location in the current frame performing the ride (e.g., a bike, a car, a horse)?",
        "answer": "No",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "2PpxiG0WU18",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 109.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1074.0,
        "question": "Where is the person currently performing the talk to (e.g., self, a person, a group) located in the picture?",
        "answer": "[0.23, 0.02, 0.85, 1.00]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "2PpxiG0WU18",
        "candidates": [
            "[0.23, 0.02, 0.85, 1.00]",
            "[0.45, 0.00, 0.86, 0.72]",
            "[0.44, 0.09, 1.00, 0.91]",
            "[0.10, 0.12, 0.66, 0.96]"
        ],
        "start": 0.0,
        "end": 179.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1079.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.21, 0.04, 0.86, 1.00]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "2PpxiG0WU18",
        "candidates": [
            "[0.00, 0.00, 1.00, 0.70]",
            "[0.21, 0.04, 0.86, 1.00]",
            "[0.38, 0.30, 0.87, 1.00]",
            "[0.55, 0.07, 1.00, 0.99]"
        ],
        "start": 0.0,
        "end": 184.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1080.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "talk to (e.g., self, a person, a group) -> ride (e.g., a bike, a car, a horse)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "2PpxiG0WU18",
        "candidates": [
            "dress/put on clothing -> talk to (e.g., self, a person, a group)",
            "put down -> ride (e.g., a bike, a car, a horse)",
            "talk to (e.g., self, a person, a group) -> ride (e.g., a bike, a car, a horse)",
            "talk to (e.g., self, a person, a group) -> get up"
        ],
        "start": 0.0,
        "end": 185.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1197.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "talk to (e.g., self, a person, a group) -> drive (e.g., a car, a truck) -> carry/hold (an object)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "2PpxiG0WU18",
        "candidates": [
            "ride (e.g., a bike, a car, a horse) -> talk to (e.g., self, a person, a group) -> drive (e.g., a car, a truck)",
            "talk to (e.g., self, a person, a group) -> drive (e.g., a car, a truck) -> carry/hold (an object)",
            "drive (e.g., a car, a truck) -> ride (e.g., a bike, a car, a horse) -> carry/hold (an object)",
            "drive (e.g., a car, a truck) -> eat -> carry/hold (an object)"
        ],
        "start": 0.0,
        "end": 302.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1264.0,
        "question": "What action is the person at the location [0.31, 0.19, 0.58, 0.75] in the image performing?",
        "answer": "sit, talk to (e.g., self, a person, a group), watch (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "2PpxiG0WU18",
        "candidates": [
            "sit, talk to (e.g., self, a person, a group), watch (a person)",
            "sit, ride (e.g., a bike, a car, a horse), listen to (a person)",
            "sit, watch (a person)",
            "sit, drive (e.g., a car, a truck)"
        ],
        "start": 0.0,
        "end": 369.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1485.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.12, 0.17, 0.78, 0.97]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "2PpxiG0WU18",
        "candidates": [
            "[0.12, 0.17, 0.78, 0.97]",
            "[0.55, 0.10, 0.95, 0.98]",
            "[0.20, 0.38, 1.00, 0.73]",
            "[0.00, 0.38, 0.56, 0.69]"
        ],
        "start": 0.0,
        "end": 590.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1508.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.54, 0.10, 0.95, 0.98]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "2PpxiG0WU18",
        "candidates": [
            "[0.78, 0.12, 1.00, 0.78]",
            "[0.68, 0.34, 1.00, 1.00]",
            "[0.41, 0.03, 0.68, 0.95]",
            "[0.54, 0.10, 0.95, 0.98]"
        ],
        "start": 0.0,
        "end": 613.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1550.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.54, 0.20, 0.95, 0.99]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "2PpxiG0WU18",
        "candidates": [
            "[0.74, 0.00, 1.00, 0.71]",
            "[0.54, 0.20, 0.95, 0.99]",
            "[0.31, 0.43, 0.83, 1.00]",
            "[0.17, 0.06, 0.84, 1.00]"
        ],
        "start": 0.0,
        "end": 655.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1575.0,
        "question": "Is the person currently in the [0.38, 0.17, 0.68, 0.98] location in the current frame performing the hug (a person)?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "2PpxiG0WU18",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 680.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1581.0,
        "question": "What action is the person at the location [0.11, 0.13, 0.51, 0.96] in the image performing?",
        "answer": "stand, grab (a person), talk to (e.g., self, a person, a group), watch (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "2PpxiG0WU18",
        "candidates": [
            "stand, grab (a person), talk to (e.g., self, a person, a group), watch (a person)",
            "stand, listen to (a person), watch (a person)",
            "sit, talk to (e.g., self, a person, a group)",
            "sit, listen to (a person), watch (a person)"
        ],
        "start": 0.0,
        "end": 686.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1584.0,
        "question": "What action is the person currently in the [0.14, 0.13, 0.53, 0.96] location likely to do next?",
        "answer": "hug (a person)",
        "sub_answer_type": "FuturePrediction-1",
        "answer_type": "FuturePrediction",
        "video": "2PpxiG0WU18",
        "candidates": [
            "hug (a person)",
            "drive (e.g., a car, a truck)",
            "walk",
            "extract"
        ],
        "start": 0.0,
        "end": 689.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1652.0,
        "question": "What action is the person at the location [0.22, 0.05, 0.62, 0.96] in the image performing?",
        "answer": "stand, watch (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "2PpxiG0WU18",
        "candidates": [
            "stand, watch (a person)",
            "stand, listen to (a person)",
            "stand, listen to (a person), watch (a person)",
            "sit, drive (e.g., a car, a truck)"
        ],
        "start": 0.0,
        "end": 757.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1703.0,
        "question": "Are there still 1 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "2PpxiG0WU18",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 808.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1768.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "walk -> bend/bow (at the waist)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "2PpxiG0WU18",
        "candidates": [
            "walk -> bend/bow (at the waist)",
            "pull (an object) -> walk",
            "point to (an object) -> bend/bow (at the waist)",
            "walk -> kick (an object)"
        ],
        "start": 0.0,
        "end": 873.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 967.0,
        "question": "Where was the person currently performing the carry/hold (an object) in the scene 8 seconds ago?",
        "answer": "[0.72, 0.16, 0.99, 0.98]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "55Ihr6uVIDA",
        "candidates": [
            "[0.03, 0.45, 0.18, 0.74]",
            "[0.72, 0.16, 0.99, 0.98]",
            "[0.51, 0.00, 1.00, 0.78]",
            "[0.48, 0.42, 1.00, 1.00]"
        ],
        "start": 0.0,
        "end": 72.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 994.0,
        "question": "What action is the person currently in the [0.25, 0.28, 0.43, 0.99] location likely to do next?",
        "answer": "play with kids",
        "sub_answer_type": "FuturePrediction-1",
        "answer_type": "FuturePrediction",
        "video": "55Ihr6uVIDA",
        "candidates": [
            "play with kids",
            "walk and talk to (e.g., self, a person, a group)",
            "play musical instrument",
            "read"
        ],
        "start": 0.0,
        "end": 99.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1003.0,
        "question": "Where is the person currently performing the carry/hold (an object) located in the picture?",
        "answer": "[0.17, 0.36, 0.75, 0.99]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "55Ihr6uVIDA",
        "candidates": [
            "[0.47, 0.63, 0.87, 1.00]",
            "[0.04, 0.00, 0.69, 1.00]",
            "[0.00, 0.28, 0.51, 0.93]",
            "[0.17, 0.36, 0.75, 0.99]"
        ],
        "start": 0.0,
        "end": 108.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1008.0,
        "question": "Where was the person currently performing the carry/hold (an object) in the scene 8 seconds ago?",
        "answer": "[0.25, 0.22, 0.81, 0.78]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "55Ihr6uVIDA",
        "candidates": [
            "[0.59, 0.32, 0.79, 0.98]",
            "[0.15, 0.07, 0.72, 0.67]",
            "[0.45, 0.01, 1.00, 0.59]",
            "[0.25, 0.22, 0.81, 0.78]"
        ],
        "start": 0.0,
        "end": 113.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1038.0,
        "question": "Where was the person currently performing the carry/hold (an object) in the scene 8 seconds ago?",
        "answer": "[0.80, 0.33, 0.99, 0.98]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "55Ihr6uVIDA",
        "candidates": [
            "[0.90, 0.05, 0.99, 0.95]",
            "[0.89, 0.61, 1.00, 1.00]",
            "[0.65, 0.20, 0.75, 0.61]",
            "[0.80, 0.33, 0.99, 0.98]"
        ],
        "start": 0.0,
        "end": 143.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1040.0,
        "question": "Is the person currently in the [0.09, 0.23, 0.38, 0.88] location in the current frame performing the talk to (e.g., self, a person, a group)?",
        "answer": "No",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "55Ihr6uVIDA",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 145.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1106.0,
        "question": "What action is the person at the location [0.47, 0.36, 0.57, 0.62] in the image performing?",
        "answer": "run/jog, carry/hold (an object), watch (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "55Ihr6uVIDA",
        "candidates": [
            "run/jog, carry/hold (an object), watch (a person)",
            "stand, talk to (e.g., self, a person, a group), watch (a person)",
            "stand, carry/hold (an object), listen to (a person)",
            "stand, carry/hold (an object)"
        ],
        "start": 0.0,
        "end": 211.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1115.0,
        "question": "What location in the frame is the person currently in the [0.36, 0.34, 0.58, 0.99] location likely to move to next?",
        "answer": "[0.03, 0.42, 0.21, 0.95]",
        "sub_answer_type": "FuturePrediction-2",
        "answer_type": "FuturePrediction",
        "video": "55Ihr6uVIDA",
        "candidates": [
            "[0.31, 0.46, 0.34, 0.99]",
            "[0.92, 0.35, 1.00, 0.55]",
            "[0.23, 0.15, 0.21, 0.99]",
            "[0.03, 0.42, 0.21, 0.95]"
        ],
        "start": 0.0,
        "end": 220.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1198.0,
        "question": "Are there still 1 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "55Ihr6uVIDA",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 303.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1268.0,
        "question": "What action is the person at the location [0.04, 0.14, 0.49, 0.64] in the image performing?",
        "answer": "stand, carry/hold (an object)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "55Ihr6uVIDA",
        "candidates": [
            "stand, carry/hold (an object), talk to (e.g., self, a person, a group), watch (a person)",
            "stand, carry/hold (an object), watch (a person)",
            "stand, carry/hold (an object)",
            "stand, talk to (e.g., self, a person, a group), watch (a person)"
        ],
        "start": 0.0,
        "end": 373.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1452.0,
        "question": "Where is the person currently performing the carry/hold (an object) located in the picture?",
        "answer": "[0.23, 0.01, 0.78, 0.95]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "55Ihr6uVIDA",
        "candidates": [
            "[0.17, 0.29, 0.58, 0.99]",
            "[0.52, 0.15, 0.97, 0.95]",
            "[0.16, 0.27, 0.95, 1.00]",
            "[0.23, 0.01, 0.78, 0.95]"
        ],
        "start": 0.0,
        "end": 557.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1471.0,
        "question": "Where was the person currently performing the carry/hold (an object) in the scene 8 seconds ago?",
        "answer": "[0.57, 0.30, 1.00, 0.99]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "55Ihr6uVIDA",
        "candidates": [
            "[0.57, 0.30, 1.00, 0.99]",
            "[0.53, 0.53, 0.82, 1.00]",
            "[0.86, 0.15, 0.94, 0.82]",
            "[0.37, 0.16, 0.96, 0.91]"
        ],
        "start": 0.0,
        "end": 576.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1484.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.29, 0.02, 0.53, 0.99]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "55Ihr6uVIDA",
        "candidates": [
            "[0.71, 0.27, 0.82, 0.66]",
            "[0.29, 0.02, 0.53, 0.99]",
            "[0.02, 0.00, 0.26, 1.00]",
            "[0.46, 0.00, 0.75, 0.75]"
        ],
        "start": 0.0,
        "end": 589.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1564.0,
        "question": "Are there still 1 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "55Ihr6uVIDA",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 669.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1692.0,
        "question": "What action is the person at the location [0.37, 0.23, 0.50, 0.77] in the image performing?",
        "answer": "stand, carry/hold (an object)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "55Ihr6uVIDA",
        "candidates": [
            "stand, carry/hold (an object), listen to (a person)",
            "carry/hold (an object), fall down, watch (a person)",
            "stand, carry/hold (an object)",
            "walk, carry/hold (an object)"
        ],
        "start": 0.0,
        "end": 797.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1737.0,
        "question": "Is the person currently in the [0.49, 0.36, 0.64, 0.80] location in the current frame performing the run/jog?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "55Ihr6uVIDA",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 842.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 968.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.56, 0.26, 0.76, 0.98] location?",
        "answer": "carry/hold (an object) [0.56, 0.26, 0.76, 0.98] -> hand clap [0.56, 0.26, 0.76, 0.98] -> sing to (e.g., self, a person, a group) [0.56, 0.26, 0.76, 0.98]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "5BDj0ow5hnA",
        "candidates": [
            "put down [0.41, 0.33, 0.60, 1.00] -> carry/hold (an object) [0.74, 0.21, 0.71, 0.94] -> hand clap [0.51, 0.43, 0.58, 1.00]",
            "sing to (e.g., self, a person, a group) [0.50, 0.34, 0.79, 0.83] -> hand clap [0.52, 0.33, 0.82, 0.86] -> paint [0.59, 0.44, 0.94, 0.80]",
            "talk to (e.g., self, a person, a group) [0.69, 0.34, 0.94, 1.00] -> sing to (e.g., self, a person, a group) [0.41, 0.20, 0.81, 0.95] -> hand clap [0.42, 0.09, 0.59, 0.99]",
            "carry/hold (an object) [0.56, 0.26, 0.76, 0.98] -> hand clap [0.56, 0.26, 0.76, 0.98] -> sing to (e.g., self, a person, a group) [0.56, 0.26, 0.76, 0.98]"
        ],
        "start": 0.0,
        "end": 73.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1025.0,
        "question": "What action is the person at the location [0.13, 0.18, 0.30, 0.97] in the image performing?",
        "answer": "stand, walk, carry/hold (an object), watch (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "5BDj0ow5hnA",
        "candidates": [
            "sit, listen to (a person), watch (a person)",
            "stand, walk, carry/hold (an object), watch (a person)",
            "sit, listen to (a person)",
            "walk, carry/hold (an object)"
        ],
        "start": 0.0,
        "end": 130.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1032.0,
        "question": "How many people were performing the watch (a person) in the scene 60 seconds ago?",
        "answer": "5",
        "sub_answer_type": "PastMemory-5",
        "answer_type": "PastMemory",
        "video": "5BDj0ow5hnA",
        "candidates": [
            "3",
            "4",
            "5",
            "6"
        ],
        "start": 0.0,
        "end": 137.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1169.0,
        "question": "Where is the person currently performing the talk to (e.g., self, a person, a group) located in the picture?",
        "answer": "[0.14, 0.00, 0.90, 0.97]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "5BDj0ow5hnA",
        "candidates": [
            "[0.14, 0.00, 0.90, 0.97]",
            "[0.39, 0.00, 1.00, 0.89]",
            "[0.79, 0.39, 0.87, 0.84]",
            "[0.19, 0.28, 0.65, 1.00]"
        ],
        "start": 0.0,
        "end": 274.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1282.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.31, 0.10, 0.71, 0.88]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "5BDj0ow5hnA",
        "candidates": [
            "[0.31, 0.10, 0.71, 0.88]",
            "[0.47, 0.00, 0.93, 1.00]",
            "[0.34, 0.00, 0.49, 0.64]",
            "[0.11, 0.13, 0.64, 0.99]"
        ],
        "start": 0.0,
        "end": 387.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1429.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.27, 0.24, 0.77, 1.00] location?",
        "answer": "walk [0.27, 0.24, 0.77, 1.00] -> carry/hold (an object) [0.27, 0.24, 0.77, 1.00] -> talk to (e.g., self, a person, a group) [0.27, 0.24, 0.77, 1.00]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "5BDj0ow5hnA",
        "candidates": [
            "write [0.34, 0.24, 0.68, 1.00] -> talk to (e.g., self, a person, a group) [0.23, 0.34, 0.59, 1.00] -> carry/hold (an object) [0.37, 0.29, 0.63, 0.95]",
            "talk to (e.g., self, a person, a group) [0.40, 0.09, 0.96, 1.00] -> get up [0.09, 0.25, 0.68, 0.90] -> walk [0.14, 0.18, 0.78, 1.00]",
            "carry/hold (an object) [0.14, 0.05, 0.89, 1.00] -> talk to (e.g., self, a person, a group) [0.26, 0.18, 0.76, 1.00] -> jump/leap [0.42, 0.35, 0.73, 1.00]",
            "walk [0.27, 0.24, 0.77, 1.00] -> carry/hold (an object) [0.27, 0.24, 0.77, 1.00] -> talk to (e.g., self, a person, a group) [0.27, 0.24, 0.77, 1.00]"
        ],
        "start": 0.0,
        "end": 534.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1436.0,
        "question": "What action is the person at the location [0.11, 0.00, 0.49, 1.00] in the image performing?",
        "answer": "stand, listen to (a person), talk to (e.g., self, a person, a group), watch (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "5BDj0ow5hnA",
        "candidates": [
            "stand, carry/hold (an object), hand clap, sing to (e.g., self, a person, a group), watch (a person)",
            "stand, carry/hold (an object), talk to (e.g., self, a person, a group)",
            "stand, listen to (a person), watch (a person)",
            "stand, listen to (a person), talk to (e.g., self, a person, a group), watch (a person)"
        ],
        "start": 0.0,
        "end": 541.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1459.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.12, 0.46, 0.23, 0.97] location?",
        "answer": "talk to (e.g., self, a person, a group) [0.27, 0.49, 0.42, 0.98] -> walk [0.12, 0.46, 0.23, 0.97] -> carry/hold (an object) [0.12, 0.46, 0.23, 0.97]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "5BDj0ow5hnA",
        "candidates": [
            "talk to (e.g., self, a person, a group) [0.21, 0.44, 0.41, 1.00] -> carry/hold (an object) [0.09, 0.46, 0.26, 1.00] -> put down [0.32, 0.62, 0.05, 0.85]",
            "catch (an object) [0.10, 0.30, 0.26, 0.92] -> talk to (e.g., self, a person, a group) [0.18, 0.46, 0.43, 1.00] -> carry/hold (an object) [0.03, 0.31, 0.37, 0.91]",
            "walk [0.00, 0.28, 0.07, 1.00] -> carry/hold (an object) [0.26, 0.50, 0.36, 0.93] -> brush teeth [0.17, 0.56, 0.53, 1.00]",
            "talk to (e.g., self, a person, a group) [0.27, 0.49, 0.42, 0.98] -> walk [0.12, 0.46, 0.23, 0.97] -> carry/hold (an object) [0.12, 0.46, 0.23, 0.97]"
        ],
        "start": 0.0,
        "end": 564.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1500.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.34, 0.00, 0.67, 0.99]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "5BDj0ow5hnA",
        "candidates": [
            "[0.07, 0.00, 0.44, 1.00]",
            "[0.34, 0.00, 0.67, 0.99]",
            "[0.55, 0.01, 0.84, 0.78]",
            "[0.62, 0.16, 0.88, 0.98]"
        ],
        "start": 0.0,
        "end": 605.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1507.0,
        "question": "Are there still 1 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "5BDj0ow5hnA",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 612.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1539.0,
        "question": "Where is the person currently performing the talk to (e.g., self, a person, a group) located in the picture?",
        "answer": "[0.28, 0.02, 0.88, 1.00]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "5BDj0ow5hnA",
        "candidates": [
            "[0.10, 0.01, 0.76, 0.99]",
            "[0.57, 0.27, 0.94, 1.00]",
            "[0.15, 0.00, 0.67, 0.70]",
            "[0.28, 0.02, 0.88, 1.00]"
        ],
        "start": 0.0,
        "end": 644.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1566.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.45, 0.35, 0.58, 0.76] location?",
        "answer": "carry/hold (an object) [0.45, 0.35, 0.58, 0.76] -> dance [0.45, 0.35, 0.58, 0.76] -> sing to (e.g., self, a person, a group) [0.45, 0.35, 0.58, 0.76]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "5BDj0ow5hnA",
        "candidates": [
            "dig [0.25, 0.46, 0.38, 0.95] -> sing to (e.g., self, a person, a group) [0.57, 0.21, 0.43, 0.61] -> dance [0.52, 0.21, 0.75, 0.56]",
            "dance [0.47, 0.24, 0.63, 0.77] -> eat [0.60, 0.17, 0.63, 0.60] -> carry/hold (an object) [0.36, 0.36, 0.66, 0.74]",
            "carry/hold (an object) [0.45, 0.35, 0.58, 0.76] -> dance [0.45, 0.35, 0.58, 0.76] -> sing to (e.g., self, a person, a group) [0.45, 0.35, 0.58, 0.76]",
            "dance [0.49, 0.51, 0.55, 0.71] -> sail boat [0.33, 0.42, 0.61, 0.74] -> sing to (e.g., self, a person, a group) [0.46, 0.42, 0.42, 0.95]"
        ],
        "start": 0.0,
        "end": 671.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1611.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.18, 0.06, 0.86, 0.98]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "5BDj0ow5hnA",
        "candidates": [
            "[0.23, 0.30, 0.63, 1.00]",
            "[0.00, 0.00, 0.76, 0.88]",
            "[0.44, 0.00, 0.90, 0.99]",
            "[0.18, 0.06, 0.86, 0.98]"
        ],
        "start": 0.0,
        "end": 716.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1618.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.46, 0.36, 0.57, 0.82] location?",
        "answer": "walk [0.46, 0.36, 0.57, 0.82] -> carry/hold (an object) [0.46, 0.36, 0.57, 0.82] -> pull (an object) [0.46, 0.36, 0.57, 0.82]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "5BDj0ow5hnA",
        "candidates": [
            "carry/hold (an object) [0.42, 0.24, 0.62, 0.65] -> pull (an object) [0.53, 0.27, 0.54, 1.00] -> climb (e.g., a mountain) [0.60, 0.29, 0.62, 1.00]",
            "walk [0.46, 0.36, 0.57, 0.82] -> carry/hold (an object) [0.46, 0.36, 0.57, 0.82] -> pull (an object) [0.46, 0.36, 0.57, 0.82]",
            "carry/hold (an object) [0.64, 0.43, 0.38, 0.92] -> pull (an object) [0.45, 0.25, 0.46, 0.98] -> catch (an object) [0.34, 0.43, 0.52, 0.86]",
            "jump/leap [0.45, 0.43, 0.40, 0.83] -> walk [0.60, 0.24, 0.39, 0.82] -> pull (an object) [0.27, 0.40, 0.67, 0.91]"
        ],
        "start": 0.0,
        "end": 723.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1619.0,
        "question": "What action is the person at the location [0.18, 0.44, 0.24, 0.69] in the image performing?",
        "answer": "walk, carry/hold (an object)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "5BDj0ow5hnA",
        "candidates": [
            "walk, carry/hold (an object)",
            "sit, listen to (a person)",
            "sit, listen to (a person), watch (a person)",
            "walk, listen to (a person)"
        ],
        "start": 0.0,
        "end": 724.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1682.0,
        "question": "How many people were performing the carry/hold (an object) in the scene 300 seconds ago?",
        "answer": "3",
        "sub_answer_type": "PastMemory-5",
        "answer_type": "PastMemory",
        "video": "5BDj0ow5hnA",
        "candidates": [
            "4",
            "8",
            "3",
            "5"
        ],
        "start": 0.0,
        "end": 787.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1700.0,
        "question": "What action is the person currently in the [0.69, 0.21, 0.75, 0.53] location likely to do next?",
        "answer": "take a photo",
        "sub_answer_type": "FuturePrediction-1",
        "answer_type": "FuturePrediction",
        "video": "5BDj0ow5hnA",
        "candidates": [
            "close (e.g., a door, a box)",
            "climb (e.g., a mountain)",
            "take a photo",
            "carry/hold (an object) and crouch/kneel"
        ],
        "start": 0.0,
        "end": 805.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1798.0,
        "question": "Are there still 1 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "5BDj0ow5hnA",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 903.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1015.0,
        "question": "Where was the person currently performing the bend/bow (at the waist) in the scene 8 seconds ago?",
        "answer": "[0.66, 0.40, 0.74, 0.70]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "6d5u6FHvz7Q",
        "candidates": [
            "[0.66, 0.40, 0.74, 0.70]",
            "[0.78, 0.23, 0.71, 0.50]",
            "[0.41, 0.20, 0.70, 0.82]",
            "[0.95, 0.15, 1.00, 0.66]"
        ],
        "start": 0.0,
        "end": 120.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1018.0,
        "question": "What action is the person at the location [0.49, 0.30, 0.68, 0.89] in the image performing?",
        "answer": "sit, ride (e.g., a bike, a car, a horse)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "6d5u6FHvz7Q",
        "candidates": [
            "sit, ride (e.g., a bike, a car, a horse)",
            "stand, talk to (e.g., self, a person, a group), watch (a person)",
            "sit, talk to (e.g., self, a person, a group), watch (a person)",
            "sit, listen to (a person), talk to (e.g., self, a person, a group), watch (a person)"
        ],
        "start": 0.0,
        "end": 123.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1071.0,
        "question": "Is the person currently in the [0.19, 0.09, 0.95, 1.00] location in the current frame performing the talk to (e.g., self, a person, a group)?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "6d5u6FHvz7Q",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 176.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1080.0,
        "question": "Where is the person currently performing the talk to (e.g., self, a person, a group) located in the picture?",
        "answer": "[0.20, 0.11, 0.94, 1.00]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "6d5u6FHvz7Q",
        "candidates": [
            "[0.19, 0.36, 0.65, 1.00]",
            "[0.42, 0.21, 1.00, 0.72]",
            "[0.04, 0.06, 0.74, 0.98]",
            "[0.20, 0.11, 0.94, 1.00]"
        ],
        "start": 0.0,
        "end": 185.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1092.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "carry/hold (an object) -> walk",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "6d5u6FHvz7Q",
        "candidates": [
            "exit -> carry/hold (an object)",
            "lift/pick up -> carry/hold (an object)",
            "carry/hold (an object) -> walk",
            "enter -> carry/hold (an object)"
        ],
        "start": 0.0,
        "end": 197.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1176.0,
        "question": "What action is the person currently in the [0.25, 0.31, 0.66, 0.95] location likely to do next?",
        "answer": "carry/hold (an object) and cut",
        "sub_answer_type": "FuturePrediction-1",
        "answer_type": "FuturePrediction",
        "video": "6d5u6FHvz7Q",
        "candidates": [
            "stir",
            "carry/hold (an object) and cut",
            "bend/bow (at the waist) and carry/hold (an object)",
            "swim"
        ],
        "start": 0.0,
        "end": 281.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1180.0,
        "question": "Where was the person currently performing the cut in the scene 8 seconds ago?",
        "answer": "[0.24, 0.34, 0.62, 0.98]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "6d5u6FHvz7Q",
        "candidates": [
            "[0.24, 0.34, 0.62, 0.98]",
            "[0.03, 0.60, 0.50, 1.00]",
            "[0.53, 0.23, 0.59, 0.81]",
            "[0.07, 0.31, 0.47, 0.91]"
        ],
        "start": 0.0,
        "end": 285.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1202.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "carry/hold (an object) -> talk to (e.g., self, a person, a group)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "6d5u6FHvz7Q",
        "candidates": [
            "close (e.g., a door, a box) -> carry/hold (an object)",
            "drive (e.g., a car, a truck) -> talk to (e.g., self, a person, a group)",
            "carry/hold (an object) -> talk to (e.g., self, a person, a group)",
            "dress/put on clothing -> talk to (e.g., self, a person, a group)"
        ],
        "start": 0.0,
        "end": 307.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1227.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "carry/hold (an object) -> talk to (e.g., self, a person, a group)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "6d5u6FHvz7Q",
        "candidates": [
            "open (e.g., a window, a car door) -> carry/hold (an object)",
            "talk to (e.g., self, a person, a group) -> lie/sleep",
            "turn (e.g., a screwdriver) -> talk to (e.g., self, a person, a group)",
            "carry/hold (an object) -> talk to (e.g., self, a person, a group)"
        ],
        "start": 0.0,
        "end": 332.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1248.0,
        "question": "Is the person currently in the [0.06, 0.06, 0.91, 0.99] location in the current frame performing the eat?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "6d5u6FHvz7Q",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 353.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1265.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "carry/hold (an object) -> talk to (e.g., self, a person, a group) -> eat",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "6d5u6FHvz7Q",
        "candidates": [
            "carry/hold (an object) -> talk to (e.g., self, a person, a group) -> eat",
            "eat -> carry/hold (an object) -> drink",
            "read -> talk to (e.g., self, a person, a group) -> eat",
            "carry/hold (an object) -> eat -> press"
        ],
        "start": 0.0,
        "end": 370.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1271.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "carry/hold (an object) -> eat",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "6d5u6FHvz7Q",
        "candidates": [
            "shoot -> carry/hold (an object)",
            "eat -> hand wave",
            "eat -> throw",
            "carry/hold (an object) -> eat"
        ],
        "start": 0.0,
        "end": 376.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1415.0,
        "question": "What action is the person at the location [0.08, 0.14, 0.53, 1.00] in the image performing?",
        "answer": "sit, watch (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "6d5u6FHvz7Q",
        "candidates": [
            "crouch/kneel, watch (a person)",
            "sit, listen to (a person), watch (a person)",
            "sit, watch (a person)",
            "sit, carry/hold (an object), listen to (a person)"
        ],
        "start": 0.0,
        "end": 520.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1430.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.45, 0.06, 0.94, 0.98]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "6d5u6FHvz7Q",
        "candidates": [
            "[0.45, 0.06, 0.94, 0.98]",
            "[0.57, 0.00, 0.97, 0.72]",
            "[0.53, 0.00, 0.66, 0.80]",
            "[0.10, 0.12, 0.50, 0.88]"
        ],
        "start": 0.0,
        "end": 535.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1566.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.13, 0.21, 0.51, 0.82]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "6d5u6FHvz7Q",
        "candidates": [
            "[0.49, 0.12, 0.85, 0.93]",
            "[0.13, 0.21, 0.51, 0.82]",
            "[0.23, 0.42, 0.36, 0.93]",
            "[0.34, 0.41, 0.77, 1.00]"
        ],
        "start": 0.0,
        "end": 671.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1604.0,
        "question": "What action is the person at the location [0.13, 0.21, 0.52, 0.81] in the image performing?",
        "answer": "sit, listen to (a person), talk to (e.g., self, a person, a group), watch (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "6d5u6FHvz7Q",
        "candidates": [
            "sit, listen to (a person), talk to (e.g., self, a person, a group), watch (a person)",
            "sit, watch (a person)",
            "sit, listen to (a person)",
            "sit, talk to (e.g., self, a person, a group), watch (a person)"
        ],
        "start": 0.0,
        "end": 709.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1677.0,
        "question": "Where is the person currently performing the talk to (e.g., self, a person, a group) located in the picture?",
        "answer": "[0.26, 0.08, 0.99, 0.99]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "6d5u6FHvz7Q",
        "candidates": [
            "[0.05, 0.08, 0.87, 1.00]",
            "[0.00, 0.00, 1.00, 0.75]",
            "[0.54, 0.33, 1.00, 1.00]",
            "[0.26, 0.08, 0.99, 0.99]"
        ],
        "start": 0.0,
        "end": 782.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1710.0,
        "question": "Are there still 1 people in the current frame now?",
        "answer": "No",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "6d5u6FHvz7Q",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 815.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1751.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.44, 0.17, 0.96, 0.98]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "6d5u6FHvz7Q",
        "candidates": [
            "[0.38, 0.17, 0.68, 0.82]",
            "[0.67, 0.10, 0.81, 0.69]",
            "[0.44, 0.17, 0.96, 0.98]",
            "[0.24, 0.35, 0.78, 0.98]"
        ],
        "start": 0.0,
        "end": 856.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 916.0,
        "question": "Where was the person currently performing the carry/hold (an object) in the scene 8 seconds ago?",
        "answer": "[0.81, 0.33, 0.96, 0.96]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "7T5G0CmwTPo",
        "candidates": [
            "[0.81, 0.33, 0.96, 0.96]",
            "[0.62, 0.59, 0.82, 1.00]",
            "[1.00, 0.51, 1.00, 1.00]",
            "[0.02, 0.06, 0.70, 0.99]"
        ],
        "start": 0.0,
        "end": 21.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 927.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.41, 0.29, 0.53, 0.90] location?",
        "answer": "talk to (e.g., self, a person, a group) [0.39, 0.31, 0.56, 0.89] -> carry/hold (an object) [0.41, 0.29, 0.53, 0.90] -> touch (an object) [0.41, 0.29, 0.53, 0.90]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "7T5G0CmwTPo",
        "candidates": [
            "talk to (e.g., self, a person, a group) [0.39, 0.31, 0.56, 0.89] -> carry/hold (an object) [0.41, 0.29, 0.53, 0.90] -> touch (an object) [0.41, 0.29, 0.53, 0.90]",
            "hand wave [0.37, 0.14, 0.58, 0.93] -> carry/hold (an object) [0.30, 0.37, 0.71, 0.84] -> touch (an object) [0.55, 0.17, 0.50, 0.99]",
            "talk to (e.g., self, a person, a group) [0.46, 0.17, 0.45, 0.91] -> touch (an object) [0.35, 0.16, 0.55, 0.94] -> enter [0.31, 0.37, 0.69, 0.83]",
            "paint [0.52, 0.42, 0.70, 1.00] -> touch (an object) [0.24, 0.40, 0.58, 0.84] -> carry/hold (an object) [0.31, 0.22, 0.69, 0.76]"
        ],
        "start": 0.0,
        "end": 32.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1041.0,
        "question": "What action is the person currently in the [0.36, 0.35, 0.50, 0.70] location likely to do next?",
        "answer": "ride (e.g., a bike, a car, a horse)",
        "sub_answer_type": "FuturePrediction-1",
        "answer_type": "FuturePrediction",
        "video": "7T5G0CmwTPo",
        "candidates": [
            "walk and carry/hold (an object)",
            "shoot",
            "enter",
            "ride (e.g., a bike, a car, a horse)"
        ],
        "start": 0.0,
        "end": 146.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1042.0,
        "question": "Where is the person currently performing the ride (e.g., a bike, a car, a horse) located in the picture?",
        "answer": "[0.36, 0.28, 0.56, 0.68]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "7T5G0CmwTPo",
        "candidates": [
            "[0.36, 0.28, 0.56, 0.68]",
            "[0.33, 0.25, 0.28, 0.54]",
            "[0.07, 0.37, 0.71, 0.95]",
            "[0.43, 0.19, 0.85, 0.98]"
        ],
        "start": 0.0,
        "end": 147.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1099.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.53, 0.34, 0.70, 0.99] location?",
        "answer": "walk [0.53, 0.34, 0.70, 0.99] -> carry/hold (an object) [0.53, 0.34, 0.70, 0.99] -> talk to (e.g., self, a person, a group) [0.53, 0.34, 0.70, 0.99]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "7T5G0CmwTPo",
        "candidates": [
            "fishing [0.67, 0.30, 0.71, 1.00] -> carry/hold (an object) [0.68, 0.21, 0.75, 1.00] -> talk to (e.g., self, a person, a group) [0.34, 0.34, 0.68, 0.89]",
            "carry/hold (an object) [0.56, 0.32, 0.69, 1.00] -> talk to (e.g., self, a person, a group) [0.68, 0.39, 0.88, 0.91] -> swim [0.46, 0.20, 0.89, 0.85]",
            "walk [0.53, 0.34, 0.70, 0.99] -> carry/hold (an object) [0.53, 0.34, 0.70, 0.99] -> talk to (e.g., self, a person, a group) [0.53, 0.34, 0.70, 0.99]",
            "ride (e.g., a bike, a car, a horse) [0.55, 0.23, 0.71, 1.00] -> talk to (e.g., self, a person, a group) [0.72, 0.27, 0.56, 0.90] -> carry/hold (an object) [0.35, 0.27, 0.52, 1.00]"
        ],
        "start": 0.0,
        "end": 204.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1122.0,
        "question": "What action is the person at the location [0.02, 0.52, 0.50, 0.99] in the image performing?",
        "answer": "stand, carry/hold (an object)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "7T5G0CmwTPo",
        "candidates": [
            "sit, listen to (a person), watch (a person)",
            "stand, carry/hold (an object)",
            "stand, talk to (e.g., self, a person, a group), watch (a person)",
            "stand, carry/hold (an object), listen to (a person)"
        ],
        "start": 0.0,
        "end": 227.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1133.0,
        "question": "Where was the person currently performing the carry/hold (an object) in the scene 8 seconds ago?",
        "answer": "[0.31, 0.20, 0.66, 0.99]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "7T5G0CmwTPo",
        "candidates": [
            "[0.31, 0.20, 0.66, 0.99]",
            "[0.48, 0.00, 0.79, 1.00]",
            "[0.24, 0.01, 0.52, 0.84]",
            "[0.07, 0.23, 0.48, 0.98]"
        ],
        "start": 0.0,
        "end": 238.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1184.0,
        "question": "Is the person currently in the [0.01, 0.10, 0.39, 1.00] location in the current frame performing the carry/hold (an object)?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "7T5G0CmwTPo",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 289.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1218.0,
        "question": "Are there still 2 people in the current frame now?",
        "answer": "No",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "7T5G0CmwTPo",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 323.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1252.0,
        "question": "Where was the person currently performing the touch (an object) in the scene 8 seconds ago?",
        "answer": "[0.16, 0.17, 0.37, 0.92]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "7T5G0CmwTPo",
        "candidates": [
            "[0.11, 0.44, 0.26, 0.94]",
            "[0.44, 0.00, 0.54, 1.00]",
            "[0.16, 0.17, 0.37, 0.92]",
            "[0.55, 0.07, 0.98, 0.97]"
        ],
        "start": 0.0,
        "end": 357.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1260.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "touch (an object) -> carry/hold (an object)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "7T5G0CmwTPo",
        "candidates": [
            "sail boat -> carry/hold (an object)",
            "take (an object) from (a person) -> carry/hold (an object)",
            "touch (an object) -> carry/hold (an object)",
            "carry/hold (an object) -> answer phone"
        ],
        "start": 0.0,
        "end": 365.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1281.0,
        "question": "What action is the person at the location [0.08, 0.28, 0.32, 0.99] in the image performing?",
        "answer": "stand, carry/hold (an object), listen to (a person), watch (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "7T5G0CmwTPo",
        "candidates": [
            "stand, carry/hold (an object), pull (an object)",
            "stand, talk to (e.g., self, a person, a group), watch (a person)",
            "stand, carry/hold (an object), listen to (a person), watch (a person)",
            "stand, listen to (a person), watch (a person)"
        ],
        "start": 0.0,
        "end": 386.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1387.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "walk -> carry/hold (an object) -> touch (an object)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "7T5G0CmwTPo",
        "candidates": [
            "push (an object) -> carry/hold (an object) -> walk",
            "carry/hold (an object) -> martial art -> walk",
            "carry/hold (an object) -> dress/put on clothing -> walk",
            "walk -> carry/hold (an object) -> touch (an object)"
        ],
        "start": 0.0,
        "end": 492.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1442.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.34, 0.16, 0.75, 0.85] location?",
        "answer": "crouch/kneel [0.34, 0.15, 0.74, 0.86] -> carry/hold (an object) [0.34, 0.16, 0.75, 0.85] -> cut [0.34, 0.16, 0.75, 0.85]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "7T5G0CmwTPo",
        "candidates": [
            "crouch/kneel [0.34, 0.15, 0.74, 0.86] -> carry/hold (an object) [0.34, 0.16, 0.75, 0.85] -> cut [0.34, 0.16, 0.75, 0.85]",
            "cut [0.43, 0.26, 0.94, 1.00] -> dress/put on clothing [0.27, 0.07, 0.60, 0.83] -> carry/hold (an object) [0.43, 0.07, 0.87, 0.82]",
            "crouch/kneel [0.30, 0.31, 0.81, 0.95] -> ride (e.g., a bike, a car, a horse) [0.31, 0.14, 0.91, 1.00] -> carry/hold (an object) [0.17, 0.14, 0.63, 0.76]",
            "carry/hold (an object) [0.31, 0.17, 0.79, 0.76] -> text on/look at a cellphone [0.23, 0.00, 0.58, 0.72] -> cut [0.29, 0.28, 0.60, 0.79]"
        ],
        "start": 0.0,
        "end": 547.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1478.0,
        "question": "Is the person currently in the [0.50, 0.24, 0.81, 0.99] location in the current frame performing the carry/hold (an object)?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "7T5G0CmwTPo",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 583.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1535.0,
        "question": "Where was the person currently performing the touch (an object) in the scene 8 seconds ago?",
        "answer": "[0.34, 0.60, 0.48, 0.86]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "7T5G0CmwTPo",
        "candidates": [
            "[0.09, 0.28, 0.42, 0.99]",
            "[0.34, 0.60, 0.48, 0.86]",
            "[0.62, 0.52, 0.57, 0.92]",
            "[0.13, 0.85, 0.70, 1.00]"
        ],
        "start": 0.0,
        "end": 640.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1540.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "carry/hold (an object) -> talk to (e.g., self, a person, a group)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "7T5G0CmwTPo",
        "candidates": [
            "catch (an object) -> carry/hold (an object)",
            "talk to (e.g., self, a person, a group) -> hand wave",
            "carry/hold (an object) -> talk to (e.g., self, a person, a group)",
            "talk to (e.g., self, a person, a group) -> kick (a person)"
        ],
        "start": 0.0,
        "end": 645.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1551.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.27, 0.19, 0.62, 0.87] location?",
        "answer": "carry/hold (an object) [0.27, 0.19, 0.62, 0.87] -> crouch/kneel [0.27, 0.19, 0.62, 0.87] -> talk to (e.g., self, a person, a group) [0.27, 0.19, 0.62, 0.87]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "7T5G0CmwTPo",
        "candidates": [
            "talk to (e.g., self, a person, a group) [0.32, 0.03, 0.54, 1.00] -> carry/hold (an object) [0.28, 0.01, 0.77, 0.79] -> write [0.29, 0.39, 0.81, 0.70]",
            "carry/hold (an object) [0.27, 0.19, 0.62, 0.87] -> crouch/kneel [0.27, 0.19, 0.62, 0.87] -> talk to (e.g., self, a person, a group) [0.27, 0.19, 0.62, 0.87]",
            "crouch/kneel [0.09, 0.05, 0.75, 0.69] -> carry/hold (an object) [0.37, 0.21, 0.56, 0.88] -> touch (an object) [0.10, 0.15, 0.67, 0.82]",
            "crouch/kneel [0.21, 0.16, 0.48, 0.71] -> paint [0.11, 0.34, 0.47, 0.73] -> carry/hold (an object) [0.18, 0.35, 0.49, 0.83]"
        ],
        "start": 0.0,
        "end": 656.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1553.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "carry/hold (an object) -> talk to (e.g., self, a person, a group) -> crouch/kneel -> touch (an object)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "7T5G0CmwTPo",
        "candidates": [
            "carry/hold (an object) -> paint -> touch (an object) -> crouch/kneel",
            "touch (an object) -> crouch/kneel -> read -> carry/hold (an object)",
            "carry/hold (an object) -> talk to (e.g., self, a person, a group) -> crouch/kneel -> touch (an object)",
            "crouch/kneel -> talk to (e.g., self, a person, a group) -> fishing -> touch (an object)"
        ],
        "start": 0.0,
        "end": 658.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1576.0,
        "question": "Where is the person currently performing the carry/hold (an object) located in the picture?",
        "answer": "[0.26, 0.21, 0.61, 0.90]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "7T5G0CmwTPo",
        "candidates": [
            "[0.54, 0.30, 0.94, 1.00]",
            "[0.26, 0.21, 0.61, 0.90]",
            "[0.00, 0.00, 0.54, 1.00]",
            "[0.38, 0.26, 0.82, 0.89]"
        ],
        "start": 0.0,
        "end": 681.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1576.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "carry/hold (an object) -> crouch/kneel -> touch (an object) -> talk to (e.g., self, a person, a group)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "7T5G0CmwTPo",
        "candidates": [
            "text on/look at a cellphone -> touch (an object) -> carry/hold (an object) -> talk to (e.g., self, a person, a group)",
            "touch (an object) -> crouch/kneel -> talk to (e.g., self, a person, a group) -> watch (e.g., TV)",
            "touch (an object) -> swim -> crouch/kneel -> carry/hold (an object)",
            "carry/hold (an object) -> crouch/kneel -> touch (an object) -> talk to (e.g., self, a person, a group)"
        ],
        "start": 0.0,
        "end": 681.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1639.0,
        "question": "Where is the person currently performing the carry/hold (an object) located in the picture?",
        "answer": "[0.23, 0.12, 0.73, 0.98]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "7T5G0CmwTPo",
        "candidates": [
            "[0.06, 0.04, 0.79, 0.71]",
            "[0.23, 0.12, 0.73, 0.98]",
            "[0.02, 0.29, 0.65, 0.99]",
            "[0.32, 0.00, 0.95, 0.99]"
        ],
        "start": 0.0,
        "end": 744.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1662.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.56, 0.19, 0.86, 0.98] location?",
        "answer": "carry/hold (an object) [0.56, 0.19, 0.86, 0.98] -> give/serve (an object) to (a person) [0.56, 0.19, 0.86, 0.98] -> talk to (e.g., self, a person, a group) [0.56, 0.19, 0.86, 0.98]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "7T5G0CmwTPo",
        "candidates": [
            "talk to (e.g., self, a person, a group) [0.75, 0.34, 0.69, 0.96] -> hand wave [0.60, 0.36, 0.95, 0.84] -> carry/hold (an object) [0.63, 0.21, 1.00, 0.79]",
            "talk to (e.g., self, a person, a group) [0.62, 0.14, 1.00, 0.82] -> give/serve (an object) to (a person) [0.36, 0.12, 1.00, 1.00] -> hand clap [0.69, 0.03, 0.66, 0.83]",
            "carry/hold (an object) [0.56, 0.19, 0.86, 0.98] -> give/serve (an object) to (a person) [0.56, 0.19, 0.86, 0.98] -> talk to (e.g., self, a person, a group) [0.56, 0.19, 0.86, 0.98]",
            "carry/hold (an object) [0.59, 0.29, 0.92, 1.00] -> give/serve (an object) to (a person) [0.57, 0.22, 0.97, 0.80] -> give/serve (an object) to (a person) [0.54, 0.37, 0.73, 1.00]"
        ],
        "start": 0.0,
        "end": 767.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1688.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.53, 0.07, 0.98, 0.96]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "7T5G0CmwTPo",
        "candidates": [
            "[0.53, 0.07, 0.98, 0.96]",
            "[0.51, 0.00, 0.95, 0.69]",
            "[0.81, 0.15, 1.00, 0.99]",
            "[0.39, 0.25, 0.55, 0.72]"
        ],
        "start": 0.0,
        "end": 793.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 951.0,
        "question": "Is the person currently in the [0.01, 0.13, 0.95, 0.98] location in the current frame performing the carry/hold (an object)?",
        "answer": "No",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "914yZXz-iRs",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 56.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 954.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "carry/hold (an object) -> read",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "914yZXz-iRs",
        "candidates": [
            "read -> throw",
            "take a photo -> read",
            "carry/hold (an object) -> read",
            "crawl -> carry/hold (an object)"
        ],
        "start": 0.0,
        "end": 59.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 977.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "read -> carry/hold (an object) -> talk to (e.g., self, a person, a group)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "914yZXz-iRs",
        "candidates": [
            "read -> carry/hold (an object) -> talk to (e.g., self, a person, a group)",
            "open (e.g., a window, a car door) -> read -> talk to (e.g., self, a person, a group)",
            "grab (a person) -> read -> talk to (e.g., self, a person, a group)",
            "carry/hold (an object) -> read -> give/serve (an object) to (a person)"
        ],
        "start": 0.0,
        "end": 82.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1005.0,
        "question": "Where was the person currently performing the carry/hold (an object) in the scene 8 seconds ago?",
        "answer": "[0.31, 0.12, 0.82, 0.96]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "914yZXz-iRs",
        "candidates": [
            "[0.50, 0.00, 0.89, 0.86]",
            "[0.00, 0.09, 0.41, 1.00]",
            "[0.43, 0.15, 0.54, 0.68]",
            "[0.31, 0.12, 0.82, 0.96]"
        ],
        "start": 0.0,
        "end": 110.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1007.0,
        "question": "What action is the person at the location [0.01, 0.63, 0.36, 0.99] in the image performing?",
        "answer": "sit, listen to (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "914yZXz-iRs",
        "candidates": [
            "sit, listen to (a person)",
            "stand, carry/hold (an object), talk to (e.g., self, a person, a group)",
            "walk, listen to (a person), watch (a person)",
            "sit, watch (a person)"
        ],
        "start": 0.0,
        "end": 112.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1031.0,
        "question": "Where was the person currently performing the sing to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.45, 0.10, 0.91, 0.97]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "914yZXz-iRs",
        "candidates": [
            "[0.65, 0.21, 1.00, 1.00]",
            "[0.61, 0.00, 0.61, 0.74]",
            "[0.45, 0.10, 0.91, 0.97]",
            "[0.00, 0.06, 0.51, 1.00]"
        ],
        "start": 0.0,
        "end": 136.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1113.0,
        "question": "Where is the person currently performing the walk located in the picture?",
        "answer": "[0.55, 0.14, 0.87, 0.85]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "914yZXz-iRs",
        "candidates": [
            "[0.47, 0.34, 1.00, 0.99]",
            "[0.25, 0.13, 0.90, 1.00]",
            "[0.80, 0.09, 0.89, 0.68]",
            "[0.55, 0.14, 0.87, 0.85]"
        ],
        "start": 0.0,
        "end": 218.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1162.0,
        "question": "Are there still 1 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "914yZXz-iRs",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 267.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1172.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.01, 0.09, 0.59, 0.99] location?",
        "answer": "bend/bow (at the waist) [0.01, 0.09, 0.59, 0.99] -> grab (a person) [0.01, 0.09, 0.59, 0.99] -> talk to (e.g., self, a person, a group) [0.01, 0.09, 0.59, 0.99]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "914yZXz-iRs",
        "candidates": [
            "bend/bow (at the waist) [0.01, 0.09, 0.59, 0.99] -> grab (a person) [0.01, 0.09, 0.59, 0.99] -> talk to (e.g., self, a person, a group) [0.01, 0.09, 0.59, 0.99]",
            "lift/pick up [0.00, 0.05, 0.76, 1.00] -> bend/bow (at the waist) [0.00, 0.00, 0.59, 1.00] -> talk to (e.g., self, a person, a group) [0.16, 0.00, 0.45, 0.92]",
            "bend/bow (at the waist) [0.00, 0.03, 0.45, 1.00] -> grab (a person) [0.16, 0.07, 0.42, 1.00] -> stir [0.07, 0.02, 0.69, 1.00]",
            "bend/bow (at the waist) [0.00, 0.13, 0.70, 0.90] -> talk to (e.g., self, a person, a group) [0.17, 0.28, 0.69, 1.00] -> take a photo [0.00, 0.19, 0.73, 0.97]"
        ],
        "start": 0.0,
        "end": 277.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1220.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.20, 0.07, 0.50, 0.73] location?",
        "answer": "talk to (e.g., self, a person, a group) [0.00, 0.06, 0.51, 1.00] -> bend/bow (at the waist) [0.20, 0.07, 0.50, 0.73] -> carry/hold (an object) [0.20, 0.07, 0.50, 0.73]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "914yZXz-iRs",
        "candidates": [
            "talk to (e.g., self, a person, a group) [0.00, 0.06, 0.42, 1.00] -> carry/hold (an object) [0.14, 0.03, 0.37, 0.74] -> carry/hold (an object) [0.33, 0.09, 0.49, 0.63]",
            "talk to (e.g., self, a person, a group) [0.00, 0.06, 0.51, 1.00] -> bend/bow (at the waist) [0.20, 0.07, 0.50, 0.73] -> carry/hold (an object) [0.20, 0.07, 0.50, 0.73]",
            "talk to (e.g., self, a person, a group) [0.00, 0.00, 0.51, 0.90] -> bend/bow (at the waist) [0.11, 0.00, 0.59, 0.84] -> touch (an object) [0.06, 0.22, 0.39, 0.74]",
            "bend/bow (at the waist) [0.04, 0.10, 0.65, 0.88] -> talk to (e.g., self, a person, a group) [0.13, 0.25, 0.56, 1.00] -> take (an object) from (a person) [0.32, 0.00, 0.46, 0.79]"
        ],
        "start": 0.0,
        "end": 325.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1224.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.00, 0.06, 0.53, 1.00] location?",
        "answer": "bend/bow (at the waist) [0.00, 0.06, 0.53, 1.00] -> carry/hold (an object) [0.00, 0.06, 0.53, 1.00] -> talk to (e.g., self, a person, a group) [0.00, 0.06, 0.53, 1.00]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "914yZXz-iRs",
        "candidates": [
            "bend/bow (at the waist) [0.14, 0.00, 0.36, 1.00] -> paint [0.00, 0.00, 0.53, 1.00] -> talk to (e.g., self, a person, a group) [0.18, 0.17, 0.47, 0.90]",
            "bend/bow (at the waist) [0.00, 0.06, 0.53, 1.00] -> carry/hold (an object) [0.00, 0.06, 0.53, 1.00] -> talk to (e.g., self, a person, a group) [0.00, 0.06, 0.53, 1.00]",
            "enter [0.00, 0.00, 0.52, 0.85] -> bend/bow (at the waist) [0.06, 0.22, 0.56, 0.84] -> carry/hold (an object) [0.00, 0.09, 0.54, 1.00]",
            "carry/hold (an object) [0.08, 0.00, 0.47, 1.00] -> bend/bow (at the waist) [0.13, 0.25, 0.60, 1.00] -> bend/bow (at the waist) [0.19, 0.04, 0.66, 1.00]"
        ],
        "start": 0.0,
        "end": 329.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1226.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.00, 0.06, 0.54, 1.00] location?",
        "answer": "talk to (e.g., self, a person, a group) [0.00, 0.06, 0.54, 0.99] -> bend/bow (at the waist) [0.00, 0.06, 0.54, 1.00] -> carry/hold (an object) [0.00, 0.06, 0.54, 1.00] -> give/serve (an object) to (a person) [0.00, 0.06, 0.54, 1.00]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "914yZXz-iRs",
        "candidates": [
            "bend/bow (at the waist) [0.00, 0.07, 0.41, 0.83] -> give/serve (an object) to (a person) [0.00, 0.01, 0.42, 1.00] -> carry/hold (an object) [0.17, 0.00, 0.46, 0.83] -> enter [0.14, 0.01, 0.56, 0.95]",
            "kick (an object) [0.00, 0.24, 0.64, 0.86] -> bend/bow (at the waist) [0.08, 0.22, 0.56, 0.88] -> give/serve (an object) to (a person) [0.04, 0.13, 0.50, 1.00] -> carry/hold (an object) [0.00, 0.08, 0.62, 1.00]",
            "talk to (e.g., self, a person, a group) [0.16, 0.20, 0.64, 1.00] -> open (e.g., a window, a car door) [0.00, 0.00, 0.35, 1.00] -> carry/hold (an object) [0.00, 0.08, 0.51, 1.00] -> give/serve (an object) to (a person) [0.10, 0.03, 0.43, 1.00]",
            "talk to (e.g., self, a person, a group) [0.00, 0.06, 0.54, 0.99] -> bend/bow (at the waist) [0.00, 0.06, 0.54, 1.00] -> carry/hold (an object) [0.00, 0.06, 0.54, 1.00] -> give/serve (an object) to (a person) [0.00, 0.06, 0.54, 1.00]"
        ],
        "start": 0.0,
        "end": 331.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1298.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "carry/hold (an object) -> talk to (e.g., self, a person, a group)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "914yZXz-iRs",
        "candidates": [
            "carry/hold (an object) -> talk to (e.g., self, a person, a group)",
            "carry/hold (an object) -> hand wave",
            "talk to (e.g., self, a person, a group) -> crouch/kneel",
            "talk to (e.g., self, a person, a group) -> exit"
        ],
        "start": 0.0,
        "end": 403.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1305.0,
        "question": "What action is the person at the location [0.20, 0.28, 0.37, 0.92] in the image performing?",
        "answer": "stand, carry/hold (an object), watch (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "914yZXz-iRs",
        "candidates": [
            "sit, listen to (a person)",
            "walk, listen to (a person)",
            "sit, watch (a person)",
            "stand, carry/hold (an object), watch (a person)"
        ],
        "start": 0.0,
        "end": 410.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1380.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "carry/hold (an object) -> talk to (e.g., self, a person, a group)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "914yZXz-iRs",
        "candidates": [
            "carry/hold (an object) -> talk to (e.g., self, a person, a group)",
            "hand wave -> carry/hold (an object)",
            "carry/hold (an object) -> text on/look at a cellphone",
            "kiss (a person) -> carry/hold (an object)"
        ],
        "start": 0.0,
        "end": 485.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1440.0,
        "question": "Are there still 2 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "914yZXz-iRs",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 545.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1504.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.25, 0.23, 0.73, 0.98] location?",
        "answer": "walk [0.25, 0.23, 0.73, 0.98] -> carry/hold (an object) [0.25, 0.23, 0.73, 0.98] -> talk to (e.g., self, a person, a group) [0.25, 0.23, 0.73, 0.98]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "914yZXz-iRs",
        "candidates": [
            "talk to (e.g., self, a person, a group) [0.41, 0.41, 0.86, 0.98] -> carry/hold (an object) [0.24, 0.12, 0.83, 0.79] -> throw [0.13, 0.12, 0.90, 1.00]",
            "talk to (e.g., self, a person, a group) [0.18, 0.25, 0.68, 0.89] -> carry/hold (an object) [0.41, 0.33, 0.86, 0.97] -> fishing [0.10, 0.10, 0.71, 1.00]",
            "walk [0.25, 0.23, 0.73, 0.98] -> carry/hold (an object) [0.25, 0.23, 0.73, 0.98] -> talk to (e.g., self, a person, a group) [0.25, 0.23, 0.73, 0.98]",
            "shoot [0.11, 0.14, 0.57, 0.89] -> talk to (e.g., self, a person, a group) [0.12, 0.33, 0.54, 1.00] -> carry/hold (an object) [0.14, 0.06, 0.53, 0.91]"
        ],
        "start": 0.0,
        "end": 609.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1508.0,
        "question": "What action is the person at the location [0.21, 0.15, 0.66, 0.99] in the image performing?",
        "answer": "stand, carry/hold (an object), talk to (e.g., self, a person, a group), watch (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "914yZXz-iRs",
        "candidates": [
            "stand, carry/hold (an object), talk to (e.g., self, a person, a group), watch (a person)",
            "carry/hold (an object), lie/sleep",
            "sit, listen to (a person), watch (a person)",
            "sit, listen to (a person)"
        ],
        "start": 0.0,
        "end": 613.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1545.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.50, 0.07, 1.00, 0.98]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "914yZXz-iRs",
        "candidates": [
            "[0.23, 0.00, 1.00, 0.77]",
            "[0.50, 0.07, 1.00, 0.98]",
            "[0.75, 0.00, 0.98, 0.73]",
            "[0.34, 0.13, 0.84, 0.98]"
        ],
        "start": 0.0,
        "end": 650.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1594.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.64, 0.17, 1.00, 0.97]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "914yZXz-iRs",
        "candidates": [
            "[0.33, 0.09, 0.92, 0.97]",
            "[0.93, 0.44, 1.00, 0.93]",
            "[0.92, 0.05, 0.94, 0.82]",
            "[0.64, 0.17, 1.00, 0.97]"
        ],
        "start": 0.0,
        "end": 699.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1623.0,
        "question": "Is the person currently in the [0.51, 0.32, 0.98, 0.98] location in the current frame performing the carry/hold (an object)?",
        "answer": "No",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "914yZXz-iRs",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 728.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1651.0,
        "question": "What action is the person at the location [0.00, 0.47, 0.67, 1.00] in the image performing?",
        "answer": "carry/hold (an object), talk to (e.g., self, a person, a group), lie/sleep",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "914yZXz-iRs",
        "candidates": [
            "carry/hold (an object), talk to (e.g., self, a person, a group), lie/sleep",
            "stand, watch (a person)",
            "stand, listen to (a person), watch (a person)",
            "sit, listen to (a person)"
        ],
        "start": 0.0,
        "end": 756.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1666.0,
        "question": "What action is the person currently in the [0.18, 0.23, 0.92, 0.99] location likely to do next?",
        "answer": "carry/hold (an object) and lie/sleep",
        "sub_answer_type": "FuturePrediction-1",
        "answer_type": "FuturePrediction",
        "video": "914yZXz-iRs",
        "candidates": [
            "talk to (e.g., self, a person, a group)",
            "clink glass",
            "extract",
            "carry/hold (an object) and lie/sleep"
        ],
        "start": 0.0,
        "end": 771.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1683.0,
        "question": "Are there still 2 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "914yZXz-iRs",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 788.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1739.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.49, 0.17, 0.89, 0.98]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "914yZXz-iRs",
        "candidates": [
            "[0.49, 0.17, 0.89, 0.98]",
            "[0.01, 0.21, 0.43, 0.99]",
            "[0.40, 0.44, 0.81, 1.00]",
            "[0.33, 0.08, 1.00, 0.74]"
        ],
        "start": 0.0,
        "end": 844.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1779.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "walk -> talk to (e.g., self, a person, a group)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "914yZXz-iRs",
        "candidates": [
            "walk -> hand clap",
            "walk -> put down",
            "walk -> talk to (e.g., self, a person, a group)",
            "walk -> text on/look at a cellphone"
        ],
        "start": 0.0,
        "end": 884.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 920.0,
        "question": "How many people in the current frame are performing the action:  dance?",
        "answer": "3",
        "sub_answer_type": "SpatialPerception-2",
        "answer_type": "SpatialPerception",
        "video": "9F2voT6QWvQ",
        "candidates": [
            "3",
            "2",
            "7",
            "4"
        ],
        "start": 0.0,
        "end": 25.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 927.0,
        "question": "Are there still 5 people in the current frame now?",
        "answer": "No",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "9F2voT6QWvQ",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 32.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1009.0,
        "question": "How many people in the current frame are performing the action:  dance?",
        "answer": "6",
        "sub_answer_type": "SpatialPerception-2",
        "answer_type": "SpatialPerception",
        "video": "9F2voT6QWvQ",
        "candidates": [
            "6",
            "3",
            "4",
            "2"
        ],
        "start": 0.0,
        "end": 114.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1023.0,
        "question": "Is the person currently in the [0.26, 0.28, 0.45, 0.87] location in the current frame performing the dance?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "9F2voT6QWvQ",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 128.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1034.0,
        "question": "What was the minimum number of people in the scene over the past 15 seconds?",
        "answer": "4",
        "sub_answer_type": "PastMemory-3",
        "answer_type": "PastMemory",
        "video": "9F2voT6QWvQ",
        "candidates": [
            "3",
            "4",
            "2",
            "1"
        ],
        "start": 0.0,
        "end": 139.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1098.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.46, 0.30, 0.56, 0.85] location?",
        "answer": "talk to (e.g., self, a person, a group) [0.43, 0.32, 0.54, 0.84] -> walk [0.46, 0.30, 0.56, 0.85] -> grab (a person) [0.46, 0.30, 0.56, 0.85]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "9F2voT6QWvQ",
        "candidates": [
            "talk to (e.g., self, a person, a group) [0.43, 0.32, 0.54, 0.84] -> walk [0.46, 0.30, 0.56, 0.85] -> grab (a person) [0.46, 0.30, 0.56, 0.85]",
            "work on a computer [0.54, 0.28, 0.41, 0.95] -> grab (a person) [0.61, 0.11, 0.73, 0.81] -> talk to (e.g., self, a person, a group) [0.33, 0.39, 0.38, 0.84]",
            "press [0.34, 0.46, 0.61, 0.90] -> grab (a person) [0.47, 0.29, 0.75, 1.00] -> talk to (e.g., self, a person, a group) [0.47, 0.41, 0.63, 0.65]",
            "grab (a person) [0.47, 0.46, 0.64, 0.65] -> walk [0.66, 0.32, 0.51, 0.68] -> open (e.g., a window, a car door) [0.48, 0.28, 0.60, 0.86]"
        ],
        "start": 0.0,
        "end": 203.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1101.0,
        "question": "How many people were performing the dance in the scene 180 seconds ago?",
        "answer": "4",
        "sub_answer_type": "PastMemory-5",
        "answer_type": "PastMemory",
        "video": "9F2voT6QWvQ",
        "candidates": [
            "4",
            "6",
            "7",
            "3"
        ],
        "start": 0.0,
        "end": 206.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1103.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.44, 0.31, 0.53, 0.87] location?",
        "answer": "walk [0.44, 0.31, 0.53, 0.87] -> carry/hold (an object) [0.44, 0.31, 0.53, 0.87] -> talk to (e.g., self, a person, a group) [0.44, 0.31, 0.53, 0.87]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "9F2voT6QWvQ",
        "candidates": [
            "carry/hold (an object) [0.47, 0.32, 0.51, 0.87] -> talk to (e.g., self, a person, a group) [0.26, 0.32, 0.69, 0.75] -> kiss (a person) [0.51, 0.34, 0.67, 0.85]",
            "extract [0.51, 0.41, 0.60, 0.68] -> carry/hold (an object) [0.36, 0.43, 0.56, 0.92] -> talk to (e.g., self, a person, a group) [0.61, 0.18, 0.66, 0.89]",
            "walk [0.44, 0.31, 0.53, 0.87] -> carry/hold (an object) [0.44, 0.31, 0.53, 0.87] -> talk to (e.g., self, a person, a group) [0.44, 0.31, 0.53, 0.87]",
            "hand shake [0.52, 0.31, 0.38, 0.69] -> carry/hold (an object) [0.34, 0.50, 0.67, 0.79] -> walk [0.30, 0.15, 0.41, 0.68]"
        ],
        "start": 0.0,
        "end": 208.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1123.0,
        "question": "Is the person currently in the [0.00, 0.26, 0.28, 0.84] location in the current frame performing the eat?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "9F2voT6QWvQ",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 228.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1129.0,
        "question": "Where is the person currently performing the talk to (e.g., self, a person, a group) located in the picture?",
        "answer": "[0.11, 0.09, 0.85, 0.88]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "9F2voT6QWvQ",
        "candidates": [
            "[0.18, 0.31, 0.56, 0.89]",
            "[0.11, 0.09, 0.85, 0.88]",
            "[0.00, 0.08, 0.69, 0.69]",
            "[0.10, 0.00, 0.88, 0.59]"
        ],
        "start": 0.0,
        "end": 234.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1242.0,
        "question": "What location in the frame is the person currently in the [0.35, 0.13, 0.83, 0.92] location likely to move to next?",
        "answer": "[0.01, 0.21, 0.55, 0.89]",
        "sub_answer_type": "FuturePrediction-2",
        "answer_type": "FuturePrediction",
        "video": "9F2voT6QWvQ",
        "candidates": [
            "[0.00, 0.00, 0.63, 0.78]",
            "[0.00, 0.49, 0.69, 1.00]",
            "[0.00, 0.33, 0.17, 0.88]",
            "[0.01, 0.21, 0.55, 0.89]"
        ],
        "start": 0.0,
        "end": 347.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1319.0,
        "question": "How many people were performing the dance in the scene 240 seconds ago?",
        "answer": "7",
        "sub_answer_type": "PastMemory-5",
        "answer_type": "PastMemory",
        "video": "9F2voT6QWvQ",
        "candidates": [
            "7",
            "4",
            "6",
            "3"
        ],
        "start": 0.0,
        "end": 424.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1344.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "fight/hit (a person) -> martial art",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "9F2voT6QWvQ",
        "candidates": [
            "fight/hit (a person) -> hand clap",
            "touch (an object) -> fight/hit (a person)",
            "martial art -> push (an object)",
            "fight/hit (a person) -> martial art"
        ],
        "start": 0.0,
        "end": 449.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1378.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.21, 0.10, 0.91, 0.93] location?",
        "answer": "bend/bow (at the waist) [0.21, 0.10, 0.91, 0.93] -> fight/hit (a person) [0.21, 0.10, 0.91, 0.93] -> talk to (e.g., self, a person, a group) [0.21, 0.10, 0.91, 0.93]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "9F2voT6QWvQ",
        "candidates": [
            "lift (a person) [0.22, 0.24, 1.00, 1.00] -> talk to (e.g., self, a person, a group) [0.05, 0.09, 0.72, 1.00] -> bend/bow (at the waist) [0.11, 0.00, 0.82, 0.88]",
            "talk to (e.g., self, a person, a group) [0.07, 0.06, 0.74, 1.00] -> fight/hit (a person) [0.24, 0.01, 1.00, 0.90] -> kick (a person) [0.34, 0.16, 0.89, 1.00]",
            "watch (e.g., TV) [0.29, 0.09, 0.85, 1.00] -> talk to (e.g., self, a person, a group) [0.36, 0.00, 0.84, 0.82] -> fight/hit (a person) [0.12, 0.00, 0.83, 1.00]",
            "bend/bow (at the waist) [0.21, 0.10, 0.91, 0.93] -> fight/hit (a person) [0.21, 0.10, 0.91, 0.93] -> talk to (e.g., self, a person, a group) [0.21, 0.10, 0.91, 0.93]"
        ],
        "start": 0.0,
        "end": 483.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1379.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "bend/bow (at the waist) -> fight/hit (a person) -> talk to (e.g., self, a person, a group)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "9F2voT6QWvQ",
        "candidates": [
            "bend/bow (at the waist) -> talk to (e.g., self, a person, a group) -> take a photo",
            "talk to (e.g., self, a person, a group) -> bend/bow (at the waist) -> walk",
            "fight/hit (a person) -> eat -> talk to (e.g., self, a person, a group)",
            "bend/bow (at the waist) -> fight/hit (a person) -> talk to (e.g., self, a person, a group)"
        ],
        "start": 0.0,
        "end": 484.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1392.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "bend/bow (at the waist) -> talk to (e.g., self, a person, a group)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "9F2voT6QWvQ",
        "candidates": [
            "take a photo -> bend/bow (at the waist)",
            "chop -> bend/bow (at the waist)",
            "read -> bend/bow (at the waist)",
            "bend/bow (at the waist) -> talk to (e.g., self, a person, a group)"
        ],
        "start": 0.0,
        "end": 497.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1406.0,
        "question": "What action is the person at the location [0.06, 0.42, 0.31, 0.87] in the image performing?",
        "answer": "sit, listen to (a person), watch (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "9F2voT6QWvQ",
        "candidates": [
            "dance, sing to (e.g., self, a person, a group)",
            "stand, talk to (e.g., self, a person, a group)",
            "sit, listen to (a person), watch (a person)",
            "stand, watch (a person)"
        ],
        "start": 0.0,
        "end": 511.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1431.0,
        "question": "How many people were performing the watch (a person) in the scene 180 seconds ago?",
        "answer": "4",
        "sub_answer_type": "PastMemory-5",
        "answer_type": "PastMemory",
        "video": "9F2voT6QWvQ",
        "candidates": [
            "4",
            "7",
            "6",
            "8"
        ],
        "start": 0.0,
        "end": 536.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1525.0,
        "question": "What action is the person currently in the [0.35, 0.14, 0.84, 0.88] location likely to do next?",
        "answer": "answer phone",
        "sub_answer_type": "FuturePrediction-1",
        "answer_type": "FuturePrediction",
        "video": "9F2voT6QWvQ",
        "candidates": [
            "carry/hold (an object)",
            "push (an object)",
            "fishing",
            "answer phone"
        ],
        "start": 0.0,
        "end": 630.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1528.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "text on/look at a cellphone -> answer phone",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "9F2voT6QWvQ",
        "candidates": [
            "cook -> answer phone",
            "text on/look at a cellphone -> take a photo",
            "text on/look at a cellphone -> answer phone",
            "climb (e.g., a mountain) -> text on/look at a cellphone"
        ],
        "start": 0.0,
        "end": 633.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1554.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "carry/hold (an object) -> walk",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "9F2voT6QWvQ",
        "candidates": [
            "carry/hold (an object) -> walk",
            "exit -> walk",
            "lift/pick up -> walk",
            "carry/hold (an object) -> carry/hold (an object)"
        ],
        "start": 0.0,
        "end": 659.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1595.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.61, 0.20, 0.94, 0.89] location?",
        "answer": "bend/bow (at the waist) [0.61, 0.20, 0.94, 0.89] -> touch (an object) [0.61, 0.20, 0.94, 0.89] -> talk to (e.g., self, a person, a group) [0.61, 0.20, 0.94, 0.89]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "9F2voT6QWvQ",
        "candidates": [
            "bend/bow (at the waist) [0.55, 0.27, 0.84, 0.84] -> talk to (e.g., self, a person, a group) [0.55, 0.37, 0.82, 0.81] -> lie/sleep [0.63, 0.37, 0.86, 0.97]",
            "paint [0.77, 0.35, 0.78, 0.78] -> touch (an object) [0.50, 0.33, 1.00, 0.89] -> bend/bow (at the waist) [0.56, 0.02, 1.00, 0.99]",
            "hand wave [0.46, 0.17, 1.00, 0.81] -> bend/bow (at the waist) [0.64, 0.40, 1.00, 0.82] -> talk to (e.g., self, a person, a group) [0.58, 0.04, 1.00, 0.80]",
            "bend/bow (at the waist) [0.61, 0.20, 0.94, 0.89] -> touch (an object) [0.61, 0.20, 0.94, 0.89] -> talk to (e.g., self, a person, a group) [0.61, 0.20, 0.94, 0.89]"
        ],
        "start": 0.0,
        "end": 700.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1600.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.57, 0.17, 0.90, 0.89] location?",
        "answer": "talk to (e.g., self, a person, a group) [0.58, 0.16, 0.90, 0.89] -> bend/bow (at the waist) [0.57, 0.17, 0.90, 0.89] -> touch (an object) [0.57, 0.17, 0.90, 0.89]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "9F2voT6QWvQ",
        "candidates": [
            "talk to (e.g., self, a person, a group) [0.58, 0.16, 0.90, 0.89] -> bend/bow (at the waist) [0.57, 0.17, 0.90, 0.89] -> touch (an object) [0.57, 0.17, 0.90, 0.89]",
            "close (e.g., a door, a box) [0.66, 0.32, 0.95, 0.92] -> touch (an object) [0.66, 0.34, 0.88, 0.84] -> talk to (e.g., self, a person, a group) [0.74, 0.28, 0.95, 0.75]",
            "pull (an object) [0.52, 0.12, 0.88, 0.95] -> talk to (e.g., self, a person, a group) [0.77, 0.09, 0.72, 0.79] -> touch (an object) [0.59, 0.12, 0.98, 1.00]",
            "play musical instrument [0.71, 0.28, 0.92, 1.00] -> bend/bow (at the waist) [0.42, 0.24, 0.84, 1.00] -> talk to (e.g., self, a person, a group) [0.39, 0.24, 0.72, 1.00]"
        ],
        "start": 0.0,
        "end": 705.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1693.0,
        "question": "Are there still 1 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "9F2voT6QWvQ",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 798.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1705.0,
        "question": "Where is the person currently performing the talk to (e.g., self, a person, a group) located in the picture?",
        "answer": "[0.20, 0.17, 0.61, 0.87]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "9F2voT6QWvQ",
        "candidates": [
            "[0.24, 0.46, 0.81, 1.00]",
            "[0.00, 0.35, 0.43, 0.64]",
            "[0.20, 0.17, 0.61, 0.87]",
            "[0.54, 0.41, 0.57, 0.48]"
        ],
        "start": 0.0,
        "end": 810.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1765.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.76, 0.12, 0.90, 0.88]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "9F2voT6QWvQ",
        "candidates": [
            "[0.11, 0.43, 0.37, 0.86]",
            "[0.97, 0.00, 1.00, 1.00]",
            "[0.76, 0.12, 0.90, 0.88]",
            "[0.74, 0.33, 0.73, 0.96]"
        ],
        "start": 0.0,
        "end": 870.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 916.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.01, 0.10, 0.61, 0.98]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "9Y_l9NsnYE0",
        "candidates": [
            "[0.03, 0.31, 0.33, 1.00]",
            "[0.50, 0.07, 0.91, 0.98]",
            "[0.01, 0.10, 0.61, 0.98]",
            "[0.29, 0.30, 0.75, 1.00]"
        ],
        "start": 0.0,
        "end": 21.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 933.0,
        "question": "Where is the person currently performing the talk to (e.g., self, a person, a group) located in the picture?",
        "answer": "[0.05, 0.05, 0.81, 0.98]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "9Y_l9NsnYE0",
        "candidates": [
            "[0.06, 0.00, 1.00, 0.74]",
            "[0.32, 0.19, 0.97, 0.98]",
            "[0.15, 0.33, 0.67, 1.00]",
            "[0.05, 0.05, 0.81, 0.98]"
        ],
        "start": 0.0,
        "end": 38.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1005.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.07, 0.08, 0.80, 0.94] location?",
        "answer": "carry/hold (an object) [0.07, 0.08, 0.80, 0.94] -> read [0.07, 0.08, 0.80, 0.94] -> talk to (e.g., self, a person, a group) [0.07, 0.08, 0.80, 0.94]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "9Y_l9NsnYE0",
        "candidates": [
            "read [0.07, 0.00, 0.80, 1.00] -> work on a computer [0.06, 0.26, 0.69, 0.81] -> carry/hold (an object) [0.02, 0.01, 0.78, 1.00]",
            "carry/hold (an object) [0.07, 0.08, 0.80, 0.94] -> read [0.07, 0.08, 0.80, 0.94] -> talk to (e.g., self, a person, a group) [0.07, 0.08, 0.80, 0.94]",
            "answer phone [0.18, 0.03, 0.61, 0.93] -> read [0.24, 0.27, 0.74, 0.92] -> carry/hold (an object) [0.00, 0.09, 0.86, 1.00]",
            "talk to (e.g., self, a person, a group) [0.26, 0.23, 0.88, 1.00] -> read [0.11, 0.06, 0.68, 0.79] -> cook [0.08, 0.27, 0.84, 0.81]"
        ],
        "start": 0.0,
        "end": 110.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1027.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.26, 0.17, 0.68, 0.98] location?",
        "answer": "walk [0.26, 0.17, 0.68, 0.98] -> carry/hold (an object) [0.26, 0.17, 0.68, 0.98] -> talk to (e.g., self, a person, a group) [0.26, 0.17, 0.68, 0.98]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "9Y_l9NsnYE0",
        "candidates": [
            "talk to (e.g., self, a person, a group) [0.07, 0.09, 0.64, 0.90] -> carry/hold (an object) [0.20, 0.04, 0.55, 1.00] -> chop [0.12, 0.26, 0.74, 1.00]",
            "text on/look at a cellphone [0.41, 0.34, 0.50, 1.00] -> carry/hold (an object) [0.32, 0.35, 0.60, 0.96] -> talk to (e.g., self, a person, a group) [0.25, 0.07, 0.59, 0.94]",
            "talk to (e.g., self, a person, a group) [0.08, 0.07, 0.59, 1.00] -> catch (an object) [0.23, 0.33, 0.55, 0.97] -> carry/hold (an object) [0.21, 0.14, 0.77, 0.79]",
            "walk [0.26, 0.17, 0.68, 0.98] -> carry/hold (an object) [0.26, 0.17, 0.68, 0.98] -> talk to (e.g., self, a person, a group) [0.26, 0.17, 0.68, 0.98]"
        ],
        "start": 0.0,
        "end": 132.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1043.0,
        "question": "Is the person currently in the [0.23, 0.12, 0.73, 0.96] location in the current frame performing the carry/hold (an object)?",
        "answer": "No",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "9Y_l9NsnYE0",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 148.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1092.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.39, 0.21, 0.54, 0.88] location?",
        "answer": "walk [0.39, 0.21, 0.54, 0.88] -> carry/hold (an object) [0.39, 0.21, 0.54, 0.88] -> close (e.g., a door, a box) [0.39, 0.21, 0.54, 0.88]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "9Y_l9NsnYE0",
        "candidates": [
            "close (e.g., a door, a box) [0.56, 0.26, 0.63, 0.89] -> sing to (e.g., self, a person, a group) [0.51, 0.31, 0.72, 0.94] -> walk [0.52, 0.40, 0.72, 0.73]",
            "walk [0.39, 0.21, 0.54, 0.88] -> carry/hold (an object) [0.39, 0.21, 0.54, 0.88] -> close (e.g., a door, a box) [0.39, 0.21, 0.54, 0.88]",
            "walk [0.27, 0.06, 0.48, 0.84] -> carry/hold (an object) [0.41, 0.07, 0.59, 0.87] -> close (e.g., a door, a box) [0.35, 0.16, 0.41, 1.00]",
            "carry/hold (an object) [0.41, 0.23, 0.65, 0.76] -> close (e.g., a door, a box) [0.57, 0.10, 0.54, 1.00] -> grab (a person) [0.24, 0.26, 0.59, 0.76]"
        ],
        "start": 0.0,
        "end": 197.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1099.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.33, 0.12, 0.60, 0.97] location?",
        "answer": "talk to (e.g., self, a person, a group) [0.34, 0.08, 0.71, 0.99] -> carry/hold (an object) [0.33, 0.12, 0.60, 0.97] -> touch (an object) [0.33, 0.12, 0.60, 0.97]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "9Y_l9NsnYE0",
        "candidates": [
            "open (e.g., a window, a car door) [0.49, 0.00, 0.60, 1.00] -> talk to (e.g., self, a person, a group) [0.20, 0.00, 0.80, 0.93] -> touch (an object) [0.23, 0.00, 0.52, 1.00]",
            "talk to (e.g., self, a person, a group) [0.34, 0.08, 0.71, 0.99] -> carry/hold (an object) [0.33, 0.12, 0.60, 0.97] -> touch (an object) [0.33, 0.12, 0.60, 0.97]",
            "touch (an object) [0.15, 0.03, 0.61, 1.00] -> sing to (e.g., self, a person, a group) [0.51, 0.24, 0.65, 0.88] -> carry/hold (an object) [0.26, 0.13, 0.76, 1.00]",
            "touch (an object) [0.40, 0.12, 0.43, 1.00] -> talk to (e.g., self, a person, a group) [0.44, 0.00, 0.83, 1.00] -> dig [0.14, 0.07, 0.61, 0.88]"
        ],
        "start": 0.0,
        "end": 204.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1109.0,
        "question": "What action is the person at the location [0.03, 0.11, 0.32, 0.96] in the image performing?",
        "answer": "stand, listen to (a person), watch (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "9Y_l9NsnYE0",
        "candidates": [
            "sit, listen to (a person)",
            "sit, listen to (a person), watch (a person)",
            "stand, talk to (e.g., self, a person, a group)",
            "stand, listen to (a person), watch (a person)"
        ],
        "start": 0.0,
        "end": 214.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1124.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.42, 0.27, 0.67, 0.81] location?",
        "answer": "carry/hold (an object) [0.42, 0.27, 0.67, 0.81] -> touch (an object) [0.42, 0.27, 0.67, 0.81] -> talk to (e.g., self, a person, a group) [0.42, 0.27, 0.67, 0.81]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "9Y_l9NsnYE0",
        "candidates": [
            "touch (an object) [0.42, 0.41, 0.59, 0.85] -> carry/hold (an object) [0.31, 0.41, 0.79, 0.72] -> open (e.g., a window, a car door) [0.39, 0.30, 0.87, 0.65]",
            "carry/hold (an object) [0.40, 0.41, 0.63, 0.70] -> push (an object) [0.60, 0.16, 0.72, 0.87] -> talk to (e.g., self, a person, a group) [0.48, 0.12, 0.81, 0.95]",
            "carry/hold (an object) [0.42, 0.27, 0.67, 0.81] -> touch (an object) [0.42, 0.27, 0.67, 0.81] -> talk to (e.g., self, a person, a group) [0.42, 0.27, 0.67, 0.81]",
            "talk to (e.g., self, a person, a group) [0.30, 0.29, 0.80, 0.62] -> carry/hold (an object) [0.54, 0.10, 0.68, 0.69] -> work on a computer [0.40, 0.18, 0.52, 0.72]"
        ],
        "start": 0.0,
        "end": 229.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1189.0,
        "question": "Are there still 1 people in the current frame now?",
        "answer": "No",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "9Y_l9NsnYE0",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 294.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1197.0,
        "question": "How many people were performing the listen to (a person) in the scene 60 seconds ago?",
        "answer": "7",
        "sub_answer_type": "PastMemory-5",
        "answer_type": "PastMemory",
        "video": "9Y_l9NsnYE0",
        "candidates": [
            "4",
            "7",
            "5",
            "3"
        ],
        "start": 0.0,
        "end": 302.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1307.0,
        "question": "How many people were performing the listen to (a person) in the scene 180 seconds ago?",
        "answer": "6",
        "sub_answer_type": "PastMemory-5",
        "answer_type": "PastMemory",
        "video": "9Y_l9NsnYE0",
        "candidates": [
            "7",
            "4",
            "3",
            "6"
        ],
        "start": 0.0,
        "end": 412.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1372.0,
        "question": "What action is the person at the location [0.17, 0.21, 0.31, 0.51] in the image performing?",
        "answer": "stand, hand shake, listen to (a person), watch (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "9Y_l9NsnYE0",
        "candidates": [
            "stand, listen to (a person), talk to (e.g., self, a person, a group), watch (a person)",
            "stand, talk to (e.g., self, a person, a group)",
            "stand, hand shake, listen to (a person), watch (a person)",
            "stand, talk to (e.g., self, a person, a group), watch (a person)"
        ],
        "start": 0.0,
        "end": 477.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1423.0,
        "question": "How many people were performing the stand in the scene 120 seconds ago?",
        "answer": "3",
        "sub_answer_type": "PastMemory-5",
        "answer_type": "PastMemory",
        "video": "9Y_l9NsnYE0",
        "candidates": [
            "6",
            "3",
            "4",
            "5"
        ],
        "start": 0.0,
        "end": 528.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1441.0,
        "question": "Are there still 3 people in the current frame now?",
        "answer": "No",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "9Y_l9NsnYE0",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 546.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1573.0,
        "question": "What action is the person at the location [0.01, 0.54, 0.42, 0.95] in the image performing?",
        "answer": "sit, watch (e.g., TV), listen to (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "9Y_l9NsnYE0",
        "candidates": [
            "sit, watch (e.g., TV), listen to (a person)",
            "sit, listen to (a person), watch (a person)",
            "sit, talk to (e.g., self, a person, a group)",
            "stand, listen to (a person), watch (a person)"
        ],
        "start": 0.0,
        "end": 678.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1595.0,
        "question": "What action is the person currently in the [0.52, 0.60, 0.87, 0.97] location likely to do next?",
        "answer": "watch (e.g., TV)",
        "sub_answer_type": "FuturePrediction-1",
        "answer_type": "FuturePrediction",
        "video": "9Y_l9NsnYE0",
        "candidates": [
            "watch (e.g., TV)",
            "read",
            "open (e.g., a window, a car door)",
            "dress/put on clothing"
        ],
        "start": 0.0,
        "end": 700.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1604.0,
        "question": "Are there still 2 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "9Y_l9NsnYE0",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 709.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1705.0,
        "question": "What action is the person at the location [0.01, 0.51, 0.26, 1.00] in the image performing?",
        "answer": "sit, listen to (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "9Y_l9NsnYE0",
        "candidates": [
            "stand, listen to (a person)",
            "sit, listen to (a person)",
            "stand, listen to (a person), watch (a person)",
            "sit, listen to (a person), watch (a person)"
        ],
        "start": 0.0,
        "end": 810.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1778.0,
        "question": "How many people were performing the listen to (a person) in the scene 60 seconds ago?",
        "answer": "6",
        "sub_answer_type": "PastMemory-5",
        "answer_type": "PastMemory",
        "video": "9Y_l9NsnYE0",
        "candidates": [
            "3",
            "4",
            "5",
            "6"
        ],
        "start": 0.0,
        "end": 883.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1796.0,
        "question": "Is the person currently in the [0.01, 0.03, 0.64, 0.98] location in the current frame performing the talk to (e.g., self, a person, a group)?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "9Y_l9NsnYE0",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 901.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 959.0,
        "question": "Where is the person currently performing the walk located in the picture?",
        "answer": "[0.58, 0.31, 0.71, 0.90]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "BXCh3r-pPAM",
        "candidates": [
            "[0.53, 0.21, 0.55, 0.66]",
            "[0.35, 0.47, 0.50, 0.72]",
            "[0.10, 0.10, 0.33, 0.98]",
            "[0.58, 0.31, 0.71, 0.90]"
        ],
        "start": 0.0,
        "end": 64.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 999.0,
        "question": "Are there still 2 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "BXCh3r-pPAM",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 104.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1002.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.24, 0.09, 0.64, 1.00]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "BXCh3r-pPAM",
        "candidates": [
            "[0.58, 0.18, 0.74, 0.68]",
            "[0.03, 0.00, 0.42, 0.92]",
            "[0.49, 0.34, 0.81, 1.00]",
            "[0.24, 0.09, 0.64, 1.00]"
        ],
        "start": 0.0,
        "end": 107.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1104.0,
        "question": "How many people were performing the dance in the scene 180 seconds ago?",
        "answer": "3",
        "sub_answer_type": "PastMemory-5",
        "answer_type": "PastMemory",
        "video": "BXCh3r-pPAM",
        "candidates": [
            "4",
            "3",
            "5",
            "6"
        ],
        "start": 0.0,
        "end": 209.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1111.0,
        "question": "What action is the person at the location [0.11, 0.07, 0.53, 0.99] in the image performing?",
        "answer": "stand, carry/hold (an object), talk to (e.g., self, a person, a group), watch (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "BXCh3r-pPAM",
        "candidates": [
            "stand, talk to (e.g., self, a person, a group)",
            "stand, talk to (e.g., self, a person, a group), watch (a person)",
            "stand, carry/hold (an object), talk to (e.g., self, a person, a group), watch (a person)",
            "walk, listen to (a person), watch (a person)"
        ],
        "start": 0.0,
        "end": 216.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1138.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "bend/bow (at the waist) -> talk to (e.g., self, a person, a group) -> play with pets",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "BXCh3r-pPAM",
        "candidates": [
            "talk to (e.g., self, a person, a group) -> bend/bow (at the waist) -> catch (an object)",
            "drink -> play with pets -> bend/bow (at the waist)",
            "give/serve (an object) to (a person) -> bend/bow (at the waist) -> talk to (e.g., self, a person, a group)",
            "bend/bow (at the waist) -> talk to (e.g., self, a person, a group) -> play with pets"
        ],
        "start": 0.0,
        "end": 243.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1196.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "carry/hold (an object) -> walk",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "BXCh3r-pPAM",
        "candidates": [
            "carry/hold (an object) -> smoke",
            "carry/hold (an object) -> walk",
            "push (another person) -> walk",
            "carry/hold (an object) -> brush teeth"
        ],
        "start": 0.0,
        "end": 301.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1264.0,
        "question": "What action is the person currently in the [0.02, 0.00, 0.94, 1.00] location likely to do next?",
        "answer": "lie/sleep",
        "sub_answer_type": "FuturePrediction-1",
        "answer_type": "FuturePrediction",
        "video": "BXCh3r-pPAM",
        "candidates": [
            "push (an object)",
            "carry/hold (an object)",
            "smoke",
            "lie/sleep"
        ],
        "start": 0.0,
        "end": 369.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1302.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "open (e.g., a window, a car door) -> bend/bow (at the waist) -> walk -> touch (an object)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "BXCh3r-pPAM",
        "candidates": [
            "touch (an object) -> open (e.g., a window, a car door) -> talk to (e.g., self, a person, a group) -> walk",
            "walk -> give/serve (an object) to (a person) -> bend/bow (at the waist) -> touch (an object)",
            "walk -> bend/bow (at the waist) -> touch (an object) -> catch (an object)",
            "open (e.g., a window, a car door) -> bend/bow (at the waist) -> walk -> touch (an object)"
        ],
        "start": 0.0,
        "end": 407.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1335.0,
        "question": "What action is the person at the location [0.03, 0.20, 0.55, 0.97] in the image performing?",
        "answer": "sit, touch (an object), watch (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "BXCh3r-pPAM",
        "candidates": [
            "dance, watch (a person)",
            "stand, listen to (a person), talk to (e.g., self, a person, a group), watch (a person)",
            "walk, listen to (a person), watch (a person)",
            "sit, touch (an object), watch (a person)"
        ],
        "start": 0.0,
        "end": 440.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1363.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "walk -> carry/hold (an object) -> talk to (e.g., self, a person, a group)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "BXCh3r-pPAM",
        "candidates": [
            "carry/hold (an object) -> talk to (e.g., self, a person, a group) -> talk to (e.g., self, a person, a group)",
            "walk -> talk to (e.g., self, a person, a group) -> close (e.g., a door, a box)",
            "walk -> carry/hold (an object) -> talk to (e.g., self, a person, a group)",
            "carry/hold (an object) -> talk to (e.g., self, a person, a group) -> bend/bow (at the waist)"
        ],
        "start": 0.0,
        "end": 468.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1391.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.47, 0.15, 0.97, 0.97]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "BXCh3r-pPAM",
        "candidates": [
            "[0.28, 0.08, 0.78, 0.99]",
            "[0.73, 0.39, 1.00, 1.00]",
            "[0.71, 0.12, 0.91, 0.68]",
            "[0.47, 0.15, 0.97, 0.97]"
        ],
        "start": 0.0,
        "end": 496.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1416.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "carry/hold (an object) -> talk to (e.g., self, a person, a group)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "BXCh3r-pPAM",
        "candidates": [
            "talk to (e.g., self, a person, a group) -> kiss (a person)",
            "carry/hold (an object) -> talk to (e.g., self, a person, a group)",
            "talk to (e.g., self, a person, a group) -> talk to (e.g., self, a person, a group)",
            "kick (a person) -> carry/hold (an object)"
        ],
        "start": 0.0,
        "end": 521.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1454.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.30, 0.08, 0.98, 0.97]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "BXCh3r-pPAM",
        "candidates": [
            "[0.01, 0.02, 0.96, 0.98]",
            "[0.25, 0.36, 0.99, 1.00]",
            "[0.17, 0.00, 0.93, 0.71]",
            "[0.30, 0.08, 0.98, 0.97]"
        ],
        "start": 0.0,
        "end": 559.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1557.0,
        "question": "What action is the person at the location [0.02, 0.12, 0.62, 0.98] in the image performing?",
        "answer": "stand, talk to (e.g., self, a person, a group), watch (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "BXCh3r-pPAM",
        "candidates": [
            "stand, talk to (e.g., self, a person, a group), watch (a person)",
            "stand, talk to (e.g., self, a person, a group)",
            "stand, listen to (a person), watch (a person)",
            "stand, play musical instrument, watch (a person)"
        ],
        "start": 0.0,
        "end": 662.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1686.0,
        "question": "How many people were performing the stand in the scene 180 seconds ago?",
        "answer": "5",
        "sub_answer_type": "PastMemory-5",
        "answer_type": "PastMemory",
        "video": "BXCh3r-pPAM",
        "candidates": [
            "5",
            "3",
            "7",
            "4"
        ],
        "start": 0.0,
        "end": 791.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1774.0,
        "question": "Where is the person currently performing the run/jog located in the picture?",
        "answer": "[0.10, 0.05, 0.95, 1.00]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "BXCh3r-pPAM",
        "candidates": [
            "[0.05, 0.09, 0.68, 0.97]",
            "[0.00, 0.00, 0.71, 0.73]",
            "[0.39, 0.10, 1.00, 1.00]",
            "[0.10, 0.05, 0.95, 1.00]"
        ],
        "start": 0.0,
        "end": 879.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 914.0,
        "question": "What action is the person currently in the [0.04, 0.13, 0.52, 0.89] location likely to do next?",
        "answer": "carry/hold (an object)",
        "sub_answer_type": "FuturePrediction-1",
        "answer_type": "FuturePrediction",
        "video": "CMCPhm2L400",
        "candidates": [
            "carry/hold (an object)",
            "carry/hold (an object) and talk to (e.g., self, a person, a group)",
            "exit",
            "work on a computer"
        ],
        "start": 0.0,
        "end": 19.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1013.0,
        "question": "Is the person currently in the [0.12, 0.03, 0.57, 0.95] location in the current frame performing the talk to (e.g., self, a person, a group)?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "CMCPhm2L400",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 118.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1125.0,
        "question": "How many people in the current frame are performing the action:  run/jog?",
        "answer": "2",
        "sub_answer_type": "SpatialPerception-2",
        "answer_type": "SpatialPerception",
        "video": "CMCPhm2L400",
        "candidates": [
            "2",
            "5",
            "4",
            "3"
        ],
        "start": 0.0,
        "end": 230.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1133.0,
        "question": "Are there still 1 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "CMCPhm2L400",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 238.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1183.0,
        "question": "How many people were performing the run/jog in the scene 60 seconds ago?",
        "answer": "3",
        "sub_answer_type": "PastMemory-5",
        "answer_type": "PastMemory",
        "video": "CMCPhm2L400",
        "candidates": [
            "3",
            "5",
            "4",
            "6"
        ],
        "start": 0.0,
        "end": 288.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1192.0,
        "question": "What action is the person at the location [0.02, 0.10, 0.46, 0.98] in the image performing?",
        "answer": "stand, listen to (a person), talk to (e.g., self, a person, a group)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "CMCPhm2L400",
        "candidates": [
            "stand, talk to (e.g., self, a person, a group)",
            "walk, watch (a person)",
            "stand, listen to (a person), talk to (e.g., self, a person, a group)",
            "stand, listen to (a person), talk to (e.g., self, a person, a group), watch (a person)"
        ],
        "start": 0.0,
        "end": 297.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1224.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.73, 0.25, 0.82, 0.57] location?",
        "answer": "carry/hold (an object) [0.74, 0.24, 0.82, 0.56] -> talk to (e.g., self, a person, a group) [0.74, 0.24, 0.82, 0.56] -> walk [0.73, 0.25, 0.82, 0.57]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "CMCPhm2L400",
        "candidates": [
            "carry/hold (an object) [0.82, 0.43, 0.71, 0.49] -> dance [0.66, 0.23, 0.88, 0.67] -> talk to (e.g., self, a person, a group) [0.87, 0.31, 0.86, 0.54]",
            "walk [0.75, 0.10, 0.85, 0.73] -> carry/hold (an object) [0.81, 0.42, 0.94, 0.38] -> swim [0.79, 0.14, 0.75, 0.52]",
            "walk [0.56, 0.22, 0.64, 0.66] -> carry/hold (an object) [0.56, 0.15, 0.83, 0.44] -> read [0.70, 0.10, 0.90, 0.40]",
            "carry/hold (an object) [0.74, 0.24, 0.82, 0.56] -> talk to (e.g., self, a person, a group) [0.74, 0.24, 0.82, 0.56] -> walk [0.73, 0.25, 0.82, 0.57]"
        ],
        "start": 0.0,
        "end": 329.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1285.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "talk to (e.g., self, a person, a group) -> walk",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "CMCPhm2L400",
        "candidates": [
            "press -> walk",
            "talk to (e.g., self, a person, a group) -> walk",
            "walk -> bend/bow (at the waist)",
            "talk to (e.g., self, a person, a group) -> exit"
        ],
        "start": 0.0,
        "end": 390.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1291.0,
        "question": "Are there still 1 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "CMCPhm2L400",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 396.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1292.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.19, 0.10, 0.71, 0.93] location?",
        "answer": "smoke [0.19, 0.10, 0.71, 0.93] -> touch (an object) [0.19, 0.10, 0.71, 0.93] -> talk to (e.g., self, a person, a group) [0.19, 0.10, 0.71, 0.93]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "CMCPhm2L400",
        "candidates": [
            "watch (e.g., TV) [0.15, 0.00, 0.80, 1.00] -> smoke [0.07, 0.00, 0.87, 0.88] -> talk to (e.g., self, a person, a group) [0.31, 0.14, 0.76, 0.73]",
            "talk to (e.g., self, a person, a group) [0.23, 0.27, 0.76, 0.82] -> smoke [0.21, 0.22, 0.76, 1.00] -> exit [0.05, 0.09, 0.54, 1.00]",
            "talk to (e.g., self, a person, a group) [0.18, 0.00, 0.72, 1.00] -> smoke [0.29, 0.30, 0.90, 0.99] -> exit [0.12, 0.20, 0.67, 1.00]",
            "smoke [0.19, 0.10, 0.71, 0.93] -> touch (an object) [0.19, 0.10, 0.71, 0.93] -> talk to (e.g., self, a person, a group) [0.19, 0.10, 0.71, 0.93]"
        ],
        "start": 0.0,
        "end": 397.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1302.0,
        "question": "How many people in the current frame are performing the action:  touch (an object)?",
        "answer": "3",
        "sub_answer_type": "SpatialPerception-2",
        "answer_type": "SpatialPerception",
        "video": "CMCPhm2L400",
        "candidates": [
            "3",
            "4",
            "5",
            "2"
        ],
        "start": 0.0,
        "end": 407.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1312.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.39, 0.16, 0.58, 0.76] location?",
        "answer": "walk [0.39, 0.16, 0.58, 0.76] -> carry/hold (an object) [0.39, 0.16, 0.58, 0.76] -> talk to (e.g., self, a person, a group) [0.39, 0.16, 0.58, 0.76]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "CMCPhm2L400",
        "candidates": [
            "walk [0.39, 0.16, 0.58, 0.76] -> carry/hold (an object) [0.39, 0.16, 0.58, 0.76] -> talk to (e.g., self, a person, a group) [0.39, 0.16, 0.58, 0.76]",
            "carry/hold (an object) [0.45, 0.34, 0.46, 0.59] -> carry/hold (an object) [0.51, 0.00, 0.63, 0.78] -> walk [0.22, 0.02, 0.74, 0.58]",
            "talk to (e.g., self, a person, a group) [0.24, 0.01, 0.63, 0.71] -> carry/hold (an object) [0.23, 0.28, 0.76, 0.78] -> hand clap [0.36, 0.00, 0.66, 0.81]",
            "carry/hold (an object) [0.30, 0.34, 0.65, 0.79] -> talk to (e.g., self, a person, a group) [0.23, 0.28, 0.76, 0.61] -> work on a computer [0.36, 0.15, 0.41, 0.85]"
        ],
        "start": 0.0,
        "end": 417.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1313.0,
        "question": "What location in the frame is the person currently in the [0.19, 0.37, 0.55, 0.88] location likely to move to next?",
        "answer": "[0.72, 0.37, 0.97, 0.86]",
        "sub_answer_type": "FuturePrediction-2",
        "answer_type": "FuturePrediction",
        "video": "CMCPhm2L400",
        "candidates": [
            "[0.89, 0.20, 0.72, 0.66]",
            "[0.72, 0.37, 0.97, 0.86]",
            "[0.02, 0.01, 0.32, 0.62]",
            "[0.81, 0.64, 1.00, 1.00]"
        ],
        "start": 0.0,
        "end": 418.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1430.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "carry/hold (an object) -> talk to (e.g., self, a person, a group) -> read",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "CMCPhm2L400",
        "candidates": [
            "carry/hold (an object) -> talk to (e.g., self, a person, a group) -> read",
            "exit -> talk to (e.g., self, a person, a group) -> read",
            "read -> hand clap -> talk to (e.g., self, a person, a group)",
            "talk to (e.g., self, a person, a group) -> point to (an object) -> read"
        ],
        "start": 0.0,
        "end": 535.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1438.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.14, 0.16, 0.39, 0.98] location?",
        "answer": "carry/hold (an object) [0.05, 0.13, 0.62, 0.94] -> open (e.g., a window, a car door) [0.05, 0.13, 0.62, 0.94] -> walk [0.14, 0.16, 0.39, 0.98]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "CMCPhm2L400",
        "candidates": [
            "carry/hold (an object) [0.05, 0.13, 0.62, 0.94] -> open (e.g., a window, a car door) [0.05, 0.13, 0.62, 0.94] -> walk [0.14, 0.16, 0.39, 0.98]",
            "carry/hold (an object) [0.21, 0.05, 0.45, 0.92] -> open (e.g., a window, a car door) [0.07, 0.21, 0.48, 1.00] -> fall down [0.19, 0.26, 0.33, 1.00]",
            "carry/hold (an object) [0.00, 0.08, 0.73, 0.94] -> walk [0.29, 0.22, 0.28, 0.92] -> crouch/kneel [0.14, 0.02, 0.62, 0.98]",
            "touch (an object) [0.17, 0.11, 0.52, 1.00] -> walk [0.31, 0.15, 0.36, 0.99] -> open (e.g., a window, a car door) [0.00, 0.01, 0.65, 0.80]"
        ],
        "start": 0.0,
        "end": 543.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1467.0,
        "question": "How many people were performing the listen to (a person) in the scene 120 seconds ago?",
        "answer": "4",
        "sub_answer_type": "PastMemory-5",
        "answer_type": "PastMemory",
        "video": "CMCPhm2L400",
        "candidates": [
            "4",
            "3",
            "6",
            "5"
        ],
        "start": 0.0,
        "end": 572.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1477.0,
        "question": "Where was the person currently performing the crouch/kneel in the scene 8 seconds ago?",
        "answer": "[0.16, 0.10, 0.30, 0.52]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "CMCPhm2L400",
        "candidates": [
            "[0.04, 0.02, 1.00, 0.98]",
            "[0.16, 0.10, 0.30, 0.52]",
            "[0.36, 0.01, 0.53, 0.31]",
            "[0.22, 0.31, 0.51, 0.81]"
        ],
        "start": 0.0,
        "end": 582.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1489.0,
        "question": "Are there still 2 people in the current frame now?",
        "answer": "No",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "CMCPhm2L400",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 594.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1496.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "carry/hold (an object) -> talk to (e.g., self, a person, a group)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "CMCPhm2L400",
        "candidates": [
            "carry/hold (an object) -> talk to (e.g., self, a person, a group)",
            "talk to (e.g., self, a person, a group) -> lift (a person)",
            "hit (an object) -> talk to (e.g., self, a person, a group)",
            "carry/hold (an object) -> extract"
        ],
        "start": 0.0,
        "end": 601.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1533.0,
        "question": "Where is the person currently performing the carry/hold (an object) located in the picture?",
        "answer": "[0.55, 0.19, 0.81, 0.85]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "CMCPhm2L400",
        "candidates": [
            "[0.75, 0.17, 1.00, 1.00]",
            "[0.39, 0.37, 0.87, 1.00]",
            "[0.02, 0.05, 0.77, 1.00]",
            "[0.55, 0.19, 0.81, 0.85]"
        ],
        "start": 0.0,
        "end": 638.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1597.0,
        "question": "How many people were performing the touch (an object) in the scene 240 seconds ago?",
        "answer": "5",
        "sub_answer_type": "PastMemory-5",
        "answer_type": "PastMemory",
        "video": "CMCPhm2L400",
        "candidates": [
            "3",
            "4",
            "5",
            "6"
        ],
        "start": 0.0,
        "end": 702.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1635.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "carry/hold (an object) -> talk to (e.g., self, a person, a group)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "CMCPhm2L400",
        "candidates": [
            "carry/hold (an object) -> talk to (e.g., self, a person, a group)",
            "touch (an object) -> talk to (e.g., self, a person, a group)",
            "lie/sleep -> carry/hold (an object)",
            "carry/hold (an object) -> play with pets"
        ],
        "start": 0.0,
        "end": 740.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1669.0,
        "question": "Where was the person currently performing the walk in the scene 8 seconds ago?",
        "answer": "[0.09, 0.15, 0.66, 0.83]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "CMCPhm2L400",
        "candidates": [
            "[0.00, 0.00, 0.71, 0.67]",
            "[0.00, 0.44, 0.66, 1.00]",
            "[0.09, 0.15, 0.66, 0.83]",
            "[0.53, 0.19, 0.72, 0.39]"
        ],
        "start": 0.0,
        "end": 774.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1683.0,
        "question": "What action is the person at the location [0.09, 0.16, 0.55, 0.98] in the image performing?",
        "answer": "sit, talk to (e.g., self, a person, a group)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "CMCPhm2L400",
        "candidates": [
            "sit, talk to (e.g., self, a person, a group)",
            "sit, talk to (e.g., self, a person, a group), watch (a person)",
            "stand, talk to (e.g., self, a person, a group)",
            "sit, listen to (a person), watch (a person)"
        ],
        "start": 0.0,
        "end": 788.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1714.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "walk -> talk to (e.g., self, a person, a group)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "CMCPhm2L400",
        "candidates": [
            "open (e.g., a window, a car door) -> talk to (e.g., self, a person, a group)",
            "work on a computer -> talk to (e.g., self, a person, a group)",
            "lift/pick up -> walk",
            "walk -> talk to (e.g., self, a person, a group)"
        ],
        "start": 0.0,
        "end": 819.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1720.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.35, 0.12, 0.76, 0.97] location?",
        "answer": "carry/hold (an object) [0.48, 0.14, 0.81, 0.97] -> talk to (e.g., self, a person, a group) [0.48, 0.14, 0.81, 0.97] -> walk [0.35, 0.12, 0.76, 0.97]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "CMCPhm2L400",
        "candidates": [
            "carry/hold (an object) [0.48, 0.14, 0.81, 0.97] -> talk to (e.g., self, a person, a group) [0.48, 0.14, 0.81, 0.97] -> walk [0.35, 0.12, 0.76, 0.97]",
            "walk [0.37, 0.31, 0.87, 1.00] -> talk to (e.g., self, a person, a group) [0.40, 0.23, 0.72, 1.00] -> drink [0.30, 0.12, 0.97, 0.89]",
            "close (e.g., a door, a box) [0.28, 0.22, 0.81, 0.99] -> walk [0.30, 0.00, 0.82, 1.00] -> talk to (e.g., self, a person, a group) [0.59, 0.27, 0.89, 1.00]",
            "talk to (e.g., self, a person, a group) [0.47, 0.02, 0.88, 0.99] -> shovel [0.35, 0.00, 0.81, 1.00] -> carry/hold (an object) [0.38, 0.23, 0.90, 0.91]"
        ],
        "start": 0.0,
        "end": 825.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1739.0,
        "question": "Are there still 1 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "CMCPhm2L400",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 844.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1072.0,
        "question": "Where is the person currently performing the talk to (e.g., self, a person, a group) located in the picture?",
        "answer": "[0.17, 0.01, 0.99, 0.97]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "CZ2NP8UsPuE",
        "candidates": [
            "[0.17, 0.01, 0.99, 0.97]",
            "[0.14, 0.11, 0.50, 1.00]",
            "[0.43, 0.00, 1.00, 0.81]",
            "[0.17, 0.02, 0.79, 0.72]"
        ],
        "start": 0.0,
        "end": 177.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1088.0,
        "question": "Is the person currently in the [0.06, 0.13, 0.56, 0.99] location in the current frame performing the walk?",
        "answer": "No",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "CZ2NP8UsPuE",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 193.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1091.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "talk to (e.g., self, a person, a group) -> walk -> carry/hold (an object)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "CZ2NP8UsPuE",
        "candidates": [
            "carry/hold (an object) -> play musical instrument -> walk",
            "kiss (a person) -> carry/hold (an object) -> walk",
            "carry/hold (an object) -> walk -> push (an object)",
            "talk to (e.g., self, a person, a group) -> walk -> carry/hold (an object)"
        ],
        "start": 0.0,
        "end": 196.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1094.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.06, 0.08, 0.79, 0.98] location?",
        "answer": "walk [0.06, 0.08, 0.79, 0.98] -> carry/hold (an object) [0.06, 0.08, 0.79, 0.98] -> talk to (e.g., self, a person, a group) [0.06, 0.08, 0.79, 0.98]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "CZ2NP8UsPuE",
        "candidates": [
            "shoot [0.23, 0.06, 0.89, 1.00] -> carry/hold (an object) [0.00, 0.00, 0.89, 0.81] -> talk to (e.g., self, a person, a group) [0.00, 0.21, 0.81, 1.00]",
            "walk [0.06, 0.08, 0.79, 0.98] -> carry/hold (an object) [0.06, 0.08, 0.79, 0.98] -> talk to (e.g., self, a person, a group) [0.06, 0.08, 0.79, 0.98]",
            "take a photo [0.25, 0.17, 0.89, 0.94] -> walk [0.01, 0.00, 0.65, 1.00] -> talk to (e.g., self, a person, a group) [0.06, 0.00, 0.92, 0.94]",
            "walk [0.00, 0.22, 0.68, 0.84] -> enter [0.18, 0.06, 0.80, 0.85] -> carry/hold (an object) [0.07, 0.10, 0.77, 1.00]"
        ],
        "start": 0.0,
        "end": 199.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1106.0,
        "question": "Where is the person currently performing the walk located in the picture?",
        "answer": "[0.32, 0.07, 0.96, 0.98]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "CZ2NP8UsPuE",
        "candidates": [
            "[0.10, 0.00, 0.77, 0.72]",
            "[0.08, 0.32, 0.70, 0.86]",
            "[0.00, 0.01, 0.38, 0.98]",
            "[0.32, 0.07, 0.96, 0.98]"
        ],
        "start": 0.0,
        "end": 211.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1130.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "walk -> carry/hold (an object) -> talk to (e.g., self, a person, a group)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "CZ2NP8UsPuE",
        "candidates": [
            "chop -> walk -> carry/hold (an object)",
            "drink -> carry/hold (an object) -> walk",
            "walk -> carry/hold (an object) -> talk to (e.g., self, a person, a group)",
            "walk -> answer phone -> talk to (e.g., self, a person, a group)"
        ],
        "start": 0.0,
        "end": 235.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1135.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "walk -> talk to (e.g., self, a person, a group)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "CZ2NP8UsPuE",
        "candidates": [
            "walk -> talk to (e.g., self, a person, a group)",
            "hand shake -> walk",
            "play with kids -> walk",
            "work on a computer -> walk"
        ],
        "start": 0.0,
        "end": 240.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1177.0,
        "question": "What action is the person currently in the [0.64, 0.23, 0.99, 0.96] location likely to do next?",
        "answer": "carry/hold (an object)",
        "sub_answer_type": "FuturePrediction-1",
        "answer_type": "FuturePrediction",
        "video": "CZ2NP8UsPuE",
        "candidates": [
            "eat",
            "carry/hold (an object)",
            "shovel",
            "press"
        ],
        "start": 0.0,
        "end": 282.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1179.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.37, 0.23, 0.52, 0.92]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "CZ2NP8UsPuE",
        "candidates": [
            "[0.53, 0.25, 0.87, 1.00]",
            "[0.36, 0.49, 0.32, 1.00]",
            "[0.19, 0.12, 0.65, 0.68]",
            "[0.37, 0.23, 0.52, 0.92]"
        ],
        "start": 0.0,
        "end": 284.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1273.0,
        "question": "Are there still 2 people in the current frame now?",
        "answer": "No",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "CZ2NP8UsPuE",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 378.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1365.0,
        "question": "How many people were performing the watch (a person) in the scene 180 seconds ago?",
        "answer": "3",
        "sub_answer_type": "PastMemory-5",
        "answer_type": "PastMemory",
        "video": "CZ2NP8UsPuE",
        "candidates": [
            "6",
            "3",
            "5",
            "4"
        ],
        "start": 0.0,
        "end": 470.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1420.0,
        "question": "What action is the person at the location [0.00, 0.15, 0.23, 0.66] in the image performing?",
        "answer": "stand, watch (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "CZ2NP8UsPuE",
        "candidates": [
            "carry/hold (an object), crouch/kneel, listen to (a person)",
            "stand, talk to (e.g., self, a person, a group), watch (a person)",
            "stand, listen to (a person), watch (a person)",
            "stand, watch (a person)"
        ],
        "start": 0.0,
        "end": 525.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1463.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "talk to (e.g., self, a person, a group) -> walk",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "CZ2NP8UsPuE",
        "candidates": [
            "play with kids -> talk to (e.g., self, a person, a group)",
            "eat -> walk",
            "talk to (e.g., self, a person, a group) -> walk",
            "talk to (e.g., self, a person, a group) -> take (an object) from (a person)"
        ],
        "start": 0.0,
        "end": 568.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1510.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.10, 0.16, 0.76, 0.98] location?",
        "answer": "walk [0.10, 0.16, 0.76, 0.98] -> carry/hold (an object) [0.10, 0.16, 0.76, 0.98] -> talk to (e.g., self, a person, a group) [0.10, 0.16, 0.76, 0.98]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "CZ2NP8UsPuE",
        "candidates": [
            "talk to (e.g., self, a person, a group) [0.12, 0.00, 0.83, 1.00] -> fight/hit (a person) [0.00, 0.05, 0.69, 1.00] -> carry/hold (an object) [0.04, 0.18, 0.92, 0.84]",
            "talk to (e.g., self, a person, a group) [0.20, 0.20, 0.58, 0.85] -> walk [0.19, 0.03, 0.95, 1.00] -> fight/hit (a person) [0.18, 0.00, 0.83, 1.00]",
            "walk [0.14, 0.08, 0.80, 1.00] -> crouch/kneel [0.25, 0.15, 0.64, 1.00] -> carry/hold (an object) [0.26, 0.01, 0.68, 0.99]",
            "walk [0.10, 0.16, 0.76, 0.98] -> carry/hold (an object) [0.10, 0.16, 0.76, 0.98] -> talk to (e.g., self, a person, a group) [0.10, 0.16, 0.76, 0.98]"
        ],
        "start": 0.0,
        "end": 615.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1526.0,
        "question": "Where is the person currently performing the carry/hold (an object) located in the picture?",
        "answer": "[0.00, 0.03, 0.61, 1.00]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "CZ2NP8UsPuE",
        "candidates": [
            "[0.06, 0.00, 0.94, 0.98]",
            "[0.00, 0.28, 0.81, 1.00]",
            "[0.00, 0.31, 0.46, 1.00]",
            "[0.00, 0.03, 0.61, 1.00]"
        ],
        "start": 0.0,
        "end": 631.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1527.0,
        "question": "Is the person currently in the [0.01, 0.04, 0.62, 0.99] location in the current frame performing the carry/hold (an object)?",
        "answer": "No",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "CZ2NP8UsPuE",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 632.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1530.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "carry/hold (an object) -> talk to (e.g., self, a person, a group)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "CZ2NP8UsPuE",
        "candidates": [
            "hit (an object) -> talk to (e.g., self, a person, a group)",
            "get up -> talk to (e.g., self, a person, a group)",
            "carry/hold (an object) -> talk to (e.g., self, a person, a group)",
            "paint -> talk to (e.g., self, a person, a group)"
        ],
        "start": 0.0,
        "end": 635.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1605.0,
        "question": "Where was the person currently performing the carry/hold (an object) in the scene 8 seconds ago?",
        "answer": "[0.59, 0.19, 0.98, 0.75]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "CZ2NP8UsPuE",
        "candidates": [
            "[0.59, 0.19, 0.98, 0.75]",
            "[0.45, 0.39, 0.99, 0.99]",
            "[0.00, 0.00, 0.85, 0.99]",
            "[0.31, 0.00, 1.00, 0.64]"
        ],
        "start": 0.0,
        "end": 710.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1622.0,
        "question": "What action is the person at the location [0.00, 0.18, 0.48, 0.99] in the image performing?",
        "answer": "sit, carry/hold (an object), listen to (a person), talk to (e.g., self, a person, a group), watch (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "CZ2NP8UsPuE",
        "candidates": [
            "stand, carry/hold (an object), talk to (e.g., self, a person, a group), watch (a person)",
            "sit, carry/hold (an object), listen to (a person), talk to (e.g., self, a person, a group), watch (a person)",
            "stand, carry/hold (an object), listen to (a person), watch (a person)",
            "stand, listen to (a person), watch (a person)"
        ],
        "start": 0.0,
        "end": 727.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1635.0,
        "question": "Where was the person currently performing the get up in the scene 8 seconds ago?",
        "answer": "[0.21, 0.01, 1.00, 0.99]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "CZ2NP8UsPuE",
        "candidates": [
            "[0.00, 0.00, 0.31, 1.00]",
            "[0.30, 0.00, 1.00, 0.70]",
            "[0.16, 0.26, 0.72, 0.99]",
            "[0.21, 0.01, 1.00, 0.99]"
        ],
        "start": 0.0,
        "end": 740.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1709.0,
        "question": "What location in the frame is the person currently in the [0.45, 0.21, 0.71, 0.94] location likely to move to next?",
        "answer": "[0.07, 0.34, 0.39, 0.98]",
        "sub_answer_type": "FuturePrediction-2",
        "answer_type": "FuturePrediction",
        "video": "CZ2NP8UsPuE",
        "candidates": [
            "[0.51, 0.15, 0.65, 0.57]",
            "[0.07, 0.34, 0.39, 0.98]",
            "[0.18, 0.26, 0.59, 0.88]",
            "[0.16, 0.06, 0.38, 0.84]"
        ],
        "start": 0.0,
        "end": 814.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1709.0,
        "question": "Is the person currently in the [0.45, 0.21, 0.71, 0.94] location in the current frame performing the walk?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "CZ2NP8UsPuE",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 814.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1712.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.44, 0.22, 0.75, 0.96] location?",
        "answer": "walk [0.44, 0.22, 0.75, 0.96] -> carry/hold (an object) [0.44, 0.22, 0.75, 0.96] -> talk to (e.g., self, a person, a group) [0.44, 0.22, 0.75, 0.96]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "CZ2NP8UsPuE",
        "candidates": [
            "talk to (e.g., self, a person, a group) [0.38, 0.23, 0.85, 1.00] -> grab (a person) [0.43, 0.31, 0.86, 1.00] -> walk [0.36, 0.34, 0.80, 0.98]",
            "extract [0.48, 0.17, 0.62, 0.90] -> carry/hold (an object) [0.58, 0.35, 0.89, 0.92] -> walk [0.29, 0.30, 0.78, 1.00]",
            "walk [0.44, 0.22, 0.75, 0.96] -> carry/hold (an object) [0.44, 0.22, 0.75, 0.96] -> talk to (e.g., self, a person, a group) [0.44, 0.22, 0.75, 0.96]",
            "carry/hold (an object) [0.44, 0.24, 0.78, 0.80] -> talk to (e.g., self, a person, a group) [0.26, 0.10, 0.72, 0.86] -> chop [0.60, 0.07, 0.73, 1.00]"
        ],
        "start": 0.0,
        "end": 817.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1716.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.34, 0.14, 0.66, 0.82] location?",
        "answer": "carry/hold (an object) [0.10, 0.11, 0.38, 0.92] -> talk to (e.g., self, a person, a group) [0.10, 0.11, 0.38, 0.92] -> walk [0.34, 0.14, 0.66, 0.82]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "CZ2NP8UsPuE",
        "candidates": [
            "carry/hold (an object) [0.10, 0.11, 0.38, 0.92] -> talk to (e.g., self, a person, a group) [0.10, 0.11, 0.38, 0.92] -> walk [0.34, 0.14, 0.66, 0.82]",
            "talk to (e.g., self, a person, a group) [0.21, 0.00, 0.48, 0.88] -> answer phone [0.48, 0.03, 0.63, 0.63] -> carry/hold (an object) [0.02, 0.17, 0.56, 1.00]",
            "talk to (e.g., self, a person, a group) [0.06, 0.19, 0.32, 1.00] -> carry/hold (an object) [0.15, 0.09, 0.34, 1.00] -> chop [0.33, 0.06, 0.77, 0.75]",
            "carry/hold (an object) [0.10, 0.25, 0.53, 0.93] -> talk to (e.g., self, a person, a group) [0.00, 0.07, 0.46, 1.00] -> pull (an object) [0.26, 0.14, 0.50, 0.77]"
        ],
        "start": 0.0,
        "end": 821.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1722.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.44, 0.08, 1.00, 0.98] location?",
        "answer": "carry/hold (an object) [0.44, 0.08, 1.00, 0.98] -> touch (an object) [0.44, 0.08, 1.00, 0.98] -> talk to (e.g., self, a person, a group) [0.44, 0.08, 1.00, 0.98]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "CZ2NP8UsPuE",
        "candidates": [
            "carry/hold (an object) [0.44, 0.08, 1.00, 0.98] -> touch (an object) [0.44, 0.08, 1.00, 0.98] -> talk to (e.g., self, a person, a group) [0.44, 0.08, 1.00, 0.98]",
            "talk to (e.g., self, a person, a group) [0.60, 0.00, 0.83, 0.96] -> talk to (e.g., self, a person, a group) [0.43, 0.24, 1.00, 0.93] -> carry/hold (an object) [0.60, 0.15, 0.84, 0.90]",
            "talk to (e.g., self, a person, a group) [0.26, 0.00, 0.98, 0.84] -> kiss (a person) [0.42, 0.00, 0.98, 0.96] -> touch (an object) [0.59, 0.10, 1.00, 0.99]",
            "touch (an object) [0.64, 0.07, 1.00, 1.00] -> turn (e.g., a screwdriver) [0.47, 0.00, 0.90, 1.00] -> talk to (e.g., self, a person, a group) [0.51, 0.01, 0.94, 0.84]"
        ],
        "start": 0.0,
        "end": 827.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1763.0,
        "question": "How many people were performing the stand in the scene 60 seconds ago?",
        "answer": "3",
        "sub_answer_type": "PastMemory-5",
        "answer_type": "PastMemory",
        "video": "CZ2NP8UsPuE",
        "candidates": [
            "4",
            "5",
            "3",
            "6"
        ],
        "start": 0.0,
        "end": 868.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 917.0,
        "question": "What action is the person at the location [0.12, 0.00, 0.47, 0.98] in the image performing?",
        "answer": "stand, listen to (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "Di1MG6auDYo",
        "candidates": [
            "sit, talk to (e.g., self, a person, a group), watch (a person)",
            "stand, listen to (a person)",
            "stand, listen to (a person), watch (a person)",
            "stand, talk to (e.g., self, a person, a group)"
        ],
        "start": 0.0,
        "end": 22.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 938.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "walk -> answer phone",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "Di1MG6auDYo",
        "candidates": [
            "walk -> brush teeth",
            "walk -> martial art",
            "walk -> answer phone",
            "walk -> dig"
        ],
        "start": 0.0,
        "end": 43.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1156.0,
        "question": "What action is the person at the location [0.00, 0.14, 0.33, 0.90] in the image performing?",
        "answer": "sit, listen to (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "Di1MG6auDYo",
        "candidates": [
            "stand, talk to (e.g., self, a person, a group)",
            "stand, listen to (a person)",
            "sit, listen to (a person)",
            "sit, talk to (e.g., self, a person, a group)"
        ],
        "start": 0.0,
        "end": 261.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1194.0,
        "question": "Are there still 1 people in the current frame now?",
        "answer": "No",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "Di1MG6auDYo",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 299.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1252.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "answer phone -> talk to (e.g., self, a person, a group) -> lie/sleep",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "Di1MG6auDYo",
        "candidates": [
            "drink -> talk to (e.g., self, a person, a group) -> lie/sleep",
            "grab (a person) -> answer phone -> talk to (e.g., self, a person, a group)",
            "lie/sleep -> touch (an object) -> talk to (e.g., self, a person, a group)",
            "answer phone -> talk to (e.g., self, a person, a group) -> lie/sleep"
        ],
        "start": 0.0,
        "end": 357.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1268.0,
        "question": "Where was the person currently performing the answer phone in the scene 8 seconds ago?",
        "answer": "[0.15, 0.01, 0.71, 0.99]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "Di1MG6auDYo",
        "candidates": [
            "[0.07, 0.00, 0.96, 0.72]",
            "[0.03, 0.00, 0.53, 0.97]",
            "[0.28, 0.14, 1.00, 1.00]",
            "[0.15, 0.01, 0.71, 0.99]"
        ],
        "start": 0.0,
        "end": 373.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1271.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "answer phone -> talk to (e.g., self, a person, a group)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "Di1MG6auDYo",
        "candidates": [
            "answer phone -> lift (a person)",
            "answer phone -> talk to (e.g., self, a person, a group)",
            "answer phone -> paint",
            "talk to (e.g., self, a person, a group) -> climb (e.g., a mountain)"
        ],
        "start": 0.0,
        "end": 376.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1295.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "answer phone -> lie/sleep",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "Di1MG6auDYo",
        "candidates": [
            "lie/sleep -> lie/sleep",
            "grab (a person) -> answer phone",
            "answer phone -> lie/sleep",
            "kick (a person) -> lie/sleep"
        ],
        "start": 0.0,
        "end": 400.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1325.0,
        "question": "What action is the person at the location [0.14, 0.00, 0.47, 1.00] in the image performing?",
        "answer": "stand, listen to (a person), watch (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "Di1MG6auDYo",
        "candidates": [
            "stand, talk to (e.g., self, a person, a group)",
            "walk, carry/hold (an object)",
            "stand, listen to (a person), watch (a person)",
            "sit, carry/hold (an object)"
        ],
        "start": 0.0,
        "end": 430.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1375.0,
        "question": "Are there still 1 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "Di1MG6auDYo",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 480.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1384.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "walk -> carry/hold (an object)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "Di1MG6auDYo",
        "candidates": [
            "walk -> touch (an object)",
            "walk -> carry/hold (an object)",
            "carry/hold (an object) -> hand shake",
            "walk -> walk"
        ],
        "start": 0.0,
        "end": 489.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1399.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.44, 0.22, 0.56, 0.89] location?",
        "answer": "walk [0.44, 0.22, 0.56, 0.89] -> carry/hold (an object) [0.44, 0.22, 0.56, 0.89] -> talk to (e.g., self, a person, a group) [0.44, 0.22, 0.56, 0.89]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "Di1MG6auDYo",
        "candidates": [
            "walk [0.42, 0.09, 0.43, 0.71] -> carry/hold (an object) [0.48, 0.03, 0.71, 0.72] -> cut [0.60, 0.40, 0.63, 0.95]",
            "walk [0.44, 0.22, 0.56, 0.89] -> carry/hold (an object) [0.44, 0.22, 0.56, 0.89] -> talk to (e.g., self, a person, a group) [0.44, 0.22, 0.56, 0.89]",
            "carry/hold (an object) [0.37, 0.12, 0.70, 0.96] -> ride (e.g., a bike, a car, a horse) [0.41, 0.41, 0.48, 0.75] -> walk [0.48, 0.17, 0.48, 0.88]",
            "walk [0.58, 0.20, 0.63, 0.92] -> carry/hold (an object) [0.44, 0.38, 0.47, 0.86] -> lift (a person) [0.61, 0.04, 0.58, 0.90]"
        ],
        "start": 0.0,
        "end": 504.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1406.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.41, 0.01, 0.62, 0.86] location?",
        "answer": "talk to (e.g., self, a person, a group) [0.35, 0.01, 0.49, 0.74] -> walk [0.41, 0.01, 0.62, 0.86] -> carry/hold (an object) [0.41, 0.01, 0.62, 0.86]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "Di1MG6auDYo",
        "candidates": [
            "talk to (e.g., self, a person, a group) [0.38, 0.15, 0.34, 0.77] -> close (e.g., a door, a box) [0.32, 0.00, 0.78, 0.92] -> carry/hold (an object) [0.22, 0.00, 0.46, 0.85]",
            "play board game [0.51, 0.15, 0.53, 0.78] -> carry/hold (an object) [0.22, 0.14, 0.43, 0.95] -> talk to (e.g., self, a person, a group) [0.40, 0.20, 0.31, 0.75]",
            "carry/hold (an object) [0.44, 0.07, 0.79, 0.80] -> run/jog [0.30, 0.10, 0.51, 0.69] -> walk [0.39, 0.00, 0.44, 0.70]",
            "talk to (e.g., self, a person, a group) [0.35, 0.01, 0.49, 0.74] -> walk [0.41, 0.01, 0.62, 0.86] -> carry/hold (an object) [0.41, 0.01, 0.62, 0.86]"
        ],
        "start": 0.0,
        "end": 511.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1409.0,
        "question": "What location in the frame is the person currently in the [0.00, 0.29, 0.35, 1.00] location likely to move to next?",
        "answer": "[0.40, 0.04, 0.81, 0.88]",
        "sub_answer_type": "FuturePrediction-2",
        "answer_type": "FuturePrediction",
        "video": "Di1MG6auDYo",
        "candidates": [
            "[0.54, 0.08, 0.98, 0.99]",
            "[0.15, 0.14, 0.70, 0.92]",
            "[0.40, 0.04, 0.81, 0.88]",
            "[0.14, 0.00, 0.74, 0.70]"
        ],
        "start": 0.0,
        "end": 514.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1422.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.39, 0.12, 0.80, 0.91] location?",
        "answer": "talk to (e.g., self, a person, a group) [0.37, 0.07, 0.76, 0.90] -> carry/hold (an object) [0.39, 0.12, 0.80, 0.91] -> read [0.39, 0.12, 0.80, 0.91]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "Di1MG6auDYo",
        "candidates": [
            "talk to (e.g., self, a person, a group) [0.37, 0.07, 0.76, 0.90] -> carry/hold (an object) [0.39, 0.12, 0.80, 0.91] -> read [0.39, 0.12, 0.80, 0.91]",
            "pull (an object) [0.50, 0.00, 0.89, 0.88] -> read [0.48, 0.04, 0.71, 0.78] -> carry/hold (an object) [0.25, 0.18, 0.86, 0.93]",
            "carry/hold (an object) [0.57, 0.00, 0.82, 1.00] -> talk to (e.g., self, a person, a group) [0.35, 0.00, 0.71, 0.72] -> turn (e.g., a screwdriver) [0.43, 0.00, 0.82, 0.90]",
            "shovel [0.17, 0.08, 0.95, 0.95] -> carry/hold (an object) [0.43, 0.21, 0.63, 0.82] -> read [0.24, 0.25, 0.64, 0.96]"
        ],
        "start": 0.0,
        "end": 527.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1423.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.19, 0.26, 0.33, 0.56] location?",
        "answer": "bend/bow (at the waist) [0.19, 0.26, 0.33, 0.56] -> carry/hold (an object) [0.19, 0.26, 0.33, 0.56] -> talk to (e.g., self, a person, a group) [0.19, 0.26, 0.33, 0.56]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "Di1MG6auDYo",
        "candidates": [
            "push (another person) [0.19, 0.16, 0.41, 0.47] -> talk to (e.g., self, a person, a group) [0.01, 0.39, 0.23, 0.66] -> bend/bow (at the waist) [0.28, 0.33, 0.21, 0.69]",
            "bend/bow (at the waist) [0.19, 0.26, 0.33, 0.56] -> carry/hold (an object) [0.19, 0.26, 0.33, 0.56] -> talk to (e.g., self, a person, a group) [0.19, 0.26, 0.33, 0.56]",
            "bend/bow (at the waist) [0.21, 0.11, 0.47, 0.74] -> talk to (e.g., self, a person, a group) [0.03, 0.46, 0.30, 0.47] -> open (e.g., a window, a car door) [0.27, 0.25, 0.46, 0.40]",
            "catch (an object) [0.05, 0.44, 0.21, 0.53] -> talk to (e.g., self, a person, a group) [0.06, 0.13, 0.45, 0.42] -> carry/hold (an object) [0.17, 0.23, 0.43, 0.58]"
        ],
        "start": 0.0,
        "end": 528.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1424.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.39, 0.12, 0.80, 0.91] location?",
        "answer": "talk to (e.g., self, a person, a group) [0.37, 0.07, 0.76, 0.90] -> carry/hold (an object) [0.39, 0.12, 0.80, 0.91] -> read [0.39, 0.12, 0.80, 0.91]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "Di1MG6auDYo",
        "candidates": [
            "read [0.23, 0.06, 0.63, 1.00] -> talk to (e.g., self, a person, a group) [0.33, 0.10, 0.71, 0.95] -> sing to (e.g., self, a person, a group) [0.21, 0.00, 0.98, 0.75]",
            "play with kids [0.48, 0.04, 0.78, 0.90] -> read [0.56, 0.30, 0.80, 0.91] -> talk to (e.g., self, a person, a group) [0.29, 0.23, 0.84, 1.00]",
            "talk to (e.g., self, a person, a group) [0.37, 0.07, 0.76, 0.90] -> carry/hold (an object) [0.39, 0.12, 0.80, 0.91] -> read [0.39, 0.12, 0.80, 0.91]",
            "exit [0.33, 0.28, 0.74, 1.00] -> talk to (e.g., self, a person, a group) [0.35, 0.05, 0.59, 0.79] -> carry/hold (an object) [0.51, 0.09, 0.94, 1.00]"
        ],
        "start": 0.0,
        "end": 529.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1448.0,
        "question": "What action is the person currently in the [0.17, 0.25, 0.34, 0.58] location likely to do next?",
        "answer": "bend/bow (at the waist)",
        "sub_answer_type": "FuturePrediction-1",
        "answer_type": "FuturePrediction",
        "video": "Di1MG6auDYo",
        "candidates": [
            "answer phone",
            "work on a computer",
            "sail boat",
            "bend/bow (at the waist)"
        ],
        "start": 0.0,
        "end": 553.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1450.0,
        "question": "What action is the person at the location [0.19, 0.27, 0.35, 0.57] in the image performing?",
        "answer": "bend/bow (at the waist), work on a computer",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "Di1MG6auDYo",
        "candidates": [
            "bend/bow (at the waist), work on a computer",
            "sit, talk to (e.g., self, a person, a group), watch (a person)",
            "walk, carry/hold (an object)",
            "stand, listen to (a person)"
        ],
        "start": 0.0,
        "end": 555.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1566.0,
        "question": "Where was the person currently performing the answer phone in the scene 8 seconds ago?",
        "answer": "[0.58, 0.01, 0.92, 0.99]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "Di1MG6auDYo",
        "candidates": [
            "[0.02, 0.14, 0.52, 1.00]",
            "[0.29, 0.00, 0.78, 0.78]",
            "[0.58, 0.01, 0.92, 0.99]",
            "[0.88, 0.00, 1.00, 0.95]"
        ],
        "start": 0.0,
        "end": 671.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1596.0,
        "question": "Where was the person currently performing the text on/look at a cellphone in the scene 8 seconds ago?",
        "answer": "[0.64, 0.01, 1.00, 0.98]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "Di1MG6auDYo",
        "candidates": [
            "[0.64, 0.01, 1.00, 0.98]",
            "[0.87, 0.10, 1.00, 0.69]",
            "[0.00, 0.00, 0.42, 0.99]",
            "[0.43, 0.12, 0.94, 1.00]"
        ],
        "start": 0.0,
        "end": 701.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1687.0,
        "question": "What action is the person at the location [0.00, 0.05, 0.39, 0.98] in the image performing?",
        "answer": "stand, talk to (e.g., self, a person, a group)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "Di1MG6auDYo",
        "candidates": [
            "stand, talk to (e.g., self, a person, a group)",
            "sit, carry/hold (an object), listen to (a person)",
            "stand, listen to (a person), watch (a person)",
            "walk, carry/hold (an object)"
        ],
        "start": 0.0,
        "end": 792.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1698.0,
        "question": "Is the person currently in the [0.00, 0.00, 0.44, 0.99] location in the current frame performing the talk to (e.g., self, a person, a group)?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "Di1MG6auDYo",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 803.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1719.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.58, 0.00, 0.95, 1.00]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "Di1MG6auDYo",
        "candidates": [
            "[0.32, 0.00, 0.74, 0.87]",
            "[0.86, 0.00, 1.00, 0.91]",
            "[0.58, 0.00, 0.95, 1.00]",
            "[0.54, 0.42, 0.62, 0.76]"
        ],
        "start": 0.0,
        "end": 824.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1751.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.59, 0.02, 1.00, 1.00]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "Di1MG6auDYo",
        "candidates": [
            "[0.43, 0.02, 0.80, 1.00]",
            "[0.04, 0.00, 0.35, 1.00]",
            "[0.59, 0.02, 1.00, 1.00]",
            "[0.89, 0.00, 1.00, 0.90]"
        ],
        "start": 0.0,
        "end": 856.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 925.0,
        "question": "What action is the person currently in the [0.52, 0.08, 0.82, 0.97] location likely to do next?",
        "answer": "walk",
        "sub_answer_type": "FuturePrediction-1",
        "answer_type": "FuturePrediction",
        "video": "Ekwy7wzLfjc",
        "candidates": [
            "watch (e.g., TV)",
            "walk",
            "carry/hold (an object) and talk to (e.g., self, a person, a group)",
            "hit (an object)"
        ],
        "start": 0.0,
        "end": 30.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 984.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.40, 0.05, 0.76, 0.98] location?",
        "answer": "bend/bow (at the waist) [0.40, 0.05, 0.76, 0.98] -> hug (a person) [0.40, 0.05, 0.76, 0.98] -> talk to (e.g., self, a person, a group) [0.40, 0.05, 0.76, 0.98]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "Ekwy7wzLfjc",
        "candidates": [
            "bend/bow (at the waist) [0.40, 0.05, 0.76, 0.98] -> hug (a person) [0.40, 0.05, 0.76, 0.98] -> talk to (e.g., self, a person, a group) [0.40, 0.05, 0.76, 0.98]",
            "talk to (e.g., self, a person, a group) [0.28, 0.11, 0.84, 0.88] -> touch (an object) [0.21, 0.00, 0.86, 1.00] -> hug (a person) [0.54, 0.00, 0.81, 0.95]",
            "watch (e.g., TV) [0.55, 0.00, 0.88, 1.00] -> hug (a person) [0.23, 0.05, 0.83, 0.90] -> talk to (e.g., self, a person, a group) [0.29, 0.05, 0.89, 0.97]",
            "hug (a person) [0.34, 0.16, 0.77, 1.00] -> talk to (e.g., self, a person, a group) [0.60, 0.00, 0.57, 1.00] -> close (e.g., a door, a box) [0.38, 0.24, 0.89, 1.00]"
        ],
        "start": 0.0,
        "end": 89.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 989.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.38, 0.10, 0.75, 0.96] location?",
        "answer": "hug (a person) [0.38, 0.09, 0.76, 0.97] -> talk to (e.g., self, a person, a group) [0.38, 0.09, 0.76, 0.97] -> bend/bow (at the waist) [0.38, 0.10, 0.75, 0.96]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "Ekwy7wzLfjc",
        "candidates": [
            "point to (an object) [0.26, 0.14, 0.79, 0.80] -> hug (a person) [0.48, 0.25, 0.73, 1.00] -> talk to (e.g., self, a person, a group) [0.37, 0.00, 0.73, 0.93]",
            "bend/bow (at the waist) [0.24, 0.03, 0.82, 1.00] -> hug (a person) [0.33, 0.06, 0.63, 0.86] -> extract [0.26, 0.04, 0.73, 0.85]",
            "talk to (e.g., self, a person, a group) [0.27, 0.11, 0.90, 1.00] -> hug (a person) [0.49, 0.06, 0.96, 0.97] -> martial art [0.54, 0.00, 0.92, 0.88]",
            "hug (a person) [0.38, 0.09, 0.76, 0.97] -> talk to (e.g., self, a person, a group) [0.38, 0.09, 0.76, 0.97] -> bend/bow (at the waist) [0.38, 0.10, 0.75, 0.96]"
        ],
        "start": 0.0,
        "end": 94.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 990.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.38, 0.10, 0.75, 0.96] location?",
        "answer": "hug (a person) [0.38, 0.09, 0.76, 0.97] -> talk to (e.g., self, a person, a group) [0.38, 0.09, 0.76, 0.97] -> bend/bow (at the waist) [0.38, 0.10, 0.75, 0.96]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "Ekwy7wzLfjc",
        "candidates": [
            "take a photo [0.34, 0.18, 0.74, 1.00] -> bend/bow (at the waist) [0.50, 0.23, 0.93, 1.00] -> talk to (e.g., self, a person, a group) [0.48, 0.07, 0.93, 0.94]",
            "brush teeth [0.32, 0.24, 0.66, 0.98] -> bend/bow (at the waist) [0.32, 0.18, 0.75, 0.95] -> hug (a person) [0.55, 0.00, 0.63, 1.00]",
            "hug (a person) [0.50, 0.04, 0.60, 0.81] -> hug (a person) [0.32, 0.06, 0.87, 1.00] -> bend/bow (at the waist) [0.19, 0.00, 0.73, 1.00]",
            "hug (a person) [0.38, 0.09, 0.76, 0.97] -> talk to (e.g., self, a person, a group) [0.38, 0.09, 0.76, 0.97] -> bend/bow (at the waist) [0.38, 0.10, 0.75, 0.96]"
        ],
        "start": 0.0,
        "end": 95.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1017.0,
        "question": "Where is the person currently performing the answer phone located in the picture?",
        "answer": "[0.46, 0.05, 0.96, 0.97]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "Ekwy7wzLfjc",
        "candidates": [
            "[0.36, 0.00, 0.67, 0.84]",
            "[0.02, 0.37, 0.12, 0.89]",
            "[0.67, 0.27, 0.94, 1.00]",
            "[0.46, 0.05, 0.96, 0.97]"
        ],
        "start": 0.0,
        "end": 122.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1052.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "talk to (e.g., self, a person, a group) -> lie/sleep",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "Ekwy7wzLfjc",
        "candidates": [
            "talk to (e.g., self, a person, a group) -> lie/sleep",
            "work on a computer -> talk to (e.g., self, a person, a group)",
            "talk to (e.g., self, a person, a group) -> drink",
            "give/serve (an object) to (a person) -> lie/sleep"
        ],
        "start": 0.0,
        "end": 157.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1063.0,
        "question": "Is the person currently in the [0.20, 0.01, 0.94, 0.98] location in the current frame performing the talk to (e.g., self, a person, a group)?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "Ekwy7wzLfjc",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 168.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1066.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "talk to (e.g., self, a person, a group) -> lie/sleep",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "Ekwy7wzLfjc",
        "candidates": [
            "point to (an object) -> lie/sleep",
            "talk to (e.g., self, a person, a group) -> lie/sleep",
            "lie/sleep -> dig",
            "lie/sleep -> shovel"
        ],
        "start": 0.0,
        "end": 171.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1084.0,
        "question": "Where was the person currently performing the lie/sleep in the scene 8 seconds ago?",
        "answer": "[0.14, 0.07, 0.86, 0.97]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "Ekwy7wzLfjc",
        "candidates": [
            "[0.14, 0.07, 0.86, 0.97]",
            "[0.33, 0.34, 0.49, 0.98]",
            "[0.27, 0.32, 0.86, 1.00]",
            "[0.39, 0.34, 1.00, 0.69]"
        ],
        "start": 0.0,
        "end": 189.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1116.0,
        "question": "Where is the person currently performing the carry/hold (an object) located in the picture?",
        "answer": "[0.58, 0.29, 0.71, 0.98]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "Ekwy7wzLfjc",
        "candidates": [
            "[0.38, 0.50, 0.55, 0.82]",
            "[0.21, 0.00, 0.93, 0.98]",
            "[0.82, 0.36, 0.88, 0.97]",
            "[0.58, 0.29, 0.71, 0.98]"
        ],
        "start": 0.0,
        "end": 221.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1160.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.34, 0.01, 0.85, 0.98]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "Ekwy7wzLfjc",
        "candidates": [
            "[0.22, 0.05, 0.71, 0.78]",
            "[0.53, 0.27, 0.96, 1.00]",
            "[0.31, 0.18, 0.56, 0.99]",
            "[0.34, 0.01, 0.85, 0.98]"
        ],
        "start": 0.0,
        "end": 265.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1190.0,
        "question": "Are there still 1 people in the current frame now?",
        "answer": "No",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "Ekwy7wzLfjc",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 295.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1224.0,
        "question": "Where was the person currently performing the touch (an object) in the scene 8 seconds ago?",
        "answer": "[0.03, 0.01, 0.77, 0.99]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "Ekwy7wzLfjc",
        "candidates": [
            "[0.03, 0.01, 0.77, 0.99]",
            "[0.27, 0.00, 0.86, 1.00]",
            "[0.14, 0.00, 0.48, 0.75]",
            "[0.66, 0.31, 0.97, 0.98]"
        ],
        "start": 0.0,
        "end": 329.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1251.0,
        "question": "What action is the person at the location [0.10, 0.33, 0.47, 0.97] in the image performing?",
        "answer": "sit, touch (an object), talk to (e.g., self, a person, a group), watch (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "Ekwy7wzLfjc",
        "candidates": [
            "walk, carry/hold (an object)",
            "stand, talk to (e.g., self, a person, a group), watch (a person)",
            "stand, listen to (a person), watch (a person)",
            "sit, touch (an object), talk to (e.g., self, a person, a group), watch (a person)"
        ],
        "start": 0.0,
        "end": 356.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1260.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "carry/hold (an object) -> talk to (e.g., self, a person, a group)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "Ekwy7wzLfjc",
        "candidates": [
            "talk to (e.g., self, a person, a group) -> fight/hit (a person)",
            "dig -> talk to (e.g., self, a person, a group)",
            "carry/hold (an object) -> talk to (e.g., self, a person, a group)",
            "talk to (e.g., self, a person, a group) -> dress/put on clothing"
        ],
        "start": 0.0,
        "end": 365.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1319.0,
        "question": "Are there still 1 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "Ekwy7wzLfjc",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 424.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1390.0,
        "question": "Where was the person currently performing the carry/hold (an object) in the scene 8 seconds ago?",
        "answer": "[0.33, 0.34, 0.49, 0.98]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "Ekwy7wzLfjc",
        "candidates": [
            "[0.22, 0.45, 0.21, 1.00]",
            "[0.33, 0.34, 0.49, 0.98]",
            "[0.00, 0.00, 0.74, 0.98]",
            "[0.56, 0.12, 0.61, 0.96]"
        ],
        "start": 0.0,
        "end": 495.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1391.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "walk -> carry/hold (an object)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "Ekwy7wzLfjc",
        "candidates": [
            "walk -> carry/hold (an object)",
            "stir -> carry/hold (an object)",
            "dig -> carry/hold (an object)",
            "climb (e.g., a mountain) -> walk"
        ],
        "start": 0.0,
        "end": 496.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1444.0,
        "question": "Is the person currently in the [0.20, 0.01, 0.95, 0.98] location in the current frame performing the talk to (e.g., self, a person, a group)?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "Ekwy7wzLfjc",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 549.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1465.0,
        "question": "Where is the person currently performing the walk located in the picture?",
        "answer": "[0.60, 0.36, 0.71, 0.66]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "Ekwy7wzLfjc",
        "candidates": [
            "[0.60, 0.36, 0.71, 0.66]",
            "[0.33, 0.16, 0.62, 0.88]",
            "[0.78, 0.48, 0.92, 0.85]",
            "[0.82, 0.09, 0.82, 0.89]"
        ],
        "start": 0.0,
        "end": 570.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1519.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "carry/hold (an object) -> text on/look at a cellphone",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "Ekwy7wzLfjc",
        "candidates": [
            "carry/hold (an object) -> walk",
            "text on/look at a cellphone -> carry/hold (an object)",
            "carry/hold (an object) -> text on/look at a cellphone",
            "watch (e.g., TV) -> text on/look at a cellphone"
        ],
        "start": 0.0,
        "end": 624.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1528.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.17, 0.34, 0.40, 1.00] location?",
        "answer": "answer phone [0.39, 0.26, 0.60, 0.99] -> carry/hold (an object) [0.39, 0.26, 0.60, 0.99] -> walk [0.17, 0.34, 0.40, 1.00]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "Ekwy7wzLfjc",
        "candidates": [
            "carry/hold (an object) [0.25, 0.09, 0.79, 0.95] -> walk [0.37, 0.42, 0.39, 0.99] -> dress/put on clothing [0.46, 0.18, 0.60, 1.00]",
            "answer phone [0.39, 0.26, 0.60, 0.99] -> carry/hold (an object) [0.39, 0.26, 0.60, 0.99] -> walk [0.17, 0.34, 0.40, 1.00]",
            "walk [0.37, 0.25, 0.30, 1.00] -> push (an object) [0.36, 0.27, 0.59, 0.87] -> answer phone [0.21, 0.30, 0.45, 1.00]",
            "answer phone [0.30, 0.44, 0.73, 0.90] -> carry/hold (an object) [0.47, 0.26, 0.49, 1.00] -> write [0.18, 0.17, 0.32, 1.00]"
        ],
        "start": 0.0,
        "end": 633.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1531.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.08, 0.39, 0.15, 0.79] location?",
        "answer": "carry/hold (an object) [0.02, 0.37, 0.12, 0.89] -> walk [0.08, 0.39, 0.15, 0.79] -> answer phone [0.08, 0.39, 0.15, 0.79]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "Ekwy7wzLfjc",
        "candidates": [
            "carry/hold (an object) [0.02, 0.37, 0.12, 0.89] -> walk [0.08, 0.39, 0.15, 0.79] -> answer phone [0.08, 0.39, 0.15, 0.79]",
            "carry/hold (an object) [0.00, 0.17, 0.18, 0.89] -> extract [0.26, 0.56, 0.04, 0.97] -> answer phone [0.08, 0.45, 0.33, 0.64]",
            "answer phone [0.09, 0.44, 0.34, 0.81] -> walk [0.26, 0.30, 0.01, 0.64] -> grab (a person) [0.00, 0.42, 0.00, 0.95]",
            "dress/put on clothing [0.16, 0.48, 0.14, 0.87] -> answer phone [0.00, 0.43, 0.00, 0.74] -> carry/hold (an object) [0.00, 0.53, 0.12, 1.00]"
        ],
        "start": 0.0,
        "end": 636.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1687.0,
        "question": "Where is the person currently performing the walk located in the picture?",
        "answer": "[0.19, 0.15, 0.81, 0.99]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "Ekwy7wzLfjc",
        "candidates": [
            "[0.36, 0.00, 1.00, 1.00]",
            "[0.31, 0.30, 0.98, 1.00]",
            "[0.19, 0.15, 0.81, 0.99]",
            "[0.04, 0.00, 0.66, 0.98]"
        ],
        "start": 0.0,
        "end": 792.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1731.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.18, 0.01, 0.88, 0.97]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "Ekwy7wzLfjc",
        "candidates": [
            "[0.00, 0.00, 0.93, 0.68]",
            "[0.00, 0.04, 0.67, 1.00]",
            "[0.62, 0.03, 0.99, 0.96]",
            "[0.18, 0.01, 0.88, 0.97]"
        ],
        "start": 0.0,
        "end": 836.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1744.0,
        "question": "Are there still 2 people in the current frame now?",
        "answer": "No",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "Ekwy7wzLfjc",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 849.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 914.0,
        "question": "Where was the person currently performing the answer phone in the scene 8 seconds ago?",
        "answer": "[0.29, 0.20, 0.36, 0.60]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "G4qq1MRXCiY",
        "candidates": [
            "[0.24, 0.04, 0.67, 0.97]",
            "[0.13, 0.12, 0.18, 0.46]",
            "[0.29, 0.20, 0.36, 0.60]",
            "[0.09, 0.02, 0.61, 0.43]"
        ],
        "start": 0.0,
        "end": 19.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 925.0,
        "question": "Are there still 2 people in the current frame now?",
        "answer": "No",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "G4qq1MRXCiY",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 30.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1021.0,
        "question": "Where is the person currently performing the walk located in the picture?",
        "answer": "[0.35, 0.39, 0.47, 0.98]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "G4qq1MRXCiY",
        "candidates": [
            "[0.35, 0.39, 0.47, 0.98]",
            "[0.59, 0.43, 0.62, 1.00]",
            "[0.24, 0.04, 0.98, 0.97]",
            "[0.57, 0.11, 0.31, 0.78]"
        ],
        "start": 0.0,
        "end": 126.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1137.0,
        "question": "Where is the person currently performing the brush teeth located in the picture?",
        "answer": "[0.40, 0.33, 0.68, 0.99]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "G4qq1MRXCiY",
        "candidates": [
            "[0.20, 0.02, 0.82, 1.00]",
            "[0.14, 0.17, 0.52, 1.00]",
            "[0.40, 0.33, 0.68, 0.99]",
            "[0.14, 0.52, 0.47, 1.00]"
        ],
        "start": 0.0,
        "end": 242.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1202.0,
        "question": "Is the person currently in the [0.45, 0.31, 0.56, 0.84] location in the current frame performing the carry/hold (an object)?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "G4qq1MRXCiY",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 307.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1336.0,
        "question": "What action is the person at the location [0.10, 0.07, 0.79, 0.98] in the image performing?",
        "answer": "stand, talk to (e.g., self, a person, a group), watch (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "G4qq1MRXCiY",
        "candidates": [
            "stand, listen to (a person)",
            "stand, carry/hold (an object), listen to (a person), watch (a person)",
            "stand, talk to (e.g., self, a person, a group), watch (a person)",
            "stand, talk to (e.g., self, a person, a group)"
        ],
        "start": 0.0,
        "end": 441.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1369.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.55, 0.29, 0.66, 0.68]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "G4qq1MRXCiY",
        "candidates": [
            "[0.53, 0.50, 0.90, 0.82]",
            "[0.80, 0.29, 0.96, 0.84]",
            "[0.70, 0.20, 0.85, 0.53]",
            "[0.55, 0.29, 0.66, 0.68]"
        ],
        "start": 0.0,
        "end": 474.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1375.0,
        "question": "What action is the person currently in the [0.02, 0.28, 0.11, 0.59] location likely to do next?",
        "answer": "carry/hold (an object)",
        "sub_answer_type": "FuturePrediction-1",
        "answer_type": "FuturePrediction",
        "video": "G4qq1MRXCiY",
        "candidates": [
            "cut",
            "carry/hold (an object)",
            "answer phone",
            "dance"
        ],
        "start": 0.0,
        "end": 480.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1420.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.04, 0.02, 0.73, 0.98]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "G4qq1MRXCiY",
        "candidates": [
            "[0.01, 0.28, 0.49, 0.90]",
            "[0.53, 0.03, 0.94, 1.00]",
            "[0.04, 0.02, 0.73, 0.98]",
            "[0.21, 0.11, 0.91, 0.89]"
        ],
        "start": 0.0,
        "end": 525.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1464.0,
        "question": "What action is the person at the location [0.03, 0.31, 0.12, 0.62] in the image performing?",
        "answer": "stand, carry/hold (an object), listen to (a person), talk to (e.g., self, a person, a group), watch (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "G4qq1MRXCiY",
        "candidates": [
            "stand, carry/hold (an object), talk to (e.g., self, a person, a group), watch (a person)",
            "stand, carry/hold (an object), listen to (a person), watch (a person)",
            "stand, carry/hold (an object), listen to (a person), talk to (e.g., self, a person, a group), watch (a person)",
            "stand, watch (a person)"
        ],
        "start": 0.0,
        "end": 569.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1530.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.35, 0.24, 0.51, 0.99]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "G4qq1MRXCiY",
        "candidates": [
            "[0.35, 0.24, 0.51, 0.99]",
            "[0.09, 0.27, 0.30, 0.98]",
            "[0.47, 0.12, 0.53, 0.82]",
            "[0.56, 0.34, 0.62, 1.00]"
        ],
        "start": 0.0,
        "end": 635.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1635.0,
        "question": "Where is the person currently performing the talk to (e.g., self, a person, a group) located in the picture?",
        "answer": "[0.07, 0.10, 0.34, 0.97]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "G4qq1MRXCiY",
        "candidates": [
            "[0.05, 0.00, 0.20, 0.78]",
            "[0.00, 0.02, 0.75, 0.96]",
            "[0.07, 0.10, 0.34, 0.97]",
            "[0.36, 0.30, 0.53, 1.00]"
        ],
        "start": 0.0,
        "end": 740.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1713.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.16, 0.00, 0.79, 0.99]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "G4qq1MRXCiY",
        "candidates": [
            "[0.41, 0.06, 0.90, 1.00]",
            "[0.16, 0.00, 0.79, 0.99]",
            "[0.73, 0.02, 1.00, 0.97]",
            "[0.00, 0.28, 0.85, 1.00]"
        ],
        "start": 0.0,
        "end": 818.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1744.0,
        "question": "Is the person currently in the [0.82, 0.37, 1.00, 1.00] location in the current frame performing the eat?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "G4qq1MRXCiY",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 849.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1767.0,
        "question": "What location in the frame is the person currently in the [0.48, 0.39, 0.58, 0.70] location likely to move to next?",
        "answer": "[0.76, 0.09, 1.00, 1.00]",
        "sub_answer_type": "FuturePrediction-2",
        "answer_type": "FuturePrediction",
        "video": "G4qq1MRXCiY",
        "candidates": [
            "[0.58, 0.37, 0.95, 1.00]",
            "[0.52, 0.22, 0.75, 0.99]",
            "[0.66, 0.00, 0.89, 0.79]",
            "[0.76, 0.09, 1.00, 1.00]"
        ],
        "start": 0.0,
        "end": 872.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 966.0,
        "question": "Is the person currently in the [0.28, 0.07, 0.87, 1.00] location in the current frame performing the talk to (e.g., self, a person, a group)?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "Gvp-cj3bmIY",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 71.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 994.0,
        "question": "How many people in the current frame are performing the action:  ride (e.g., a bike, a car, a horse)?",
        "answer": "2",
        "sub_answer_type": "SpatialPerception-2",
        "answer_type": "SpatialPerception",
        "video": "Gvp-cj3bmIY",
        "candidates": [
            "6",
            "2",
            "3",
            "4"
        ],
        "start": 0.0,
        "end": 99.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1027.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.48, 0.17, 0.71, 0.98] location?",
        "answer": "ride (e.g., a bike, a car, a horse) [0.45, 0.13, 0.72, 1.00] -> talk to (e.g., self, a person, a group) [0.45, 0.13, 0.72, 1.00] -> carry/hold (an object) [0.48, 0.17, 0.71, 0.98]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "Gvp-cj3bmIY",
        "candidates": [
            "ride (e.g., a bike, a car, a horse) [0.45, 0.13, 0.72, 1.00] -> talk to (e.g., self, a person, a group) [0.45, 0.13, 0.72, 1.00] -> carry/hold (an object) [0.48, 0.17, 0.71, 0.98]",
            "talk to (e.g., self, a person, a group) [0.57, 0.00, 0.63, 1.00] -> ride (e.g., a bike, a car, a horse) [0.43, 0.25, 0.85, 1.00] -> take (an object) from (a person) [0.65, 0.11, 0.69, 1.00]",
            "brush teeth [0.26, 0.00, 0.89, 1.00] -> talk to (e.g., self, a person, a group) [0.61, 0.00, 0.54, 0.97] -> carry/hold (an object) [0.36, 0.12, 0.70, 0.85]",
            "ride (e.g., a bike, a car, a horse) [0.36, 0.20, 0.56, 0.92] -> kick (a person) [0.64, 0.03, 0.55, 0.88] -> talk to (e.g., self, a person, a group) [0.33, 0.32, 0.80, 1.00]"
        ],
        "start": 0.0,
        "end": 132.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1073.0,
        "question": "Are there still 3 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "Gvp-cj3bmIY",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 178.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1098.0,
        "question": "What action is the person at the location [0.15, 0.22, 0.45, 0.98] in the image performing?",
        "answer": "sit, ride (e.g., a bike, a car, a horse), listen to (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "Gvp-cj3bmIY",
        "candidates": [
            "walk, carry/hold (an object)",
            "stand, talk to (e.g., self, a person, a group), watch (a person)",
            "sit, ride (e.g., a bike, a car, a horse), listen to (a person)",
            "walk, watch (a person)"
        ],
        "start": 0.0,
        "end": 203.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1219.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.13, 0.01, 0.54, 1.00]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "Gvp-cj3bmIY",
        "candidates": [
            "[0.20, 0.30, 0.26, 1.00]",
            "[0.64, 0.35, 0.81, 0.92]",
            "[0.13, 0.01, 0.54, 1.00]",
            "[0.16, 0.00, 0.72, 0.71]"
        ],
        "start": 0.0,
        "end": 324.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1237.0,
        "question": "What action is the person currently in the [0.65, 0.03, 0.82, 0.97] location likely to do next?",
        "answer": "paint",
        "sub_answer_type": "FuturePrediction-1",
        "answer_type": "FuturePrediction",
        "video": "Gvp-cj3bmIY",
        "candidates": [
            "walk",
            "open (e.g., a window, a car door)",
            "paint",
            "crouch/kneel"
        ],
        "start": 0.0,
        "end": 342.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1280.0,
        "question": "Where was the person currently performing the carry/hold (an object) in the scene 8 seconds ago?",
        "answer": "[0.25, 0.15, 0.52, 0.93]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "Gvp-cj3bmIY",
        "candidates": [
            "[0.38, 0.30, 0.80, 1.00]",
            "[0.57, 0.04, 0.73, 0.94]",
            "[0.04, 0.00, 0.28, 0.93]",
            "[0.25, 0.15, 0.52, 0.93]"
        ],
        "start": 0.0,
        "end": 385.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1294.0,
        "question": "Where is the person currently performing the walk located in the picture?",
        "answer": "[0.39, 0.21, 0.57, 0.98]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "Gvp-cj3bmIY",
        "candidates": [
            "[0.46, 0.48, 0.67, 1.00]",
            "[0.39, 0.21, 0.57, 0.98]",
            "[0.57, 0.04, 0.85, 1.00]",
            "[0.10, 0.00, 0.40, 0.79]"
        ],
        "start": 0.0,
        "end": 399.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1315.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.14, 0.05, 0.56, 0.96] location?",
        "answer": "carry/hold (an object) [0.14, 0.05, 0.56, 0.96] -> talk to (e.g., self, a person, a group) [0.14, 0.05, 0.56, 0.96] -> lie/sleep [0.14, 0.05, 0.56, 0.96]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "Gvp-cj3bmIY",
        "candidates": [
            "carry/hold (an object) [0.14, 0.05, 0.56, 0.96] -> talk to (e.g., self, a person, a group) [0.14, 0.05, 0.56, 0.96] -> lie/sleep [0.14, 0.05, 0.56, 0.96]",
            "talk to (e.g., self, a person, a group) [0.13, 0.20, 0.48, 0.94] -> carry/hold (an object) [0.00, 0.24, 0.42, 0.95] -> get up [0.03, 0.16, 0.64, 0.78]",
            "talk to (e.g., self, a person, a group) [0.08, 0.00, 0.59, 0.93] -> grab (a person) [0.27, 0.11, 0.74, 0.90] -> carry/hold (an object) [0.04, 0.00, 0.67, 0.92]",
            "lie/sleep [0.27, 0.00, 0.39, 1.00] -> text on/look at a cellphone [0.20, 0.19, 0.65, 1.00] -> carry/hold (an object) [0.02, 0.00, 0.74, 0.98]"
        ],
        "start": 0.0,
        "end": 420.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1320.0,
        "question": "Are there still 2 people in the current frame now?",
        "answer": "No",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "Gvp-cj3bmIY",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 425.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1343.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.13, 0.02, 0.62, 1.00] location?",
        "answer": "bend/bow (at the waist) [0.13, 0.02, 0.62, 1.00] -> carry/hold (an object) [0.13, 0.02, 0.62, 1.00] -> talk to (e.g., self, a person, a group) [0.13, 0.02, 0.62, 1.00]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "Gvp-cj3bmIY",
        "candidates": [
            "carry/hold (an object) [0.14, 0.12, 0.79, 0.98] -> bend/bow (at the waist) [0.30, 0.17, 0.58, 0.99] -> swim [0.07, 0.00, 0.57, 0.88]",
            "carry/hold (an object) [0.00, 0.00, 0.50, 0.88] -> carry/hold (an object) [0.00, 0.00, 0.45, 0.93] -> bend/bow (at the waist) [0.30, 0.00, 0.74, 0.95]",
            "bend/bow (at the waist) [0.13, 0.02, 0.62, 1.00] -> carry/hold (an object) [0.13, 0.02, 0.62, 1.00] -> talk to (e.g., self, a person, a group) [0.13, 0.02, 0.62, 1.00]",
            "text on/look at a cellphone [0.03, 0.00, 0.79, 1.00] -> bend/bow (at the waist) [0.17, 0.09, 0.49, 1.00] -> carry/hold (an object) [0.05, 0.07, 0.51, 0.94]"
        ],
        "start": 0.0,
        "end": 448.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1350.0,
        "question": "What action is the person at the location [0.17, 0.13, 0.62, 0.94] in the image performing?",
        "answer": "carry/hold (an object), lie/sleep",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "Gvp-cj3bmIY",
        "candidates": [
            "stand, listen to (a person), watch (a person)",
            "sit, ride (e.g., a bike, a car, a horse)",
            "carry/hold (an object), lie/sleep",
            "stand, carry/hold (an object), smoke"
        ],
        "start": 0.0,
        "end": 455.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1384.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.36, 0.00, 0.86, 0.96] location?",
        "answer": "carry/hold (an object) [0.36, 0.00, 0.86, 0.96] -> talk to (e.g., self, a person, a group) [0.36, 0.00, 0.86, 0.96] -> lie/sleep [0.36, 0.00, 0.86, 0.96]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "Gvp-cj3bmIY",
        "candidates": [
            "lie/sleep [0.33, 0.09, 1.00, 0.86] -> carry/hold (an object) [0.51, 0.01, 0.77, 0.79] -> shoot [0.32, 0.01, 0.82, 1.00]",
            "talk to (e.g., self, a person, a group) [0.47, 0.00, 0.97, 0.82] -> carry/hold (an object) [0.45, 0.01, 0.66, 1.00] -> exit [0.56, 0.11, 0.93, 1.00]",
            "lie/sleep [0.26, 0.09, 0.81, 0.93] -> point to (an object) [0.30, 0.00, 0.78, 0.84] -> talk to (e.g., self, a person, a group) [0.43, 0.11, 0.94, 1.00]",
            "carry/hold (an object) [0.36, 0.00, 0.86, 0.96] -> talk to (e.g., self, a person, a group) [0.36, 0.00, 0.86, 0.96] -> lie/sleep [0.36, 0.00, 0.86, 0.96]"
        ],
        "start": 0.0,
        "end": 489.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1392.0,
        "question": "Where was the person currently performing the lie/sleep in the scene 8 seconds ago?",
        "answer": "[0.23, 0.01, 0.83, 0.99]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "Gvp-cj3bmIY",
        "candidates": [
            "[0.38, 0.00, 0.89, 0.73]",
            "[0.55, 0.16, 0.86, 0.99]",
            "[0.23, 0.01, 0.83, 0.99]",
            "[0.13, 0.00, 0.57, 0.71]"
        ],
        "start": 0.0,
        "end": 497.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1545.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.19, 0.04, 0.59, 0.98]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "Gvp-cj3bmIY",
        "candidates": [
            "[0.12, 0.32, 0.38, 0.83]",
            "[0.19, 0.04, 0.59, 0.98]",
            "[0.53, 0.14, 0.70, 0.99]",
            "[0.00, 0.00, 0.34, 0.81]"
        ],
        "start": 0.0,
        "end": 650.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1561.0,
        "question": "Are there still 1 people in the current frame now?",
        "answer": "No",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "Gvp-cj3bmIY",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 666.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1580.0,
        "question": "Where is the person currently performing the talk to (e.g., self, a person, a group) located in the picture?",
        "answer": "[0.14, 0.01, 0.70, 1.00]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "Gvp-cj3bmIY",
        "candidates": [
            "[0.57, 0.00, 0.66, 0.67]",
            "[0.14, 0.01, 0.70, 1.00]",
            "[0.00, 0.19, 0.43, 1.00]",
            "[0.01, 0.00, 0.44, 0.75]"
        ],
        "start": 0.0,
        "end": 685.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1703.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.54, 0.00, 0.85, 0.96] location?",
        "answer": "carry/hold (an object) [0.57, 0.04, 0.73, 0.94] -> talk to (e.g., self, a person, a group) [0.57, 0.04, 0.73, 0.94] -> walk [0.54, 0.00, 0.85, 0.96]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "Gvp-cj3bmIY",
        "candidates": [
            "fall down [0.48, 0.00, 0.90, 1.00] -> talk to (e.g., self, a person, a group) [0.42, 0.09, 0.90, 0.78] -> carry/hold (an object) [0.50, 0.00, 0.89, 0.98]",
            "carry/hold (an object) [0.52, 0.13, 0.62, 0.78] -> martial art [0.41, 0.00, 0.85, 0.79] -> talk to (e.g., self, a person, a group) [0.69, 0.00, 0.62, 0.91]",
            "carry/hold (an object) [0.57, 0.04, 0.73, 0.94] -> talk to (e.g., self, a person, a group) [0.57, 0.04, 0.73, 0.94] -> walk [0.54, 0.00, 0.85, 0.96]",
            "walk [0.57, 0.00, 0.75, 0.96] -> put down [0.61, 0.00, 0.85, 1.00] -> carry/hold (an object) [0.47, 0.00, 0.73, 1.00]"
        ],
        "start": 0.0,
        "end": 808.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1713.0,
        "question": "Where was the person currently performing the bend/bow (at the waist) in the scene 8 seconds ago?",
        "answer": "[0.24, 0.23, 0.58, 0.95]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "Gvp-cj3bmIY",
        "candidates": [
            "[0.00, 0.24, 0.45, 0.96]",
            "[0.66, 0.31, 0.85, 0.92]",
            "[0.24, 0.23, 0.58, 0.95]",
            "[0.49, 0.00, 0.67, 1.00]"
        ],
        "start": 0.0,
        "end": 818.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1036.0,
        "question": "How many people in the current frame are performing the action:  martial art?",
        "answer": "2",
        "sub_answer_type": "SpatialPerception-2",
        "answer_type": "SpatialPerception",
        "video": "Hscyg0vLKc8",
        "candidates": [
            "5",
            "2",
            "3",
            "4"
        ],
        "start": 0.0,
        "end": 141.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1065.0,
        "question": "What action is the person at the location [0.72, 0.49, 0.83, 0.89] in the image performing?",
        "answer": "stand, watch (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "Hscyg0vLKc8",
        "candidates": [
            "stand, watch (a person)",
            "stand, carry/hold (an object), listen to (a person), watch (a person)",
            "fight/hit (a person), martial art",
            "stand, carry/hold (an object), listen to (a person)"
        ],
        "start": 0.0,
        "end": 170.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1068.0,
        "question": "Are there still 2 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "Hscyg0vLKc8",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 173.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1096.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.00, 0.14, 0.57, 0.91]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "Hscyg0vLKc8",
        "candidates": [
            "[0.32, 0.26, 0.60, 0.90]",
            "[0.00, 0.00, 0.40, 0.78]",
            "[0.00, 0.14, 0.57, 0.91]",
            "[0.00, 0.30, 0.27, 0.97]"
        ],
        "start": 0.0,
        "end": 201.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1117.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "talk to (e.g., self, a person, a group) -> carry/hold (an object)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "Hscyg0vLKc8",
        "candidates": [
            "talk to (e.g., self, a person, a group) -> carry/hold (an object)",
            "extract -> carry/hold (an object)",
            "press -> talk to (e.g., self, a person, a group)",
            "talk to (e.g., self, a person, a group) -> fall down"
        ],
        "start": 0.0,
        "end": 222.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1256.0,
        "question": "Are there still 2 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "Hscyg0vLKc8",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 361.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1259.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.15, 0.23, 0.42, 0.88]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "Hscyg0vLKc8",
        "candidates": [
            "[0.37, 0.45, 0.39, 0.94]",
            "[0.15, 0.23, 0.42, 0.88]",
            "[0.09, 0.00, 0.15, 0.69]",
            "[0.71, 0.28, 0.97, 0.90]"
        ],
        "start": 0.0,
        "end": 364.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1286.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "carry/hold (an object) -> talk to (e.g., self, a person, a group)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "Hscyg0vLKc8",
        "candidates": [
            "carry/hold (an object) -> throw",
            "talk to (e.g., self, a person, a group) -> shoot",
            "carry/hold (an object) -> talk to (e.g., self, a person, a group)",
            "talk to (e.g., self, a person, a group) -> work on a computer"
        ],
        "start": 0.0,
        "end": 391.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1306.0,
        "question": "Where was the person currently performing the carry/hold (an object) in the scene 8 seconds ago?",
        "answer": "[0.49, 0.24, 0.88, 0.89]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "Hscyg0vLKc8",
        "candidates": [
            "[0.23, 0.45, 1.00, 1.00]",
            "[0.72, 0.20, 0.58, 0.60]",
            "[0.10, 0.34, 0.77, 0.67]",
            "[0.49, 0.24, 0.88, 0.89]"
        ],
        "start": 0.0,
        "end": 411.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1322.0,
        "question": "What action is the person currently in the [0.68, 0.28, 0.90, 0.89] location likely to do next?",
        "answer": "talk to (e.g., self, a person, a group)",
        "sub_answer_type": "FuturePrediction-1",
        "answer_type": "FuturePrediction",
        "video": "Hscyg0vLKc8",
        "candidates": [
            "carry/hold (an object)",
            "point to (an object)",
            "talk to (e.g., self, a person, a group)",
            "fight/hit (a person)"
        ],
        "start": 0.0,
        "end": 427.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1412.0,
        "question": "Where is the person currently performing the martial art located in the picture?",
        "answer": "[0.11, 0.10, 0.69, 0.90]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "Hscyg0vLKc8",
        "candidates": [
            "[0.08, 0.23, 0.41, 1.00]",
            "[0.11, 0.10, 0.69, 0.90]",
            "[0.39, 0.40, 0.58, 0.88]",
            "[0.22, 0.15, 0.90, 0.85]"
        ],
        "start": 0.0,
        "end": 517.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1490.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "carry/hold (an object) -> talk to (e.g., self, a person, a group)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "Hscyg0vLKc8",
        "candidates": [
            "talk to (e.g., self, a person, a group) -> write",
            "carry/hold (an object) -> talk to (e.g., self, a person, a group)",
            "play board game -> talk to (e.g., self, a person, a group)",
            "open (e.g., a window, a car door) -> carry/hold (an object)"
        ],
        "start": 0.0,
        "end": 595.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1528.0,
        "question": "How many people in the current frame are performing the action:  fight/hit (a person)?",
        "answer": "2",
        "sub_answer_type": "SpatialPerception-2",
        "answer_type": "SpatialPerception",
        "video": "Hscyg0vLKc8",
        "candidates": [
            "2",
            "3",
            "9",
            "4"
        ],
        "start": 0.0,
        "end": 633.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1663.0,
        "question": "How many people in the current frame are performing the action:  martial art?",
        "answer": "3",
        "sub_answer_type": "SpatialPerception-2",
        "answer_type": "SpatialPerception",
        "video": "Hscyg0vLKc8",
        "candidates": [
            "6",
            "3",
            "2",
            "4"
        ],
        "start": 0.0,
        "end": 768.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1667.0,
        "question": "How many people were performing the watch (a person) in the scene 60 seconds ago?",
        "answer": "9",
        "sub_answer_type": "PastMemory-5",
        "answer_type": "PastMemory",
        "video": "Hscyg0vLKc8",
        "candidates": [
            "9",
            "5",
            "7",
            "8"
        ],
        "start": 0.0,
        "end": 772.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1679.0,
        "question": "Is the person currently in the [0.07, 0.08, 0.76, 0.88] location in the current frame performing the lie/sleep?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "Hscyg0vLKc8",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 784.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1680.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "fight/hit (a person) -> lie/sleep",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "Hscyg0vLKc8",
        "candidates": [
            "hand clap -> lie/sleep",
            "lie/sleep -> work on a computer",
            "fight/hit (a person) -> lie/sleep",
            "cut -> lie/sleep"
        ],
        "start": 0.0,
        "end": 785.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1699.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "lie/sleep -> fall down",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "Hscyg0vLKc8",
        "candidates": [
            "fall down -> get up",
            "lie/sleep -> smoke",
            "fall down -> brush teeth",
            "lie/sleep -> fall down"
        ],
        "start": 0.0,
        "end": 804.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1746.0,
        "question": "Where was the person currently performing the carry/hold (an object) in the scene 8 seconds ago?",
        "answer": "[0.30, 0.22, 0.61, 0.90]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "Hscyg0vLKc8",
        "candidates": [
            "[0.36, 0.05, 0.66, 0.63]",
            "[0.19, 0.03, 0.45, 0.87]",
            "[0.43, 0.23, 0.88, 0.89]",
            "[0.30, 0.22, 0.61, 0.90]"
        ],
        "start": 0.0,
        "end": 851.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 913.0,
        "question": "What action is the person currently in the [0.43, 0.12, 0.71, 0.98] location likely to do next?",
        "answer": "walk and carry/hold (an object)",
        "sub_answer_type": "FuturePrediction-1",
        "answer_type": "FuturePrediction",
        "video": "IzvOYVMltkI",
        "candidates": [
            "walk and carry/hold (an object)",
            "play board game",
            "talk to (e.g., self, a person, a group) and lie/sleep",
            "exit"
        ],
        "start": 0.0,
        "end": 18.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 925.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.42, 0.06, 0.61, 0.74] location?",
        "answer": "carry/hold (an object) [0.42, 0.06, 0.61, 0.74] -> close (e.g., a door, a box) [0.42, 0.06, 0.61, 0.74] -> talk to (e.g., self, a person, a group) [0.42, 0.06, 0.61, 0.74]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "IzvOYVMltkI",
        "candidates": [
            "extract [0.41, 0.00, 0.41, 0.77] -> carry/hold (an object) [0.53, 0.00, 0.76, 0.80] -> talk to (e.g., self, a person, a group) [0.34, 0.23, 0.55, 0.78]",
            "carry/hold (an object) [0.42, 0.06, 0.61, 0.74] -> close (e.g., a door, a box) [0.42, 0.06, 0.61, 0.74] -> talk to (e.g., self, a person, a group) [0.42, 0.06, 0.61, 0.74]",
            "carry/hold (an object) [0.43, 0.25, 0.67, 0.73] -> talk to (e.g., self, a person, a group) [0.27, 0.01, 0.42, 0.69] -> point to (an object) [0.55, 0.00, 0.68, 0.90]",
            "close (e.g., a door, a box) [0.31, 0.02, 0.66, 0.86] -> ride (e.g., a bike, a car, a horse) [0.56, 0.25, 0.62, 0.65] -> talk to (e.g., self, a person, a group) [0.26, 0.04, 0.73, 0.77]"
        ],
        "start": 0.0,
        "end": 30.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 934.0,
        "question": "Are there still 2 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "IzvOYVMltkI",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 39.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 963.0,
        "question": "What action is the person at the location [0.06, 0.07, 0.38, 0.74] in the image performing?",
        "answer": "bend/bow (at the waist), pull (an object)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "IzvOYVMltkI",
        "candidates": [
            "sit, carry/hold (an object), write",
            "sit, listen to (a person)",
            "sit, listen to (a person), watch (a person)",
            "bend/bow (at the waist), pull (an object)"
        ],
        "start": 0.0,
        "end": 68.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 975.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "talk to (e.g., self, a person, a group) -> lie/sleep",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "IzvOYVMltkI",
        "candidates": [
            "talk to (e.g., self, a person, a group) -> lie/sleep",
            "talk to (e.g., self, a person, a group) -> jump/leap",
            "lie/sleep -> paint",
            "lie/sleep -> clink glass"
        ],
        "start": 0.0,
        "end": 80.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1024.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "carry/hold (an object) -> talk to (e.g., self, a person, a group) -> lie/sleep",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "IzvOYVMltkI",
        "candidates": [
            "put down -> lie/sleep -> carry/hold (an object)",
            "carry/hold (an object) -> talk to (e.g., self, a person, a group) -> lie/sleep",
            "talk to (e.g., self, a person, a group) -> carry/hold (an object) -> sing to (e.g., self, a person, a group)",
            "talk to (e.g., self, a person, a group) -> work on a computer -> carry/hold (an object)"
        ],
        "start": 0.0,
        "end": 129.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1094.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "carry/hold (an object) -> talk to (e.g., self, a person, a group)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "IzvOYVMltkI",
        "candidates": [
            "carry/hold (an object) -> push (another person)",
            "carry/hold (an object) -> talk to (e.g., self, a person, a group)",
            "throw -> carry/hold (an object)",
            "talk to (e.g., self, a person, a group) -> talk to (e.g., self, a person, a group)"
        ],
        "start": 0.0,
        "end": 199.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1136.0,
        "question": "Where is the person currently performing the talk to (e.g., self, a person, a group) located in the picture?",
        "answer": "[0.22, 0.09, 0.95, 0.99]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "IzvOYVMltkI",
        "candidates": [
            "[0.12, 0.00, 1.00, 0.70]",
            "[0.21, 0.33, 0.53, 1.00]",
            "[0.51, 0.25, 0.96, 0.72]",
            "[0.22, 0.09, 0.95, 0.99]"
        ],
        "start": 0.0,
        "end": 241.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1144.0,
        "question": "Is the person currently in the [0.33, 0.15, 0.80, 0.99] location in the current frame performing the talk to (e.g., self, a person, a group)?",
        "answer": "No",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "IzvOYVMltkI",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 249.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1185.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "walk -> open (e.g., a window, a car door)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "IzvOYVMltkI",
        "candidates": [
            "work on a computer -> open (e.g., a window, a car door)",
            "walk -> open (e.g., a window, a car door)",
            "drive (e.g., a car, a truck) -> walk",
            "walk -> grab (a person)"
        ],
        "start": 0.0,
        "end": 290.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1222.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.46, 0.00, 0.81, 1.00]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "IzvOYVMltkI",
        "candidates": [
            "[0.28, 0.00, 0.75, 0.75]",
            "[0.43, 0.27, 0.57, 1.00]",
            "[0.65, 0.15, 0.97, 1.00]",
            "[0.46, 0.00, 0.81, 1.00]"
        ],
        "start": 0.0,
        "end": 327.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1296.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.54, 0.11, 0.78, 0.92] location?",
        "answer": "walk [0.54, 0.11, 0.78, 0.92] -> carry/hold (an object) [0.54, 0.11, 0.78, 0.92] -> talk to (e.g., self, a person, a group) [0.54, 0.11, 0.78, 0.92]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "IzvOYVMltkI",
        "candidates": [
            "walk [0.54, 0.11, 0.78, 0.92] -> carry/hold (an object) [0.54, 0.11, 0.78, 0.92] -> talk to (e.g., self, a person, a group) [0.54, 0.11, 0.78, 0.92]",
            "carry/hold (an object) [0.56, 0.09, 0.71, 0.95] -> dance [0.36, 0.00, 0.59, 0.78] -> talk to (e.g., self, a person, a group) [0.61, 0.00, 0.60, 0.85]",
            "crouch/kneel [0.70, 0.23, 0.74, 0.75] -> talk to (e.g., self, a person, a group) [0.66, 0.00, 0.64, 1.00] -> carry/hold (an object) [0.49, 0.11, 0.75, 0.72]",
            "walk [0.38, 0.01, 0.82, 0.93] -> carry/hold (an object) [0.39, 0.06, 0.89, 0.98] -> push (another person) [0.43, 0.30, 0.88, 0.95]"
        ],
        "start": 0.0,
        "end": 401.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1373.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "talk to (e.g., self, a person, a group) -> take (an object) from (a person)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "IzvOYVMltkI",
        "candidates": [
            "talk to (e.g., self, a person, a group) -> take (an object) from (a person)",
            "take (an object) from (a person) -> push (an object)",
            "play board game -> take (an object) from (a person)",
            "talk to (e.g., self, a person, a group) -> give/serve (an object) to (a person)"
        ],
        "start": 0.0,
        "end": 478.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1383.0,
        "question": "How many people were performing the carry/hold (an object) in the scene 120 seconds ago?",
        "answer": "3",
        "sub_answer_type": "PastMemory-5",
        "answer_type": "PastMemory",
        "video": "IzvOYVMltkI",
        "candidates": [
            "4",
            "6",
            "5",
            "3"
        ],
        "start": 0.0,
        "end": 488.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1438.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.09, 0.01, 0.37, 0.96] location?",
        "answer": "walk [0.09, 0.01, 0.37, 0.96] -> carry/hold (an object) [0.09, 0.01, 0.37, 0.96] -> talk to (e.g., self, a person, a group) [0.09, 0.01, 0.37, 0.96]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "IzvOYVMltkI",
        "candidates": [
            "talk to (e.g., self, a person, a group) [0.18, 0.00, 0.49, 1.00] -> walk [0.00, 0.07, 0.56, 1.00] -> kiss (a person) [0.22, 0.00, 0.54, 0.95]",
            "talk to (e.g., self, a person, a group) [0.27, 0.08, 0.47, 0.89] -> walk [0.00, 0.18, 0.41, 1.00] -> play with pets [0.20, 0.00, 0.52, 1.00]",
            "walk [0.09, 0.01, 0.37, 0.96] -> carry/hold (an object) [0.09, 0.01, 0.37, 0.96] -> talk to (e.g., self, a person, a group) [0.09, 0.01, 0.37, 0.96]",
            "walk [0.11, 0.10, 0.56, 0.98] -> fall down [0.00, 0.06, 0.45, 0.76] -> talk to (e.g., self, a person, a group) [0.00, 0.13, 0.18, 0.96]"
        ],
        "start": 0.0,
        "end": 543.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1448.0,
        "question": "Where is the person currently performing the dress/put on clothing located in the picture?",
        "answer": "[0.05, 0.07, 0.49, 0.99]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "IzvOYVMltkI",
        "candidates": [
            "[0.25, 0.34, 0.42, 1.00]",
            "[0.05, 0.07, 0.49, 0.99]",
            "[0.37, 0.06, 0.74, 0.98]",
            "[0.04, 0.28, 0.20, 1.00]"
        ],
        "start": 0.0,
        "end": 553.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1465.0,
        "question": "Is the person currently in the [0.27, 0.01, 0.77, 0.97] location in the current frame performing the talk to (e.g., self, a person, a group)?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "IzvOYVMltkI",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 570.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1466.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.27, 0.01, 0.77, 0.97] location?",
        "answer": "smoke [0.35, 0.04, 0.90, 0.98] -> talk to (e.g., self, a person, a group) [0.35, 0.04, 0.90, 0.98] -> walk [0.27, 0.01, 0.77, 0.97] -> carry/hold (an object) [0.27, 0.01, 0.77, 0.97]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "IzvOYVMltkI",
        "candidates": [
            "smoke [0.44, 0.02, 0.88, 1.00] -> talk to (e.g., self, a person, a group) [0.39, 0.00, 0.71, 1.00] -> cook [0.41, 0.00, 0.89, 0.88] -> carry/hold (an object) [0.23, 0.00, 0.74, 0.95]",
            "carry/hold (an object) [0.12, 0.00, 0.80, 0.77] -> eat [0.53, 0.24, 0.95, 0.86] -> smoke [0.33, 0.20, 0.76, 0.84] -> walk [0.28, 0.00, 0.85, 0.91]",
            "smoke [0.35, 0.04, 0.90, 0.98] -> talk to (e.g., self, a person, a group) [0.35, 0.04, 0.90, 0.98] -> walk [0.27, 0.01, 0.77, 0.97] -> carry/hold (an object) [0.27, 0.01, 0.77, 0.97]",
            "walk [0.44, 0.19, 0.85, 1.00] -> smoke [0.27, 0.12, 0.74, 1.00] -> talk to (e.g., self, a person, a group) [0.33, 0.09, 0.98, 1.00] -> lift (a person) [0.33, 0.06, 0.57, 1.00]"
        ],
        "start": 0.0,
        "end": 571.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1483.0,
        "question": "How many people were performing the watch (a person) in the scene 240 seconds ago?",
        "answer": "5",
        "sub_answer_type": "PastMemory-5",
        "answer_type": "PastMemory",
        "video": "IzvOYVMltkI",
        "candidates": [
            "7",
            "4",
            "3",
            "5"
        ],
        "start": 0.0,
        "end": 588.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1524.0,
        "question": "What action is the person at the location [0.04, 0.32, 0.30, 0.97] in the image performing?",
        "answer": "sit, drink",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "IzvOYVMltkI",
        "candidates": [
            "stand, listen to (a person)",
            "walk, talk to (e.g., self, a person, a group), watch (a person)",
            "sit, drink",
            "sit, listen to (a person), watch (a person)"
        ],
        "start": 0.0,
        "end": 629.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1615.0,
        "question": "How many people in the current frame are performing the action:  talk to (e.g., self, a person, a group)?",
        "answer": "3",
        "sub_answer_type": "SpatialPerception-2",
        "answer_type": "SpatialPerception",
        "video": "IzvOYVMltkI",
        "candidates": [
            "7",
            "4",
            "2",
            "3"
        ],
        "start": 0.0,
        "end": 720.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1634.0,
        "question": "Is the person currently in the [0.10, 0.05, 0.91, 0.98] location in the current frame performing the ride (e.g., a bike, a car, a horse)?",
        "answer": "No",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "IzvOYVMltkI",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 739.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1675.0,
        "question": "Where was the person currently performing the carry/hold (an object) in the scene 8 seconds ago?",
        "answer": "[0.20, 0.62, 0.45, 1.00]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "IzvOYVMltkI",
        "candidates": [
            "[0.20, 0.62, 0.45, 1.00]",
            "[0.11, 0.78, 0.19, 1.00]",
            "[0.40, 0.33, 0.17, 0.71]",
            "[0.04, 0.35, 0.39, 0.99]"
        ],
        "start": 0.0,
        "end": 780.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1755.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.38, 0.22, 0.61, 0.97] location?",
        "answer": "carry/hold (an object) [0.41, 0.24, 0.69, 0.99] -> talk to (e.g., self, a person, a group) [0.41, 0.24, 0.69, 0.99] -> walk [0.38, 0.22, 0.61, 0.97]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "IzvOYVMltkI",
        "candidates": [
            "fight/hit (a person) [0.42, 0.15, 0.77, 1.00] -> talk to (e.g., self, a person, a group) [0.46, 0.38, 0.54, 0.87] -> carry/hold (an object) [0.57, 0.18, 0.76, 0.98]",
            "carry/hold (an object) [0.44, 0.42, 0.62, 1.00] -> give/serve (an object) to (a person) [0.29, 0.05, 0.77, 1.00] -> walk [0.20, 0.40, 0.48, 0.87]",
            "carry/hold (an object) [0.61, 0.19, 0.69, 1.00] -> point to (an object) [0.47, 0.35, 0.55, 0.99] -> talk to (e.g., self, a person, a group) [0.27, 0.40, 0.86, 1.00]",
            "carry/hold (an object) [0.41, 0.24, 0.69, 0.99] -> talk to (e.g., self, a person, a group) [0.41, 0.24, 0.69, 0.99] -> walk [0.38, 0.22, 0.61, 0.97]"
        ],
        "start": 0.0,
        "end": 860.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1758.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.11, 0.05, 0.48, 0.99]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "IzvOYVMltkI",
        "candidates": [
            "[0.00, 0.00, 0.49, 0.74]",
            "[0.09, 0.28, 0.18, 1.00]",
            "[0.26, 0.04, 0.79, 0.95]",
            "[0.11, 0.05, 0.48, 0.99]"
        ],
        "start": 0.0,
        "end": 863.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 928.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "walk -> carry/hold (an object) -> drink",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "KHHgQ_Pe4cI",
        "candidates": [
            "get up -> carry/hold (an object) -> walk",
            "walk -> run/jog -> drink",
            "walk -> carry/hold (an object) -> drink",
            "walk -> play with pets -> carry/hold (an object)"
        ],
        "start": 0.0,
        "end": 33.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 983.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.30, 0.15, 0.69, 0.98] location?",
        "answer": "carry/hold (an object) [0.30, 0.15, 0.69, 0.98] -> crouch/kneel [0.30, 0.15, 0.69, 0.98] -> talk to (e.g., self, a person, a group) [0.30, 0.15, 0.69, 0.98]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "KHHgQ_Pe4cI",
        "candidates": [
            "carry/hold (an object) [0.30, 0.15, 0.69, 0.98] -> crouch/kneel [0.30, 0.15, 0.69, 0.98] -> talk to (e.g., self, a person, a group) [0.30, 0.15, 0.69, 0.98]",
            "push (an object) [0.28, 0.07, 0.81, 1.00] -> crouch/kneel [0.39, 0.22, 0.53, 1.00] -> talk to (e.g., self, a person, a group) [0.35, 0.07, 0.88, 1.00]",
            "carry/hold (an object) [0.42, 0.30, 0.85, 0.92] -> read [0.36, 0.16, 0.74, 0.91] -> crouch/kneel [0.46, 0.24, 0.74, 0.92]",
            "carry/hold (an object) [0.29, 0.18, 0.82, 0.85] -> talk to (e.g., self, a person, a group) [0.46, 0.19, 0.57, 0.82] -> write [0.43, 0.25, 0.74, 1.00]"
        ],
        "start": 0.0,
        "end": 88.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 988.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.30, 0.15, 0.69, 0.98] location?",
        "answer": "carry/hold (an object) [0.30, 0.15, 0.69, 0.98] -> crouch/kneel [0.30, 0.15, 0.69, 0.98] -> talk to (e.g., self, a person, a group) [0.30, 0.15, 0.69, 0.98]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "KHHgQ_Pe4cI",
        "candidates": [
            "fishing [0.39, 0.29, 0.70, 0.92] -> talk to (e.g., self, a person, a group) [0.27, 0.24, 0.62, 1.00] -> crouch/kneel [0.43, 0.28, 0.52, 1.00]",
            "carry/hold (an object) [0.30, 0.15, 0.69, 0.98] -> crouch/kneel [0.30, 0.15, 0.69, 0.98] -> talk to (e.g., self, a person, a group) [0.30, 0.15, 0.69, 0.98]",
            "carry/hold (an object) [0.14, 0.23, 0.64, 0.95] -> crouch/kneel [0.45, 0.28, 0.68, 0.90] -> hug (a person) [0.38, 0.13, 0.88, 0.90]",
            "crouch/kneel [0.12, 0.01, 0.87, 1.00] -> dress/put on clothing [0.32, 0.31, 0.71, 1.00] -> carry/hold (an object) [0.22, 0.11, 0.62, 1.00]"
        ],
        "start": 0.0,
        "end": 93.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 991.0,
        "question": "Are there still 1 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "KHHgQ_Pe4cI",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 96.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 993.0,
        "question": "Where was the person currently performing the carry/hold (an object) in the scene 8 seconds ago?",
        "answer": "[0.28, 0.16, 0.70, 0.98]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "KHHgQ_Pe4cI",
        "candidates": [
            "[0.32, 0.34, 0.41, 1.00]",
            "[0.00, 0.00, 0.49, 0.81]",
            "[0.28, 0.16, 0.70, 0.98]",
            "[0.52, 0.24, 0.85, 0.91]"
        ],
        "start": 0.0,
        "end": 98.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1016.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "carry/hold (an object) -> take (an object) from (a person) -> talk to (e.g., self, a person, a group)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "KHHgQ_Pe4cI",
        "candidates": [
            "carry/hold (an object) -> take (an object) from (a person) -> talk to (e.g., self, a person, a group)",
            "talk to (e.g., self, a person, a group) -> get up -> carry/hold (an object)",
            "carry/hold (an object) -> push (another person) -> take (an object) from (a person)",
            "read -> take (an object) from (a person) -> carry/hold (an object)"
        ],
        "start": 0.0,
        "end": 121.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1037.0,
        "question": "Where is the person currently performing the talk to (e.g., self, a person, a group) located in the picture?",
        "answer": "[0.12, 0.01, 0.67, 0.98]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "KHHgQ_Pe4cI",
        "candidates": [
            "[0.32, 0.00, 0.56, 0.69]",
            "[0.43, 0.18, 0.82, 0.97]",
            "[0.12, 0.01, 0.67, 0.98]",
            "[0.00, 0.29, 0.55, 1.00]"
        ],
        "start": 0.0,
        "end": 142.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1063.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.39, 0.22, 0.61, 0.85]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "KHHgQ_Pe4cI",
        "candidates": [
            "[0.39, 0.22, 0.61, 0.85]",
            "[0.10, 0.42, 0.83, 1.00]",
            "[0.67, 0.05, 0.54, 0.62]",
            "[0.59, 0.39, 0.75, 0.92]"
        ],
        "start": 0.0,
        "end": 168.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1172.0,
        "question": "What action is the person at the location [0.12, 0.08, 0.51, 0.98] in the image performing?",
        "answer": "stand, listen to (a person), watch (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "KHHgQ_Pe4cI",
        "candidates": [
            "stand, listen to (a person), watch (a person)",
            "stand, carry/hold (an object), talk to (e.g., self, a person, a group)",
            "stand, carry/hold (an object), listen to (a person), watch (a person)",
            "stand, carry/hold (an object), talk to (e.g., self, a person, a group), watch (a person)"
        ],
        "start": 0.0,
        "end": 277.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1194.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "talk to (e.g., self, a person, a group) -> carry/hold (an object)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "KHHgQ_Pe4cI",
        "candidates": [
            "talk to (e.g., self, a person, a group) -> carry/hold (an object)",
            "talk to (e.g., self, a person, a group) -> point to (an object)",
            "shovel -> talk to (e.g., self, a person, a group)",
            "talk to (e.g., self, a person, a group) -> hand shake"
        ],
        "start": 0.0,
        "end": 299.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1258.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.33, 0.19, 0.47, 0.89]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "KHHgQ_Pe4cI",
        "candidates": [
            "[0.62, 0.17, 0.83, 0.97]",
            "[0.54, 0.03, 0.63, 1.00]",
            "[0.42, 0.01, 0.43, 0.67]",
            "[0.33, 0.19, 0.47, 0.89]"
        ],
        "start": 0.0,
        "end": 363.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1283.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "read -> carry/hold (an object)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "KHHgQ_Pe4cI",
        "candidates": [
            "catch (an object) -> read",
            "point to (an object) -> carry/hold (an object)",
            "read -> carry/hold (an object)",
            "carry/hold (an object) -> hand wave"
        ],
        "start": 0.0,
        "end": 388.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1354.0,
        "question": "Where is the person currently performing the talk to (e.g., self, a person, a group) located in the picture?",
        "answer": "[0.43, 0.14, 0.76, 0.97]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "KHHgQ_Pe4cI",
        "candidates": [
            "[0.43, 0.14, 0.76, 0.97]",
            "[0.49, 0.01, 0.52, 0.69]",
            "[0.35, 0.22, 0.43, 0.78]",
            "[0.38, 0.40, 0.96, 1.00]"
        ],
        "start": 0.0,
        "end": 459.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1357.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "talk to (e.g., self, a person, a group) -> carry/hold (an object)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "KHHgQ_Pe4cI",
        "candidates": [
            "play with pets -> carry/hold (an object)",
            "carry/hold (an object) -> play board game",
            "talk to (e.g., self, a person, a group) -> carry/hold (an object)",
            "hug (a person) -> carry/hold (an object)"
        ],
        "start": 0.0,
        "end": 462.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1407.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.24, 0.12, 0.48, 0.90]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "KHHgQ_Pe4cI",
        "candidates": [
            "[0.48, 0.00, 0.71, 0.77]",
            "[0.24, 0.12, 0.48, 0.90]",
            "[0.55, 0.07, 0.88, 0.94]",
            "[0.23, 0.33, 0.35, 1.00]"
        ],
        "start": 0.0,
        "end": 512.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1447.0,
        "question": "Are there still 2 people in the current frame now?",
        "answer": "No",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "KHHgQ_Pe4cI",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 552.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1533.0,
        "question": "Are there still 1 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "KHHgQ_Pe4cI",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 638.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1622.0,
        "question": "What action is the person at the location [0.13, 0.04, 0.68, 0.98] in the image performing?",
        "answer": "stand, listen to (a person), talk to (e.g., self, a person, a group), watch (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "KHHgQ_Pe4cI",
        "candidates": [
            "sit, listen to (a person)",
            "stand, talk to (e.g., self, a person, a group)",
            "stand, talk to (e.g., self, a person, a group), watch (a person)",
            "stand, listen to (a person), talk to (e.g., self, a person, a group), watch (a person)"
        ],
        "start": 0.0,
        "end": 727.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1657.0,
        "question": "What action is the person at the location [0.39, 0.14, 0.49, 0.81] in the image performing?",
        "answer": "walk, watch (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "KHHgQ_Pe4cI",
        "candidates": [
            "stand, carry/hold (an object)",
            "stand, carry/hold (an object), watch (a person)",
            "walk, watch (a person)",
            "stand, listen to (a person)"
        ],
        "start": 0.0,
        "end": 762.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1660.0,
        "question": "What action is the person currently in the [0.58, 0.39, 0.75, 0.92] location likely to do next?",
        "answer": "carry/hold (an object)",
        "sub_answer_type": "FuturePrediction-1",
        "answer_type": "FuturePrediction",
        "video": "KHHgQ_Pe4cI",
        "candidates": [
            "carry/hold (an object)",
            "touch (an object)",
            "cook",
            "chop"
        ],
        "start": 0.0,
        "end": 765.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1714.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.37, 0.19, 0.56, 0.96] location?",
        "answer": "carry/hold (an object) [0.35, 0.21, 0.55, 0.97] -> talk to (e.g., self, a person, a group) [0.35, 0.21, 0.55, 0.97] -> walk [0.37, 0.19, 0.56, 0.96]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "KHHgQ_Pe4cI",
        "candidates": [
            "walk [0.54, 0.09, 0.46, 1.00] -> talk to (e.g., self, a person, a group) [0.26, 0.33, 0.59, 0.79] -> hand wave [0.31, 0.29, 0.67, 1.00]",
            "play with kids [0.30, 0.39, 0.69, 0.91] -> carry/hold (an object) [0.37, 0.11, 0.46, 0.98] -> talk to (e.g., self, a person, a group) [0.48, 0.30, 0.71, 1.00]",
            "walk [0.47, 0.13, 0.51, 1.00] -> talk to (e.g., self, a person, a group) [0.32, 0.24, 0.58, 0.84] -> push (an object) [0.27, 0.11, 0.35, 0.85]",
            "carry/hold (an object) [0.35, 0.21, 0.55, 0.97] -> talk to (e.g., self, a person, a group) [0.35, 0.21, 0.55, 0.97] -> walk [0.37, 0.19, 0.56, 0.96]"
        ],
        "start": 0.0,
        "end": 819.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1722.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.35, 0.23, 0.58, 0.84] location?",
        "answer": "carry/hold (an object) [0.35, 0.23, 0.58, 0.84] -> put down [0.35, 0.23, 0.58, 0.84] -> talk to (e.g., self, a person, a group) [0.35, 0.23, 0.58, 0.84]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "KHHgQ_Pe4cI",
        "candidates": [
            "carry/hold (an object) [0.35, 0.23, 0.58, 0.84] -> put down [0.35, 0.23, 0.58, 0.84] -> talk to (e.g., self, a person, a group) [0.35, 0.23, 0.58, 0.84]",
            "carry/hold (an object) [0.34, 0.30, 0.51, 0.89] -> talk to (e.g., self, a person, a group) [0.23, 0.40, 0.48, 0.67] -> dress/put on clothing [0.20, 0.36, 0.71, 0.85]",
            "talk to (e.g., self, a person, a group) [0.31, 0.04, 0.62, 0.79] -> play board game [0.22, 0.31, 0.53, 0.83] -> put down [0.40, 0.24, 0.41, 1.00]",
            "put down [0.16, 0.33, 0.50, 0.93] -> put down [0.49, 0.28, 0.71, 0.89] -> talk to (e.g., self, a person, a group) [0.30, 0.23, 0.66, 0.97]"
        ],
        "start": 0.0,
        "end": 827.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1773.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.20, 0.41, 0.55, 0.98] location?",
        "answer": "lie/sleep [0.19, 0.44, 0.55, 0.98] -> carry/hold (an object) [0.20, 0.41, 0.55, 0.98] -> talk to (e.g., self, a person, a group) [0.20, 0.41, 0.55, 0.98]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "KHHgQ_Pe4cI",
        "candidates": [
            "talk to (e.g., self, a person, a group) [0.13, 0.49, 0.65, 0.99] -> exit [0.23, 0.53, 0.43, 1.00] -> lie/sleep [0.15, 0.48, 0.70, 0.99]",
            "carry/hold (an object) [0.27, 0.31, 0.52, 0.88] -> talk to (e.g., self, a person, a group) [0.02, 0.54, 0.38, 0.80] -> ride (e.g., a bike, a car, a horse) [0.00, 0.63, 0.41, 0.80]",
            "shovel [0.32, 0.35, 0.56, 0.78] -> talk to (e.g., self, a person, a group) [0.28, 0.44, 0.45, 0.86] -> carry/hold (an object) [0.16, 0.41, 0.60, 0.99]",
            "lie/sleep [0.19, 0.44, 0.55, 0.98] -> carry/hold (an object) [0.20, 0.41, 0.55, 0.98] -> talk to (e.g., self, a person, a group) [0.20, 0.41, 0.55, 0.98]"
        ],
        "start": 0.0,
        "end": 878.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1792.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.17, 0.22, 0.42, 0.73]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "KHHgQ_Pe4cI",
        "candidates": [
            "[0.12, 0.49, 0.16, 0.93]",
            "[0.00, 0.10, 0.54, 0.50]",
            "[0.17, 0.22, 0.42, 0.73]",
            "[0.14, 0.13, 0.71, 0.98]"
        ],
        "start": 0.0,
        "end": 897.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 934.0,
        "question": "What action is the person at the location [0.01, 0.11, 0.47, 0.95] in the image performing?",
        "answer": "stand, talk to (e.g., self, a person, a group), watch (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "KVq6If6ozMY",
        "candidates": [
            "stand, talk to (e.g., self, a person, a group)",
            "stand, listen to (a person)",
            "stand, talk to (e.g., self, a person, a group), watch (a person)",
            "stand, carry/hold (an object), talk to (e.g., self, a person, a group), watch (a person)"
        ],
        "start": 0.0,
        "end": 39.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 963.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.46, 0.13, 0.98, 0.92] location?",
        "answer": "write [0.48, 0.14, 0.97, 0.92] -> talk to (e.g., self, a person, a group) [0.48, 0.14, 0.97, 0.92] -> carry/hold (an object) [0.46, 0.13, 0.98, 0.92]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "KVq6If6ozMY",
        "candidates": [
            "carry/hold (an object) [0.46, 0.30, 1.00, 1.00] -> get up [0.63, 0.01, 1.00, 0.80] -> write [0.43, 0.03, 0.80, 0.98]",
            "talk to (e.g., self, a person, a group) [0.28, 0.22, 1.00, 0.84] -> row boat [0.60, 0.24, 0.91, 0.97] -> carry/hold (an object) [0.32, 0.32, 1.00, 0.83]",
            "write [0.48, 0.14, 0.97, 0.92] -> talk to (e.g., self, a person, a group) [0.48, 0.14, 0.97, 0.92] -> carry/hold (an object) [0.46, 0.13, 0.98, 0.92]",
            "throw [0.35, 0.24, 0.93, 0.97] -> carry/hold (an object) [0.56, 0.00, 0.93, 0.97] -> talk to (e.g., self, a person, a group) [0.52, 0.23, 1.00, 0.75]"
        ],
        "start": 0.0,
        "end": 68.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 987.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "carry/hold (an object) -> write -> talk to (e.g., self, a person, a group)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "KVq6If6ozMY",
        "candidates": [
            "carry/hold (an object) -> write -> talk to (e.g., self, a person, a group)",
            "talk to (e.g., self, a person, a group) -> cut -> write",
            "write -> climb (e.g., a mountain) -> carry/hold (an object)",
            "drink -> write -> talk to (e.g., self, a person, a group)"
        ],
        "start": 0.0,
        "end": 92.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1030.0,
        "question": "Where was the person currently performing the carry/hold (an object) in the scene 8 seconds ago?",
        "answer": "[0.18, 0.29, 0.48, 0.89]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "KVq6If6ozMY",
        "candidates": [
            "[0.18, 0.29, 0.48, 0.89]",
            "[0.25, 0.49, 0.40, 1.00]",
            "[0.34, 0.21, 0.70, 0.87]",
            "[0.56, 0.15, 0.98, 0.91]"
        ],
        "start": 0.0,
        "end": 135.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1060.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "carry/hold (an object) -> talk to (e.g., self, a person, a group)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "KVq6If6ozMY",
        "candidates": [
            "carry/hold (an object) -> sail boat",
            "carry/hold (an object) -> talk to (e.g., self, a person, a group)",
            "give/serve (an object) to (a person) -> talk to (e.g., self, a person, a group)",
            "talk to (e.g., self, a person, a group) -> open (e.g., a window, a car door)"
        ],
        "start": 0.0,
        "end": 165.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1072.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.36, 0.20, 0.92, 0.87] location?",
        "answer": "carry/hold (an object) [0.36, 0.20, 0.92, 0.87] -> pull (an object) [0.36, 0.20, 0.92, 0.87] -> talk to (e.g., self, a person, a group) [0.36, 0.20, 0.92, 0.87]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "KVq6If6ozMY",
        "candidates": [
            "sail boat [0.27, 0.36, 0.87, 0.75] -> talk to (e.g., self, a person, a group) [0.43, 0.16, 1.00, 0.71] -> pull (an object) [0.27, 0.09, 0.79, 0.69]",
            "hand wave [0.54, 0.09, 0.72, 0.79] -> pull (an object) [0.34, 0.34, 0.73, 0.97] -> talk to (e.g., self, a person, a group) [0.22, 0.28, 0.90, 0.99]",
            "carry/hold (an object) [0.36, 0.20, 0.92, 0.87] -> pull (an object) [0.36, 0.20, 0.92, 0.87] -> talk to (e.g., self, a person, a group) [0.36, 0.20, 0.92, 0.87]",
            "pull (an object) [0.20, 0.30, 0.91, 0.71] -> carry/hold (an object) [0.55, 0.01, 1.00, 0.72] -> talk to (e.g., self, a person, a group) [0.25, 0.23, 1.00, 0.80]"
        ],
        "start": 0.0,
        "end": 177.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1075.0,
        "question": "Are there still 2 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "KVq6If6ozMY",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 180.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1098.0,
        "question": "What action is the person at the location [0.32, 0.23, 0.54, 0.56] in the image performing?",
        "answer": "watch (a person), martial art",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "KVq6If6ozMY",
        "candidates": [
            "stand, listen to (a person), watch (a person)",
            "stand, carry/hold (an object), watch (e.g., TV)",
            "watch (a person), martial art",
            "sit, carry/hold (an object), listen to (a person), watch (a person)"
        ],
        "start": 0.0,
        "end": 203.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1175.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "lie/sleep -> talk to (e.g., self, a person, a group)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "KVq6If6ozMY",
        "candidates": [
            "clink glass -> lie/sleep",
            "lie/sleep -> get up",
            "lie/sleep -> hand wave",
            "lie/sleep -> talk to (e.g., self, a person, a group)"
        ],
        "start": 0.0,
        "end": 280.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1192.0,
        "question": "Where was the person currently performing the walk in the scene 8 seconds ago?",
        "answer": "[0.23, 0.24, 0.46, 0.78]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "KVq6If6ozMY",
        "candidates": [
            "[0.05, 0.10, 0.62, 0.61]",
            "[0.44, 0.00, 0.73, 0.59]",
            "[0.48, 0.17, 0.93, 0.89]",
            "[0.23, 0.24, 0.46, 0.78]"
        ],
        "start": 0.0,
        "end": 297.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1226.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.36, 0.26, 0.52, 0.87] location?",
        "answer": "walk [0.36, 0.26, 0.52, 0.87] -> carry/hold (an object) [0.36, 0.26, 0.52, 0.87] -> talk to (e.g., self, a person, a group) [0.36, 0.26, 0.52, 0.87]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "KVq6If6ozMY",
        "candidates": [
            "talk to (e.g., self, a person, a group) [0.24, 0.09, 0.69, 0.90] -> carry/hold (an object) [0.49, 0.32, 0.45, 1.00] -> dress/put on clothing [0.53, 0.21, 0.34, 0.77]",
            "talk to (e.g., self, a person, a group) [0.50, 0.28, 0.34, 0.84] -> talk to (e.g., self, a person, a group) [0.18, 0.14, 0.33, 0.92] -> walk [0.51, 0.26, 0.69, 0.87]",
            "walk [0.36, 0.26, 0.52, 0.87] -> carry/hold (an object) [0.36, 0.26, 0.52, 0.87] -> talk to (e.g., self, a person, a group) [0.36, 0.26, 0.52, 0.87]",
            "carry/hold (an object) [0.21, 0.45, 0.71, 0.88] -> talk to (e.g., self, a person, a group) [0.38, 0.15, 0.47, 1.00] -> kick (an object) [0.18, 0.18, 0.46, 0.90]"
        ],
        "start": 0.0,
        "end": 331.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1234.0,
        "question": "Is the person currently in the [0.04, 0.14, 0.60, 0.86] location in the current frame performing the talk to (e.g., self, a person, a group)?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "KVq6If6ozMY",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 339.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1280.0,
        "question": "What action is the person at the location [0.00, 0.11, 0.27, 0.91] in the image performing?",
        "answer": "stand, listen to (a person), watch (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "KVq6If6ozMY",
        "candidates": [
            "stand, listen to (a person), watch (a person)",
            "sit, carry/hold (an object), talk to (e.g., self, a person, a group), watch (a person)",
            "stand, talk to (e.g., self, a person, a group), watch (a person)",
            "stand, watch (a person)"
        ],
        "start": 0.0,
        "end": 385.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1290.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "carry/hold (an object) -> talk to (e.g., self, a person, a group)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "KVq6If6ozMY",
        "candidates": [
            "carry/hold (an object) -> hand clap",
            "carry/hold (an object) -> talk to (e.g., self, a person, a group)",
            "hug (a person) -> talk to (e.g., self, a person, a group)",
            "lift/pick up -> carry/hold (an object)"
        ],
        "start": 0.0,
        "end": 395.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1313.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.53, 0.26, 0.82, 0.85] location?",
        "answer": "bend/bow (at the waist) [0.53, 0.26, 0.82, 0.85] -> touch (an object) [0.53, 0.26, 0.82, 0.85] -> talk to (e.g., self, a person, a group) [0.53, 0.26, 0.82, 0.85]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "KVq6If6ozMY",
        "candidates": [
            "talk to (e.g., self, a person, a group) [0.36, 0.38, 0.88, 1.00] -> bend/bow (at the waist) [0.70, 0.23, 0.69, 0.78] -> shovel [0.48, 0.36, 0.69, 0.87]",
            "bend/bow (at the waist) [0.43, 0.10, 0.70, 0.68] -> talk to (e.g., self, a person, a group) [0.54, 0.41, 0.98, 0.68] -> open (e.g., a window, a car door) [0.50, 0.19, 0.70, 0.66]",
            "bend/bow (at the waist) [0.40, 0.35, 0.73, 0.81] -> touch (an object) [0.56, 0.39, 0.76, 0.79] -> talk to (e.g., self, a person, a group) [0.70, 0.14, 0.65, 1.00]",
            "bend/bow (at the waist) [0.53, 0.26, 0.82, 0.85] -> touch (an object) [0.53, 0.26, 0.82, 0.85] -> talk to (e.g., self, a person, a group) [0.53, 0.26, 0.82, 0.85]"
        ],
        "start": 0.0,
        "end": 418.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1379.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.57, 0.19, 0.95, 0.90] location?",
        "answer": "walk [0.57, 0.19, 0.95, 0.90] -> carry/hold (an object) [0.57, 0.19, 0.95, 0.90] -> talk to (e.g., self, a person, a group) [0.57, 0.19, 0.95, 0.90]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "KVq6If6ozMY",
        "candidates": [
            "walk [0.75, 0.02, 0.95, 0.73] -> swim [0.68, 0.38, 0.85, 0.72] -> talk to (e.g., self, a person, a group) [0.53, 0.17, 1.00, 0.85]",
            "walk [0.57, 0.19, 0.95, 0.90] -> carry/hold (an object) [0.57, 0.19, 0.95, 0.90] -> talk to (e.g., self, a person, a group) [0.57, 0.19, 0.95, 0.90]",
            "walk [0.53, 0.38, 0.93, 1.00] -> sail boat [0.74, 0.30, 0.76, 1.00] -> carry/hold (an object) [0.38, 0.30, 1.00, 0.81]",
            "talk to (e.g., self, a person, a group) [0.60, 0.30, 0.87, 0.90] -> dance [0.50, 0.11, 0.98, 0.72] -> carry/hold (an object) [0.69, 0.25, 0.95, 0.88]"
        ],
        "start": 0.0,
        "end": 484.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1456.0,
        "question": "Are there still 1 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "KVq6If6ozMY",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 561.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1505.0,
        "question": "What action is the person currently in the [0.08, 0.23, 0.52, 0.90] location likely to do next?",
        "answer": "sing to (e.g., self, a person, a group)",
        "sub_answer_type": "FuturePrediction-1",
        "answer_type": "FuturePrediction",
        "video": "KVq6If6ozMY",
        "candidates": [
            "sing to (e.g., self, a person, a group)",
            "carry/hold (an object) and climb (e.g., a mountain)",
            "kick (a person)",
            "push (another person)"
        ],
        "start": 0.0,
        "end": 610.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1509.0,
        "question": "Where is the person currently performing the walk located in the picture?",
        "answer": "[0.12, 0.30, 0.77, 0.88]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "KVq6If6ozMY",
        "candidates": [
            "[0.39, 0.33, 0.84, 0.90]",
            "[0.29, 0.55, 0.98, 1.00]",
            "[0.00, 0.33, 0.55, 0.88]",
            "[0.12, 0.30, 0.77, 0.88]"
        ],
        "start": 0.0,
        "end": 614.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1554.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.46, 0.16, 0.98, 0.89]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "KVq6If6ozMY",
        "candidates": [
            "[0.46, 0.16, 0.98, 0.89]",
            "[0.23, 0.00, 1.00, 0.65]",
            "[0.75, 0.36, 0.91, 1.00]",
            "[0.28, 0.23, 0.55, 0.84]"
        ],
        "start": 0.0,
        "end": 659.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1608.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "bend/bow (at the waist) -> carry/hold (an object)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "KVq6If6ozMY",
        "candidates": [
            "bend/bow (at the waist) -> row boat",
            "walk -> bend/bow (at the waist)",
            "bend/bow (at the waist) -> carry/hold (an object)",
            "bend/bow (at the waist) -> climb (e.g., a mountain)"
        ],
        "start": 0.0,
        "end": 713.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1734.0,
        "question": "What action is the person at the location [0.12, 0.19, 0.37, 0.88] in the image performing?",
        "answer": "stand, carry/hold (an object), listen to (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "KVq6If6ozMY",
        "candidates": [
            "sit, carry/hold (an object), listen to (a person), watch (a person)",
            "stand, carry/hold (an object), listen to (a person)",
            "stand, talk to (e.g., self, a person, a group)",
            "stand, carry/hold (an object)"
        ],
        "start": 0.0,
        "end": 839.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1748.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.65, 0.39, 0.97, 0.89]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "KVq6If6ozMY",
        "candidates": [
            "[0.91, 0.19, 0.89, 0.81]",
            "[0.41, 0.10, 1.00, 0.95]",
            "[0.65, 0.39, 0.97, 0.89]",
            "[0.08, 0.25, 0.34, 0.85]"
        ],
        "start": 0.0,
        "end": 853.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1764.0,
        "question": "Where was the person currently performing the carry/hold (an object) in the scene 8 seconds ago?",
        "answer": "[0.00, 0.13, 0.29, 0.89]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "KVq6If6ozMY",
        "candidates": [
            "[0.25, 0.09, 0.92, 0.99]",
            "[0.00, 0.00, 0.02, 0.83]",
            "[0.00, 0.13, 0.29, 0.89]",
            "[0.23, 0.00, 0.51, 1.00]"
        ],
        "start": 0.0,
        "end": 869.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 912.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.51, 0.24, 0.87, 0.97]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "Lg1jOu8cUBM",
        "candidates": [
            "[0.51, 0.24, 0.87, 0.97]",
            "[0.72, 0.46, 0.97, 1.00]",
            "[0.79, 0.03, 1.00, 1.00]",
            "[0.07, 0.12, 0.92, 0.98]"
        ],
        "start": 0.0,
        "end": 17.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 918.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "smoke -> talk to (e.g., self, a person, a group)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "Lg1jOu8cUBM",
        "candidates": [
            "smoke -> talk to (e.g., self, a person, a group)",
            "smoke -> work on a computer",
            "shoot -> smoke",
            "talk to (e.g., self, a person, a group) -> clink glass"
        ],
        "start": 0.0,
        "end": 23.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 960.0,
        "question": "Are there still 1 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "Lg1jOu8cUBM",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 65.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 979.0,
        "question": "Where is the person currently performing the talk to (e.g., self, a person, a group) located in the picture?",
        "answer": "[0.21, 0.09, 0.98, 0.98]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "Lg1jOu8cUBM",
        "candidates": [
            "[0.02, 0.07, 0.86, 0.98]",
            "[0.38, 0.03, 1.00, 0.77]",
            "[0.49, 0.15, 1.00, 1.00]",
            "[0.21, 0.09, 0.98, 0.98]"
        ],
        "start": 0.0,
        "end": 84.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 997.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "talk to (e.g., self, a person, a group) -> walk",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "Lg1jOu8cUBM",
        "candidates": [
            "extract -> talk to (e.g., self, a person, a group)",
            "talk to (e.g., self, a person, a group) -> ride (e.g., a bike, a car, a horse)",
            "walk -> cook",
            "talk to (e.g., self, a person, a group) -> walk"
        ],
        "start": 0.0,
        "end": 102.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1000.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.00, 0.12, 0.97, 0.97] location?",
        "answer": "smoke [0.00, 0.11, 0.94, 0.99] -> talk to (e.g., self, a person, a group) [0.00, 0.11, 0.94, 0.99] -> carry/hold (an object) [0.00, 0.12, 0.97, 0.97]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "Lg1jOu8cUBM",
        "candidates": [
            "talk to (e.g., self, a person, a group) [0.02, 0.08, 0.92, 0.85] -> hug (a person) [0.06, 0.19, 0.97, 1.00] -> carry/hold (an object) [0.00, 0.31, 1.00, 1.00]",
            "smoke [0.00, 0.14, 0.89, 1.00] -> sail boat [0.00, 0.08, 1.00, 0.89] -> talk to (e.g., self, a person, a group) [0.09, 0.00, 1.00, 0.89]",
            "carry/hold (an object) [0.17, 0.14, 0.94, 0.96] -> swim [0.16, 0.19, 0.91, 0.98] -> smoke [0.19, 0.26, 0.84, 0.91]",
            "smoke [0.00, 0.11, 0.94, 0.99] -> talk to (e.g., self, a person, a group) [0.00, 0.11, 0.94, 0.99] -> carry/hold (an object) [0.00, 0.12, 0.97, 0.97]"
        ],
        "start": 0.0,
        "end": 105.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1070.0,
        "question": "Is the person currently in the [0.08, 0.10, 0.94, 0.98] location in the current frame performing the smoke?",
        "answer": "No",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "Lg1jOu8cUBM",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 175.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1109.0,
        "question": "What action is the person at the location [0.10, 0.05, 0.59, 0.99] in the image performing?",
        "answer": "sit, carry/hold (an object)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "Lg1jOu8cUBM",
        "candidates": [
            "carry/hold (an object), get up, talk to (e.g., self, a person, a group)",
            "stand, talk to (e.g., self, a person, a group), watch (a person)",
            "sit, carry/hold (an object)",
            "stand, carry/hold (an object), talk to (e.g., self, a person, a group)"
        ],
        "start": 0.0,
        "end": 214.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1159.0,
        "question": "What action is the person currently in the [0.21, 0.38, 0.27, 0.61] location likely to do next?",
        "answer": "walk",
        "sub_answer_type": "FuturePrediction-1",
        "answer_type": "FuturePrediction",
        "video": "Lg1jOu8cUBM",
        "candidates": [
            "press",
            "walk",
            "hug (a person)",
            "smoke and talk to (e.g., self, a person, a group)"
        ],
        "start": 0.0,
        "end": 264.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1159.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.21, 0.38, 0.27, 0.61] location?",
        "answer": "walk [0.21, 0.38, 0.27, 0.61] -> carry/hold (an object) [0.21, 0.38, 0.27, 0.61] -> talk to (e.g., self, a person, a group) [0.21, 0.38, 0.27, 0.61]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "Lg1jOu8cUBM",
        "candidates": [
            "carry/hold (an object) [0.10, 0.26, 0.40, 0.45] -> carry/hold (an object) [0.27, 0.46, 0.35, 0.66] -> walk [0.02, 0.38, 0.38, 0.78]",
            "carry/hold (an object) [0.35, 0.20, 0.12, 0.60] -> watch (e.g., TV) [0.24, 0.23, 0.28, 0.70] -> talk to (e.g., self, a person, a group) [0.35, 0.24, 0.40, 0.69]",
            "carry/hold (an object) [0.04, 0.47, 0.40, 0.51] -> talk to (e.g., self, a person, a group) [0.28, 0.49, 0.23, 0.65] -> swim [0.12, 0.28, 0.29, 0.41]",
            "walk [0.21, 0.38, 0.27, 0.61] -> carry/hold (an object) [0.21, 0.38, 0.27, 0.61] -> talk to (e.g., self, a person, a group) [0.21, 0.38, 0.27, 0.61]"
        ],
        "start": 0.0,
        "end": 264.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1164.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.26, 0.28, 0.38, 0.65] location?",
        "answer": "walk [0.26, 0.28, 0.38, 0.65] -> carry/hold (an object) [0.26, 0.28, 0.38, 0.65] -> talk to (e.g., self, a person, a group) [0.26, 0.28, 0.38, 0.65]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "Lg1jOu8cUBM",
        "candidates": [
            "kick (a person) [0.11, 0.24, 0.49, 0.66] -> walk [0.25, 0.31, 0.48, 0.53] -> carry/hold (an object) [0.43, 0.14, 0.47, 0.65]",
            "lift (a person) [0.12, 0.35, 0.34, 0.62] -> talk to (e.g., self, a person, a group) [0.12, 0.20, 0.49, 0.67] -> walk [0.07, 0.26, 0.38, 0.57]",
            "walk [0.26, 0.28, 0.38, 0.65] -> carry/hold (an object) [0.26, 0.28, 0.38, 0.65] -> talk to (e.g., self, a person, a group) [0.26, 0.28, 0.38, 0.65]",
            "walk [0.07, 0.28, 0.43, 0.69] -> talk to (e.g., self, a person, a group) [0.33, 0.29, 0.56, 0.51] -> sail boat [0.07, 0.11, 0.41, 0.78]"
        ],
        "start": 0.0,
        "end": 269.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1168.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.28, 0.14, 0.55, 0.99] location?",
        "answer": "walk [0.28, 0.14, 0.55, 0.99] -> carry/hold (an object) [0.28, 0.14, 0.55, 0.99] -> talk to (e.g., self, a person, a group) [0.28, 0.14, 0.55, 0.99]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "Lg1jOu8cUBM",
        "candidates": [
            "walk [0.28, 0.14, 0.55, 0.99] -> carry/hold (an object) [0.28, 0.14, 0.55, 0.99] -> talk to (e.g., self, a person, a group) [0.28, 0.14, 0.55, 0.99]",
            "carry/hold (an object) [0.27, 0.27, 0.59, 1.00] -> lie/sleep [0.30, 0.18, 0.41, 1.00] -> walk [0.35, 0.09, 0.50, 1.00]",
            "carry/hold (an object) [0.21, 0.27, 0.53, 0.93] -> walk [0.10, 0.23, 0.36, 1.00] -> talk to (e.g., self, a person, a group) [0.38, 0.23, 0.58, 0.85]",
            "talk to (e.g., self, a person, a group) [0.19, 0.20, 0.58, 0.90] -> walk [0.10, 0.05, 0.41, 1.00] -> answer phone [0.11, 0.11, 0.46, 0.87]"
        ],
        "start": 0.0,
        "end": 273.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1181.0,
        "question": "Where was the person currently performing the carry/hold (an object) in the scene 8 seconds ago?",
        "answer": "[0.07, 0.07, 0.97, 0.99]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "Lg1jOu8cUBM",
        "candidates": [
            "[0.07, 0.07, 0.97, 0.99]",
            "[0.00, 0.00, 1.00, 0.74]",
            "[0.21, 0.38, 0.27, 0.61]",
            "[0.00, 0.34, 0.92, 1.00]"
        ],
        "start": 0.0,
        "end": 286.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1182.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "talk to (e.g., self, a person, a group) -> carry/hold (an object)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "Lg1jOu8cUBM",
        "candidates": [
            "talk to (e.g., self, a person, a group) -> work on a computer",
            "carry/hold (an object) -> shoot",
            "jump/leap -> carry/hold (an object)",
            "talk to (e.g., self, a person, a group) -> carry/hold (an object)"
        ],
        "start": 0.0,
        "end": 287.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1183.0,
        "question": "Are there still 1 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "Lg1jOu8cUBM",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 288.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1381.0,
        "question": "Where was the person currently performing the touch (an object) in the scene 8 seconds ago?",
        "answer": "[0.13, 0.10, 0.92, 0.99]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "Lg1jOu8cUBM",
        "candidates": [
            "[0.00, 0.33, 0.62, 1.00]",
            "[0.40, 0.00, 0.99, 1.00]",
            "[0.13, 0.10, 0.92, 0.99]",
            "[0.26, 0.31, 0.43, 0.65]"
        ],
        "start": 0.0,
        "end": 486.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1385.0,
        "question": "Where is the person currently performing the close (e.g., a door, a box) located in the picture?",
        "answer": "[0.02, 0.15, 0.76, 1.00]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "Lg1jOu8cUBM",
        "candidates": [
            "[0.02, 0.15, 0.76, 1.00]",
            "[0.23, 0.17, 0.36, 0.68]",
            "[0.25, 0.34, 1.00, 0.95]",
            "[0.00, 0.45, 0.89, 1.00]"
        ],
        "start": 0.0,
        "end": 490.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1408.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "talk to (e.g., self, a person, a group) -> carry/hold (an object)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "Lg1jOu8cUBM",
        "candidates": [
            "talk to (e.g., self, a person, a group) -> carry/hold (an object)",
            "play musical instrument -> talk to (e.g., self, a person, a group)",
            "carry/hold (an object) -> ride (e.g., a bike, a car, a horse)",
            "talk to (e.g., self, a person, a group) -> hit (an object)"
        ],
        "start": 0.0,
        "end": 513.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1419.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.00, 0.11, 0.95, 0.99] location?",
        "answer": "carry/hold (an object) [0.00, 0.11, 0.95, 0.99] -> smoke [0.00, 0.11, 0.95, 0.99] -> talk to (e.g., self, a person, a group) [0.00, 0.11, 0.95, 0.99]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "Lg1jOu8cUBM",
        "candidates": [
            "press [0.00, 0.29, 0.92, 0.80] -> talk to (e.g., self, a person, a group) [0.07, 0.03, 1.00, 1.00] -> carry/hold (an object) [0.00, 0.00, 0.90, 0.91]",
            "brush teeth [0.18, 0.24, 0.78, 1.00] -> smoke [0.00, 0.28, 0.99, 0.80] -> talk to (e.g., self, a person, a group) [0.00, 0.06, 1.00, 1.00]",
            "put down [0.18, 0.16, 0.79, 0.88] -> carry/hold (an object) [0.00, 0.27, 0.82, 1.00] -> smoke [0.11, 0.00, 0.86, 1.00]",
            "carry/hold (an object) [0.00, 0.11, 0.95, 0.99] -> smoke [0.00, 0.11, 0.95, 0.99] -> talk to (e.g., self, a person, a group) [0.00, 0.11, 0.95, 0.99]"
        ],
        "start": 0.0,
        "end": 524.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1481.0,
        "question": "Where was the person currently performing the carry/hold (an object) in the scene 8 seconds ago?",
        "answer": "[0.28, 0.40, 0.61, 0.86]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "Lg1jOu8cUBM",
        "candidates": [
            "[0.51, 0.23, 0.87, 0.96]",
            "[0.28, 0.40, 0.61, 0.86]",
            "[0.23, 0.65, 0.39, 1.00]",
            "[0.47, 0.23, 0.62, 0.56]"
        ],
        "start": 0.0,
        "end": 586.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1481.0,
        "question": "Where is the person currently performing the carry/hold (an object) located in the picture?",
        "answer": "[0.43, 0.14, 0.67, 0.88]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "Lg1jOu8cUBM",
        "candidates": [
            "[0.43, 0.14, 0.67, 0.88]",
            "[0.29, 0.39, 0.61, 0.88]",
            "[0.20, 0.08, 0.41, 0.59]",
            "[0.43, 0.06, 0.75, 0.64]"
        ],
        "start": 0.0,
        "end": 586.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1497.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "walk -> close (e.g., a door, a box)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "Lg1jOu8cUBM",
        "candidates": [
            "walk -> paint",
            "walk -> close (e.g., a door, a box)",
            "walk -> drive (e.g., a car, a truck)",
            "crawl -> close (e.g., a door, a box)"
        ],
        "start": 0.0,
        "end": 602.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1530.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.20, 0.22, 0.39, 0.62]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "Lg1jOu8cUBM",
        "candidates": [
            "[0.20, 0.22, 0.39, 0.62]",
            "[0.48, 0.00, 0.49, 0.52]",
            "[0.46, 0.19, 0.67, 0.82]",
            "[0.06, 0.00, 0.17, 0.41]"
        ],
        "start": 0.0,
        "end": 635.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1543.0,
        "question": "Are there still 1 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "Lg1jOu8cUBM",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 648.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1785.0,
        "question": "What action is the person at the location [0.27, 0.36, 0.40, 0.65] in the image performing?",
        "answer": "sit, listen to (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "Lg1jOu8cUBM",
        "candidates": [
            "stand, carry/hold (an object), talk to (e.g., self, a person, a group)",
            "sit, listen to (a person)",
            "sit, talk to (e.g., self, a person, a group)",
            "sit, carry/hold (an object)"
        ],
        "start": 0.0,
        "end": 890.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1794.0,
        "question": "Are there still 2 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "Lg1jOu8cUBM",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 899.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 914.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.79, 0.32, 0.98, 0.93]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "NO2esmws190",
        "candidates": [
            "[0.66, 0.40, 0.69, 1.00]",
            "[0.79, 0.32, 0.98, 0.93]",
            "[0.27, 0.87, 0.36, 0.99]",
            "[0.91, 0.07, 1.00, 0.75]"
        ],
        "start": 0.0,
        "end": 19.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1033.0,
        "question": "Is the person currently in the [0.17, 0.19, 0.85, 1.00] location in the current frame performing the walk?",
        "answer": "No",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "NO2esmws190",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 138.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1056.0,
        "question": "Where is the person currently performing the walk located in the picture?",
        "answer": "[0.05, 0.04, 0.69, 0.95]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "NO2esmws190",
        "candidates": [
            "[0.00, 0.26, 0.49, 1.00]",
            "[0.26, 0.09, 0.85, 0.99]",
            "[0.00, 0.00, 0.42, 0.71]",
            "[0.05, 0.04, 0.69, 0.95]"
        ],
        "start": 0.0,
        "end": 161.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1187.0,
        "question": "What action is the person at the location [0.01, 0.01, 0.45, 0.99] in the image performing?",
        "answer": "stand, hand wave, talk to (e.g., self, a person, a group), watch (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "NO2esmws190",
        "candidates": [
            "stand, hand wave, talk to (e.g., self, a person, a group), watch (a person)",
            "sit, listen to (a person), talk to (e.g., self, a person, a group)",
            "stand, carry/hold (an object), listen to (a person), watch (a person)",
            "stand, listen to (a person), watch (a person)"
        ],
        "start": 0.0,
        "end": 292.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1192.0,
        "question": "How many people were performing the carry/hold (an object) in the scene 240 seconds ago?",
        "answer": "5",
        "sub_answer_type": "PastMemory-5",
        "answer_type": "PastMemory",
        "video": "NO2esmws190",
        "candidates": [
            "5",
            "7",
            "6",
            "3"
        ],
        "start": 0.0,
        "end": 297.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1212.0,
        "question": "What action is the person at the location [0.80, 0.40, 1.00, 1.00] in the image performing?",
        "answer": "walk, watch (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "NO2esmws190",
        "candidates": [
            "walk, watch (a person)",
            "walk, carry/hold (an object), watch (a person)",
            "sit, listen to (a person), watch (a person)",
            "stand, talk to (e.g., self, a person, a group), watch (a person)"
        ],
        "start": 0.0,
        "end": 317.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1239.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.47, 0.23, 0.70, 0.81] location?",
        "answer": "walk [0.47, 0.23, 0.70, 0.81] -> carry/hold (an object) [0.47, 0.23, 0.70, 0.81] -> talk to (e.g., self, a person, a group) [0.47, 0.23, 0.70, 0.81]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "NO2esmws190",
        "candidates": [
            "talk to (e.g., self, a person, a group) [0.47, 0.41, 0.52, 0.78] -> dance [0.53, 0.23, 0.76, 0.93] -> walk [0.51, 0.11, 0.63, 0.95]",
            "take (an object) from (a person) [0.34, 0.29, 0.71, 0.88] -> walk [0.36, 0.05, 0.75, 1.00] -> carry/hold (an object) [0.52, 0.36, 0.89, 0.69]",
            "walk [0.47, 0.23, 0.70, 0.81] -> carry/hold (an object) [0.47, 0.23, 0.70, 0.81] -> talk to (e.g., self, a person, a group) [0.47, 0.23, 0.70, 0.81]",
            "open (e.g., a window, a car door) [0.31, 0.34, 0.64, 0.94] -> carry/hold (an object) [0.49, 0.09, 0.56, 1.00] -> walk [0.45, 0.20, 0.70, 0.93]"
        ],
        "start": 0.0,
        "end": 344.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1337.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.20, 0.15, 0.41, 0.96] location?",
        "answer": "walk [0.20, 0.15, 0.41, 0.96] -> carry/hold (an object) [0.20, 0.15, 0.41, 0.96] -> talk to (e.g., self, a person, a group) [0.20, 0.15, 0.41, 0.96]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "NO2esmws190",
        "candidates": [
            "walk [0.16, 0.20, 0.42, 0.77] -> talk to (e.g., self, a person, a group) [0.25, 0.06, 0.36, 0.98] -> walk [0.33, 0.13, 0.46, 0.96]",
            "carry/hold (an object) [0.37, 0.23, 0.46, 0.98] -> talk to (e.g., self, a person, a group) [0.40, 0.07, 0.56, 1.00] -> crawl [0.01, 0.00, 0.43, 1.00]",
            "walk [0.20, 0.15, 0.41, 0.96] -> carry/hold (an object) [0.20, 0.15, 0.41, 0.96] -> talk to (e.g., self, a person, a group) [0.20, 0.15, 0.41, 0.96]",
            "walk [0.15, 0.00, 0.30, 0.83] -> dig [0.23, 0.05, 0.25, 1.00] -> talk to (e.g., self, a person, a group) [0.15, 0.31, 0.34, 0.80]"
        ],
        "start": 0.0,
        "end": 442.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1338.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.20, 0.15, 0.41, 0.96] location?",
        "answer": "walk [0.20, 0.15, 0.41, 0.96] -> carry/hold (an object) [0.20, 0.15, 0.41, 0.96] -> talk to (e.g., self, a person, a group) [0.20, 0.15, 0.41, 0.96]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "NO2esmws190",
        "candidates": [
            "walk [0.20, 0.15, 0.41, 0.96] -> carry/hold (an object) [0.20, 0.15, 0.41, 0.96] -> talk to (e.g., self, a person, a group) [0.20, 0.15, 0.41, 0.96]",
            "walk [0.19, 0.24, 0.28, 0.91] -> talk to (e.g., self, a person, a group) [0.37, 0.27, 0.59, 1.00] -> run/jog [0.05, 0.16, 0.31, 1.00]",
            "walk [0.15, 0.28, 0.48, 0.90] -> carry/hold (an object) [0.09, 0.30, 0.34, 0.95] -> text on/look at a cellphone [0.13, 0.22, 0.30, 0.98]",
            "walk [0.31, 0.30, 0.25, 1.00] -> talk to (e.g., self, a person, a group) [0.26, 0.24, 0.43, 0.83] -> martial art [0.23, 0.00, 0.34, 1.00]"
        ],
        "start": 0.0,
        "end": 443.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1408.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.17, 0.06, 0.97, 1.00]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "NO2esmws190",
        "candidates": [
            "[0.00, 0.18, 0.83, 1.00]",
            "[0.00, 0.00, 1.00, 0.71]",
            "[0.42, 0.00, 1.00, 0.91]",
            "[0.17, 0.06, 0.97, 1.00]"
        ],
        "start": 0.0,
        "end": 513.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1414.0,
        "question": "What action is the person currently in the [0.74, 0.43, 0.90, 0.94] location likely to do next?",
        "answer": "walk",
        "sub_answer_type": "FuturePrediction-1",
        "answer_type": "FuturePrediction",
        "video": "NO2esmws190",
        "candidates": [
            "work on a computer",
            "bend/bow (at the waist) and carry/hold (an object)",
            "eat",
            "walk"
        ],
        "start": 0.0,
        "end": 519.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1500.0,
        "question": "How many people were performing the stand in the scene 180 seconds ago?",
        "answer": "5",
        "sub_answer_type": "PastMemory-5",
        "answer_type": "PastMemory",
        "video": "NO2esmws190",
        "candidates": [
            "6",
            "5",
            "8",
            "3"
        ],
        "start": 0.0,
        "end": 605.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1543.0,
        "question": "How many people in the current frame are performing the action:  lie/sleep?",
        "answer": "5",
        "sub_answer_type": "SpatialPerception-2",
        "answer_type": "SpatialPerception",
        "video": "NO2esmws190",
        "candidates": [
            "3",
            "5",
            "2",
            "4"
        ],
        "start": 0.0,
        "end": 648.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1566.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.23, 0.10, 0.41, 0.55] location?",
        "answer": "walk [0.23, 0.10, 0.41, 0.55] -> carry/hold (an object) [0.23, 0.10, 0.41, 0.55] -> talk to (e.g., self, a person, a group) [0.23, 0.10, 0.41, 0.55]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "NO2esmws190",
        "candidates": [
            "walk [0.23, 0.10, 0.41, 0.55] -> carry/hold (an object) [0.23, 0.10, 0.41, 0.55] -> talk to (e.g., self, a person, a group) [0.23, 0.10, 0.41, 0.55]",
            "walk [0.28, 0.19, 0.24, 0.36] -> swim [0.10, 0.01, 0.34, 0.72] -> carry/hold (an object) [0.10, 0.28, 0.24, 0.74]",
            "lift/pick up [0.12, 0.15, 0.32, 0.64] -> talk to (e.g., self, a person, a group) [0.41, 0.17, 0.44, 0.53] -> carry/hold (an object) [0.43, 0.04, 0.31, 0.60]",
            "walk [0.15, 0.00, 0.33, 0.48] -> talk to (e.g., self, a person, a group) [0.33, 0.23, 0.43, 0.49] -> play with kids [0.39, 0.14, 0.53, 0.38]"
        ],
        "start": 0.0,
        "end": 671.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1656.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.66, 0.38, 0.75, 0.69] location?",
        "answer": "walk [0.66, 0.38, 0.75, 0.69] -> carry/hold (an object) [0.66, 0.38, 0.75, 0.69] -> talk to (e.g., self, a person, a group) [0.66, 0.38, 0.75, 0.69]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "NO2esmws190",
        "candidates": [
            "get up [0.67, 0.42, 0.61, 0.57] -> talk to (e.g., self, a person, a group) [0.63, 0.45, 0.57, 0.74] -> carry/hold (an object) [0.67, 0.36, 0.64, 0.85]",
            "play board game [0.62, 0.25, 0.75, 0.76] -> talk to (e.g., self, a person, a group) [0.61, 0.58, 0.79, 0.74] -> carry/hold (an object) [0.58, 0.37, 0.93, 0.71]",
            "carry/hold (an object) [0.63, 0.48, 0.84, 0.53] -> walk [0.63, 0.57, 0.60, 0.64] -> walk [0.86, 0.41, 0.81, 0.70]",
            "walk [0.66, 0.38, 0.75, 0.69] -> carry/hold (an object) [0.66, 0.38, 0.75, 0.69] -> talk to (e.g., self, a person, a group) [0.66, 0.38, 0.75, 0.69]"
        ],
        "start": 0.0,
        "end": 761.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1670.0,
        "question": "What action is the person at the location [0.00, 0.19, 0.17, 0.86] in the image performing?",
        "answer": "stand, carry/hold (an object), listen to (a person), watch (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "NO2esmws190",
        "candidates": [
            "walk, carry/hold (an object)",
            "stand, carry/hold (an object), listen to (a person), watch (a person)",
            "stand, watch (a person)",
            "stand, carry/hold (an object), watch (a person)"
        ],
        "start": 0.0,
        "end": 775.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1674.0,
        "question": "How many people were performing the listen to (a person) in the scene 240 seconds ago?",
        "answer": "3",
        "sub_answer_type": "PastMemory-5",
        "answer_type": "PastMemory",
        "video": "NO2esmws190",
        "candidates": [
            "3",
            "6",
            "4",
            "5"
        ],
        "start": 0.0,
        "end": 779.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 953.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.01, 0.02, 0.33, 0.89] location?",
        "answer": "walk [0.01, 0.02, 0.33, 0.89] -> carry/hold (an object) [0.01, 0.02, 0.33, 0.89] -> smoke [0.01, 0.02, 0.33, 0.89] -> talk to (e.g., self, a person, a group) [0.01, 0.02, 0.33, 0.89]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "OGNnUvJq9RI",
        "candidates": [
            "talk to (e.g., self, a person, a group) [0.00, 0.02, 0.44, 0.96] -> play with kids [0.00, 0.00, 0.21, 0.88] -> carry/hold (an object) [0.19, 0.00, 0.37, 0.72] -> walk [0.00, 0.00, 0.20, 0.83]",
            "talk to (e.g., self, a person, a group) [0.01, 0.00, 0.22, 0.76] -> carry/hold (an object) [0.21, 0.00, 0.50, 0.80] -> walk [0.00, 0.14, 0.15, 0.71] -> dance [0.10, 0.08, 0.14, 0.87]",
            "walk [0.01, 0.02, 0.33, 0.89] -> carry/hold (an object) [0.01, 0.02, 0.33, 0.89] -> smoke [0.01, 0.02, 0.33, 0.89] -> talk to (e.g., self, a person, a group) [0.01, 0.02, 0.33, 0.89]",
            "talk to (e.g., self, a person, a group) [0.00, 0.00, 0.39, 0.84] -> turn (e.g., a screwdriver) [0.20, 0.10, 0.41, 1.00] -> carry/hold (an object) [0.00, 0.08, 0.14, 0.88] -> smoke [0.00, 0.11, 0.33, 0.99]"
        ],
        "start": 0.0,
        "end": 58.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 961.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.00, 0.04, 0.38, 0.99] location?",
        "answer": "walk [0.00, 0.04, 0.38, 0.99] -> carry/hold (an object) [0.00, 0.04, 0.38, 0.99] -> smoke [0.00, 0.04, 0.38, 0.99] -> talk to (e.g., self, a person, a group) [0.00, 0.04, 0.38, 0.99]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "OGNnUvJq9RI",
        "candidates": [
            "drive (e.g., a car, a truck) [0.03, 0.11, 0.34, 0.81] -> carry/hold (an object) [0.02, 0.01, 0.37, 1.00] -> talk to (e.g., self, a person, a group) [0.16, 0.15, 0.42, 1.00] -> walk [0.00, 0.09, 0.22, 1.00]",
            "talk to (e.g., self, a person, a group) [0.00, 0.08, 0.56, 0.86] -> carry/hold (an object) [0.03, 0.00, 0.27, 0.92] -> walk [0.18, 0.00, 0.40, 0.93] -> chop [0.00, 0.21, 0.54, 1.00]",
            "walk [0.00, 0.04, 0.38, 0.99] -> carry/hold (an object) [0.00, 0.04, 0.38, 0.99] -> smoke [0.00, 0.04, 0.38, 0.99] -> talk to (e.g., self, a person, a group) [0.00, 0.04, 0.38, 0.99]",
            "walk [0.14, 0.00, 0.18, 1.00] -> carry/hold (an object) [0.00, 0.02, 0.35, 1.00] -> fall down [0.01, 0.09, 0.27, 0.85] -> smoke [0.00, 0.22, 0.34, 0.91]"
        ],
        "start": 0.0,
        "end": 66.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 962.0,
        "question": "Where was the person currently performing the smoke in the scene 8 seconds ago?",
        "answer": "[0.00, 0.08, 0.29, 0.98]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "OGNnUvJq9RI",
        "candidates": [
            "[0.25, 0.18, 0.50, 1.00]",
            "[0.00, 0.08, 0.29, 0.98]",
            "[0.43, 0.15, 0.72, 0.97]",
            "[0.03, 0.04, 0.37, 0.72]"
        ],
        "start": 0.0,
        "end": 67.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1013.0,
        "question": "Where is the person currently performing the carry/hold (an object) located in the picture?",
        "answer": "[0.17, 0.01, 1.00, 0.97]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "OGNnUvJq9RI",
        "candidates": [
            "[0.41, 0.32, 1.00, 0.99]",
            "[0.03, 0.00, 0.82, 0.77]",
            "[0.01, 0.27, 0.99, 1.00]",
            "[0.17, 0.01, 1.00, 0.97]"
        ],
        "start": 0.0,
        "end": 118.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1051.0,
        "question": "Are there still 3 people in the current frame now?",
        "answer": "No",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "OGNnUvJq9RI",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 156.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1086.0,
        "question": "How many people in the current frame are performing the action:  carry/hold (an object)?",
        "answer": "2",
        "sub_answer_type": "SpatialPerception-2",
        "answer_type": "SpatialPerception",
        "video": "OGNnUvJq9RI",
        "candidates": [
            "3",
            "2",
            "7",
            "4"
        ],
        "start": 0.0,
        "end": 191.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1136.0,
        "question": "How many people were performing the listen to (a person) in the scene 180 seconds ago?",
        "answer": "5",
        "sub_answer_type": "PastMemory-5",
        "answer_type": "PastMemory",
        "video": "OGNnUvJq9RI",
        "candidates": [
            "7",
            "5",
            "4",
            "3"
        ],
        "start": 0.0,
        "end": 241.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1161.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.04, 0.11, 0.19, 0.61] location?",
        "answer": "walk [0.04, 0.11, 0.19, 0.61] -> carry/hold (an object) [0.04, 0.11, 0.19, 0.61] -> talk to (e.g., self, a person, a group) [0.04, 0.11, 0.19, 0.61]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "OGNnUvJq9RI",
        "candidates": [
            "walk [0.04, 0.11, 0.19, 0.61] -> carry/hold (an object) [0.04, 0.11, 0.19, 0.61] -> talk to (e.g., self, a person, a group) [0.04, 0.11, 0.19, 0.61]",
            "play musical instrument [0.00, 0.16, 0.19, 0.71] -> talk to (e.g., self, a person, a group) [0.00, 0.23, 0.13, 0.62] -> walk [0.00, 0.01, 0.16, 0.70]",
            "carry/hold (an object) [0.00, 0.29, 0.32, 0.53] -> fight/hit (a person) [0.14, 0.21, 0.22, 0.80] -> walk [0.17, 0.07, 0.18, 0.52]",
            "crawl [0.00, 0.00, 0.14, 0.68] -> carry/hold (an object) [0.00, 0.00, 0.09, 0.53] -> talk to (e.g., self, a person, a group) [0.00, 0.26, 0.27, 0.73]"
        ],
        "start": 0.0,
        "end": 266.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1183.0,
        "question": "Are there still 2 people in the current frame now?",
        "answer": "No",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "OGNnUvJq9RI",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 288.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1232.0,
        "question": "How many people were performing the walk in the scene 60 seconds ago?",
        "answer": "4",
        "sub_answer_type": "PastMemory-5",
        "answer_type": "PastMemory",
        "video": "OGNnUvJq9RI",
        "candidates": [
            "4",
            "6",
            "5",
            "3"
        ],
        "start": 0.0,
        "end": 337.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1303.0,
        "question": "What action is the person at the location [0.06, 0.22, 0.12, 0.36] in the image performing?",
        "answer": "sit, ride (e.g., a bike, a car, a horse)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "OGNnUvJq9RI",
        "candidates": [
            "stand, talk to (e.g., self, a person, a group)",
            "stand, watch (a person)",
            "sit, ride (e.g., a bike, a car, a horse)",
            "stand, listen to (a person)"
        ],
        "start": 0.0,
        "end": 408.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1322.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.01, 0.23, 0.28, 0.98] location?",
        "answer": "walk [0.01, 0.23, 0.28, 0.98] -> carry/hold (an object) [0.01, 0.23, 0.28, 0.98] -> talk to (e.g., self, a person, a group) [0.01, 0.23, 0.28, 0.98]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "OGNnUvJq9RI",
        "candidates": [
            "walk [0.00, 0.16, 0.27, 1.00] -> answer phone [0.00, 0.13, 0.15, 0.95] -> talk to (e.g., self, a person, a group) [0.05, 0.17, 0.40, 0.80]",
            "walk [0.00, 0.12, 0.32, 0.81] -> watch (e.g., TV) [0.00, 0.13, 0.24, 1.00] -> carry/hold (an object) [0.16, 0.34, 0.10, 1.00]",
            "walk [0.01, 0.23, 0.28, 0.98] -> carry/hold (an object) [0.01, 0.23, 0.28, 0.98] -> talk to (e.g., self, a person, a group) [0.01, 0.23, 0.28, 0.98]",
            "dress/put on clothing [0.17, 0.07, 0.44, 0.95] -> carry/hold (an object) [0.02, 0.41, 0.23, 0.95] -> walk [0.10, 0.24, 0.17, 1.00]"
        ],
        "start": 0.0,
        "end": 427.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1325.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.33, 0.07, 0.79, 1.00]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "OGNnUvJq9RI",
        "candidates": [
            "[0.21, 0.00, 0.64, 0.70]",
            "[0.33, 0.07, 0.79, 1.00]",
            "[0.10, 0.33, 0.60, 1.00]",
            "[0.73, 0.17, 0.88, 0.93]"
        ],
        "start": 0.0,
        "end": 430.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1403.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "walk -> carry/hold (an object) -> talk to (e.g., self, a person, a group) -> crawl",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "OGNnUvJq9RI",
        "candidates": [
            "walk -> talk to (e.g., self, a person, a group) -> carry/hold (an object) -> swim",
            "talk to (e.g., self, a person, a group) -> crawl -> walk -> close (e.g., a door, a box)",
            "walk -> carry/hold (an object) -> talk to (e.g., self, a person, a group) -> crawl",
            "sing to (e.g., self, a person, a group) -> talk to (e.g., self, a person, a group) -> carry/hold (an object) -> walk"
        ],
        "start": 0.0,
        "end": 508.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1426.0,
        "question": "How many people in the current frame are performing the action:  run/jog?",
        "answer": "3",
        "sub_answer_type": "SpatialPerception-2",
        "answer_type": "SpatialPerception",
        "video": "OGNnUvJq9RI",
        "candidates": [
            "7",
            "3",
            "2",
            "4"
        ],
        "start": 0.0,
        "end": 531.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1429.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "run/jog -> talk to (e.g., self, a person, a group)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "OGNnUvJq9RI",
        "candidates": [
            "talk to (e.g., self, a person, a group) -> push (an object)",
            "run/jog -> talk to (e.g., self, a person, a group)",
            "lie/sleep -> run/jog",
            "push (another person) -> run/jog"
        ],
        "start": 0.0,
        "end": 534.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1526.0,
        "question": "What action is the person currently in the [0.02, 0.09, 0.70, 0.98] location likely to do next?",
        "answer": "talk to (e.g., self, a person, a group)",
        "sub_answer_type": "FuturePrediction-1",
        "answer_type": "FuturePrediction",
        "video": "OGNnUvJq9RI",
        "candidates": [
            "talk to (e.g., self, a person, a group)",
            "play with pets",
            "carry/hold (an object)",
            "eat"
        ],
        "start": 0.0,
        "end": 631.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1544.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "bend/bow (at the waist) -> carry/hold (an object)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "OGNnUvJq9RI",
        "candidates": [
            "press -> carry/hold (an object)",
            "swim -> carry/hold (an object)",
            "bend/bow (at the waist) -> turn (e.g., a screwdriver)",
            "bend/bow (at the waist) -> carry/hold (an object)"
        ],
        "start": 0.0,
        "end": 649.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1557.0,
        "question": "Is the person currently in the [0.00, 0.01, 0.68, 0.98] location in the current frame performing the carry/hold (an object)?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "OGNnUvJq9RI",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 662.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1562.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "carry/hold (an object) -> hit (an object) -> talk to (e.g., self, a person, a group)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "OGNnUvJq9RI",
        "candidates": [
            "kick (an object) -> hit (an object) -> talk to (e.g., self, a person, a group)",
            "carry/hold (an object) -> hit (an object) -> talk to (e.g., self, a person, a group)",
            "talk to (e.g., self, a person, a group) -> hit (an object) -> fight/hit (a person)",
            "enter -> carry/hold (an object) -> hit (an object)"
        ],
        "start": 0.0,
        "end": 667.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1641.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.45, 0.18, 0.68, 0.99] location?",
        "answer": "carry/hold (an object) [0.45, 0.18, 0.68, 0.99] -> grab (a person) [0.45, 0.18, 0.68, 0.99] -> talk to (e.g., self, a person, a group) [0.45, 0.18, 0.68, 0.99]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "OGNnUvJq9RI",
        "candidates": [
            "talk to (e.g., self, a person, a group) [0.36, 0.08, 0.63, 0.80] -> carry/hold (an object) [0.62, 0.37, 0.67, 1.00] -> take (an object) from (a person) [0.46, 0.14, 0.86, 1.00]",
            "drink [0.32, 0.33, 0.66, 0.81] -> talk to (e.g., self, a person, a group) [0.28, 0.37, 0.77, 0.87] -> carry/hold (an object) [0.63, 0.26, 0.69, 1.00]",
            "carry/hold (an object) [0.45, 0.18, 0.68, 0.99] -> grab (a person) [0.45, 0.18, 0.68, 0.99] -> talk to (e.g., self, a person, a group) [0.45, 0.18, 0.68, 0.99]",
            "carry/hold (an object) [0.58, 0.28, 0.69, 0.91] -> drink [0.26, 0.25, 0.67, 1.00] -> talk to (e.g., self, a person, a group) [0.61, 0.20, 0.52, 0.97]"
        ],
        "start": 0.0,
        "end": 746.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1649.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.45, 0.18, 0.68, 0.99]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "OGNnUvJq9RI",
        "candidates": [
            "[0.20, 0.00, 0.63, 0.88]",
            "[0.45, 0.18, 0.68, 0.99]",
            "[0.04, 0.39, 0.80, 0.99]",
            "[0.70, 0.10, 0.88, 0.74]"
        ],
        "start": 0.0,
        "end": 754.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1651.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "talk to (e.g., self, a person, a group) -> carry/hold (an object)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "OGNnUvJq9RI",
        "candidates": [
            "talk to (e.g., self, a person, a group) -> carry/hold (an object)",
            "hand wave -> carry/hold (an object)",
            "hug (a person) -> carry/hold (an object)",
            "carry/hold (an object) -> bend/bow (at the waist)"
        ],
        "start": 0.0,
        "end": 756.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1778.0,
        "question": "What action is the person at the location [0.00, 0.10, 0.42, 0.99] in the image performing?",
        "answer": "stand, listen to (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "OGNnUvJq9RI",
        "candidates": [
            "sit, watch (a person)",
            "sit, carry/hold (an object), watch (a person)",
            "stand, carry/hold (an object)",
            "stand, listen to (a person)"
        ],
        "start": 0.0,
        "end": 883.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 986.0,
        "question": "What action is the person at the location [0.02, 0.05, 0.62, 0.97] in the image performing?",
        "answer": "dance, watch (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "O_NYCUhZ9zw",
        "candidates": [
            "sit, answer phone",
            "stand, answer phone",
            "sit, talk to (e.g., self, a person, a group)",
            "dance, watch (a person)"
        ],
        "start": 0.0,
        "end": 91.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1037.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.55, 0.03, 1.00, 0.97]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "O_NYCUhZ9zw",
        "candidates": [
            "[0.55, 0.03, 1.00, 0.97]",
            "[0.30, 0.09, 1.00, 0.69]",
            "[0.64, 0.00, 0.99, 0.68]",
            "[0.53, 0.30, 0.71, 0.92]"
        ],
        "start": 0.0,
        "end": 142.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1069.0,
        "question": "Are there still 2 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "O_NYCUhZ9zw",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 174.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1119.0,
        "question": "Where was the person currently performing the carry/hold (an object) in the scene 8 seconds ago?",
        "answer": "[0.05, 0.10, 0.34, 0.98]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "O_NYCUhZ9zw",
        "candidates": [
            "[0.05, 0.10, 0.34, 0.98]",
            "[0.03, 0.06, 0.88, 1.00]",
            "[0.01, 0.29, 0.64, 1.00]",
            "[0.00, 0.02, 0.13, 0.69]"
        ],
        "start": 0.0,
        "end": 224.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1211.0,
        "question": "Are there still 1 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "O_NYCUhZ9zw",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 316.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1231.0,
        "question": "Where is the person currently performing the talk to (e.g., self, a person, a group) located in the picture?",
        "answer": "[0.14, 0.08, 1.00, 1.00]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "O_NYCUhZ9zw",
        "candidates": [
            "[0.00, 0.32, 0.75, 0.97]",
            "[0.14, 0.08, 1.00, 1.00]",
            "[0.57, 0.11, 0.97, 0.99]",
            "[0.11, 0.03, 1.00, 0.74]"
        ],
        "start": 0.0,
        "end": 336.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1294.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.45, 0.00, 0.99, 0.93] location?",
        "answer": "carry/hold (an object) [0.56, 0.04, 1.00, 0.92] -> talk to (e.g., self, a person, a group) [0.56, 0.04, 1.00, 0.92] -> bend/bow (at the waist) [0.45, 0.00, 0.99, 0.93]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "O_NYCUhZ9zw",
        "candidates": [
            "carry/hold (an object) [0.56, 0.04, 1.00, 0.92] -> talk to (e.g., self, a person, a group) [0.56, 0.04, 1.00, 0.92] -> bend/bow (at the waist) [0.45, 0.00, 0.99, 0.93]",
            "crawl [0.62, 0.00, 0.93, 1.00] -> talk to (e.g., self, a person, a group) [0.68, 0.17, 0.84, 1.00] -> bend/bow (at the waist) [0.45, 0.15, 1.00, 1.00]",
            "bend/bow (at the waist) [0.34, 0.01, 0.88, 0.79] -> carry/hold (an object) [0.66, 0.00, 1.00, 0.77] -> row boat [0.75, 0.00, 1.00, 1.00]",
            "talk to (e.g., self, a person, a group) [0.70, 0.00, 1.00, 0.82] -> carry/hold (an object) [0.70, 0.11, 0.85, 0.74] -> hug (a person) [0.50, 0.00, 0.83, 0.91]"
        ],
        "start": 0.0,
        "end": 399.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1301.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.02, 0.16, 0.46, 0.92] location?",
        "answer": "carry/hold (an object) [0.02, 0.16, 0.46, 0.92] -> read [0.02, 0.16, 0.46, 0.92] -> talk to (e.g., self, a person, a group) [0.02, 0.16, 0.46, 0.92]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "O_NYCUhZ9zw",
        "candidates": [
            "talk to (e.g., self, a person, a group) [0.00, 0.30, 0.46, 1.00] -> read [0.04, 0.04, 0.40, 1.00] -> sing to (e.g., self, a person, a group) [0.00, 0.10, 0.66, 0.90]",
            "dress/put on clothing [0.12, 0.23, 0.54, 1.00] -> talk to (e.g., self, a person, a group) [0.00, 0.04, 0.41, 0.88] -> read [0.17, 0.29, 0.59, 0.82]",
            "carry/hold (an object) [0.02, 0.16, 0.46, 0.92] -> read [0.02, 0.16, 0.46, 0.92] -> talk to (e.g., self, a person, a group) [0.02, 0.16, 0.46, 0.92]",
            "talk to (e.g., self, a person, a group) [0.11, 0.24, 0.44, 0.83] -> read [0.17, 0.34, 0.59, 0.94] -> dance [0.04, 0.07, 0.44, 0.96]"
        ],
        "start": 0.0,
        "end": 406.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1307.0,
        "question": "Where was the person currently performing the carry/hold (an object) in the scene 8 seconds ago?",
        "answer": "[0.03, 0.15, 0.46, 0.93]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "O_NYCUhZ9zw",
        "candidates": [
            "[0.59, 0.03, 0.99, 0.98]",
            "[0.00, 0.41, 0.23, 0.86]",
            "[0.03, 0.15, 0.46, 0.93]",
            "[0.25, 0.00, 0.71, 0.99]"
        ],
        "start": 0.0,
        "end": 412.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1309.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.02, 0.15, 0.44, 0.93] location?",
        "answer": "carry/hold (an object) [0.02, 0.15, 0.44, 0.93] -> read [0.02, 0.15, 0.44, 0.93] -> talk to (e.g., self, a person, a group) [0.02, 0.15, 0.44, 0.93]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "O_NYCUhZ9zw",
        "candidates": [
            "walk [0.14, 0.19, 0.57, 0.76] -> read [0.08, 0.31, 0.36, 1.00] -> talk to (e.g., self, a person, a group) [0.10, 0.06, 0.42, 0.78]",
            "carry/hold (an object) [0.00, 0.03, 0.51, 1.00] -> give/serve (an object) to (a person) [0.08, 0.29, 0.24, 0.75] -> read [0.17, 0.00, 0.47, 0.75]",
            "carry/hold (an object) [0.02, 0.15, 0.44, 0.93] -> read [0.02, 0.15, 0.44, 0.93] -> talk to (e.g., self, a person, a group) [0.02, 0.15, 0.44, 0.93]",
            "carry/hold (an object) [0.07, 0.01, 0.53, 0.80] -> push (an object) [0.00, 0.15, 0.49, 0.99] -> read [0.16, 0.08, 0.58, 1.00]"
        ],
        "start": 0.0,
        "end": 414.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1373.0,
        "question": "What action is the person at the location [0.08, 0.20, 0.36, 0.98] in the image performing?",
        "answer": "stand, answer phone",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "O_NYCUhZ9zw",
        "candidates": [
            "sit, listen to (a person), watch (a person)",
            "stand, listen to (a person), watch (a person)",
            "stand, answer phone",
            "sit, answer phone"
        ],
        "start": 0.0,
        "end": 478.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1398.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.63, 0.28, 1.00, 0.85] location?",
        "answer": "carry/hold (an object) [0.63, 0.28, 1.00, 0.85] -> read [0.63, 0.28, 1.00, 0.85] -> talk to (e.g., self, a person, a group) [0.63, 0.28, 1.00, 0.85]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "O_NYCUhZ9zw",
        "candidates": [
            "close (e.g., a door, a box) [0.54, 0.24, 0.96, 0.99] -> talk to (e.g., self, a person, a group) [0.83, 0.16, 0.90, 1.00] -> read [0.48, 0.41, 1.00, 0.79]",
            "hand wave [0.75, 0.35, 0.81, 1.00] -> read [0.60, 0.13, 1.00, 1.00] -> talk to (e.g., self, a person, a group) [0.72, 0.09, 0.89, 0.71]",
            "carry/hold (an object) [0.63, 0.28, 1.00, 0.85] -> read [0.63, 0.28, 1.00, 0.85] -> talk to (e.g., self, a person, a group) [0.63, 0.28, 1.00, 0.85]",
            "kiss (a person) [0.73, 0.19, 1.00, 0.83] -> carry/hold (an object) [0.70, 0.31, 0.98, 0.90] -> talk to (e.g., self, a person, a group) [0.44, 0.37, 1.00, 0.85]"
        ],
        "start": 0.0,
        "end": 503.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1419.0,
        "question": "Where was the person currently performing the touch (an object) in the scene 8 seconds ago?",
        "answer": "[0.65, 0.28, 1.00, 0.89]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "O_NYCUhZ9zw",
        "candidates": [
            "[0.65, 0.28, 1.00, 0.89]",
            "[0.00, 0.23, 0.36, 1.00]",
            "[0.35, 0.16, 1.00, 0.65]",
            "[0.76, 0.58, 1.00, 1.00]"
        ],
        "start": 0.0,
        "end": 524.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1426.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.65, 0.29, 0.99, 0.80] location?",
        "answer": "carry/hold (an object) [0.65, 0.29, 0.99, 0.80] -> read [0.65, 0.29, 0.99, 0.80] -> talk to (e.g., self, a person, a group) [0.65, 0.29, 0.99, 0.80]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "O_NYCUhZ9zw",
        "candidates": [
            "carry/hold (an object) [0.65, 0.29, 0.99, 0.80] -> read [0.65, 0.29, 0.99, 0.80] -> talk to (e.g., self, a person, a group) [0.65, 0.29, 0.99, 0.80]",
            "read [0.56, 0.37, 1.00, 0.68] -> drive (e.g., a car, a truck) [0.48, 0.47, 1.00, 0.80] -> talk to (e.g., self, a person, a group) [0.73, 0.13, 0.81, 0.67]",
            "carry/hold (an object) [0.52, 0.10, 0.95, 0.77] -> hit (an object) [0.67, 0.16, 0.93, 1.00] -> talk to (e.g., self, a person, a group) [0.48, 0.21, 1.00, 0.71]",
            "carry/hold (an object) [0.81, 0.39, 0.89, 0.93] -> push (another person) [0.82, 0.28, 1.00, 0.89] -> talk to (e.g., self, a person, a group) [0.77, 0.09, 1.00, 0.99]"
        ],
        "start": 0.0,
        "end": 531.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1432.0,
        "question": "Is the person currently in the [0.14, 0.19, 0.52, 0.99] location in the current frame performing the walk?",
        "answer": "No",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "O_NYCUhZ9zw",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 537.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1556.0,
        "question": "Where is the person currently performing the answer phone located in the picture?",
        "answer": "[0.48, 0.35, 0.66, 0.80]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "O_NYCUhZ9zw",
        "candidates": [
            "[0.49, 0.36, 0.95, 0.54]",
            "[0.62, 0.59, 0.79, 0.73]",
            "[0.48, 0.35, 0.66, 0.80]",
            "[0.01, 0.15, 0.76, 0.96]"
        ],
        "start": 0.0,
        "end": 661.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1575.0,
        "question": "What action is the person currently in the [0.49, 0.09, 0.87, 0.93] location likely to do next?",
        "answer": "bend/bow (at the waist)",
        "sub_answer_type": "FuturePrediction-1",
        "answer_type": "FuturePrediction",
        "video": "O_NYCUhZ9zw",
        "candidates": [
            "brush teeth",
            "fight/hit (a person)",
            "talk to (e.g., self, a person, a group)",
            "bend/bow (at the waist)"
        ],
        "start": 0.0,
        "end": 680.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1623.0,
        "question": "Where was the person currently performing the grab (a person) in the scene 8 seconds ago?",
        "answer": "[0.03, 0.15, 0.48, 0.98]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "O_NYCUhZ9zw",
        "candidates": [
            "[0.26, 0.19, 0.75, 0.91]",
            "[0.03, 0.15, 0.48, 0.98]",
            "[0.38, 0.50, 0.57, 0.99]",
            "[0.20, 0.01, 0.56, 0.71]"
        ],
        "start": 0.0,
        "end": 728.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1706.0,
        "question": "Are there still 2 people in the current frame now?",
        "answer": "No",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "O_NYCUhZ9zw",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 811.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1795.0,
        "question": "Where is the person currently performing the talk to (e.g., self, a person, a group) located in the picture?",
        "answer": "[0.01, 0.10, 0.73, 0.98]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "O_NYCUhZ9zw",
        "candidates": [
            "[0.01, 0.10, 0.73, 0.98]",
            "[0.21, 0.39, 1.00, 1.00]",
            "[0.00, 0.00, 0.94, 0.77]",
            "[0.51, 0.09, 0.89, 0.95]"
        ],
        "start": 0.0,
        "end": 900.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 915.0,
        "question": "What action is the person at the location [0.14, 0.12, 0.26, 0.82] in the image performing?",
        "answer": "stand, watch (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "Ov0za6Xb1LM",
        "candidates": [
            "stand, listen to (a person)",
            "stand, carry/hold (an object)",
            "sit, watch (a person)",
            "stand, watch (a person)"
        ],
        "start": 0.0,
        "end": 20.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 921.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "carry/hold (an object) -> crouch/kneel",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "Ov0za6Xb1LM",
        "candidates": [
            "fight/hit (a person) -> carry/hold (an object)",
            "carry/hold (an object) -> crouch/kneel",
            "carry/hold (an object) -> drink",
            "carry/hold (an object) -> ride (e.g., a bike, a car, a horse)"
        ],
        "start": 0.0,
        "end": 26.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 927.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "carry/hold (an object) -> crouch/kneel",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "Ov0za6Xb1LM",
        "candidates": [
            "climb (e.g., a mountain) -> carry/hold (an object)",
            "carry/hold (an object) -> crouch/kneel",
            "crouch/kneel -> enter",
            "crouch/kneel -> press"
        ],
        "start": 0.0,
        "end": 32.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 980.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.51, 0.29, 0.64, 0.97] location?",
        "answer": "walk [0.51, 0.29, 0.64, 0.97] -> carry/hold (an object) [0.51, 0.29, 0.64, 0.97] -> talk to (e.g., self, a person, a group) [0.51, 0.29, 0.64, 0.97]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "Ov0za6Xb1LM",
        "candidates": [
            "walk [0.51, 0.29, 0.64, 0.97] -> carry/hold (an object) [0.51, 0.29, 0.64, 0.97] -> talk to (e.g., self, a person, a group) [0.51, 0.29, 0.64, 0.97]",
            "carry/hold (an object) [0.35, 0.14, 0.69, 0.84] -> walk [0.67, 0.19, 0.60, 0.97] -> talk to (e.g., self, a person, a group) [0.32, 0.40, 0.56, 1.00]",
            "talk to (e.g., self, a person, a group) [0.62, 0.11, 0.51, 0.78] -> walk [0.39, 0.33, 0.50, 1.00] -> answer phone [0.43, 0.34, 0.66, 0.80]",
            "walk [0.70, 0.35, 0.49, 0.85] -> talk to (e.g., self, a person, a group) [0.35, 0.39, 0.65, 1.00] -> jump/leap [0.70, 0.20, 0.73, 0.91]"
        ],
        "start": 0.0,
        "end": 85.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1002.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "drink -> talk to (e.g., self, a person, a group)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "Ov0za6Xb1LM",
        "candidates": [
            "drink -> write",
            "dig -> drink",
            "drink -> talk to (e.g., self, a person, a group)",
            "talk to (e.g., self, a person, a group) -> hand clap"
        ],
        "start": 0.0,
        "end": 107.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1067.0,
        "question": "Is the person currently in the [0.00, 0.14, 0.31, 0.99] location in the current frame performing the walk?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "Ov0za6Xb1LM",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 172.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1122.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.40, 0.10, 0.87, 0.98] location?",
        "answer": "carry/hold (an object) [0.40, 0.10, 0.87, 0.98] -> give/serve (an object) to (a person) [0.40, 0.10, 0.87, 0.98] -> talk to (e.g., self, a person, a group) [0.40, 0.10, 0.87, 0.98]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "Ov0za6Xb1LM",
        "candidates": [
            "carry/hold (an object) [0.40, 0.10, 0.87, 0.98] -> give/serve (an object) to (a person) [0.40, 0.10, 0.87, 0.98] -> talk to (e.g., self, a person, a group) [0.40, 0.10, 0.87, 0.98]",
            "give/serve (an object) to (a person) [0.47, 0.29, 1.00, 1.00] -> carry/hold (an object) [0.25, 0.01, 1.00, 1.00] -> give/serve (an object) to (a person) [0.50, 0.00, 0.81, 1.00]",
            "swim [0.45, 0.08, 0.77, 1.00] -> carry/hold (an object) [0.59, 0.00, 0.80, 1.00] -> talk to (e.g., self, a person, a group) [0.23, 0.15, 1.00, 0.83]",
            "give/serve (an object) to (a person) [0.31, 0.08, 1.00, 0.95] -> talk to (e.g., self, a person, a group) [0.59, 0.05, 0.74, 1.00] -> climb (e.g., a mountain) [0.45, 0.28, 0.94, 0.98]"
        ],
        "start": 0.0,
        "end": 227.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1123.0,
        "question": "What action is the person currently in the [0.04, 0.60, 0.23, 0.98] location likely to do next?",
        "answer": "lie/sleep",
        "sub_answer_type": "FuturePrediction-1",
        "answer_type": "FuturePrediction",
        "video": "Ov0za6Xb1LM",
        "candidates": [
            "lie/sleep",
            "clink glass",
            "drink",
            "talk to (e.g., self, a person, a group)"
        ],
        "start": 0.0,
        "end": 228.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1139.0,
        "question": "Where was the person currently performing the lie/sleep in the scene 8 seconds ago?",
        "answer": "[0.03, 0.60, 0.24, 0.98]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "Ov0za6Xb1LM",
        "candidates": [
            "[0.03, 0.60, 0.24, 0.98]",
            "[0.03, 0.30, 0.27, 0.83]",
            "[0.00, 0.00, 0.85, 0.99]",
            "[0.15, 0.75, 0.51, 0.93]"
        ],
        "start": 0.0,
        "end": 244.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1182.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.48, 0.00, 1.00, 0.97]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "Ov0za6Xb1LM",
        "candidates": [
            "[0.21, 0.00, 1.00, 0.80]",
            "[0.32, 0.29, 1.00, 0.98]",
            "[0.29, 0.20, 0.66, 0.91]",
            "[0.48, 0.00, 1.00, 0.97]"
        ],
        "start": 0.0,
        "end": 287.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1216.0,
        "question": "What action is the person at the location [0.24, 0.14, 0.46, 0.83] in the image performing?",
        "answer": "sit, carry/hold (an object), listen to (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "Ov0za6Xb1LM",
        "candidates": [
            "sit, watch (a person)",
            "sit, carry/hold (an object), listen to (a person)",
            "sit, talk to (e.g., self, a person, a group), watch (a person)",
            "walk, lift/pick up"
        ],
        "start": 0.0,
        "end": 321.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1383.0,
        "question": "How many people were performing the watch (a person) in the scene 240 seconds ago?",
        "answer": "3",
        "sub_answer_type": "PastMemory-5",
        "answer_type": "PastMemory",
        "video": "Ov0za6Xb1LM",
        "candidates": [
            "7",
            "4",
            "3",
            "5"
        ],
        "start": 0.0,
        "end": 488.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1398.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.32, 0.22, 0.56, 0.98] location?",
        "answer": "walk [0.34, 0.30, 0.50, 0.98] -> carry/hold (an object) [0.34, 0.30, 0.50, 0.98] -> run/jog [0.32, 0.22, 0.56, 0.98]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "Ov0za6Xb1LM",
        "candidates": [
            "run/jog [0.50, 0.34, 0.43, 1.00] -> walk [0.43, 0.42, 0.64, 1.00] -> lift/pick up [0.27, 0.19, 0.55, 1.00]",
            "walk [0.34, 0.30, 0.50, 0.98] -> carry/hold (an object) [0.34, 0.30, 0.50, 0.98] -> run/jog [0.32, 0.22, 0.56, 0.98]",
            "run/jog [0.31, 0.34, 0.68, 1.00] -> carry/hold (an object) [0.41, 0.36, 0.39, 1.00] -> stir [0.26, 0.10, 0.41, 0.82]",
            "walk [0.28, 0.24, 0.39, 0.96] -> play board game [0.15, 0.29, 0.39, 0.98] -> run/jog [0.51, 0.20, 0.47, 0.99]"
        ],
        "start": 0.0,
        "end": 503.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1398.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "walk -> carry/hold (an object) -> run/jog",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "Ov0za6Xb1LM",
        "candidates": [
            "walk -> clink glass -> run/jog",
            "walk -> cook -> carry/hold (an object)",
            "walk -> carry/hold (an object) -> run/jog",
            "run/jog -> walk -> smoke"
        ],
        "start": 0.0,
        "end": 503.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1488.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.15, 0.14, 0.66, 0.95] location?",
        "answer": "bend/bow (at the waist) [0.15, 0.14, 0.66, 0.95] -> carry/hold (an object) [0.15, 0.14, 0.66, 0.95] -> shoot [0.15, 0.14, 0.66, 0.95]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "Ov0za6Xb1LM",
        "candidates": [
            "get up [0.27, 0.10, 0.82, 0.81] -> carry/hold (an object) [0.23, 0.04, 0.81, 0.80] -> shoot [0.01, 0.32, 0.58, 1.00]",
            "carry/hold (an object) [0.32, 0.20, 0.84, 0.90] -> shoot [0.06, 0.01, 0.84, 1.00] -> bend/bow (at the waist) [0.18, 0.16, 0.50, 1.00]",
            "shoot [0.15, 0.15, 0.65, 0.79] -> carry/hold (an object) [0.25, 0.00, 0.81, 1.00] -> close (e.g., a door, a box) [0.00, 0.27, 0.66, 0.81]",
            "bend/bow (at the waist) [0.15, 0.14, 0.66, 0.95] -> carry/hold (an object) [0.15, 0.14, 0.66, 0.95] -> shoot [0.15, 0.14, 0.66, 0.95]"
        ],
        "start": 0.0,
        "end": 593.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1499.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "bend/bow (at the waist) -> carry/hold (an object) -> crouch/kneel",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "Ov0za6Xb1LM",
        "candidates": [
            "crouch/kneel -> shovel -> bend/bow (at the waist)",
            "carry/hold (an object) -> bend/bow (at the waist) -> shovel",
            "bend/bow (at the waist) -> carry/hold (an object) -> crouch/kneel",
            "bend/bow (at the waist) -> martial art -> carry/hold (an object)"
        ],
        "start": 0.0,
        "end": 604.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1514.0,
        "question": "How many people in the current frame are performing the action:  bend/bow (at the waist)?",
        "answer": "2",
        "sub_answer_type": "SpatialPerception-2",
        "answer_type": "SpatialPerception",
        "video": "Ov0za6Xb1LM",
        "candidates": [
            "3",
            "7",
            "4",
            "2"
        ],
        "start": 0.0,
        "end": 619.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1629.0,
        "question": "What action is the person at the location [0.02, 0.13, 0.51, 0.98] in the image performing?",
        "answer": "sit, listen to (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "Ov0za6Xb1LM",
        "candidates": [
            "stand, carry/hold (an object)",
            "sit, watch (a person)",
            "sit, listen to (a person)",
            "stand, listen to (a person), watch (a person)"
        ],
        "start": 0.0,
        "end": 734.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1639.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.50, 0.02, 1.00, 0.99]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "Ov0za6Xb1LM",
        "candidates": [
            "[0.17, 0.25, 0.40, 0.98]",
            "[0.59, 0.00, 1.00, 0.70]",
            "[0.46, 0.00, 0.74, 0.70]",
            "[0.50, 0.02, 1.00, 0.99]"
        ],
        "start": 0.0,
        "end": 744.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1671.0,
        "question": "Are there still 6 people in the current frame now?",
        "answer": "No",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "Ov0za6Xb1LM",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 776.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1715.0,
        "question": "How many people were performing the stand in the scene 120 seconds ago?",
        "answer": "5",
        "sub_answer_type": "PastMemory-5",
        "answer_type": "PastMemory",
        "video": "Ov0za6Xb1LM",
        "candidates": [
            "3",
            "6",
            "4",
            "5"
        ],
        "start": 0.0,
        "end": 820.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1764.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.28, 0.16, 0.55, 0.99] location?",
        "answer": "walk [0.28, 0.16, 0.55, 0.99] -> carry/hold (an object) [0.28, 0.16, 0.55, 0.99] -> push (an object) [0.28, 0.16, 0.55, 0.99]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "Ov0za6Xb1LM",
        "candidates": [
            "walk [0.27, 0.31, 0.52, 0.80] -> grab (a person) [0.36, 0.28, 0.41, 0.81] -> carry/hold (an object) [0.09, 0.33, 0.48, 1.00]",
            "walk [0.14, 0.00, 0.55, 1.00] -> push (an object) [0.17, 0.24, 0.36, 1.00] -> sail boat [0.29, 0.15, 0.56, 1.00]",
            "walk [0.28, 0.16, 0.55, 0.99] -> carry/hold (an object) [0.28, 0.16, 0.55, 0.99] -> push (an object) [0.28, 0.16, 0.55, 0.99]",
            "push (an object) [0.30, 0.00, 0.45, 0.99] -> exit [0.09, 0.14, 0.63, 0.81] -> carry/hold (an object) [0.09, 0.30, 0.72, 0.84]"
        ],
        "start": 0.0,
        "end": 869.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1768.0,
        "question": "Where is the person currently performing the ride (e.g., a bike, a car, a horse) located in the picture?",
        "answer": "[0.67, 0.49, 0.75, 0.87]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "Ov0za6Xb1LM",
        "candidates": [
            "[0.43, 0.61, 0.51, 1.00]",
            "[0.42, 0.35, 1.00, 0.61]",
            "[0.06, 0.01, 0.61, 0.96]",
            "[0.67, 0.49, 0.75, 0.87]"
        ],
        "start": 0.0,
        "end": 873.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1022.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "walk -> crouch/kneel",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "QCLQYnt3aMo",
        "candidates": [
            "walk -> crouch/kneel",
            "bend/bow (at the waist) -> walk",
            "pull (an object) -> walk",
            "walk -> hand wave"
        ],
        "start": 0.0,
        "end": 127.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1031.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "carry/hold (an object) -> crouch/kneel",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "QCLQYnt3aMo",
        "candidates": [
            "crouch/kneel -> eat",
            "carry/hold (an object) -> crouch/kneel",
            "carry/hold (an object) -> play musical instrument",
            "crouch/kneel -> lift/pick up"
        ],
        "start": 0.0,
        "end": 136.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1041.0,
        "question": "Where is the person currently performing the run/jog located in the picture?",
        "answer": "[0.56, 0.36, 0.98, 1.00]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "QCLQYnt3aMo",
        "candidates": [
            "[0.37, 0.28, 0.73, 0.99]",
            "[0.56, 0.36, 0.98, 1.00]",
            "[0.58, 0.09, 1.00, 0.79]",
            "[0.47, 0.61, 0.85, 0.96]"
        ],
        "start": 0.0,
        "end": 146.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1055.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.42, 0.33, 0.61, 0.86] location?",
        "answer": "talk to (e.g., self, a person, a group) [0.41, 0.43, 0.63, 0.87] -> crouch/kneel [0.42, 0.33, 0.61, 0.86] -> grab (a person) [0.42, 0.33, 0.61, 0.86]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "QCLQYnt3aMo",
        "candidates": [
            "talk to (e.g., self, a person, a group) [0.41, 0.43, 0.63, 0.87] -> crouch/kneel [0.42, 0.33, 0.61, 0.86] -> grab (a person) [0.42, 0.33, 0.61, 0.86]",
            "grab (a person) [0.59, 0.21, 0.52, 0.95] -> crouch/kneel [0.43, 0.29, 0.70, 0.93] -> dig [0.34, 0.28, 0.71, 1.00]",
            "crouch/kneel [0.29, 0.34, 0.72, 0.95] -> open (e.g., a window, a car door) [0.53, 0.36, 0.67, 0.86] -> talk to (e.g., self, a person, a group) [0.55, 0.42, 0.63, 1.00]",
            "grab (a person) [0.54, 0.36, 0.81, 1.00] -> extract [0.30, 0.49, 0.54, 0.76] -> crouch/kneel [0.55, 0.17, 0.72, 0.98]"
        ],
        "start": 0.0,
        "end": 160.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1107.0,
        "question": "Where is the person currently performing the walk located in the picture?",
        "answer": "[0.21, 0.17, 0.57, 0.98]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "QCLQYnt3aMo",
        "candidates": [
            "[0.33, 0.03, 0.70, 0.77]",
            "[0.00, 0.46, 0.49, 1.00]",
            "[0.21, 0.17, 0.57, 0.98]",
            "[0.56, 0.36, 0.98, 1.00]"
        ],
        "start": 0.0,
        "end": 212.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1114.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "walk -> carry/hold (an object) -> shoot",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "QCLQYnt3aMo",
        "candidates": [
            "walk -> carry/hold (an object) -> shoot",
            "carry/hold (an object) -> walk -> watch (e.g., TV)",
            "carry/hold (an object) -> ride (e.g., a bike, a car, a horse) -> shoot",
            "carry/hold (an object) -> shoot -> dress/put on clothing"
        ],
        "start": 0.0,
        "end": 219.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1145.0,
        "question": "Where was the person currently performing the carry/hold (an object) in the scene 8 seconds ago?",
        "answer": "[0.26, 0.18, 0.61, 0.99]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "QCLQYnt3aMo",
        "candidates": [
            "[0.26, 0.18, 0.61, 0.99]",
            "[0.44, 0.00, 0.52, 0.78]",
            "[0.12, 0.20, 0.32, 0.81]",
            "[0.33, 0.07, 0.94, 1.00]"
        ],
        "start": 0.0,
        "end": 250.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1147.0,
        "question": "Is the person currently in the [0.32, 0.04, 0.59, 0.96] location in the current frame performing the walk?",
        "answer": "No",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "QCLQYnt3aMo",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 252.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1161.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "walk -> talk to (e.g., self, a person, a group)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "QCLQYnt3aMo",
        "candidates": [
            "walk -> talk to (e.g., self, a person, a group)",
            "shoot -> walk",
            "walk -> hand shake",
            "kiss (a person) -> walk"
        ],
        "start": 0.0,
        "end": 266.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1173.0,
        "question": "What location in the frame is the person currently in the [0.24, 0.17, 0.62, 0.99] location likely to move to next?",
        "answer": "[0.52, 0.09, 0.98, 1.00]",
        "sub_answer_type": "FuturePrediction-2",
        "answer_type": "FuturePrediction",
        "video": "QCLQYnt3aMo",
        "candidates": [
            "[0.48, 0.00, 1.00, 0.70]",
            "[0.90, 0.27, 0.97, 0.64]",
            "[0.72, 0.38, 1.00, 1.00]",
            "[0.52, 0.09, 0.98, 1.00]"
        ],
        "start": 0.0,
        "end": 278.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1226.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.32, 0.19, 0.58, 0.99]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "QCLQYnt3aMo",
        "candidates": [
            "[0.38, 0.10, 0.99, 0.99]",
            "[0.12, 0.07, 0.47, 0.78]",
            "[0.32, 0.19, 0.58, 0.99]",
            "[0.57, 0.46, 0.74, 1.00]"
        ],
        "start": 0.0,
        "end": 331.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1306.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "carry/hold (an object) -> put down",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "QCLQYnt3aMo",
        "candidates": [
            "take a photo -> put down",
            "drink -> put down",
            "carry/hold (an object) -> put down",
            "kick (a person) -> carry/hold (an object)"
        ],
        "start": 0.0,
        "end": 411.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1366.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.42, 0.19, 0.54, 0.79] location?",
        "answer": "walk [0.42, 0.19, 0.54, 0.79] -> carry/hold (an object) [0.42, 0.19, 0.54, 0.79] -> talk to (e.g., self, a person, a group) [0.42, 0.19, 0.54, 0.79]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "QCLQYnt3aMo",
        "candidates": [
            "carry/hold (an object) [0.27, 0.18, 0.60, 0.92] -> kick (an object) [0.33, 0.03, 0.69, 0.68] -> talk to (e.g., self, a person, a group) [0.35, 0.34, 0.52, 0.68]",
            "walk [0.28, 0.17, 0.70, 0.85] -> talk to (e.g., self, a person, a group) [0.40, 0.26, 0.40, 0.95] -> hug (a person) [0.47, 0.10, 0.40, 0.98]",
            "exit [0.50, 0.01, 0.69, 0.79] -> talk to (e.g., self, a person, a group) [0.44, 0.15, 0.62, 0.65] -> walk [0.48, 0.21, 0.38, 0.84]",
            "walk [0.42, 0.19, 0.54, 0.79] -> carry/hold (an object) [0.42, 0.19, 0.54, 0.79] -> talk to (e.g., self, a person, a group) [0.42, 0.19, 0.54, 0.79]"
        ],
        "start": 0.0,
        "end": 471.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1374.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.51, 0.13, 0.69, 0.94] location?",
        "answer": "walk [0.51, 0.13, 0.69, 0.94] -> carry/hold (an object) [0.51, 0.13, 0.69, 0.94] -> talk to (e.g., self, a person, a group) [0.51, 0.13, 0.69, 0.94]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "QCLQYnt3aMo",
        "candidates": [
            "walk [0.51, 0.13, 0.69, 0.94] -> carry/hold (an object) [0.51, 0.13, 0.69, 0.94] -> talk to (e.g., self, a person, a group) [0.51, 0.13, 0.69, 0.94]",
            "talk to (e.g., self, a person, a group) [0.60, 0.00, 0.51, 1.00] -> walk [0.66, 0.00, 0.79, 1.00] -> fishing [0.71, 0.09, 0.49, 0.94]",
            "take (an object) from (a person) [0.63, 0.26, 0.71, 1.00] -> walk [0.69, 0.00, 0.71, 1.00] -> talk to (e.g., self, a person, a group) [0.61, 0.14, 0.68, 0.81]",
            "brush teeth [0.70, 0.25, 0.79, 1.00] -> walk [0.40, 0.07, 0.69, 0.94] -> talk to (e.g., self, a person, a group) [0.45, 0.17, 0.58, 1.00]"
        ],
        "start": 0.0,
        "end": 479.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1379.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.38, 0.12, 0.57, 0.99] location?",
        "answer": "walk [0.38, 0.12, 0.57, 0.99] -> carry/hold (an object) [0.38, 0.12, 0.57, 0.99] -> talk to (e.g., self, a person, a group) [0.38, 0.12, 0.57, 0.99]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "QCLQYnt3aMo",
        "candidates": [
            "walk [0.38, 0.12, 0.57, 0.99] -> carry/hold (an object) [0.38, 0.12, 0.57, 0.99] -> talk to (e.g., self, a person, a group) [0.38, 0.12, 0.57, 0.99]",
            "carry/hold (an object) [0.53, 0.04, 0.45, 1.00] -> take a photo [0.50, 0.04, 0.63, 1.00] -> talk to (e.g., self, a person, a group) [0.29, 0.23, 0.54, 1.00]",
            "talk to (e.g., self, a person, a group) [0.38, 0.27, 0.39, 0.94] -> walk [0.43, 0.20, 0.44, 0.97] -> get up [0.33, 0.03, 0.74, 0.84]",
            "give/serve (an object) to (a person) [0.33, 0.26, 0.53, 1.00] -> walk [0.28, 0.12, 0.76, 1.00] -> talk to (e.g., self, a person, a group) [0.36, 0.21, 0.58, 1.00]"
        ],
        "start": 0.0,
        "end": 484.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1387.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.46, 0.14, 0.72, 0.92] location?",
        "answer": "walk [0.46, 0.14, 0.72, 0.92] -> carry/hold (an object) [0.46, 0.14, 0.72, 0.92] -> talk to (e.g., self, a person, a group) [0.46, 0.14, 0.72, 0.92]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "QCLQYnt3aMo",
        "candidates": [
            "talk to (e.g., self, a person, a group) [0.46, 0.21, 0.54, 0.74] -> cut [0.43, 0.13, 0.61, 0.93] -> walk [0.43, 0.05, 0.55, 1.00]",
            "crouch/kneel [0.60, 0.02, 0.82, 0.92] -> talk to (e.g., self, a person, a group) [0.61, 0.02, 0.69, 0.73] -> walk [0.65, 0.06, 0.63, 0.74]",
            "walk [0.46, 0.14, 0.72, 0.92] -> carry/hold (an object) [0.46, 0.14, 0.72, 0.92] -> talk to (e.g., self, a person, a group) [0.46, 0.14, 0.72, 0.92]",
            "talk to (e.g., self, a person, a group) [0.56, 0.11, 0.77, 0.85] -> give/serve (an object) to (a person) [0.55, 0.04, 0.55, 0.85] -> walk [0.40, 0.32, 0.74, 1.00]"
        ],
        "start": 0.0,
        "end": 492.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1399.0,
        "question": "What action is the person at the location [0.36, 0.19, 0.68, 0.98] in the image performing?",
        "answer": "walk, listen to (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "QCLQYnt3aMo",
        "candidates": [
            "stand, listen to (a person), watch (a person)",
            "walk, listen to (a person)",
            "walk, talk to (e.g., self, a person, a group)",
            "stand, carry/hold (an object), talk to (e.g., self, a person, a group), watch (a person)"
        ],
        "start": 0.0,
        "end": 504.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1428.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.00, 0.00, 0.75, 0.98]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "QCLQYnt3aMo",
        "candidates": [
            "[0.07, 0.28, 0.78, 1.00]",
            "[0.01, 0.05, 0.54, 0.70]",
            "[0.18, 0.01, 0.91, 0.98]",
            "[0.00, 0.00, 0.75, 0.98]"
        ],
        "start": 0.0,
        "end": 533.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1534.0,
        "question": "Where is the person currently performing the smoke located in the picture?",
        "answer": "[0.13, 0.00, 1.00, 0.98]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "QCLQYnt3aMo",
        "candidates": [
            "[0.35, 0.00, 0.91, 0.69]",
            "[0.13, 0.00, 1.00, 0.98]",
            "[0.59, 0.15, 0.88, 0.99]",
            "[0.00, 0.09, 0.81, 1.00]"
        ],
        "start": 0.0,
        "end": 639.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1569.0,
        "question": "What action is the person currently in the [0.45, 0.08, 0.90, 0.99] location likely to do next?",
        "answer": "read",
        "sub_answer_type": "FuturePrediction-1",
        "answer_type": "FuturePrediction",
        "video": "QCLQYnt3aMo",
        "candidates": [
            "drive (e.g., a car, a truck)",
            "carry/hold (an object)",
            "play board game",
            "read"
        ],
        "start": 0.0,
        "end": 674.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1574.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.14, 0.08, 0.63, 1.00]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "QCLQYnt3aMo",
        "candidates": [
            "[0.42, 0.37, 0.88, 1.00]",
            "[0.18, 0.38, 0.44, 1.00]",
            "[0.14, 0.08, 0.63, 1.00]",
            "[0.04, 0.00, 0.43, 0.99]"
        ],
        "start": 0.0,
        "end": 679.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1679.0,
        "question": "Is the person currently in the [0.44, 0.07, 0.66, 0.71] location in the current frame performing the talk to (e.g., self, a person, a group)?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "QCLQYnt3aMo",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 784.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1689.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.43, 0.07, 0.65, 0.65]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "QCLQYnt3aMo",
        "candidates": [
            "[0.57, 0.37, 0.90, 0.41]",
            "[0.43, 0.07, 0.65, 0.65]",
            "[0.15, 0.00, 0.50, 0.69]",
            "[0.54, 0.08, 0.83, 0.98]"
        ],
        "start": 0.0,
        "end": 794.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1770.0,
        "question": "What action is the person at the location [0.00, 0.02, 0.66, 0.99] in the image performing?",
        "answer": "sit, listen to (a person), watch (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "QCLQYnt3aMo",
        "candidates": [
            "sit, listen to (a person), watch (a person)",
            "stand, talk to (e.g., self, a person, a group), watch (a person)",
            "walk, talk to (e.g., self, a person, a group)",
            "listen to (a person), lie/sleep, watch (a person)"
        ],
        "start": 0.0,
        "end": 875.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 910.0,
        "question": "Where is the person currently performing the talk to (e.g., self, a person, a group) located in the picture?",
        "answer": "[0.65, 0.21, 0.87, 0.80]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "QTmwhrVal1g",
        "candidates": [
            "[0.74, 0.11, 0.91, 0.55]",
            "[0.69, 0.38, 0.95, 1.00]",
            "[0.65, 0.21, 0.87, 0.80]",
            "[0.14, 0.05, 0.70, 0.99]"
        ],
        "start": 0.0,
        "end": 15.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 928.0,
        "question": "Where was the person currently performing the drive (e.g., a car, a truck) in the scene 8 seconds ago?",
        "answer": "[0.13, 0.18, 0.55, 0.80]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "QTmwhrVal1g",
        "candidates": [
            "[0.00, 0.21, 0.37, 0.79]",
            "[0.13, 0.18, 0.55, 0.80]",
            "[0.00, 0.14, 0.34, 0.54]",
            "[0.20, 0.06, 0.81, 1.00]"
        ],
        "start": 0.0,
        "end": 33.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1031.0,
        "question": "Are there still 1 people in the current frame now?",
        "answer": "No",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "QTmwhrVal1g",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 136.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1088.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "lie/sleep -> answer phone",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "QTmwhrVal1g",
        "candidates": [
            "lie/sleep -> hand wave",
            "lie/sleep -> answer phone",
            "carry/hold (an object) -> lie/sleep",
            "answer phone -> push (another person)"
        ],
        "start": 0.0,
        "end": 193.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1131.0,
        "question": "What action is the person at the location [0.12, 0.06, 0.32, 0.97] in the image performing?",
        "answer": "sit, carry/hold (an object), talk to (e.g., self, a person, a group)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "QTmwhrVal1g",
        "candidates": [
            "walk, carry/hold (an object), give/serve (an object) to (a person), watch (a person)",
            "sit, drive (e.g., a car, a truck), listen to (a person)",
            "sit, drive (e.g., a car, a truck)",
            "sit, carry/hold (an object), talk to (e.g., self, a person, a group)"
        ],
        "start": 0.0,
        "end": 236.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1194.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.16, 0.11, 0.40, 0.77] location?",
        "answer": "touch (an object) [0.13, 0.05, 0.42, 0.83] -> answer phone [0.16, 0.11, 0.40, 0.77] -> carry/hold (an object) [0.16, 0.11, 0.40, 0.77]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "QTmwhrVal1g",
        "candidates": [
            "touch (an object) [0.13, 0.05, 0.42, 0.83] -> answer phone [0.16, 0.11, 0.40, 0.77] -> carry/hold (an object) [0.16, 0.11, 0.40, 0.77]",
            "touch (an object) [0.17, 0.15, 0.34, 0.95] -> answer phone [0.00, 0.31, 0.46, 0.59] -> press [0.03, 0.28, 0.49, 0.81]",
            "answer phone [0.26, 0.00, 0.52, 0.82] -> carry/hold (an object) [0.35, 0.05, 0.27, 0.84] -> lift (a person) [0.15, 0.14, 0.36, 0.88]",
            "answer phone [0.18, 0.25, 0.38, 0.73] -> carry/hold (an object) [0.17, 0.14, 0.50, 0.67] -> pull (an object) [0.20, 0.00, 0.30, 0.77]"
        ],
        "start": 0.0,
        "end": 299.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1195.0,
        "question": "What action is the person currently in the [0.54, 0.67, 0.60, 0.97] location likely to do next?",
        "answer": "touch (an object)",
        "sub_answer_type": "FuturePrediction-1",
        "answer_type": "FuturePrediction",
        "video": "QTmwhrVal1g",
        "candidates": [
            "answer phone and touch (an object)",
            "fight/hit (a person)",
            "touch (an object)",
            "crawl"
        ],
        "start": 0.0,
        "end": 300.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1200.0,
        "question": "Is the person currently in the [0.13, 0.08, 0.42, 0.75] location in the current frame performing the carry/hold (an object)?",
        "answer": "No",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "QTmwhrVal1g",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 305.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1207.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "answer phone -> touch (an object)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "QTmwhrVal1g",
        "candidates": [
            "answer phone -> push (an object)",
            "touch (an object) -> dance",
            "kiss (a person) -> answer phone",
            "answer phone -> touch (an object)"
        ],
        "start": 0.0,
        "end": 312.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1217.0,
        "question": "How many people were performing the watch (a person) in the scene 60 seconds ago?",
        "answer": "3",
        "sub_answer_type": "PastMemory-5",
        "answer_type": "PastMemory",
        "video": "QTmwhrVal1g",
        "candidates": [
            "6",
            "5",
            "3",
            "4"
        ],
        "start": 0.0,
        "end": 322.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1255.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.64, 0.14, 0.88, 0.97] location?",
        "answer": "bend/bow (at the waist) [0.64, 0.14, 0.88, 0.97] -> touch (an object) [0.64, 0.14, 0.88, 0.97] -> talk to (e.g., self, a person, a group) [0.64, 0.14, 0.88, 0.97]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "QTmwhrVal1g",
        "candidates": [
            "paint [0.72, 0.03, 0.70, 0.79] -> bend/bow (at the waist) [0.57, 0.04, 1.00, 1.00] -> talk to (e.g., self, a person, a group) [0.52, 0.21, 0.93, 0.79]",
            "touch (an object) [0.79, 0.09, 1.00, 0.82] -> press [0.76, 0.06, 0.82, 1.00] -> talk to (e.g., self, a person, a group) [0.70, 0.25, 0.84, 0.81]",
            "touch (an object) [0.68, 0.00, 0.86, 1.00] -> play with kids [0.61, 0.14, 0.71, 1.00] -> bend/bow (at the waist) [0.46, 0.25, 0.78, 0.85]",
            "bend/bow (at the waist) [0.64, 0.14, 0.88, 0.97] -> touch (an object) [0.64, 0.14, 0.88, 0.97] -> talk to (e.g., self, a person, a group) [0.64, 0.14, 0.88, 0.97]"
        ],
        "start": 0.0,
        "end": 360.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1255.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "bend/bow (at the waist) -> touch (an object) -> talk to (e.g., self, a person, a group)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "QTmwhrVal1g",
        "candidates": [
            "talk to (e.g., self, a person, a group) -> answer phone -> touch (an object)",
            "talk to (e.g., self, a person, a group) -> bend/bow (at the waist) -> touch (an object)",
            "bend/bow (at the waist) -> touch (an object) -> extract",
            "bend/bow (at the waist) -> touch (an object) -> talk to (e.g., self, a person, a group)"
        ],
        "start": 0.0,
        "end": 360.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1278.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.24, 0.00, 0.83, 0.97] location?",
        "answer": "drive (e.g., a car, a truck) [0.21, 0.00, 0.80, 0.93] -> talk to (e.g., self, a person, a group) [0.21, 0.00, 0.80, 0.93] -> carry/hold (an object) [0.24, 0.00, 0.83, 0.97]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "QTmwhrVal1g",
        "candidates": [
            "drive (e.g., a car, a truck) [0.21, 0.00, 0.80, 0.93] -> talk to (e.g., self, a person, a group) [0.21, 0.00, 0.80, 0.93] -> carry/hold (an object) [0.24, 0.00, 0.83, 0.97]",
            "carry/hold (an object) [0.19, 0.14, 0.95, 1.00] -> talk to (e.g., self, a person, a group) [0.35, 0.06, 0.63, 0.94] -> chop [0.02, 0.20, 0.64, 1.00]",
            "carry/hold (an object) [0.26, 0.17, 0.76, 0.79] -> row boat [0.05, 0.15, 0.77, 0.86] -> drive (e.g., a car, a truck) [0.13, 0.00, 0.63, 0.97]",
            "talk to (e.g., self, a person, a group) [0.36, 0.17, 0.93, 0.95] -> drive (e.g., a car, a truck) [0.09, 0.13, 0.84, 0.90] -> paint [0.35, 0.06, 0.85, 1.00]"
        ],
        "start": 0.0,
        "end": 383.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1293.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "answer phone -> touch (an object)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "QTmwhrVal1g",
        "candidates": [
            "fishing -> touch (an object)",
            "chop -> answer phone",
            "answer phone -> touch (an object)",
            "touch (an object) -> hug (a person)"
        ],
        "start": 0.0,
        "end": 398.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1357.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.38, 0.11, 0.82, 0.98] location?",
        "answer": "talk to (e.g., self, a person, a group) [0.45, 0.25, 0.80, 0.98] -> bend/bow (at the waist) [0.38, 0.11, 0.82, 0.98] -> touch (an object) [0.38, 0.11, 0.82, 0.98]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "QTmwhrVal1g",
        "candidates": [
            "dig [0.43, 0.14, 0.84, 1.00] -> bend/bow (at the waist) [0.45, 0.24, 0.96, 0.79] -> talk to (e.g., self, a person, a group) [0.52, 0.16, 0.83, 1.00]",
            "talk to (e.g., self, a person, a group) [0.62, 0.07, 0.84, 0.87] -> fall down [0.50, 0.16, 0.85, 0.98] -> touch (an object) [0.35, 0.03, 0.86, 0.93]",
            "talk to (e.g., self, a person, a group) [0.45, 0.25, 0.80, 0.98] -> bend/bow (at the waist) [0.38, 0.11, 0.82, 0.98] -> touch (an object) [0.38, 0.11, 0.82, 0.98]",
            "kiss (a person) [0.53, 0.08, 0.84, 1.00] -> bend/bow (at the waist) [0.30, 0.29, 0.65, 0.98] -> touch (an object) [0.23, 0.12, 0.67, 1.00]"
        ],
        "start": 0.0,
        "end": 462.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1380.0,
        "question": "Where was the person currently performing the drive (e.g., a car, a truck) in the scene 8 seconds ago?",
        "answer": "[0.31, 0.21, 0.88, 0.80]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "QTmwhrVal1g",
        "candidates": [
            "[0.59, 0.13, 0.76, 0.58]",
            "[0.57, 0.65, 0.69, 0.99]",
            "[0.34, 0.34, 0.85, 0.98]",
            "[0.31, 0.21, 0.88, 0.80]"
        ],
        "start": 0.0,
        "end": 485.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1401.0,
        "question": "Where is the person currently performing the ride (e.g., a bike, a car, a horse) located in the picture?",
        "answer": "[0.15, 0.04, 0.76, 0.99]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "QTmwhrVal1g",
        "candidates": [
            "[0.12, 0.09, 0.35, 0.73]",
            "[0.15, 0.04, 0.76, 0.99]",
            "[0.15, 0.32, 0.83, 1.00]",
            "[0.45, 0.08, 0.94, 0.83]"
        ],
        "start": 0.0,
        "end": 506.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1408.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "ride (e.g., a bike, a car, a horse) -> answer phone",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "QTmwhrVal1g",
        "candidates": [
            "ride (e.g., a bike, a car, a horse) -> hand clap",
            "ride (e.g., a bike, a car, a horse) -> answer phone",
            "answer phone -> play board game",
            "touch (an object) -> ride (e.g., a bike, a car, a horse)"
        ],
        "start": 0.0,
        "end": 513.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1412.0,
        "question": "Where is the person currently performing the answer phone located in the picture?",
        "answer": "[0.27, 0.03, 0.72, 1.00]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "QTmwhrVal1g",
        "candidates": [
            "[0.30, 0.01, 0.88, 0.72]",
            "[0.00, 0.12, 0.69, 1.00]",
            "[0.51, 0.00, 0.88, 1.00]",
            "[0.27, 0.03, 0.72, 1.00]"
        ],
        "start": 0.0,
        "end": 517.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1452.0,
        "question": "Are there still 2 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "QTmwhrVal1g",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 557.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1466.0,
        "question": "Where was the person currently performing the ride (e.g., a bike, a car, a horse) in the scene 8 seconds ago?",
        "answer": "[0.63, 0.26, 0.88, 0.81]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "QTmwhrVal1g",
        "candidates": [
            "[0.15, 0.06, 0.71, 1.00]",
            "[0.63, 0.26, 0.88, 0.81]",
            "[0.45, 0.39, 0.65, 0.97]",
            "[0.66, 0.00, 0.71, 0.63]"
        ],
        "start": 0.0,
        "end": 571.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1626.0,
        "question": "Is the person currently in the [0.16, 0.02, 0.58, 0.95] location in the current frame performing the drive (e.g., a car, a truck)?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "QTmwhrVal1g",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 731.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1648.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.61, 0.18, 0.86, 0.63] location?",
        "answer": "carry/hold (an object) [0.61, 0.18, 0.86, 0.63] -> ride (e.g., a bike, a car, a horse) [0.61, 0.18, 0.86, 0.63] -> talk to (e.g., self, a person, a group) [0.61, 0.18, 0.86, 0.63]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "QTmwhrVal1g",
        "candidates": [
            "carry/hold (an object) [0.61, 0.18, 0.86, 0.63] -> ride (e.g., a bike, a car, a horse) [0.61, 0.18, 0.86, 0.63] -> talk to (e.g., self, a person, a group) [0.61, 0.18, 0.86, 0.63]",
            "push (another person) [0.51, 0.12, 0.83, 0.48] -> carry/hold (an object) [0.57, 0.35, 0.77, 0.65] -> talk to (e.g., self, a person, a group) [0.76, 0.16, 0.98, 0.58]",
            "talk to (e.g., self, a person, a group) [0.71, 0.03, 0.78, 0.47] -> carry/hold (an object) [0.68, 0.14, 0.69, 0.69] -> jump/leap [0.47, 0.17, 0.96, 0.57]",
            "ride (e.g., a bike, a car, a horse) [0.58, 0.20, 0.81, 0.80] -> hit (an object) [0.56, 0.02, 0.73, 0.45] -> carry/hold (an object) [0.74, 0.06, 0.94, 0.69]"
        ],
        "start": 0.0,
        "end": 753.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1712.0,
        "question": "What action is the person at the location [0.17, 0.07, 0.22, 0.35] in the image performing?",
        "answer": "walk, listen to (a person), watch (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "QTmwhrVal1g",
        "candidates": [
            "sit, drive (e.g., a car, a truck), listen to (a person)",
            "sit, drive (e.g., a car, a truck), talk to (e.g., self, a person, a group)",
            "stand, listen to (a person), watch (a person)",
            "walk, listen to (a person), watch (a person)"
        ],
        "start": 0.0,
        "end": 817.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1787.0,
        "question": "How many people were performing the stand in the scene 60 seconds ago?",
        "answer": "4",
        "sub_answer_type": "PastMemory-5",
        "answer_type": "PastMemory",
        "video": "QTmwhrVal1g",
        "candidates": [
            "7",
            "5",
            "3",
            "4"
        ],
        "start": 0.0,
        "end": 892.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 943.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.71, 0.22, 0.96, 0.98] location?",
        "answer": "talk to (e.g., self, a person, a group) [0.66, 0.25, 0.89, 0.97] -> walk [0.71, 0.22, 0.96, 0.98] -> carry/hold (an object) [0.71, 0.22, 0.96, 0.98]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "SCh-ZImnyyk",
        "candidates": [
            "talk to (e.g., self, a person, a group) [0.66, 0.25, 0.89, 0.97] -> walk [0.71, 0.22, 0.96, 0.98] -> carry/hold (an object) [0.71, 0.22, 0.96, 0.98]",
            "carry/hold (an object) [0.52, 0.27, 0.93, 1.00] -> stir [0.75, 0.35, 1.00, 1.00] -> talk to (e.g., self, a person, a group) [0.51, 0.44, 0.79, 0.99]",
            "talk to (e.g., self, a person, a group) [0.68, 0.40, 0.84, 0.78] -> turn (e.g., a screwdriver) [0.88, 0.17, 0.81, 0.87] -> carry/hold (an object) [0.69, 0.41, 1.00, 0.82]",
            "carry/hold (an object) [0.54, 0.17, 0.93, 1.00] -> talk to (e.g., self, a person, a group) [0.58, 0.13, 0.73, 1.00] -> stir [0.64, 0.24, 1.00, 0.92]"
        ],
        "start": 0.0,
        "end": 48.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1005.0,
        "question": "What action is the person at the location [0.11, 0.34, 0.48, 0.80] in the image performing?",
        "answer": "sit, touch (an object), listen to (a person), talk to (e.g., self, a person, a group), watch (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "SCh-ZImnyyk",
        "candidates": [
            "sit, talk to (e.g., self, a person, a group), watch (a person)",
            "sit, touch (an object), listen to (a person), talk to (e.g., self, a person, a group), watch (a person)",
            "sit, text on/look at a cellphone, touch (an object), listen to (a person)",
            "sit, carry/hold (an object), talk to (e.g., self, a person, a group)"
        ],
        "start": 0.0,
        "end": 110.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1045.0,
        "question": "Is the person currently in the [0.01, 0.01, 0.93, 0.99] location in the current frame performing the talk to (e.g., self, a person, a group)?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "SCh-ZImnyyk",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 150.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1099.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.20, 0.35, 0.46, 0.81]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "SCh-ZImnyyk",
        "candidates": [
            "[0.22, 0.48, 0.60, 1.00]",
            "[0.38, 0.28, 0.29, 0.54]",
            "[0.51, 0.30, 0.77, 0.86]",
            "[0.20, 0.35, 0.46, 0.81]"
        ],
        "start": 0.0,
        "end": 204.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1104.0,
        "question": "Where is the person currently performing the talk to (e.g., self, a person, a group) located in the picture?",
        "answer": "[0.01, 0.03, 0.98, 0.99]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "SCh-ZImnyyk",
        "candidates": [
            "[0.01, 0.03, 0.98, 0.99]",
            "[0.06, 0.00, 1.00, 0.70]",
            "[0.30, 0.00, 1.00, 1.00]",
            "[0.22, 0.09, 0.41, 0.79]"
        ],
        "start": 0.0,
        "end": 209.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1132.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.45, 0.21, 0.88, 0.99] location?",
        "answer": "bend/bow (at the waist) [0.45, 0.21, 0.88, 0.99] -> carry/hold (an object) [0.45, 0.21, 0.88, 0.99] -> give/serve (an object) to (a person) [0.45, 0.21, 0.88, 0.99]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "SCh-ZImnyyk",
        "candidates": [
            "crouch/kneel [0.48, 0.24, 1.00, 0.96] -> carry/hold (an object) [0.59, 0.25, 1.00, 0.85] -> bend/bow (at the waist) [0.40, 0.09, 0.94, 0.91]",
            "carry/hold (an object) [0.29, 0.11, 0.69, 0.81] -> carry/hold (an object) [0.39, 0.15, 1.00, 1.00] -> bend/bow (at the waist) [0.65, 0.33, 0.95, 1.00]",
            "bend/bow (at the waist) [0.58, 0.32, 1.00, 0.87] -> give/serve (an object) to (a person) [0.52, 0.39, 0.92, 0.80] -> dig [0.64, 0.02, 0.70, 0.88]",
            "bend/bow (at the waist) [0.45, 0.21, 0.88, 0.99] -> carry/hold (an object) [0.45, 0.21, 0.88, 0.99] -> give/serve (an object) to (a person) [0.45, 0.21, 0.88, 0.99]"
        ],
        "start": 0.0,
        "end": 237.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1166.0,
        "question": "Are there still 3 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "SCh-ZImnyyk",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 271.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1222.0,
        "question": "What action is the person at the location [0.17, 0.00, 0.39, 0.99] in the image performing?",
        "answer": "stand, carry/hold (an object), talk to (e.g., self, a person, a group), watch (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "SCh-ZImnyyk",
        "candidates": [
            "stand, carry/hold (an object), talk to (e.g., self, a person, a group), watch (a person)",
            "sit, watch (a person)",
            "sit, talk to (e.g., self, a person, a group), watch (a person)",
            "sit, listen to (a person), watch (a person)"
        ],
        "start": 0.0,
        "end": 327.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1290.0,
        "question": "Where was the person currently performing the carry/hold (an object) in the scene 8 seconds ago?",
        "answer": "[0.58, 0.07, 0.99, 0.97]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "SCh-ZImnyyk",
        "candidates": [
            "[0.57, 0.00, 1.00, 0.71]",
            "[0.17, 0.22, 0.52, 0.74]",
            "[0.79, 0.35, 0.99, 1.00]",
            "[0.58, 0.07, 0.99, 0.97]"
        ],
        "start": 0.0,
        "end": 395.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1307.0,
        "question": "Is the person currently in the [0.47, 0.00, 0.81, 0.89] location in the current frame performing the walk?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "SCh-ZImnyyk",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 412.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1307.0,
        "question": "Where is the person currently performing the walk located in the picture?",
        "answer": "[0.47, 0.00, 0.81, 0.89]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "SCh-ZImnyyk",
        "candidates": [
            "[0.49, 0.26, 1.00, 1.00]",
            "[0.69, 0.00, 1.00, 0.73]",
            "[0.47, 0.00, 0.81, 0.89]",
            "[0.30, 0.36, 0.70, 0.91]"
        ],
        "start": 0.0,
        "end": 412.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1313.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.28, 0.07, 0.54, 1.00] location?",
        "answer": "talk to (e.g., self, a person, a group) [0.34, 0.17, 0.48, 0.83] -> walk [0.28, 0.07, 0.54, 1.00] -> carry/hold (an object) [0.28, 0.07, 0.54, 1.00]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "SCh-ZImnyyk",
        "candidates": [
            "carry/hold (an object) [0.31, 0.03, 0.62, 1.00] -> exit [0.36, 0.32, 0.39, 1.00] -> walk [0.42, 0.06, 0.44, 1.00]",
            "walk [0.40, 0.20, 0.41, 0.82] -> carry/hold (an object) [0.21, 0.04, 0.53, 1.00] -> push (another person) [0.41, 0.32, 0.51, 0.78]",
            "talk to (e.g., self, a person, a group) [0.34, 0.17, 0.48, 0.83] -> walk [0.28, 0.07, 0.54, 1.00] -> carry/hold (an object) [0.28, 0.07, 0.54, 1.00]",
            "talk to (e.g., self, a person, a group) [0.35, 0.32, 0.34, 0.75] -> walk [0.29, 0.00, 0.51, 0.81] -> pull (an object) [0.46, 0.10, 0.42, 0.93]"
        ],
        "start": 0.0,
        "end": 418.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1404.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.28, 0.29, 0.60, 0.87]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "SCh-ZImnyyk",
        "candidates": [
            "[0.28, 0.29, 0.60, 0.87]",
            "[0.34, 0.58, 0.42, 0.91]",
            "[0.49, 0.07, 0.99, 0.93]",
            "[0.38, 0.01, 0.59, 0.60]"
        ],
        "start": 0.0,
        "end": 509.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1448.0,
        "question": "Are there still 1 people in the current frame now?",
        "answer": "No",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "SCh-ZImnyyk",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 553.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1563.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.05, 0.01, 0.93, 0.99]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "SCh-ZImnyyk",
        "candidates": [
            "[0.33, 0.08, 1.00, 1.00]",
            "[0.52, 0.09, 0.69, 0.64]",
            "[0.05, 0.01, 0.93, 0.99]",
            "[0.02, 0.00, 0.64, 0.77]"
        ],
        "start": 0.0,
        "end": 668.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1663.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.03, 0.14, 0.58, 0.98]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "SCh-ZImnyyk",
        "candidates": [
            "[0.03, 0.14, 0.58, 0.98]",
            "[0.15, 0.31, 0.79, 1.00]",
            "[0.30, 0.20, 0.66, 0.71]",
            "[0.54, 0.09, 0.70, 0.62]"
        ],
        "start": 0.0,
        "end": 768.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1678.0,
        "question": "Are there still 2 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "SCh-ZImnyyk",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 783.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1748.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.55, 0.28, 0.90, 0.80] location?",
        "answer": "talk to (e.g., self, a person, a group) [0.55, 0.28, 0.90, 0.81] -> carry/hold (an object) [0.55, 0.28, 0.90, 0.80] -> touch (an object) [0.55, 0.28, 0.90, 0.80]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "SCh-ZImnyyk",
        "candidates": [
            "touch (an object) [0.66, 0.34, 1.00, 0.74] -> play with kids [0.60, 0.34, 1.00, 0.77] -> carry/hold (an object) [0.37, 0.30, 1.00, 0.93]",
            "carry/hold (an object) [0.61, 0.34, 0.77, 0.95] -> kick (an object) [0.38, 0.40, 0.81, 0.79] -> touch (an object) [0.46, 0.40, 0.88, 0.71]",
            "talk to (e.g., self, a person, a group) [0.55, 0.28, 0.90, 0.81] -> carry/hold (an object) [0.55, 0.28, 0.90, 0.80] -> touch (an object) [0.55, 0.28, 0.90, 0.80]",
            "talk to (e.g., self, a person, a group) [0.44, 0.18, 0.75, 0.91] -> extract [0.55, 0.20, 0.86, 0.79] -> touch (an object) [0.61, 0.27, 1.00, 0.61]"
        ],
        "start": 0.0,
        "end": 853.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1751.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.17, 0.32, 0.55, 0.74] location?",
        "answer": "carry/hold (an object) [0.17, 0.32, 0.55, 0.74] -> touch (an object) [0.17, 0.32, 0.55, 0.74] -> talk to (e.g., self, a person, a group) [0.17, 0.32, 0.55, 0.74]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "SCh-ZImnyyk",
        "candidates": [
            "talk to (e.g., self, a person, a group) [0.22, 0.26, 0.66, 0.85] -> hug (a person) [0.33, 0.36, 0.61, 0.91] -> carry/hold (an object) [0.29, 0.21, 0.71, 0.78]",
            "talk to (e.g., self, a person, a group) [0.32, 0.44, 0.38, 0.89] -> stir [0.17, 0.23, 0.67, 0.81] -> carry/hold (an object) [0.09, 0.25, 0.37, 0.85]",
            "talk to (e.g., self, a person, a group) [0.06, 0.33, 0.44, 0.59] -> touch (an object) [0.18, 0.15, 0.56, 0.78] -> crouch/kneel [0.14, 0.39, 0.56, 0.65]",
            "carry/hold (an object) [0.17, 0.32, 0.55, 0.74] -> touch (an object) [0.17, 0.32, 0.55, 0.74] -> talk to (e.g., self, a person, a group) [0.17, 0.32, 0.55, 0.74]"
        ],
        "start": 0.0,
        "end": 856.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1763.0,
        "question": "What action is the person currently in the [0.18, 0.20, 0.52, 0.76] location likely to do next?",
        "answer": "text on/look at a cellphone",
        "sub_answer_type": "FuturePrediction-1",
        "answer_type": "FuturePrediction",
        "video": "SCh-ZImnyyk",
        "candidates": [
            "carry/hold (an object) and talk to (e.g., self, a person, a group)",
            "cut",
            "lift (a person)",
            "text on/look at a cellphone"
        ],
        "start": 0.0,
        "end": 868.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1773.0,
        "question": "Where is the person currently performing the touch (an object) located in the picture?",
        "answer": "[0.58, 0.27, 0.96, 0.83]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "SCh-ZImnyyk",
        "candidates": [
            "[0.84, 0.44, 1.00, 0.54]",
            "[0.58, 0.27, 0.96, 0.83]",
            "[0.29, 0.37, 1.00, 0.97]",
            "[0.03, 0.06, 1.00, 0.99]"
        ],
        "start": 0.0,
        "end": 878.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 914.0,
        "question": "Are there still 1 people in the current frame now?",
        "answer": "No",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "TEQ9sAj-DPo",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 19.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 944.0,
        "question": "Where was the person currently performing the sail boat in the scene 8 seconds ago?",
        "answer": "[0.03, 0.01, 0.67, 0.93]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "TEQ9sAj-DPo",
        "candidates": [
            "[0.00, 0.08, 0.38, 1.00]",
            "[0.33, 0.08, 0.98, 1.00]",
            "[0.03, 0.01, 0.67, 0.93]",
            "[0.08, 0.22, 0.81, 0.98]"
        ],
        "start": 0.0,
        "end": 49.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 967.0,
        "question": "What action is the person at the location [0.01, 0.05, 0.37, 0.99] in the image performing?",
        "answer": "stand, carry/hold (an object), talk to (e.g., self, a person, a group), watch (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "TEQ9sAj-DPo",
        "candidates": [
            "sit, listen to (a person)",
            "stand, watch (a person)",
            "stand, carry/hold (an object), talk to (e.g., self, a person, a group), watch (a person)",
            "sit, ride (e.g., a bike, a car, a horse)"
        ],
        "start": 0.0,
        "end": 72.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1080.0,
        "question": "Where was the person currently performing the carry/hold (an object) in the scene 8 seconds ago?",
        "answer": "[0.31, 0.08, 0.99, 0.98]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "TEQ9sAj-DPo",
        "candidates": [
            "[0.02, 0.00, 1.00, 0.70]",
            "[0.34, 0.00, 1.00, 0.72]",
            "[0.09, 0.25, 0.40, 0.97]",
            "[0.31, 0.08, 0.99, 0.98]"
        ],
        "start": 0.0,
        "end": 185.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1149.0,
        "question": "Where is the person currently performing the talk to (e.g., self, a person, a group) located in the picture?",
        "answer": "[0.35, 0.17, 0.73, 0.76]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "TEQ9sAj-DPo",
        "candidates": [
            "[0.10, 0.05, 0.67, 1.00]",
            "[0.31, 0.00, 0.54, 0.51]",
            "[0.35, 0.17, 0.73, 0.76]",
            "[0.20, 0.44, 0.80, 1.00]"
        ],
        "start": 0.0,
        "end": 254.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1164.0,
        "question": "What action is the person currently in the [0.46, 0.01, 0.99, 0.98] location likely to do next?",
        "answer": "ride (e.g., a bike, a car, a horse)",
        "sub_answer_type": "FuturePrediction-1",
        "answer_type": "FuturePrediction",
        "video": "TEQ9sAj-DPo",
        "candidates": [
            "watch (e.g., TV)",
            "exit",
            "ride (e.g., a bike, a car, a horse)",
            "drive (e.g., a car, a truck)"
        ],
        "start": 0.0,
        "end": 269.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1177.0,
        "question": "Where was the person currently performing the ride (e.g., a bike, a car, a horse) in the scene 8 seconds ago?",
        "answer": "[0.22, 0.00, 0.94, 0.96]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "TEQ9sAj-DPo",
        "candidates": [
            "[0.22, 0.00, 0.94, 0.96]",
            "[0.12, 0.27, 1.00, 1.00]",
            "[0.01, 0.00, 0.83, 1.00]",
            "[0.62, 0.01, 1.00, 0.99]"
        ],
        "start": 0.0,
        "end": 282.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1187.0,
        "question": "Where was the person currently performing the carry/hold (an object) in the scene 8 seconds ago?",
        "answer": "[0.52, 0.00, 1.00, 1.00]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "TEQ9sAj-DPo",
        "candidates": [
            "[0.34, 0.25, 0.80, 1.00]",
            "[0.05, 0.01, 0.74, 0.92]",
            "[0.52, 0.00, 1.00, 1.00]",
            "[0.56, 0.00, 0.76, 0.74]"
        ],
        "start": 0.0,
        "end": 292.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1219.0,
        "question": "Is the person currently in the [0.00, 0.00, 0.35, 0.99] location in the current frame performing the drive (e.g., a car, a truck)?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "TEQ9sAj-DPo",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 324.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1251.0,
        "question": "Are there still 1 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "TEQ9sAj-DPo",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 356.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1259.0,
        "question": "Where is the person currently performing the ride (e.g., a bike, a car, a horse) located in the picture?",
        "answer": "[0.05, 0.00, 0.79, 0.98]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "TEQ9sAj-DPo",
        "candidates": [
            "[0.42, 0.11, 0.99, 1.00]",
            "[0.00, 0.00, 0.59, 0.69]",
            "[0.26, 0.00, 0.88, 0.72]",
            "[0.05, 0.00, 0.79, 0.98]"
        ],
        "start": 0.0,
        "end": 364.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1450.0,
        "question": "Where was the person currently performing the walk in the scene 8 seconds ago?",
        "answer": "[0.14, 0.46, 0.29, 0.99]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "TEQ9sAj-DPo",
        "candidates": [
            "[0.35, 0.08, 0.98, 0.98]",
            "[0.41, 0.31, 0.49, 1.00]",
            "[0.24, 0.17, 0.06, 0.79]",
            "[0.14, 0.46, 0.29, 0.99]"
        ],
        "start": 0.0,
        "end": 555.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1487.0,
        "question": "Where is the person currently performing the walk located in the picture?",
        "answer": "[0.11, 0.17, 0.68, 0.99]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "TEQ9sAj-DPo",
        "candidates": [
            "[0.46, 0.34, 0.71, 0.99]",
            "[0.00, 0.00, 0.66, 0.75]",
            "[0.35, 0.00, 0.70, 1.00]",
            "[0.11, 0.17, 0.68, 0.99]"
        ],
        "start": 0.0,
        "end": 592.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1503.0,
        "question": "Are there still 2 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "TEQ9sAj-DPo",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 608.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1600.0,
        "question": "Where is the person currently performing the walk located in the picture?",
        "answer": "[0.16, 0.00, 0.78, 0.99]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "TEQ9sAj-DPo",
        "candidates": [
            "[0.45, 0.00, 0.84, 0.91]",
            "[0.14, 0.47, 0.39, 0.99]",
            "[0.07, 0.00, 0.57, 0.74]",
            "[0.16, 0.00, 0.78, 0.99]"
        ],
        "start": 0.0,
        "end": 705.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1676.0,
        "question": "Are there still 1 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "TEQ9sAj-DPo",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 781.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1061.0,
        "question": "Where is the person currently performing the walk located in the picture?",
        "answer": "[0.11, 0.04, 0.82, 0.98]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "UOyyTUX5Vo4",
        "candidates": [
            "[0.00, 0.05, 0.58, 0.98]",
            "[0.11, 0.04, 0.82, 0.98]",
            "[0.00, 0.32, 1.00, 1.00]",
            "[0.39, 0.00, 0.89, 0.79]"
        ],
        "start": 0.0,
        "end": 166.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1095.0,
        "question": "Are there still 1 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "UOyyTUX5Vo4",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 200.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1151.0,
        "question": "Is the person currently in the [0.51, 0.00, 1.00, 0.99] location in the current frame performing the carry/hold (an object)?",
        "answer": "No",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "UOyyTUX5Vo4",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 256.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1191.0,
        "question": "Where is the person currently performing the carry/hold (an object) located in the picture?",
        "answer": "[0.00, 0.01, 0.92, 0.94]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "UOyyTUX5Vo4",
        "candidates": [
            "[0.02, 0.37, 0.28, 0.99]",
            "[0.20, 0.00, 0.87, 0.64]",
            "[0.00, 0.01, 0.92, 0.94]",
            "[0.00, 0.17, 0.67, 1.00]"
        ],
        "start": 0.0,
        "end": 296.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1217.0,
        "question": "Where was the person currently performing the bend/bow (at the waist) in the scene 8 seconds ago?",
        "answer": "[0.31, 0.31, 0.77, 0.98]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "UOyyTUX5Vo4",
        "candidates": [
            "[0.07, 0.26, 0.54, 1.00]",
            "[0.32, 0.14, 0.83, 0.70]",
            "[0.31, 0.31, 0.77, 0.98]",
            "[0.27, 0.16, 0.53, 0.86]"
        ],
        "start": 0.0,
        "end": 322.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1316.0,
        "question": "Is the person currently in the [0.24, 0.51, 0.29, 0.83] location in the current frame performing the carry/hold (an object)?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "UOyyTUX5Vo4",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 421.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1326.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.62, 0.19, 0.73, 0.63]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "UOyyTUX5Vo4",
        "candidates": [
            "[0.83, 0.00, 0.51, 0.46]",
            "[0.14, 0.22, 0.44, 0.99]",
            "[0.62, 0.19, 0.73, 0.63]",
            "[0.76, 0.29, 0.80, 0.83]"
        ],
        "start": 0.0,
        "end": 431.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1438.0,
        "question": "Where is the person currently performing the carry/hold (an object) located in the picture?",
        "answer": "[0.54, 0.29, 0.89, 0.92]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "UOyyTUX5Vo4",
        "candidates": [
            "[0.07, 0.16, 0.50, 0.97]",
            "[0.30, 0.19, 0.94, 0.75]",
            "[0.54, 0.29, 0.89, 0.92]",
            "[0.77, 0.50, 1.00, 0.77]"
        ],
        "start": 0.0,
        "end": 543.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1453.0,
        "question": "What action is the person currently in the [0.01, 0.02, 0.64, 0.98] location likely to do next?",
        "answer": "walk and talk to (e.g., self, a person, a group)",
        "sub_answer_type": "FuturePrediction-1",
        "answer_type": "FuturePrediction",
        "video": "UOyyTUX5Vo4",
        "candidates": [
            "walk and talk to (e.g., self, a person, a group)",
            "shovel",
            "play with pets",
            "carry/hold (an object)"
        ],
        "start": 0.0,
        "end": 558.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1481.0,
        "question": "Is the person currently in the [0.14, 0.20, 0.49, 0.99] location in the current frame performing the talk to (e.g., self, a person, a group)?",
        "answer": "No",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "UOyyTUX5Vo4",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 586.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1515.0,
        "question": "Where is the person currently performing the carry/hold (an object) located in the picture?",
        "answer": "[0.10, 0.16, 0.40, 1.00]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "UOyyTUX5Vo4",
        "candidates": [
            "[0.10, 0.16, 0.40, 1.00]",
            "[0.25, 0.08, 0.40, 0.61]",
            "[0.33, 0.22, 0.70, 1.00]",
            "[0.00, 0.09, 0.14, 1.00]"
        ],
        "start": 0.0,
        "end": 620.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1525.0,
        "question": "Where was the person currently performing the carry/hold (an object) in the scene 8 seconds ago?",
        "answer": "[0.08, 0.19, 0.39, 0.99]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "UOyyTUX5Vo4",
        "candidates": [
            "[0.56, 0.25, 0.85, 0.98]",
            "[0.00, 0.00, 0.56, 0.73]",
            "[0.00, 0.00, 0.16, 1.00]",
            "[0.08, 0.19, 0.39, 0.99]"
        ],
        "start": 0.0,
        "end": 630.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1538.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.47, 0.05, 0.76, 0.99]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "UOyyTUX5Vo4",
        "candidates": [
            "[0.22, 0.00, 0.68, 0.79]",
            "[0.31, 0.28, 0.54, 1.00]",
            "[0.13, 0.23, 0.39, 0.98]",
            "[0.47, 0.05, 0.76, 0.99]"
        ],
        "start": 0.0,
        "end": 643.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1551.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.47, 0.06, 0.75, 0.98]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "UOyyTUX5Vo4",
        "candidates": [
            "[0.47, 0.06, 0.75, 0.98]",
            "[0.52, 0.32, 0.88, 0.99]",
            "[0.00, 0.46, 0.33, 0.99]",
            "[0.33, 0.00, 0.61, 0.90]"
        ],
        "start": 0.0,
        "end": 656.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1768.0,
        "question": "What action is the person at the location [0.14, 0.27, 0.46, 0.72] in the image performing?",
        "answer": "sit, listen to (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "UOyyTUX5Vo4",
        "candidates": [
            "sit, listen to (a person)",
            "stand, listen to (a person), watch (a person)",
            "sit, carry/hold (an object), listen to (a person)",
            "stand, talk to (e.g., self, a person, a group), watch (a person)"
        ],
        "start": 0.0,
        "end": 873.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 903.0,
        "question": "Are there still 3 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "UrsCy6qIGoo",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 8.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 903.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.67, 0.53, 0.74, 0.75] location?",
        "answer": "carry/hold (an object) [0.67, 0.53, 0.74, 0.75] -> crouch/kneel [0.67, 0.53, 0.74, 0.75] -> talk to (e.g., self, a person, a group) [0.67, 0.53, 0.74, 0.75]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "UrsCy6qIGoo",
        "candidates": [
            "talk to (e.g., self, a person, a group) [0.75, 0.55, 0.82, 0.89] -> carry/hold (an object) [0.64, 0.60, 0.87, 0.90] -> hand shake [0.87, 0.45, 0.62, 0.77]",
            "talk to (e.g., self, a person, a group) [0.57, 0.51, 0.88, 0.56] -> kiss (a person) [0.56, 0.43, 0.82, 0.90] -> crouch/kneel [0.86, 0.62, 0.82, 0.77]",
            "carry/hold (an object) [0.67, 0.53, 0.74, 0.75] -> crouch/kneel [0.67, 0.53, 0.74, 0.75] -> talk to (e.g., self, a person, a group) [0.67, 0.53, 0.74, 0.75]",
            "carry/hold (an object) [0.75, 0.63, 0.58, 0.59] -> talk to (e.g., self, a person, a group) [0.51, 0.57, 0.91, 0.71] -> crouch/kneel [0.66, 0.33, 0.73, 0.92]"
        ],
        "start": 0.0,
        "end": 8.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 939.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "ride (e.g., a bike, a car, a horse) -> carry/hold (an object)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "UrsCy6qIGoo",
        "candidates": [
            "ride (e.g., a bike, a car, a horse) -> kick (an object)",
            "carry/hold (an object) -> row boat",
            "ride (e.g., a bike, a car, a horse) -> carry/hold (an object)",
            "eat -> carry/hold (an object)"
        ],
        "start": 0.0,
        "end": 44.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 943.0,
        "question": "Where is the person currently performing the run/jog located in the picture?",
        "answer": "[0.82, 0.36, 0.85, 0.50]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "UrsCy6qIGoo",
        "candidates": [
            "[0.82, 0.36, 0.85, 0.50]",
            "[0.08, 0.02, 0.78, 0.99]",
            "[1.00, 0.21, 0.93, 0.50]",
            "[0.54, 0.09, 1.00, 0.35]"
        ],
        "start": 0.0,
        "end": 48.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1008.0,
        "question": "Where was the person currently performing the read in the scene 8 seconds ago?",
        "answer": "[0.66, 0.16, 1.00, 0.94]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "UrsCy6qIGoo",
        "candidates": [
            "[0.00, 0.16, 0.59, 0.97]",
            "[0.66, 0.16, 1.00, 0.94]",
            "[0.61, 0.26, 0.74, 1.00]",
            "[0.59, 0.00, 0.72, 0.83]"
        ],
        "start": 0.0,
        "end": 113.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1020.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.71, 0.17, 0.99, 0.94] location?",
        "answer": "talk to (e.g., self, a person, a group) [0.70, 0.18, 0.99, 0.94] -> carry/hold (an object) [0.71, 0.17, 0.99, 0.94] -> read [0.71, 0.17, 0.99, 0.94]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "UrsCy6qIGoo",
        "candidates": [
            "talk to (e.g., self, a person, a group) [0.70, 0.18, 0.99, 0.94] -> carry/hold (an object) [0.71, 0.17, 0.99, 0.94] -> read [0.71, 0.17, 0.99, 0.94]",
            "shoot [0.73, 0.34, 1.00, 0.96] -> talk to (e.g., self, a person, a group) [0.61, 0.11, 0.96, 0.74] -> read [0.76, 0.14, 0.99, 1.00]",
            "carry/hold (an object) [0.74, 0.08, 0.92, 1.00] -> talk to (e.g., self, a person, a group) [0.90, 0.20, 0.99, 0.84] -> ride (e.g., a bike, a car, a horse) [0.67, 0.08, 1.00, 0.97]",
            "fight/hit (a person) [0.59, 0.10, 1.00, 0.96] -> carry/hold (an object) [0.64, 0.01, 0.86, 0.87] -> talk to (e.g., self, a person, a group) [0.80, 0.12, 0.99, 1.00]"
        ],
        "start": 0.0,
        "end": 125.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1121.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "drive (e.g., a car, a truck) -> talk to (e.g., self, a person, a group)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "UrsCy6qIGoo",
        "candidates": [
            "drive (e.g., a car, a truck) -> talk to (e.g., self, a person, a group)",
            "talk to (e.g., self, a person, a group) -> brush teeth",
            "talk to (e.g., self, a person, a group) -> give/serve (an object) to (a person)",
            "clink glass -> talk to (e.g., self, a person, a group)"
        ],
        "start": 0.0,
        "end": 226.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1123.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "ride (e.g., a bike, a car, a horse) -> talk to (e.g., self, a person, a group)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "UrsCy6qIGoo",
        "candidates": [
            "ride (e.g., a bike, a car, a horse) -> talk to (e.g., self, a person, a group)",
            "row boat -> talk to (e.g., self, a person, a group)",
            "ride (e.g., a bike, a car, a horse) -> dance",
            "take (an object) from (a person) -> talk to (e.g., self, a person, a group)"
        ],
        "start": 0.0,
        "end": 228.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1134.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "ride (e.g., a bike, a car, a horse) -> talk to (e.g., self, a person, a group)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "UrsCy6qIGoo",
        "candidates": [
            "talk to (e.g., self, a person, a group) -> drive (e.g., a car, a truck)",
            "ride (e.g., a bike, a car, a horse) -> talk to (e.g., self, a person, a group)",
            "shoot -> ride (e.g., a bike, a car, a horse)",
            "talk to (e.g., self, a person, a group) -> catch (an object)"
        ],
        "start": 0.0,
        "end": 239.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1145.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.09, 0.19, 0.41, 0.97] location?",
        "answer": "bend/bow (at the waist) [0.09, 0.19, 0.41, 0.97] -> carry/hold (an object) [0.09, 0.19, 0.41, 0.97] -> talk to (e.g., self, a person, a group) [0.09, 0.19, 0.41, 0.97]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "UrsCy6qIGoo",
        "candidates": [
            "hit (an object) [0.00, 0.10, 0.60, 1.00] -> carry/hold (an object) [0.01, 0.09, 0.44, 0.97] -> bend/bow (at the waist) [0.28, 0.25, 0.28, 0.86]",
            "talk to (e.g., self, a person, a group) [0.23, 0.05, 0.44, 1.00] -> swim [0.24, 0.26, 0.44, 0.82] -> bend/bow (at the waist) [0.09, 0.16, 0.37, 0.86]",
            "bend/bow (at the waist) [0.09, 0.19, 0.41, 0.97] -> carry/hold (an object) [0.09, 0.19, 0.41, 0.97] -> talk to (e.g., self, a person, a group) [0.09, 0.19, 0.41, 0.97]",
            "talk to (e.g., self, a person, a group) [0.00, 0.22, 0.31, 1.00] -> drive (e.g., a car, a truck) [0.27, 0.01, 0.50, 1.00] -> carry/hold (an object) [0.15, 0.01, 0.59, 0.79]"
        ],
        "start": 0.0,
        "end": 250.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1156.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.04, 0.17, 0.23, 0.73] location?",
        "answer": "bend/bow (at the waist) [0.04, 0.17, 0.23, 0.73] -> carry/hold (an object) [0.04, 0.17, 0.23, 0.73] -> talk to (e.g., self, a person, a group) [0.04, 0.17, 0.23, 0.73]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "UrsCy6qIGoo",
        "candidates": [
            "bend/bow (at the waist) [0.18, 0.17, 0.41, 0.86] -> carry/hold (an object) [0.01, 0.34, 0.06, 0.84] -> talk to (e.g., self, a person, a group) [0.00, 0.15, 0.19, 0.86]",
            "bend/bow (at the waist) [0.04, 0.17, 0.23, 0.73] -> carry/hold (an object) [0.04, 0.17, 0.23, 0.73] -> talk to (e.g., self, a person, a group) [0.04, 0.17, 0.23, 0.73]",
            "talk to (e.g., self, a person, a group) [0.00, 0.15, 0.18, 0.63] -> carry/hold (an object) [0.08, 0.35, 0.20, 0.75] -> touch (an object) [0.19, 0.21, 0.26, 0.78]",
            "brush teeth [0.00, 0.30, 0.31, 0.85] -> talk to (e.g., self, a person, a group) [0.02, 0.04, 0.13, 0.85] -> bend/bow (at the waist) [0.15, 0.00, 0.04, 0.66]"
        ],
        "start": 0.0,
        "end": 261.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1298.0,
        "question": "What action is the person at the location [0.00, 0.04, 0.45, 0.97] in the image performing?",
        "answer": "sit, talk to (e.g., self, a person, a group), watch (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "UrsCy6qIGoo",
        "candidates": [
            "sit, talk to (e.g., self, a person, a group), watch (a person)",
            "sit, listen to (a person), watch (a person)",
            "walk, carry/hold (an object), give/serve (an object) to (a person), listen to (a person), watch (a person)",
            "stand, listen to (a person), watch (a person)"
        ],
        "start": 0.0,
        "end": 403.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1368.0,
        "question": "Are there still 2 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "UrsCy6qIGoo",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 473.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1379.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.04, 0.07, 0.48, 0.96]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "UrsCy6qIGoo",
        "candidates": [
            "[0.00, 0.29, 0.30, 1.00]",
            "[0.05, 0.00, 0.77, 1.00]",
            "[0.70, 0.48, 0.93, 0.97]",
            "[0.04, 0.07, 0.48, 0.96]"
        ],
        "start": 0.0,
        "end": 484.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1380.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "carry/hold (an object) -> talk to (e.g., self, a person, a group)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "UrsCy6qIGoo",
        "candidates": [
            "sail boat -> carry/hold (an object)",
            "take (an object) from (a person) -> carry/hold (an object)",
            "hand shake -> carry/hold (an object)",
            "carry/hold (an object) -> talk to (e.g., self, a person, a group)"
        ],
        "start": 0.0,
        "end": 485.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1490.0,
        "question": "How many people in the current frame are performing the action:  walk?",
        "answer": "5",
        "sub_answer_type": "SpatialPerception-2",
        "answer_type": "SpatialPerception",
        "video": "UrsCy6qIGoo",
        "candidates": [
            "2",
            "5",
            "6",
            "3"
        ],
        "start": 0.0,
        "end": 595.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1513.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.33, 0.24, 0.46, 0.94]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "UrsCy6qIGoo",
        "candidates": [
            "[0.43, 0.14, 0.91, 0.96]",
            "[0.33, 0.24, 0.46, 0.94]",
            "[0.36, 0.04, 0.49, 0.78]",
            "[0.45, 0.36, 0.65, 0.99]"
        ],
        "start": 0.0,
        "end": 618.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1564.0,
        "question": "Is the person currently in the [0.15, 0.12, 0.97, 0.95] location in the current frame performing the talk to (e.g., self, a person, a group)?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "UrsCy6qIGoo",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 669.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1567.0,
        "question": "Where is the person currently performing the talk to (e.g., self, a person, a group) located in the picture?",
        "answer": "[0.02, 0.09, 0.56, 0.96]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "UrsCy6qIGoo",
        "candidates": [
            "[0.00, 0.34, 0.70, 1.00]",
            "[0.30, 0.17, 0.87, 0.97]",
            "[0.02, 0.09, 0.56, 0.96]",
            "[0.21, 0.00, 0.36, 0.72]"
        ],
        "start": 0.0,
        "end": 672.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1692.0,
        "question": "How many people in the current frame are performing the action:  walk?",
        "answer": "3",
        "sub_answer_type": "SpatialPerception-2",
        "answer_type": "SpatialPerception",
        "video": "UrsCy6qIGoo",
        "candidates": [
            "5",
            "2",
            "3",
            "4"
        ],
        "start": 0.0,
        "end": 797.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1708.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.54, 0.22, 0.74, 0.95]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "UrsCy6qIGoo",
        "candidates": [
            "[0.38, 0.13, 0.53, 1.00]",
            "[0.54, 0.22, 0.74, 0.95]",
            "[0.20, 0.00, 0.45, 0.95]",
            "[0.73, 0.41, 0.94, 1.00]"
        ],
        "start": 0.0,
        "end": 813.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1730.0,
        "question": "How many people were performing the walk in the scene 240 seconds ago?",
        "answer": "5",
        "sub_answer_type": "PastMemory-5",
        "answer_type": "PastMemory",
        "video": "UrsCy6qIGoo",
        "candidates": [
            "3",
            "6",
            "4",
            "5"
        ],
        "start": 0.0,
        "end": 835.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1757.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.47, 0.23, 0.73, 0.95] location?",
        "answer": "talk to (e.g., self, a person, a group) [0.42, 0.24, 0.67, 0.95] -> walk [0.47, 0.23, 0.73, 0.95] -> grab (a person) [0.47, 0.23, 0.73, 0.95]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "UrsCy6qIGoo",
        "candidates": [
            "talk to (e.g., self, a person, a group) [0.42, 0.24, 0.67, 0.95] -> walk [0.47, 0.23, 0.73, 0.95] -> grab (a person) [0.47, 0.23, 0.73, 0.95]",
            "walk [0.38, 0.31, 0.92, 1.00] -> talk to (e.g., self, a person, a group) [0.23, 0.34, 0.70, 0.86] -> grab (a person) [0.63, 0.42, 0.81, 0.91]",
            "catch (an object) [0.40, 0.35, 0.69, 0.80] -> grab (a person) [0.48, 0.18, 0.73, 0.80] -> talk to (e.g., self, a person, a group) [0.53, 0.26, 0.55, 0.96]",
            "grab (a person) [0.37, 0.08, 0.65, 0.84] -> paint [0.43, 0.35, 0.76, 0.94] -> walk [0.48, 0.08, 0.60, 1.00]"
        ],
        "start": 0.0,
        "end": 862.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1766.0,
        "question": "Is the person currently in the [0.13, 0.08, 0.60, 0.97] location in the current frame performing the walk?",
        "answer": "No",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "UrsCy6qIGoo",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 871.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1778.0,
        "question": "What action is the person currently in the [0.44, 0.08, 0.95, 0.95] location likely to do next?",
        "answer": "talk to (e.g., self, a person, a group)",
        "sub_answer_type": "FuturePrediction-1",
        "answer_type": "FuturePrediction",
        "video": "UrsCy6qIGoo",
        "candidates": [
            "carry/hold (an object)",
            "walk and talk to (e.g., self, a person, a group)",
            "talk to (e.g., self, a person, a group)",
            "put down"
        ],
        "start": 0.0,
        "end": 883.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 916.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "answer phone -> walk",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "WSPvfxtqisg",
        "candidates": [
            "answer phone -> smoke",
            "answer phone -> cook",
            "kick (a person) -> answer phone",
            "answer phone -> walk"
        ],
        "start": 0.0,
        "end": 21.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 934.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.34, 0.15, 0.52, 0.93] location?",
        "answer": "touch (an object) [0.35, 0.17, 0.54, 0.94] -> walk [0.34, 0.15, 0.52, 0.93] -> enter [0.34, 0.15, 0.52, 0.93]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "WSPvfxtqisg",
        "candidates": [
            "touch (an object) [0.35, 0.17, 0.54, 0.94] -> walk [0.34, 0.15, 0.52, 0.93] -> enter [0.34, 0.15, 0.52, 0.93]",
            "walk [0.36, 0.32, 0.42, 0.88] -> touch (an object) [0.39, 0.09, 0.69, 0.74] -> cook [0.40, 0.24, 0.65, 0.88]",
            "enter [0.38, 0.18, 0.63, 0.99] -> touch (an object) [0.54, 0.34, 0.60, 0.84] -> climb (e.g., a mountain) [0.42, 0.34, 0.41, 0.76]",
            "touch (an object) [0.22, 0.00, 0.61, 1.00] -> enter [0.41, 0.10, 0.48, 0.74] -> cut [0.17, 0.28, 0.56, 1.00]"
        ],
        "start": 0.0,
        "end": 39.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 947.0,
        "question": "What action is the person currently in the [0.33, 0.12, 0.91, 0.97] location likely to do next?",
        "answer": "walk and answer phone",
        "sub_answer_type": "FuturePrediction-1",
        "answer_type": "FuturePrediction",
        "video": "WSPvfxtqisg",
        "candidates": [
            "hand clap",
            "paint",
            "walk and answer phone",
            "walk"
        ],
        "start": 0.0,
        "end": 52.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 956.0,
        "question": "Is the person currently in the [0.24, 0.06, 0.93, 0.95] location in the current frame performing the answer phone?",
        "answer": "No",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "WSPvfxtqisg",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 61.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 985.0,
        "question": "Where was the person currently performing the bend/bow (at the waist) in the scene 8 seconds ago?",
        "answer": "[0.01, 0.07, 0.91, 0.95]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "WSPvfxtqisg",
        "candidates": [
            "[0.32, 0.08, 0.92, 0.93]",
            "[0.01, 0.07, 0.91, 0.95]",
            "[0.00, 0.13, 0.64, 0.78]",
            "[0.00, 0.36, 0.77, 0.95]"
        ],
        "start": 0.0,
        "end": 90.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1004.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.08, 0.10, 0.84, 0.96]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "WSPvfxtqisg",
        "candidates": [
            "[0.08, 0.10, 0.84, 0.96]",
            "[0.00, 0.39, 0.56, 1.00]",
            "[0.05, 0.06, 0.83, 0.68]",
            "[0.40, 0.11, 0.99, 0.95]"
        ],
        "start": 0.0,
        "end": 109.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1102.0,
        "question": "Is the person currently in the [0.11, 0.06, 0.96, 0.96] location in the current frame performing the talk to (e.g., self, a person, a group)?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "WSPvfxtqisg",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 207.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1111.0,
        "question": "Where is the person currently performing the talk to (e.g., self, a person, a group) located in the picture?",
        "answer": "[0.14, 0.04, 0.94, 0.95]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "WSPvfxtqisg",
        "candidates": [
            "[0.65, 0.32, 0.75, 0.75]",
            "[0.06, 0.00, 0.66, 0.86]",
            "[0.14, 0.04, 0.94, 0.95]",
            "[0.21, 0.32, 1.00, 1.00]"
        ],
        "start": 0.0,
        "end": 216.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1143.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "talk to (e.g., self, a person, a group) -> work on a computer",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "WSPvfxtqisg",
        "candidates": [
            "talk to (e.g., self, a person, a group) -> take (an object) from (a person)",
            "lift/pick up -> work on a computer",
            "talk to (e.g., self, a person, a group) -> drink",
            "talk to (e.g., self, a person, a group) -> work on a computer"
        ],
        "start": 0.0,
        "end": 248.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1165.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.18, 0.26, 0.55, 0.72] location?",
        "answer": "touch (an object) [0.20, 0.25, 0.50, 0.70] -> answer phone [0.18, 0.26, 0.55, 0.72] -> carry/hold (an object) [0.18, 0.26, 0.55, 0.72]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "WSPvfxtqisg",
        "candidates": [
            "answer phone [0.00, 0.18, 0.47, 0.81] -> swim [0.37, 0.11, 0.41, 0.85] -> carry/hold (an object) [0.01, 0.13, 0.74, 0.81]",
            "carry/hold (an object) [0.26, 0.12, 0.47, 0.62] -> touch (an object) [0.33, 0.23, 0.54, 0.63] -> swim [0.28, 0.38, 0.65, 0.71]",
            "touch (an object) [0.20, 0.25, 0.50, 0.70] -> answer phone [0.18, 0.26, 0.55, 0.72] -> carry/hold (an object) [0.18, 0.26, 0.55, 0.72]",
            "put down [0.16, 0.15, 0.38, 0.54] -> carry/hold (an object) [0.24, 0.38, 0.44, 0.66] -> answer phone [0.13, 0.27, 0.72, 0.88]"
        ],
        "start": 0.0,
        "end": 270.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1171.0,
        "question": "Where was the person currently performing the write in the scene 8 seconds ago?",
        "answer": "[0.27, 0.25, 0.73, 0.70]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "WSPvfxtqisg",
        "candidates": [
            "[0.42, 0.27, 0.88, 0.91]",
            "[0.45, 0.12, 0.92, 0.45]",
            "[0.27, 0.25, 0.73, 0.70]",
            "[0.00, 0.25, 0.85, 0.97]"
        ],
        "start": 0.0,
        "end": 276.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1175.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.13, 0.23, 0.45, 0.62] location?",
        "answer": "touch (an object) [0.13, 0.23, 0.45, 0.62] -> write [0.13, 0.23, 0.45, 0.62] -> talk to (e.g., self, a person, a group) [0.13, 0.23, 0.45, 0.62]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "WSPvfxtqisg",
        "candidates": [
            "touch (an object) [0.13, 0.23, 0.45, 0.62] -> write [0.13, 0.23, 0.45, 0.62] -> talk to (e.g., self, a person, a group) [0.13, 0.23, 0.45, 0.62]",
            "lift/pick up [0.07, 0.33, 0.45, 0.60] -> talk to (e.g., self, a person, a group) [0.00, 0.41, 0.35, 0.82] -> touch (an object) [0.01, 0.25, 0.59, 0.68]",
            "touch (an object) [0.32, 0.19, 0.39, 0.80] -> play board game [0.24, 0.29, 0.52, 0.44] -> talk to (e.g., self, a person, a group) [0.31, 0.29, 0.51, 0.69]",
            "touch (an object) [0.06, 0.39, 0.60, 0.59] -> talk to (e.g., self, a person, a group) [0.00, 0.41, 0.59, 0.60] -> catch (an object) [0.05, 0.26, 0.35, 0.45]"
        ],
        "start": 0.0,
        "end": 280.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1185.0,
        "question": "Where is the person currently performing the talk to (e.g., self, a person, a group) located in the picture?",
        "answer": "[0.19, 0.21, 0.43, 0.48]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "WSPvfxtqisg",
        "candidates": [
            "[0.44, 0.00, 0.34, 0.34]",
            "[0.01, 0.10, 0.60, 0.94]",
            "[0.12, 0.41, 0.15, 0.28]",
            "[0.19, 0.21, 0.43, 0.48]"
        ],
        "start": 0.0,
        "end": 290.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1197.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "touch (an object) -> answer phone -> carry/hold (an object) -> write -> talk to (e.g., self, a person, a group)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "WSPvfxtqisg",
        "candidates": [
            "touch (an object) -> answer phone -> carry/hold (an object) -> write -> talk to (e.g., self, a person, a group)",
            "dig -> write -> answer phone -> touch (an object) -> talk to (e.g., self, a person, a group)",
            "touch (an object) -> answer phone -> carry/hold (an object) -> play board game -> talk to (e.g., self, a person, a group)",
            "answer phone -> hand clap -> talk to (e.g., self, a person, a group) -> write -> carry/hold (an object)"
        ],
        "start": 0.0,
        "end": 302.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1227.0,
        "question": "Where was the person currently performing the work on a computer in the scene 8 seconds ago?",
        "answer": "[0.15, 0.15, 0.79, 0.96]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "WSPvfxtqisg",
        "candidates": [
            "[0.30, 0.00, 0.74, 0.76]",
            "[0.15, 0.15, 0.79, 0.96]",
            "[0.35, 0.20, 0.91, 1.00]",
            "[0.01, 0.08, 0.48, 0.96]"
        ],
        "start": 0.0,
        "end": 332.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1298.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.28, 0.08, 0.47, 1.00] location?",
        "answer": "talk to (e.g., self, a person, a group) [0.34, 0.03, 0.59, 0.89] -> walk [0.28, 0.08, 0.47, 1.00] -> carry/hold (an object) [0.28, 0.08, 0.47, 1.00]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "WSPvfxtqisg",
        "candidates": [
            "eat [0.33, 0.05, 0.62, 1.00] -> walk [0.37, 0.12, 0.39, 0.91] -> talk to (e.g., self, a person, a group) [0.14, 0.05, 0.71, 0.86]",
            "talk to (e.g., self, a person, a group) [0.34, 0.03, 0.59, 0.89] -> walk [0.28, 0.08, 0.47, 1.00] -> carry/hold (an object) [0.28, 0.08, 0.47, 1.00]",
            "take a photo [0.15, 0.00, 0.43, 0.86] -> carry/hold (an object) [0.42, 0.01, 0.29, 1.00] -> walk [0.32, 0.10, 0.41, 0.82]",
            "carry/hold (an object) [0.32, 0.00, 0.54, 1.00] -> run/jog [0.50, 0.13, 0.51, 0.78] -> walk [0.27, 0.00, 0.62, 0.95]"
        ],
        "start": 0.0,
        "end": 403.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1306.0,
        "question": "What location in the frame is the person currently in the [0.02, 0.08, 0.86, 0.96] location likely to move to next?",
        "answer": "[0.62, 0.44, 0.97, 0.79]",
        "sub_answer_type": "FuturePrediction-2",
        "answer_type": "FuturePrediction",
        "video": "WSPvfxtqisg",
        "candidates": [
            "[0.11, 0.06, 0.96, 0.96]",
            "[0.89, 0.46, 1.00, 1.00]",
            "[0.62, 0.44, 0.97, 0.79]",
            "[0.39, 0.26, 1.00, 0.54]"
        ],
        "start": 0.0,
        "end": 411.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1327.0,
        "question": "Are there still 1 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "WSPvfxtqisg",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 432.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1344.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.62, 0.20, 0.77, 0.80] location?",
        "answer": "bend/bow (at the waist) [0.62, 0.20, 0.77, 0.80] -> carry/hold (an object) [0.62, 0.20, 0.77, 0.80] -> give/serve (an object) to (a person) [0.62, 0.20, 0.77, 0.80]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "WSPvfxtqisg",
        "candidates": [
            "shoot [0.78, 0.37, 0.75, 0.66] -> bend/bow (at the waist) [0.46, 0.28, 0.63, 0.68] -> carry/hold (an object) [0.44, 0.32, 0.74, 0.95]",
            "bend/bow (at the waist) [0.62, 0.20, 0.77, 0.80] -> carry/hold (an object) [0.62, 0.20, 0.77, 0.80] -> give/serve (an object) to (a person) [0.62, 0.20, 0.77, 0.80]",
            "hug (a person) [0.66, 0.12, 0.92, 0.73] -> bend/bow (at the waist) [0.68, 0.19, 0.89, 0.91] -> give/serve (an object) to (a person) [0.70, 0.24, 0.73, 0.72]",
            "give/serve (an object) to (a person) [0.65, 0.08, 0.85, 0.88] -> bend/bow (at the waist) [0.69, 0.14, 0.93, 0.89] -> play with pets [0.43, 0.11, 0.70, 0.87]"
        ],
        "start": 0.0,
        "end": 449.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1346.0,
        "question": "Where is the person currently performing the bend/bow (at the waist) located in the picture?",
        "answer": "[0.48, 0.27, 0.75, 0.80]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "WSPvfxtqisg",
        "candidates": [
            "[0.20, 0.03, 0.54, 0.59]",
            "[0.68, 0.10, 0.88, 0.67]",
            "[0.48, 0.27, 0.75, 0.80]",
            "[0.02, 0.17, 0.88, 0.98]"
        ],
        "start": 0.0,
        "end": 451.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1352.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "drink -> talk to (e.g., self, a person, a group)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "WSPvfxtqisg",
        "candidates": [
            "drink -> talk to (e.g., self, a person, a group)",
            "talk to (e.g., self, a person, a group) -> ride (e.g., a bike, a car, a horse)",
            "drink -> kiss (a person)",
            "fight/hit (a person) -> talk to (e.g., self, a person, a group)"
        ],
        "start": 0.0,
        "end": 457.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1500.0,
        "question": "Are there still 2 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "WSPvfxtqisg",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 605.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1501.0,
        "question": "Where was the person currently performing the bend/bow (at the waist) in the scene 8 seconds ago?",
        "answer": "[0.33, 0.26, 0.88, 0.96]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "WSPvfxtqisg",
        "candidates": [
            "[0.33, 0.26, 0.88, 0.96]",
            "[0.17, 0.12, 0.67, 0.89]",
            "[0.49, 0.35, 1.00, 0.75]",
            "[0.10, 0.39, 0.77, 1.00]"
        ],
        "start": 0.0,
        "end": 606.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1630.0,
        "question": "What action is the person at the location [0.00, 0.02, 0.39, 0.96] in the image performing?",
        "answer": "stand, listen to (a person), watch (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "WSPvfxtqisg",
        "candidates": [
            "stand, talk to (e.g., self, a person, a group), watch (a person)",
            "stand, listen to (a person), watch (a person)",
            "sit, drink, listen to (a person), watch (a person)",
            "walk, carry/hold (an object), listen to (a person)"
        ],
        "start": 0.0,
        "end": 735.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1674.0,
        "question": "What action is the person at the location [0.00, 0.01, 0.50, 0.93] in the image performing?",
        "answer": "stand, listen to (a person), watch (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "WSPvfxtqisg",
        "candidates": [
            "stand, talk to (e.g., self, a person, a group), watch (a person)",
            "stand, listen to (a person), watch (a person)",
            "sit, carry/hold (an object), talk to (e.g., self, a person, a group)",
            "sit, watch (a person)"
        ],
        "start": 0.0,
        "end": 779.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1691.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "carry/hold (an object) -> talk to (e.g., self, a person, a group)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "WSPvfxtqisg",
        "candidates": [
            "carry/hold (an object) -> crouch/kneel",
            "carry/hold (an object) -> talk to (e.g., self, a person, a group)",
            "fishing -> carry/hold (an object)",
            "work on a computer -> carry/hold (an object)"
        ],
        "start": 0.0,
        "end": 796.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1738.0,
        "question": "Is the person currently in the [0.83, 0.42, 0.96, 0.64] location in the current frame performing the touch (an object)?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "WSPvfxtqisg",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 843.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 904.0,
        "question": "Is the person currently in the [0.22, 0.09, 0.63, 0.89] location in the current frame performing the carry/hold (an object)?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "XpGRS72ghag",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 9.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 917.0,
        "question": "Where was the person currently performing the carry/hold (an object) in the scene 8 seconds ago?",
        "answer": "[0.26, 0.10, 0.75, 0.88]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "XpGRS72ghag",
        "candidates": [
            "[0.26, 0.10, 0.75, 0.88]",
            "[0.51, 0.10, 0.99, 0.91]",
            "[0.06, 0.00, 0.90, 0.63]",
            "[0.05, 0.28, 0.92, 1.00]"
        ],
        "start": 0.0,
        "end": 22.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 941.0,
        "question": "What action is the person at the location [0.04, 0.10, 0.57, 0.93] in the image performing?",
        "answer": "sit, smoke, listen to (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "XpGRS72ghag",
        "candidates": [
            "sit, smoke, talk to (e.g., self, a person, a group), watch (a person)",
            "sit, listen to (a person), watch (a person)",
            "sit, smoke, listen to (a person)",
            "stand, listen to (a person), watch (a person)"
        ],
        "start": 0.0,
        "end": 46.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 986.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.49, 0.10, 0.94, 0.91]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "XpGRS72ghag",
        "candidates": [
            "[0.40, 0.34, 0.69, 0.98]",
            "[0.49, 0.10, 0.94, 0.91]",
            "[0.22, 0.10, 0.66, 0.89]",
            "[0.71, 0.17, 1.00, 0.67]"
        ],
        "start": 0.0,
        "end": 91.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1076.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.41, 0.10, 0.81, 0.92]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "XpGRS72ghag",
        "candidates": [
            "[0.18, 0.37, 1.00, 1.00]",
            "[0.57, 0.00, 1.00, 0.90]",
            "[0.34, 0.47, 0.38, 0.54]",
            "[0.41, 0.10, 0.81, 0.92]"
        ],
        "start": 0.0,
        "end": 181.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1113.0,
        "question": "Are there still 2 people in the current frame now?",
        "answer": "No",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "XpGRS72ghag",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 218.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1148.0,
        "question": "What action is the person at the location [0.16, 0.09, 0.52, 0.90] in the image performing?",
        "answer": "stand, kiss (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "XpGRS72ghag",
        "candidates": [
            "sit, smoke, listen to (a person)",
            "stand, kiss (a person)",
            "sit, talk to (e.g., self, a person, a group), watch (a person)",
            "stand, listen to (a person), watch (a person)"
        ],
        "start": 0.0,
        "end": 253.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1213.0,
        "question": "Where was the person currently performing the open (e.g., a window, a car door) in the scene 8 seconds ago?",
        "answer": "[0.18, 0.19, 0.44, 0.90]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "XpGRS72ghag",
        "candidates": [
            "[0.18, 0.19, 0.44, 0.90]",
            "[0.13, 0.00, 0.42, 0.72]",
            "[0.53, 0.10, 1.00, 0.90]",
            "[0.00, 0.47, 0.63, 1.00]"
        ],
        "start": 0.0,
        "end": 318.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1247.0,
        "question": "What action is the person at the location [0.17, 0.18, 0.60, 0.90] in the image performing?",
        "answer": "sit, talk to (e.g., self, a person, a group), watch (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "XpGRS72ghag",
        "candidates": [
            "stand, talk to (e.g., self, a person, a group), watch (a person)",
            "sit, listen to (a person)",
            "sit, talk to (e.g., self, a person, a group), watch (a person)",
            "walk, talk to (e.g., self, a person, a group), watch (a person)"
        ],
        "start": 0.0,
        "end": 352.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1341.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.00, 0.07, 0.36, 0.93]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "XpGRS72ghag",
        "candidates": [
            "[0.04, 0.07, 0.64, 0.88]",
            "[0.00, 0.07, 0.36, 0.93]",
            "[0.00, 0.23, 0.11, 1.00]",
            "[0.17, 0.30, 0.37, 1.00]"
        ],
        "start": 0.0,
        "end": 446.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1351.0,
        "question": "Are there still 3 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "XpGRS72ghag",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 456.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1455.0,
        "question": "Where is the person currently performing the talk to (e.g., self, a person, a group) located in the picture?",
        "answer": "[0.05, 0.09, 0.92, 0.89]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "XpGRS72ghag",
        "candidates": [
            "[0.06, 0.12, 0.52, 0.90]",
            "[0.34, 0.00, 0.94, 0.99]",
            "[0.05, 0.09, 0.92, 0.89]",
            "[0.10, 0.29, 0.63, 1.00]"
        ],
        "start": 0.0,
        "end": 560.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1482.0,
        "question": "Is the person currently in the [0.32, 0.18, 0.65, 0.90] location in the current frame performing the talk to (e.g., self, a person, a group)?",
        "answer": "No",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "XpGRS72ghag",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 587.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1573.0,
        "question": "What action is the person currently in the [0.06, 0.14, 0.47, 0.93] location likely to do next?",
        "answer": "walk and talk to (e.g., self, a person, a group)",
        "sub_answer_type": "FuturePrediction-1",
        "answer_type": "FuturePrediction",
        "video": "XpGRS72ghag",
        "candidates": [
            "kick (a person)",
            "carry/hold (an object)",
            "walk and talk to (e.g., self, a person, a group)",
            "text on/look at a cellphone"
        ],
        "start": 0.0,
        "end": 678.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1653.0,
        "question": "What location in the frame is the person currently in the [0.54, 0.09, 1.00, 0.90] location likely to move to next?",
        "answer": "[0.12, 0.08, 0.65, 0.90]",
        "sub_answer_type": "FuturePrediction-2",
        "answer_type": "FuturePrediction",
        "video": "XpGRS72ghag",
        "candidates": [
            "[0.00, 0.04, 0.35, 0.88]",
            "[0.32, 0.12, 0.92, 0.91]",
            "[0.12, 0.08, 0.65, 0.90]",
            "[0.22, 0.34, 0.77, 0.88]"
        ],
        "start": 0.0,
        "end": 758.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1733.0,
        "question": "Are there still 2 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "XpGRS72ghag",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 838.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1751.0,
        "question": "Where is the person currently performing the talk to (e.g., self, a person, a group) located in the picture?",
        "answer": "[0.05, 0.08, 0.55, 0.93]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "XpGRS72ghag",
        "candidates": [
            "[0.00, 0.17, 0.28, 1.00]",
            "[0.06, 0.18, 0.85, 0.88]",
            "[0.05, 0.08, 0.55, 0.93]",
            "[0.22, 0.00, 0.28, 0.64]"
        ],
        "start": 0.0,
        "end": 856.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 919.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.60, 0.25, 0.89, 0.91] location?",
        "answer": "eat [0.63, 0.23, 0.89, 0.89] -> touch (an object) [0.63, 0.23, 0.89, 0.89] -> carry/hold (an object) [0.60, 0.25, 0.89, 0.91]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "Z1YV6wB037M",
        "candidates": [
            "eat [0.63, 0.23, 0.89, 0.89] -> touch (an object) [0.63, 0.23, 0.89, 0.89] -> carry/hold (an object) [0.60, 0.25, 0.89, 0.91]",
            "open (e.g., a window, a car door) [0.67, 0.24, 1.00, 0.94] -> eat [0.59, 0.17, 1.00, 0.98] -> carry/hold (an object) [0.53, 0.36, 0.99, 0.97]",
            "open (e.g., a window, a car door) [0.53, 0.08, 0.86, 0.74] -> eat [0.47, 0.32, 1.00, 1.00] -> carry/hold (an object) [0.80, 0.44, 0.98, 0.83]",
            "talk to (e.g., self, a person, a group) [0.78, 0.13, 0.70, 1.00] -> eat [0.53, 0.35, 1.00, 0.80] -> carry/hold (an object) [0.55, 0.26, 0.78, 1.00]"
        ],
        "start": 0.0,
        "end": 24.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 940.0,
        "question": "Is the person currently in the [0.54, 0.23, 0.89, 0.92] location in the current frame performing the touch (an object)?",
        "answer": "No",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "Z1YV6wB037M",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 45.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 943.0,
        "question": "How many people in the current frame are performing the action:  touch (an object)?",
        "answer": "4",
        "sub_answer_type": "SpatialPerception-2",
        "answer_type": "SpatialPerception",
        "video": "Z1YV6wB037M",
        "candidates": [
            "5",
            "3",
            "4",
            "2"
        ],
        "start": 0.0,
        "end": 48.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 958.0,
        "question": "Where was the person currently performing the carry/hold (an object) in the scene 8 seconds ago?",
        "answer": "[0.60, 0.22, 0.89, 0.89]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "Z1YV6wB037M",
        "candidates": [
            "[0.47, 0.46, 0.71, 1.00]",
            "[0.14, 0.11, 0.44, 0.83]",
            "[0.60, 0.22, 0.89, 0.89]",
            "[0.53, 0.08, 1.00, 0.61]"
        ],
        "start": 0.0,
        "end": 63.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1001.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.51, 0.25, 0.72, 0.63] location?",
        "answer": "touch (an object) [0.43, 0.23, 0.73, 0.67] -> talk to (e.g., self, a person, a group) [0.43, 0.23, 0.73, 0.67] -> eat [0.51, 0.25, 0.72, 0.63]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "Z1YV6wB037M",
        "candidates": [
            "touch (an object) [0.29, 0.42, 0.73, 0.68] -> talk to (e.g., self, a person, a group) [0.45, 0.17, 0.60, 0.57] -> close (e.g., a door, a box) [0.39, 0.16, 0.54, 0.54]",
            "hug (a person) [0.50, 0.39, 0.82, 0.50] -> touch (an object) [0.39, 0.07, 0.69, 0.52] -> talk to (e.g., self, a person, a group) [0.62, 0.08, 0.87, 0.83]",
            "read [0.47, 0.06, 0.78, 0.57] -> eat [0.38, 0.43, 0.68, 0.61] -> talk to (e.g., self, a person, a group) [0.25, 0.29, 0.59, 0.72]",
            "touch (an object) [0.43, 0.23, 0.73, 0.67] -> talk to (e.g., self, a person, a group) [0.43, 0.23, 0.73, 0.67] -> eat [0.51, 0.25, 0.72, 0.63]"
        ],
        "start": 0.0,
        "end": 106.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1028.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.26, 0.23, 0.43, 0.66] location?",
        "answer": "carry/hold (an object) [0.26, 0.23, 0.43, 0.66] -> eat [0.26, 0.23, 0.43, 0.66] -> touch (an object) [0.26, 0.23, 0.43, 0.66]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "Z1YV6wB037M",
        "candidates": [
            "carry/hold (an object) [0.26, 0.23, 0.43, 0.66] -> eat [0.26, 0.23, 0.43, 0.66] -> touch (an object) [0.26, 0.23, 0.43, 0.66]",
            "touch (an object) [0.23, 0.20, 0.28, 0.53] -> touch (an object) [0.26, 0.05, 0.26, 0.81] -> carry/hold (an object) [0.26, 0.05, 0.41, 0.50]",
            "answer phone [0.26, 0.32, 0.50, 0.84] -> carry/hold (an object) [0.36, 0.43, 0.62, 0.78] -> eat [0.10, 0.19, 0.58, 0.72]",
            "touch (an object) [0.12, 0.23, 0.52, 0.52] -> carry/hold (an object) [0.34, 0.07, 0.49, 0.80] -> extract [0.26, 0.15, 0.48, 0.61]"
        ],
        "start": 0.0,
        "end": 133.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1037.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.51, 0.27, 0.72, 0.66]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "Z1YV6wB037M",
        "candidates": [
            "[0.51, 0.27, 0.72, 0.66]",
            "[0.23, 0.05, 0.68, 0.59]",
            "[0.37, 0.52, 0.98, 0.75]",
            "[0.26, 0.25, 0.49, 0.67]"
        ],
        "start": 0.0,
        "end": 142.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1057.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.50, 0.24, 0.76, 0.68] location?",
        "answer": "touch (an object) [0.57, 0.24, 0.75, 0.68] -> talk to (e.g., self, a person, a group) [0.57, 0.24, 0.75, 0.68] -> eat [0.50, 0.24, 0.76, 0.68]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "Z1YV6wB037M",
        "candidates": [
            "eat [0.44, 0.16, 0.59, 0.58] -> take a photo [0.50, 0.18, 0.64, 0.71] -> talk to (e.g., self, a person, a group) [0.75, 0.17, 0.60, 0.61]",
            "dig [0.56, 0.30, 0.60, 0.73] -> eat [0.59, 0.29, 0.73, 0.57] -> touch (an object) [0.52, 0.18, 0.91, 0.79]",
            "talk to (e.g., self, a person, a group) [0.75, 0.14, 0.90, 0.75] -> smoke [0.50, 0.07, 0.93, 0.69] -> touch (an object) [0.71, 0.12, 0.69, 0.70]",
            "touch (an object) [0.57, 0.24, 0.75, 0.68] -> talk to (e.g., self, a person, a group) [0.57, 0.24, 0.75, 0.68] -> eat [0.50, 0.24, 0.76, 0.68]"
        ],
        "start": 0.0,
        "end": 162.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1062.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.50, 0.26, 0.73, 0.65]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "Z1YV6wB037M",
        "candidates": [
            "[0.59, 0.06, 0.94, 0.52]",
            "[0.16, 0.16, 0.70, 0.88]",
            "[0.58, 0.54, 0.62, 0.69]",
            "[0.50, 0.26, 0.73, 0.65]"
        ],
        "start": 0.0,
        "end": 167.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1110.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.59, 0.29, 0.77, 0.65] location?",
        "answer": "drink [0.59, 0.29, 0.77, 0.65] -> touch (an object) [0.59, 0.29, 0.77, 0.65] -> talk to (e.g., self, a person, a group) [0.59, 0.29, 0.77, 0.65]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "Z1YV6wB037M",
        "candidates": [
            "touch (an object) [0.63, 0.36, 0.95, 0.79] -> jump/leap [0.49, 0.15, 0.74, 0.85] -> drink [0.73, 0.10, 0.61, 0.67]",
            "talk to (e.g., self, a person, a group) [0.60, 0.43, 0.94, 0.74] -> drink [0.56, 0.45, 0.92, 0.47] -> throw [0.75, 0.27, 0.68, 0.62]",
            "drink [0.59, 0.29, 0.77, 0.65] -> touch (an object) [0.59, 0.29, 0.77, 0.65] -> talk to (e.g., self, a person, a group) [0.59, 0.29, 0.77, 0.65]",
            "touch (an object) [0.72, 0.47, 0.90, 0.81] -> text on/look at a cellphone [0.71, 0.42, 0.60, 0.64] -> talk to (e.g., self, a person, a group) [0.78, 0.24, 0.95, 0.56]"
        ],
        "start": 0.0,
        "end": 215.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1120.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.11, 0.19, 0.38, 0.88]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "Z1YV6wB037M",
        "candidates": [
            "[0.00, 0.00, 0.38, 0.61]",
            "[0.57, 0.28, 0.72, 0.66]",
            "[0.11, 0.19, 0.38, 0.88]",
            "[0.38, 0.00, 0.59, 1.00]"
        ],
        "start": 0.0,
        "end": 225.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1145.0,
        "question": "What action is the person at the location [0.12, 0.12, 0.50, 0.91] in the image performing?",
        "answer": "stand, talk to (e.g., self, a person, a group), watch (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "Z1YV6wB037M",
        "candidates": [
            "stand, talk to (e.g., self, a person, a group), watch (a person)",
            "sit, touch (an object), listen to (a person), watch (a person)",
            "sit, listen to (a person), watch (a person)",
            "sit, touch (an object)"
        ],
        "start": 0.0,
        "end": 250.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1176.0,
        "question": "Are there still 1 people in the current frame now?",
        "answer": "No",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "Z1YV6wB037M",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 281.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1206.0,
        "question": "Are there still 2 people in the current frame now?",
        "answer": "No",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "Z1YV6wB037M",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 311.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1289.0,
        "question": "Where is the person currently performing the talk to (e.g., self, a person, a group) located in the picture?",
        "answer": "[0.33, 0.17, 0.87, 0.90]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "Z1YV6wB037M",
        "candidates": [
            "[0.61, 0.26, 1.00, 0.96]",
            "[0.18, 0.12, 0.69, 0.86]",
            "[0.33, 0.17, 0.87, 0.90]",
            "[0.39, 0.00, 0.66, 0.73]"
        ],
        "start": 0.0,
        "end": 394.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1306.0,
        "question": "What action is the person currently in the [0.14, 0.10, 0.68, 0.90] location likely to do next?",
        "answer": "eat and talk to (e.g., self, a person, a group)",
        "sub_answer_type": "FuturePrediction-1",
        "answer_type": "FuturePrediction",
        "video": "Z1YV6wB037M",
        "candidates": [
            "open (e.g., a window, a car door)",
            "drink",
            "take a photo",
            "eat and talk to (e.g., self, a person, a group)"
        ],
        "start": 0.0,
        "end": 411.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1402.0,
        "question": "Where was the person currently performing the touch (an object) in the scene 8 seconds ago?",
        "answer": "[0.50, 0.21, 0.62, 0.88]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "Z1YV6wB037M",
        "candidates": [
            "[0.62, 0.00, 0.84, 0.64]",
            "[0.50, 0.21, 0.62, 0.88]",
            "[0.56, 0.00, 0.39, 0.78]",
            "[0.59, 0.18, 0.89, 0.88]"
        ],
        "start": 0.0,
        "end": 507.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1467.0,
        "question": "Is the person currently in the [0.13, 0.19, 0.74, 0.90] location in the current frame performing the talk to (e.g., self, a person, a group)?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "Z1YV6wB037M",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 572.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1553.0,
        "question": "How many people in the current frame are performing the action:  touch (an object)?",
        "answer": "2",
        "sub_answer_type": "SpatialPerception-2",
        "answer_type": "SpatialPerception",
        "video": "Z1YV6wB037M",
        "candidates": [
            "5",
            "3",
            "2",
            "4"
        ],
        "start": 0.0,
        "end": 658.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1658.0,
        "question": "Where is the person currently performing the touch (an object) located in the picture?",
        "answer": "[0.31, 0.14, 0.82, 0.88]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "Z1YV6wB037M",
        "candidates": [
            "[0.56, 0.40, 0.58, 0.96]",
            "[0.13, 0.12, 0.68, 0.90]",
            "[0.56, 0.00, 0.87, 0.62]",
            "[0.31, 0.14, 0.82, 0.88]"
        ],
        "start": 0.0,
        "end": 763.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1672.0,
        "question": "Is the person currently in the [0.57, 0.16, 0.88, 0.84] location in the current frame performing the touch (an object)?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "Z1YV6wB037M",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 777.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1120.0,
        "question": "What action is the person at the location [0.06, 0.35, 0.23, 0.62] in the image performing?",
        "answer": "sit, write, listen to (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "ZosVdkY76FU",
        "candidates": [
            "stand, watch (a person)",
            "stand, listen to (a person), talk to (e.g., self, a person, a group), watch (a person)",
            "stand, listen to (a person), watch (a person)",
            "sit, write, listen to (a person)"
        ],
        "start": 0.0,
        "end": 225.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1148.0,
        "question": "What was the minimum number of people in the scene over the past 15 seconds?",
        "answer": "7",
        "sub_answer_type": "PastMemory-3",
        "answer_type": "PastMemory",
        "video": "ZosVdkY76FU",
        "candidates": [
            "2",
            "7",
            "4",
            "1"
        ],
        "start": 0.0,
        "end": 253.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1162.0,
        "question": "Is the person currently in the [0.48, 0.20, 0.82, 0.98] location in the current frame performing the carry/hold (an object)?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "ZosVdkY76FU",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 267.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1170.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.52, 0.25, 0.95, 0.98] location?",
        "answer": "walk [0.52, 0.25, 0.95, 0.98] -> carry/hold (an object) [0.52, 0.25, 0.95, 0.98] -> talk to (e.g., self, a person, a group) [0.52, 0.25, 0.95, 0.98]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "ZosVdkY76FU",
        "candidates": [
            "walk [0.43, 0.12, 1.00, 0.93] -> sail boat [0.43, 0.29, 1.00, 0.97] -> carry/hold (an object) [0.36, 0.40, 0.89, 0.94]",
            "lie/sleep [0.62, 0.32, 1.00, 0.80] -> carry/hold (an object) [0.70, 0.22, 1.00, 0.87] -> talk to (e.g., self, a person, a group) [0.70, 0.31, 0.76, 0.86]",
            "walk [0.52, 0.25, 0.95, 0.98] -> carry/hold (an object) [0.52, 0.25, 0.95, 0.98] -> talk to (e.g., self, a person, a group) [0.52, 0.25, 0.95, 0.98]",
            "carry/hold (an object) [0.69, 0.09, 0.85, 0.93] -> extract [0.34, 0.17, 0.98, 0.96] -> talk to (e.g., self, a person, a group) [0.71, 0.26, 1.00, 0.80]"
        ],
        "start": 0.0,
        "end": 275.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1174.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.55, 0.22, 0.99, 0.99] location?",
        "answer": "talk to (e.g., self, a person, a group) [0.50, 0.26, 0.97, 0.98] -> walk [0.55, 0.22, 0.99, 0.99] -> carry/hold (an object) [0.55, 0.22, 0.99, 0.99]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "ZosVdkY76FU",
        "candidates": [
            "talk to (e.g., self, a person, a group) [0.50, 0.26, 0.97, 0.98] -> walk [0.55, 0.22, 0.99, 0.99] -> carry/hold (an object) [0.55, 0.22, 0.99, 0.99]",
            "carry/hold (an object) [0.49, 0.08, 1.00, 1.00] -> lie/sleep [0.69, 0.11, 1.00, 0.80] -> walk [0.38, 0.12, 1.00, 1.00]",
            "talk to (e.g., self, a person, a group) [0.41, 0.33, 0.82, 1.00] -> lie/sleep [0.62, 0.33, 1.00, 1.00] -> carry/hold (an object) [0.71, 0.17, 0.89, 0.80]",
            "talk to (e.g., self, a person, a group) [0.37, 0.20, 1.00, 0.93] -> walk [0.70, 0.38, 1.00, 0.90] -> carry/hold (an object) [0.47, 0.12, 0.97, 0.96]"
        ],
        "start": 0.0,
        "end": 279.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1197.0,
        "question": "Where is the person currently performing the get up located in the picture?",
        "answer": "[0.08, 0.00, 0.88, 1.00]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "ZosVdkY76FU",
        "candidates": [
            "[0.08, 0.00, 0.88, 1.00]",
            "[0.33, 0.02, 0.84, 0.71]",
            "[0.32, 0.10, 0.99, 1.00]",
            "[0.00, 0.00, 0.64, 1.00]"
        ],
        "start": 0.0,
        "end": 302.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1264.0,
        "question": "How many people were performing the listen to (a person) in the scene 120 seconds ago?",
        "answer": "8",
        "sub_answer_type": "PastMemory-5",
        "answer_type": "PastMemory",
        "video": "ZosVdkY76FU",
        "candidates": [
            "8",
            "4",
            "6",
            "3"
        ],
        "start": 0.0,
        "end": 369.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1316.0,
        "question": "What action is the person currently in the [0.27, 0.07, 1.00, 0.99] location likely to do next?",
        "answer": "answer phone and lie/sleep",
        "sub_answer_type": "FuturePrediction-1",
        "answer_type": "FuturePrediction",
        "video": "ZosVdkY76FU",
        "candidates": [
            "talk to (e.g., self, a person, a group)",
            "answer phone and lie/sleep",
            "smoke",
            "fall down"
        ],
        "start": 0.0,
        "end": 421.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1396.0,
        "question": "Where is the person currently performing the talk to (e.g., self, a person, a group) located in the picture?",
        "answer": "[0.43, 0.09, 0.91, 0.97]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "ZosVdkY76FU",
        "candidates": [
            "[0.63, 0.30, 0.89, 1.00]",
            "[0.43, 0.09, 0.91, 0.97]",
            "[0.72, 0.00, 0.97, 0.82]",
            "[0.09, 0.18, 0.35, 0.99]"
        ],
        "start": 0.0,
        "end": 501.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1433.0,
        "question": "How many people were performing the sit in the scene 300 seconds ago?",
        "answer": "5",
        "sub_answer_type": "PastMemory-5",
        "answer_type": "PastMemory",
        "video": "ZosVdkY76FU",
        "candidates": [
            "3",
            "4",
            "8",
            "5"
        ],
        "start": 0.0,
        "end": 538.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1518.0,
        "question": "Is the person currently in the [0.49, 0.16, 0.96, 0.97] location in the current frame performing the talk to (e.g., self, a person, a group)?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "ZosVdkY76FU",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 623.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1522.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.41, 0.14, 0.80, 0.97] location?",
        "answer": "talk to (e.g., self, a person, a group) [0.51, 0.18, 0.89, 0.95] -> walk [0.41, 0.14, 0.80, 0.97] -> carry/hold (an object) [0.41, 0.14, 0.80, 0.97]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "ZosVdkY76FU",
        "candidates": [
            "talk to (e.g., self, a person, a group) [0.51, 0.18, 0.89, 0.95] -> walk [0.41, 0.14, 0.80, 0.97] -> carry/hold (an object) [0.41, 0.14, 0.80, 0.97]",
            "fall down [0.44, 0.22, 0.82, 0.95] -> walk [0.37, 0.29, 0.74, 1.00] -> talk to (e.g., self, a person, a group) [0.59, 0.34, 0.88, 0.78]",
            "carry/hold (an object) [0.56, 0.11, 0.97, 0.82] -> talk to (e.g., self, a person, a group) [0.32, 0.21, 0.73, 1.00] -> text on/look at a cellphone [0.38, 0.17, 0.77, 0.83]",
            "carry/hold (an object) [0.50, 0.30, 0.98, 0.92] -> talk to (e.g., self, a person, a group) [0.51, 0.27, 0.95, 0.99] -> eat [0.22, 0.34, 0.95, 1.00]"
        ],
        "start": 0.0,
        "end": 627.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1551.0,
        "question": "What was the minimum number of people in the scene over the past 15 seconds?",
        "answer": "3",
        "sub_answer_type": "PastMemory-3",
        "answer_type": "PastMemory",
        "video": "ZosVdkY76FU",
        "candidates": [
            "4",
            "2",
            "1",
            "3"
        ],
        "start": 0.0,
        "end": 656.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1599.0,
        "question": "Is the person currently in the [0.39, 0.31, 0.59, 0.69] location in the current frame performing the touch (an object)?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "ZosVdkY76FU",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 704.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1625.0,
        "question": "How many people in the current frame are performing the action:  touch (an object)?",
        "answer": "3",
        "sub_answer_type": "SpatialPerception-2",
        "answer_type": "SpatialPerception",
        "video": "ZosVdkY76FU",
        "candidates": [
            "4",
            "5",
            "2",
            "3"
        ],
        "start": 0.0,
        "end": 730.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1714.0,
        "question": "How many people were performing the listen to (a person) in the scene 60 seconds ago?",
        "answer": "3",
        "sub_answer_type": "PastMemory-5",
        "answer_type": "PastMemory",
        "video": "ZosVdkY76FU",
        "candidates": [
            "7",
            "6",
            "4",
            "3"
        ],
        "start": 0.0,
        "end": 819.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1743.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.41, 0.34, 0.82, 0.84] location?",
        "answer": "talk to (e.g., self, a person, a group) [0.35, 0.34, 0.83, 0.83] -> carry/hold (an object) [0.41, 0.34, 0.82, 0.84] -> touch (an object) [0.41, 0.34, 0.82, 0.84]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "ZosVdkY76FU",
        "candidates": [
            "talk to (e.g., self, a person, a group) [0.32, 0.18, 0.97, 0.69] -> play board game [0.53, 0.22, 1.00, 0.83] -> carry/hold (an object) [0.35, 0.49, 0.65, 0.74]",
            "talk to (e.g., self, a person, a group) [0.35, 0.34, 0.83, 0.83] -> carry/hold (an object) [0.41, 0.34, 0.82, 0.84] -> touch (an object) [0.41, 0.34, 0.82, 0.84]",
            "talk to (e.g., self, a person, a group) [0.45, 0.53, 0.88, 0.67] -> carry/hold (an object) [0.24, 0.35, 0.96, 0.75] -> work on a computer [0.54, 0.52, 0.72, 0.68]",
            "touch (an object) [0.43, 0.42, 0.67, 0.71] -> kick (an object) [0.26, 0.32, 0.87, 1.00] -> carry/hold (an object) [0.27, 0.19, 0.78, 0.85]"
        ],
        "start": 0.0,
        "end": 848.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1745.0,
        "question": "What action is the person at the location [0.01, 0.24, 0.10, 0.62] in the image performing?",
        "answer": "stand, carry/hold (an object), listen to (a person), watch (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "ZosVdkY76FU",
        "candidates": [
            "stand, carry/hold (an object), listen to (a person), watch (a person)",
            "stand, write",
            "stand, talk to (e.g., self, a person, a group), watch (a person)",
            "stand, watch (a person)"
        ],
        "start": 0.0,
        "end": 850.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1765.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.37, 0.35, 0.81, 0.81] location?",
        "answer": "carry/hold (an object) [0.37, 0.35, 0.81, 0.81] -> touch (an object) [0.37, 0.35, 0.81, 0.81] -> talk to (e.g., self, a person, a group) [0.37, 0.35, 0.81, 0.81]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "ZosVdkY76FU",
        "candidates": [
            "carry/hold (an object) [0.37, 0.35, 0.81, 0.81] -> touch (an object) [0.37, 0.35, 0.81, 0.81] -> talk to (e.g., self, a person, a group) [0.37, 0.35, 0.81, 0.81]",
            "swim [0.45, 0.35, 0.98, 0.81] -> carry/hold (an object) [0.46, 0.23, 0.76, 0.74] -> talk to (e.g., self, a person, a group) [0.40, 0.39, 0.82, 0.70]",
            "talk to (e.g., self, a person, a group) [0.51, 0.16, 0.65, 0.77] -> carry/hold (an object) [0.31, 0.28, 0.76, 0.95] -> hug (a person) [0.50, 0.20, 0.66, 0.97]",
            "touch (an object) [0.34, 0.41, 0.81, 0.66] -> talk to (e.g., self, a person, a group) [0.20, 0.33, 0.97, 0.97] -> fishing [0.32, 0.45, 0.66, 0.80]"
        ],
        "start": 0.0,
        "end": 870.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 955.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "read -> talk to (e.g., self, a person, a group)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "_7oWZq_s_Sk",
        "candidates": [
            "read -> talk to (e.g., self, a person, a group)",
            "answer phone -> read",
            "talk to (e.g., self, a person, a group) -> crawl",
            "read -> point to (an object)"
        ],
        "start": 0.0,
        "end": 60.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 994.0,
        "question": "Are there still 1 people in the current frame now?",
        "answer": "No",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "_7oWZq_s_Sk",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 99.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1056.0,
        "question": "Where was the person currently performing the carry/hold (an object) in the scene 8 seconds ago?",
        "answer": "[0.11, 0.09, 0.64, 1.00]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "_7oWZq_s_Sk",
        "candidates": [
            "[0.25, 0.00, 0.79, 0.82]",
            "[0.01, 0.00, 0.40, 0.70]",
            "[0.05, 0.20, 0.38, 1.00]",
            "[0.11, 0.09, 0.64, 1.00]"
        ],
        "start": 0.0,
        "end": 161.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1069.0,
        "question": "What action is the person at the location [0.02, 0.01, 0.44, 0.99] in the image performing?",
        "answer": "sit, play musical instrument",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "_7oWZq_s_Sk",
        "candidates": [
            "sit, listen to (a person), watch (a person)",
            "sit, play musical instrument",
            "stand, listen to (a person), watch (a person)",
            "stand, touch (an object), listen to (a person), watch (a person)"
        ],
        "start": 0.0,
        "end": 174.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1151.0,
        "question": "Are there still 3 people in the current frame now?",
        "answer": "No",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "_7oWZq_s_Sk",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 256.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1220.0,
        "question": "What action is the person at the location [0.00, 0.08, 0.25, 1.00] in the image performing?",
        "answer": "stand, touch (an object), listen to (a person), watch (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "_7oWZq_s_Sk",
        "candidates": [
            "stand, touch (an object), listen to (a person), watch (a person)",
            "sit, talk to (e.g., self, a person, a group), watch (a person)",
            "sit, carry/hold (an object), talk to (e.g., self, a person, a group), watch (a person)",
            "sit, watch (a person)"
        ],
        "start": 0.0,
        "end": 325.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1223.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.66, 0.23, 0.97, 0.90]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "_7oWZq_s_Sk",
        "candidates": [
            "[0.66, 0.23, 0.97, 0.90]",
            "[0.28, 0.04, 0.98, 0.99]",
            "[0.49, 0.49, 0.81, 0.89]",
            "[0.80, 0.50, 1.00, 1.00]"
        ],
        "start": 0.0,
        "end": 328.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1240.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "touch (an object) -> talk to (e.g., self, a person, a group) -> carry/hold (an object)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "_7oWZq_s_Sk",
        "candidates": [
            "carry/hold (an object) -> talk to (e.g., self, a person, a group) -> get up",
            "touch (an object) -> talk to (e.g., self, a person, a group) -> carry/hold (an object)",
            "crouch/kneel -> touch (an object) -> carry/hold (an object)",
            "close (e.g., a door, a box) -> carry/hold (an object) -> touch (an object)"
        ],
        "start": 0.0,
        "end": 345.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1301.0,
        "question": "What action is the person at the location [0.00, 0.04, 0.41, 0.99] in the image performing?",
        "answer": "stand, listen to (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "_7oWZq_s_Sk",
        "candidates": [
            "stand, listen to (a person), watch (a person)",
            "stand, listen to (a person)",
            "sit, carry/hold (an object), talk to (e.g., self, a person, a group), watch (a person)",
            "sit, talk to (e.g., self, a person, a group), watch (a person)"
        ],
        "start": 0.0,
        "end": 406.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1361.0,
        "question": "Are there still 1 people in the current frame now?",
        "answer": "No",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "_7oWZq_s_Sk",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 466.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1379.0,
        "question": "Where was the person currently performing the carry/hold (an object) in the scene 8 seconds ago?",
        "answer": "[0.07, 0.24, 0.35, 0.86]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "_7oWZq_s_Sk",
        "candidates": [
            "[0.19, 0.12, 0.52, 1.00]",
            "[0.15, 0.03, 0.24, 0.66]",
            "[0.07, 0.24, 0.35, 0.86]",
            "[0.00, 0.48, 0.33, 0.93]"
        ],
        "start": 0.0,
        "end": 484.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1402.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.06, 0.20, 0.49, 0.98]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "_7oWZq_s_Sk",
        "candidates": [
            "[0.00, 0.34, 0.27, 1.00]",
            "[0.06, 0.20, 0.49, 0.98]",
            "[0.19, 0.61, 0.34, 0.96]",
            "[0.32, 0.28, 0.55, 1.00]"
        ],
        "start": 0.0,
        "end": 507.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1426.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "talk to (e.g., self, a person, a group) -> carry/hold (an object)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "_7oWZq_s_Sk",
        "candidates": [
            "carry/hold (an object) -> take a photo",
            "exit -> carry/hold (an object)",
            "talk to (e.g., self, a person, a group) -> carry/hold (an object)",
            "carry/hold (an object) -> run/jog"
        ],
        "start": 0.0,
        "end": 531.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1491.0,
        "question": "Are there still 2 people in the current frame now?",
        "answer": "No",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "_7oWZq_s_Sk",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 596.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1597.0,
        "question": "What action is the person at the location [0.01, 0.23, 0.49, 0.96] in the image performing?",
        "answer": "sit, listen to (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "_7oWZq_s_Sk",
        "candidates": [
            "sit, listen to (a person)",
            "stand, touch (an object)",
            "stand, listen to (a person), watch (a person)",
            "sit, listen to (a person), watch (a person)"
        ],
        "start": 0.0,
        "end": 702.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1622.0,
        "question": "Where was the person currently performing the carry/hold (an object) in the scene 8 seconds ago?",
        "answer": "[0.51, 0.30, 0.74, 0.69]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "_7oWZq_s_Sk",
        "candidates": [
            "[0.30, 0.01, 0.51, 0.82]",
            "[0.46, 0.57, 0.54, 0.89]",
            "[0.51, 0.30, 0.74, 0.69]",
            "[0.71, 0.26, 0.98, 0.91]"
        ],
        "start": 0.0,
        "end": 727.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1624.0,
        "question": "Are there still 2 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "_7oWZq_s_Sk",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 729.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1684.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "bend/bow (at the waist) -> talk to (e.g., self, a person, a group)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "_7oWZq_s_Sk",
        "candidates": [
            "bend/bow (at the waist) -> talk to (e.g., self, a person, a group)",
            "bend/bow (at the waist) -> walk",
            "talk to (e.g., self, a person, a group) -> watch (e.g., TV)",
            "play with pets -> bend/bow (at the waist)"
        ],
        "start": 0.0,
        "end": 789.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1704.0,
        "question": "What action is the person currently in the [0.17, 0.15, 0.47, 0.99] location likely to do next?",
        "answer": "talk to (e.g., self, a person, a group)",
        "sub_answer_type": "FuturePrediction-1",
        "answer_type": "FuturePrediction",
        "video": "_7oWZq_s_Sk",
        "candidates": [
            "paint",
            "take a photo",
            "talk to (e.g., self, a person, a group)",
            "carry/hold (an object) and talk to (e.g., self, a person, a group)"
        ],
        "start": 0.0,
        "end": 809.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1737.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "hit (an object) -> talk to (e.g., self, a person, a group) -> touch (an object)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "_7oWZq_s_Sk",
        "candidates": [
            "carry/hold (an object) -> hit (an object) -> talk to (e.g., self, a person, a group)",
            "hit (an object) -> talk to (e.g., self, a person, a group) -> touch (an object)",
            "talk to (e.g., self, a person, a group) -> touch (an object) -> shoot",
            "bend/bow (at the waist) -> talk to (e.g., self, a person, a group) -> hit (an object)"
        ],
        "start": 0.0,
        "end": 842.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1773.0,
        "question": "Where is the person currently performing the talk to (e.g., self, a person, a group) located in the picture?",
        "answer": "[0.06, 0.19, 0.54, 0.98]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "_7oWZq_s_Sk",
        "candidates": [
            "[0.06, 0.19, 0.54, 0.98]",
            "[0.10, 0.12, 0.60, 0.71]",
            "[0.01, 0.48, 0.83, 1.00]",
            "[0.18, 0.17, 0.90, 1.00]"
        ],
        "start": 0.0,
        "end": 878.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 963.0,
        "question": "Is the person currently in the [0.03, 0.10, 0.58, 0.94] location in the current frame performing the carry/hold (an object)?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "_dBTTYDRdRQ",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 68.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 977.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "walk -> carry/hold (an object)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "_dBTTYDRdRQ",
        "candidates": [
            "walk -> carry/hold (an object)",
            "get up -> walk",
            "walk -> climb (e.g., a mountain)",
            "crouch/kneel -> walk"
        ],
        "start": 0.0,
        "end": 82.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1029.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "crouch/kneel -> carry/hold (an object) -> drink",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "_dBTTYDRdRQ",
        "candidates": [
            "eat -> carry/hold (an object) -> drink",
            "crouch/kneel -> carry/hold (an object) -> drink",
            "text on/look at a cellphone -> carry/hold (an object) -> crouch/kneel",
            "carry/hold (an object) -> crouch/kneel -> sing to (e.g., self, a person, a group)"
        ],
        "start": 0.0,
        "end": 134.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1050.0,
        "question": "Where is the person currently performing the play musical instrument located in the picture?",
        "answer": "[0.05, 0.06, 0.62, 1.00]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "_dBTTYDRdRQ",
        "candidates": [
            "[0.00, 0.00, 0.45, 0.80]",
            "[0.41, 0.07, 0.96, 0.99]",
            "[0.00, 0.29, 0.44, 1.00]",
            "[0.05, 0.06, 0.62, 1.00]"
        ],
        "start": 0.0,
        "end": 155.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1051.0,
        "question": "Where was the person currently performing the carry/hold (an object) in the scene 8 seconds ago?",
        "answer": "[0.06, 0.00, 0.57, 0.99]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "_dBTTYDRdRQ",
        "candidates": [
            "[0.06, 0.00, 0.57, 0.99]",
            "[0.22, 0.60, 0.35, 0.99]",
            "[0.23, 0.12, 0.74, 1.00]",
            "[0.00, 0.16, 0.32, 1.00]"
        ],
        "start": 0.0,
        "end": 156.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1142.0,
        "question": "Where is the person currently performing the play musical instrument located in the picture?",
        "answer": "[0.52, 0.02, 1.00, 0.95]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "_dBTTYDRdRQ",
        "candidates": [
            "[0.52, 0.02, 1.00, 0.95]",
            "[0.33, 0.29, 1.00, 1.00]",
            "[0.45, 0.00, 0.71, 0.78]",
            "[0.40, 0.61, 0.52, 0.96]"
        ],
        "start": 0.0,
        "end": 247.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1161.0,
        "question": "Are there still 3 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "_dBTTYDRdRQ",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 266.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1213.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.35, 0.34, 0.47, 0.68] location?",
        "answer": "talk to (e.g., self, a person, a group) [0.33, 0.35, 0.48, 0.69] -> carry/hold (an object) [0.35, 0.34, 0.47, 0.68] -> give/serve (an object) to (a person) [0.35, 0.34, 0.47, 0.68]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "_dBTTYDRdRQ",
        "candidates": [
            "fishing [0.43, 0.32, 0.29, 0.61] -> talk to (e.g., self, a person, a group) [0.26, 0.44, 0.36, 0.72] -> give/serve (an object) to (a person) [0.29, 0.20, 0.57, 0.69]",
            "talk to (e.g., self, a person, a group) [0.33, 0.35, 0.48, 0.69] -> carry/hold (an object) [0.35, 0.34, 0.47, 0.68] -> give/serve (an object) to (a person) [0.35, 0.34, 0.47, 0.68]",
            "talk to (e.g., self, a person, a group) [0.49, 0.34, 0.29, 0.88] -> point to (an object) [0.17, 0.52, 0.37, 0.65] -> carry/hold (an object) [0.25, 0.53, 0.61, 0.66]",
            "give/serve (an object) to (a person) [0.33, 0.26, 0.32, 0.65] -> ride (e.g., a bike, a car, a horse) [0.46, 0.49, 0.56, 0.60] -> carry/hold (an object) [0.49, 0.35, 0.63, 0.68]"
        ],
        "start": 0.0,
        "end": 318.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1215.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.33, 0.34, 0.48, 0.71] location?",
        "answer": "bend/bow (at the waist) [0.33, 0.34, 0.48, 0.71] -> carry/hold (an object) [0.33, 0.34, 0.48, 0.71] -> talk to (e.g., self, a person, a group) [0.33, 0.34, 0.48, 0.71]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "_dBTTYDRdRQ",
        "candidates": [
            "talk to (e.g., self, a person, a group) [0.15, 0.46, 0.33, 0.66] -> carry/hold (an object) [0.38, 0.17, 0.65, 0.79] -> bend/bow (at the waist) [0.24, 0.52, 0.53, 0.68]",
            "bend/bow (at the waist) [0.33, 0.34, 0.48, 0.71] -> carry/hold (an object) [0.33, 0.34, 0.48, 0.71] -> talk to (e.g., self, a person, a group) [0.33, 0.34, 0.48, 0.71]",
            "row boat [0.38, 0.36, 0.36, 0.77] -> bend/bow (at the waist) [0.38, 0.50, 0.61, 0.57] -> talk to (e.g., self, a person, a group) [0.38, 0.45, 0.61, 0.63]",
            "talk to (e.g., self, a person, a group) [0.42, 0.34, 0.62, 0.88] -> brush teeth [0.43, 0.44, 0.37, 0.52] -> carry/hold (an object) [0.27, 0.28, 0.65, 0.87]"
        ],
        "start": 0.0,
        "end": 320.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1269.0,
        "question": "What action is the person at the location [0.34, 0.43, 0.55, 0.99] in the image performing?",
        "answer": "carry/hold (an object), crouch/kneel",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "_dBTTYDRdRQ",
        "candidates": [
            "walk, listen to (a person)",
            "sit, play musical instrument, watch (a person)",
            "carry/hold (an object), crouch/kneel",
            "stand, listen to (a person), watch (a person)"
        ],
        "start": 0.0,
        "end": 374.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1276.0,
        "question": "What location in the frame is the person currently in the [0.06, 0.48, 0.43, 0.99] location likely to move to next?",
        "answer": "[0.51, 0.51, 0.79, 1.00]",
        "sub_answer_type": "FuturePrediction-2",
        "answer_type": "FuturePrediction",
        "video": "_dBTTYDRdRQ",
        "candidates": [
            "[0.51, 0.51, 0.79, 1.00]",
            "[0.27, 0.62, 0.66, 0.92]",
            "[0.46, 0.33, 0.78, 0.78]",
            "[0.56, 0.00, 1.00, 0.98]"
        ],
        "start": 0.0,
        "end": 381.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1288.0,
        "question": "Where was the person currently performing the carry/hold (an object) in the scene 8 seconds ago?",
        "answer": "[0.11, 0.29, 0.60, 0.99]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "_dBTTYDRdRQ",
        "candidates": [
            "[0.39, 0.06, 0.48, 0.70]",
            "[0.36, 0.36, 0.73, 0.81]",
            "[0.54, 0.06, 0.97, 0.99]",
            "[0.11, 0.29, 0.60, 0.99]"
        ],
        "start": 0.0,
        "end": 393.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1353.0,
        "question": "Is the person currently in the [0.04, 0.32, 0.22, 0.93] location in the current frame performing the carry/hold (an object)?",
        "answer": "No",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "_dBTTYDRdRQ",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 458.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1388.0,
        "question": "How many people were performing the sit in the scene 60 seconds ago?",
        "answer": "5",
        "sub_answer_type": "PastMemory-5",
        "answer_type": "PastMemory",
        "video": "_dBTTYDRdRQ",
        "candidates": [
            "4",
            "5",
            "3",
            "7"
        ],
        "start": 0.0,
        "end": 493.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1442.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "carry/hold (an object) -> play musical instrument",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "_dBTTYDRdRQ",
        "candidates": [
            "sing to (e.g., self, a person, a group) -> carry/hold (an object)",
            "push (another person) -> play musical instrument",
            "carry/hold (an object) -> play musical instrument",
            "carry/hold (an object) -> shoot"
        ],
        "start": 0.0,
        "end": 547.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1492.0,
        "question": "What action is the person currently in the [0.49, 0.21, 0.94, 0.99] location likely to do next?",
        "answer": "talk to (e.g., self, a person, a group)",
        "sub_answer_type": "FuturePrediction-1",
        "answer_type": "FuturePrediction",
        "video": "_dBTTYDRdRQ",
        "candidates": [
            "smoke",
            "kiss (a person)",
            "carry/hold (an object) and talk to (e.g., self, a person, a group)",
            "talk to (e.g., self, a person, a group)"
        ],
        "start": 0.0,
        "end": 597.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1511.0,
        "question": "How many people were performing the watch (a person) in the scene 180 seconds ago?",
        "answer": "9",
        "sub_answer_type": "PastMemory-5",
        "answer_type": "PastMemory",
        "video": "_dBTTYDRdRQ",
        "candidates": [
            "3",
            "6",
            "8",
            "9"
        ],
        "start": 0.0,
        "end": 616.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1535.0,
        "question": "Where is the person currently performing the talk to (e.g., self, a person, a group) located in the picture?",
        "answer": "[0.12, 0.03, 0.86, 0.98]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "_dBTTYDRdRQ",
        "candidates": [
            "[0.32, 0.09, 0.96, 0.98]",
            "[0.12, 0.03, 0.86, 0.98]",
            "[0.19, 0.32, 0.87, 1.00]",
            "[0.00, 0.00, 0.78, 0.69]"
        ],
        "start": 0.0,
        "end": 640.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1557.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.28, 0.47, 0.34, 0.75] location?",
        "answer": "walk [0.28, 0.47, 0.34, 0.75] -> carry/hold (an object) [0.28, 0.47, 0.34, 0.75] -> grab (a person) [0.28, 0.47, 0.34, 0.75] -> talk to (e.g., self, a person, a group) [0.28, 0.47, 0.34, 0.75]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "_dBTTYDRdRQ",
        "candidates": [
            "open (e.g., a window, a car door) [0.28, 0.36, 0.39, 0.76] -> grab (a person) [0.10, 0.37, 0.23, 0.81] -> talk to (e.g., self, a person, a group) [0.24, 0.52, 0.31, 0.55] -> walk [0.17, 0.35, 0.14, 0.58]",
            "walk [0.47, 0.28, 0.53, 0.59] -> carry/hold (an object) [0.16, 0.56, 0.46, 0.56] -> talk to (e.g., self, a person, a group) [0.28, 0.62, 0.46, 0.73] -> play with kids [0.47, 0.38, 0.52, 0.62]",
            "grab (a person) [0.12, 0.42, 0.19, 0.84] -> play board game [0.23, 0.29, 0.18, 0.78] -> carry/hold (an object) [0.25, 0.50, 0.15, 0.88] -> talk to (e.g., self, a person, a group) [0.21, 0.54, 0.53, 0.85]",
            "walk [0.28, 0.47, 0.34, 0.75] -> carry/hold (an object) [0.28, 0.47, 0.34, 0.75] -> grab (a person) [0.28, 0.47, 0.34, 0.75] -> talk to (e.g., self, a person, a group) [0.28, 0.47, 0.34, 0.75]"
        ],
        "start": 0.0,
        "end": 662.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1558.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.28, 0.47, 0.34, 0.75] location?",
        "answer": "walk [0.28, 0.47, 0.34, 0.75] -> carry/hold (an object) [0.28, 0.47, 0.34, 0.75] -> grab (a person) [0.28, 0.47, 0.34, 0.75] -> talk to (e.g., self, a person, a group) [0.28, 0.47, 0.34, 0.75]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "_dBTTYDRdRQ",
        "candidates": [
            "carry/hold (an object) [0.10, 0.51, 0.21, 0.92] -> talk to (e.g., self, a person, a group) [0.47, 0.48, 0.37, 0.57] -> grab (a person) [0.18, 0.41, 0.21, 0.70] -> watch (e.g., TV) [0.17, 0.27, 0.43, 0.57]",
            "walk [0.28, 0.47, 0.34, 0.75] -> carry/hold (an object) [0.28, 0.47, 0.34, 0.75] -> grab (a person) [0.28, 0.47, 0.34, 0.75] -> talk to (e.g., self, a person, a group) [0.28, 0.47, 0.34, 0.75]",
            "walk [0.46, 0.67, 0.18, 0.70] -> open (e.g., a window, a car door) [0.37, 0.66, 0.37, 0.92] -> talk to (e.g., self, a person, a group) [0.45, 0.47, 0.40, 0.71] -> carry/hold (an object) [0.46, 0.46, 0.38, 0.66]",
            "touch (an object) [0.39, 0.40, 0.31, 0.64] -> walk [0.41, 0.57, 0.17, 0.91] -> talk to (e.g., self, a person, a group) [0.47, 0.60, 0.17, 0.59] -> grab (a person) [0.40, 0.39, 0.48, 0.68]"
        ],
        "start": 0.0,
        "end": 663.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1576.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "carry/hold (an object) -> talk to (e.g., self, a person, a group)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "_dBTTYDRdRQ",
        "candidates": [
            "carry/hold (an object) -> take (an object) from (a person)",
            "answer phone -> carry/hold (an object)",
            "carry/hold (an object) -> talk to (e.g., self, a person, a group)",
            "carry/hold (an object) -> swim"
        ],
        "start": 0.0,
        "end": 681.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1606.0,
        "question": "How many people were performing the watch (a person) in the scene 300 seconds ago?",
        "answer": "7",
        "sub_answer_type": "PastMemory-5",
        "answer_type": "PastMemory",
        "video": "_dBTTYDRdRQ",
        "candidates": [
            "7",
            "4",
            "3",
            "6"
        ],
        "start": 0.0,
        "end": 711.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1626.0,
        "question": "Is the person currently in the [0.65, 0.45, 0.76, 0.86] location in the current frame performing the carry/hold (an object)?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "_dBTTYDRdRQ",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 731.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1699.0,
        "question": "Is the person currently in the [0.72, 0.47, 0.89, 0.78] location in the current frame performing the carry/hold (an object)?",
        "answer": "No",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "_dBTTYDRdRQ",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 804.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1699.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.72, 0.47, 0.89, 0.78] location?",
        "answer": "bend/bow (at the waist) [0.72, 0.47, 0.89, 0.78] -> dig [0.72, 0.47, 0.89, 0.78] -> shovel [0.72, 0.47, 0.89, 0.78]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "_dBTTYDRdRQ",
        "candidates": [
            "talk to (e.g., self, a person, a group) [0.64, 0.64, 0.95, 0.71] -> shovel [0.65, 0.34, 0.89, 0.67] -> bend/bow (at the waist) [0.85, 0.52, 0.80, 0.67]",
            "shovel [0.57, 0.50, 0.74, 0.59] -> bend/bow (at the waist) [0.57, 0.32, 0.92, 0.63] -> catch (an object) [0.71, 0.49, 0.85, 0.83]",
            "bend/bow (at the waist) [0.72, 0.47, 0.89, 0.78] -> dig [0.72, 0.47, 0.89, 0.78] -> shovel [0.72, 0.47, 0.89, 0.78]",
            "shovel [0.71, 0.63, 0.76, 0.93] -> hand shake [0.68, 0.36, 0.88, 0.67] -> dig [0.62, 0.65, 0.83, 0.68]"
        ],
        "start": 0.0,
        "end": 804.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1709.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "carry/hold (an object) -> lift/pick up -> turn (e.g., a screwdriver)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "_dBTTYDRdRQ",
        "candidates": [
            "lift/pick up -> turn (e.g., a screwdriver) -> swim",
            "carry/hold (an object) -> lift/pick up -> turn (e.g., a screwdriver)",
            "lift/pick up -> carry/hold (an object) -> write",
            "lift/pick up -> carry/hold (an object) -> dress/put on clothing"
        ],
        "start": 0.0,
        "end": 814.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1744.0,
        "question": "Where is the person currently performing the open (e.g., a window, a car door) located in the picture?",
        "answer": "[0.58, 0.02, 0.79, 0.93]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "_dBTTYDRdRQ",
        "candidates": [
            "[0.32, 0.00, 0.57, 0.95]",
            "[0.52, 0.56, 0.57, 0.73]",
            "[0.81, 0.11, 1.00, 1.00]",
            "[0.58, 0.02, 0.79, 0.93]"
        ],
        "start": 0.0,
        "end": 849.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 903.0,
        "question": "Are there still 1 people in the current frame now?",
        "answer": "No",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "_eBah6c5kyA",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 8.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 910.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.03, 0.00, 0.81, 0.97]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "_eBah6c5kyA",
        "candidates": [
            "[0.14, 0.18, 0.42, 0.96]",
            "[0.02, 0.28, 0.89, 1.00]",
            "[0.22, 0.01, 1.00, 0.86]",
            "[0.03, 0.00, 0.81, 0.97]"
        ],
        "start": 0.0,
        "end": 15.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 949.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "carry/hold (an object) -> talk to (e.g., self, a person, a group)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "_eBah6c5kyA",
        "candidates": [
            "carry/hold (an object) -> talk to (e.g., self, a person, a group)",
            "write -> talk to (e.g., self, a person, a group)",
            "carry/hold (an object) -> bend/bow (at the waist)",
            "carry/hold (an object) -> cut"
        ],
        "start": 0.0,
        "end": 54.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 956.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.18, 0.14, 0.55, 0.97] location?",
        "answer": "walk [0.18, 0.14, 0.55, 0.97] -> carry/hold (an object) [0.18, 0.14, 0.55, 0.97] -> talk to (e.g., self, a person, a group) [0.18, 0.14, 0.55, 0.97]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "_eBah6c5kyA",
        "candidates": [
            "walk [0.18, 0.14, 0.55, 0.97] -> carry/hold (an object) [0.18, 0.14, 0.55, 0.97] -> talk to (e.g., self, a person, a group) [0.18, 0.14, 0.55, 0.97]",
            "walk [0.17, 0.28, 0.74, 1.00] -> talk to (e.g., self, a person, a group) [0.12, 0.28, 0.69, 0.84] -> dig [0.33, 0.29, 0.65, 0.94]",
            "talk to (e.g., self, a person, a group) [0.00, 0.19, 0.69, 0.92] -> carry/hold (an object) [0.21, 0.03, 0.50, 1.00] -> lift/pick up [0.18, 0.29, 0.44, 1.00]",
            "crawl [0.27, 0.14, 0.62, 0.87] -> carry/hold (an object) [0.17, 0.00, 0.51, 0.93] -> talk to (e.g., self, a person, a group) [0.14, 0.11, 0.40, 1.00]"
        ],
        "start": 0.0,
        "end": 61.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1025.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.45, 0.23, 0.66, 0.82] location?",
        "answer": "walk [0.45, 0.23, 0.66, 0.82] -> carry/hold (an object) [0.45, 0.23, 0.66, 0.82] -> talk to (e.g., self, a person, a group) [0.45, 0.23, 0.66, 0.82]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "_eBah6c5kyA",
        "candidates": [
            "hug (a person) [0.40, 0.10, 0.49, 0.75] -> carry/hold (an object) [0.37, 0.36, 0.83, 0.74] -> talk to (e.g., self, a person, a group) [0.28, 0.09, 0.64, 0.76]",
            "extract [0.36, 0.23, 0.67, 0.70] -> carry/hold (an object) [0.43, 0.06, 0.54, 0.78] -> talk to (e.g., self, a person, a group) [0.55, 0.06, 0.46, 0.70]",
            "carry/hold (an object) [0.26, 0.21, 0.61, 0.67] -> walk [0.44, 0.32, 0.81, 0.75] -> push (an object) [0.26, 0.07, 0.75, 0.62]",
            "walk [0.45, 0.23, 0.66, 0.82] -> carry/hold (an object) [0.45, 0.23, 0.66, 0.82] -> talk to (e.g., self, a person, a group) [0.45, 0.23, 0.66, 0.82]"
        ],
        "start": 0.0,
        "end": 130.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1029.0,
        "question": "What action is the person at the location [0.13, 0.28, 0.33, 0.95] in the image performing?",
        "answer": "walk, carry/hold (an object), listen to (a person), watch (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "_eBah6c5kyA",
        "candidates": [
            "stand, carry/hold (an object), listen to (a person), watch (a person)",
            "crouch/kneel, talk to (e.g., self, a person, a group), watch (a person)",
            "stand, listen to (a person), talk to (e.g., self, a person, a group), watch (a person)",
            "walk, carry/hold (an object), listen to (a person), watch (a person)"
        ],
        "start": 0.0,
        "end": 134.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1186.0,
        "question": "Is the person currently in the [0.56, 0.06, 0.89, 0.99] location in the current frame performing the carry/hold (an object)?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "_eBah6c5kyA",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 291.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1193.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "talk to (e.g., self, a person, a group) -> lie/sleep",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "_eBah6c5kyA",
        "candidates": [
            "lie/sleep -> kick (a person)",
            "play musical instrument -> lie/sleep",
            "talk to (e.g., self, a person, a group) -> run/jog",
            "talk to (e.g., self, a person, a group) -> lie/sleep"
        ],
        "start": 0.0,
        "end": 298.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1204.0,
        "question": "Where is the person currently performing the lie/sleep located in the picture?",
        "answer": "[0.11, 0.06, 0.92, 0.94]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "_eBah6c5kyA",
        "candidates": [
            "[0.20, 0.42, 0.42, 0.99]",
            "[0.39, 0.07, 1.00, 0.74]",
            "[0.39, 0.25, 1.00, 1.00]",
            "[0.11, 0.06, 0.92, 0.94]"
        ],
        "start": 0.0,
        "end": 309.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1240.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.23, 0.04, 0.52, 0.97] location?",
        "answer": "walk [0.23, 0.04, 0.52, 0.97] -> carry/hold (an object) [0.23, 0.04, 0.52, 0.97] -> talk to (e.g., self, a person, a group) [0.23, 0.04, 0.52, 0.97]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "_eBah6c5kyA",
        "candidates": [
            "hand wave [0.12, 0.10, 0.40, 0.93] -> carry/hold (an object) [0.38, 0.13, 0.55, 1.00] -> talk to (e.g., self, a person, a group) [0.12, 0.01, 0.34, 0.77]",
            "fall down [0.37, 0.05, 0.44, 1.00] -> carry/hold (an object) [0.19, 0.13, 0.60, 1.00] -> walk [0.10, 0.00, 0.35, 1.00]",
            "walk [0.23, 0.04, 0.52, 0.97] -> carry/hold (an object) [0.23, 0.04, 0.52, 0.97] -> talk to (e.g., self, a person, a group) [0.23, 0.04, 0.52, 0.97]",
            "get up [0.41, 0.00, 0.44, 1.00] -> talk to (e.g., self, a person, a group) [0.30, 0.07, 0.37, 0.96] -> carry/hold (an object) [0.32, 0.00, 0.71, 0.92]"
        ],
        "start": 0.0,
        "end": 345.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1249.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.64, 0.00, 0.98, 0.98] location?",
        "answer": "talk to (e.g., self, a person, a group) [0.50, 0.04, 0.86, 0.99] -> walk [0.64, 0.00, 0.98, 0.98] -> carry/hold (an object) [0.64, 0.00, 0.98, 0.98]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "_eBah6c5kyA",
        "candidates": [
            "talk to (e.g., self, a person, a group) [0.30, 0.00, 0.68, 0.98] -> fight/hit (a person) [0.61, 0.18, 0.79, 0.91] -> carry/hold (an object) [0.67, 0.08, 1.00, 0.81]",
            "talk to (e.g., self, a person, a group) [0.64, 0.01, 0.75, 0.96] -> work on a computer [0.78, 0.00, 0.91, 0.94] -> carry/hold (an object) [0.64, 0.00, 0.84, 1.00]",
            "carry/hold (an object) [0.55, 0.03, 1.00, 1.00] -> martial art [0.57, 0.00, 0.96, 0.97] -> walk [0.58, 0.19, 0.82, 0.96]",
            "talk to (e.g., self, a person, a group) [0.50, 0.04, 0.86, 0.99] -> walk [0.64, 0.00, 0.98, 0.98] -> carry/hold (an object) [0.64, 0.00, 0.98, 0.98]"
        ],
        "start": 0.0,
        "end": 354.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1250.0,
        "question": "Where was the person currently performing the walk in the scene 8 seconds ago?",
        "answer": "[0.25, 0.14, 0.67, 0.99]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "_eBah6c5kyA",
        "candidates": [
            "[0.20, 0.00, 0.40, 1.00]",
            "[0.25, 0.14, 0.67, 0.99]",
            "[0.48, 0.06, 0.83, 0.95]",
            "[0.26, 0.44, 0.71, 1.00]"
        ],
        "start": 0.0,
        "end": 355.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1257.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "carry/hold (an object) -> talk to (e.g., self, a person, a group) -> walk",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "_eBah6c5kyA",
        "candidates": [
            "carry/hold (an object) -> talk to (e.g., self, a person, a group) -> text on/look at a cellphone",
            "take a photo -> walk -> carry/hold (an object)",
            "carry/hold (an object) -> talk to (e.g., self, a person, a group) -> walk",
            "run/jog -> talk to (e.g., self, a person, a group) -> walk"
        ],
        "start": 0.0,
        "end": 362.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1266.0,
        "question": "Where is the person currently performing the carry/hold (an object) located in the picture?",
        "answer": "[0.38, 0.04, 0.83, 0.99]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "_eBah6c5kyA",
        "candidates": [
            "[0.64, 0.14, 1.00, 1.00]",
            "[0.00, 0.48, 0.87, 0.99]",
            "[0.38, 0.04, 0.83, 0.99]",
            "[0.20, 0.05, 0.57, 1.00]"
        ],
        "start": 0.0,
        "end": 371.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1365.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "carry/hold (an object) -> touch (an object)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "_eBah6c5kyA",
        "candidates": [
            "carry/hold (an object) -> touch (an object)",
            "touch (an object) -> play with kids",
            "crouch/kneel -> carry/hold (an object)",
            "touch (an object) -> bend/bow (at the waist)"
        ],
        "start": 0.0,
        "end": 470.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1414.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.49, 0.11, 0.65, 0.98]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "_eBah6c5kyA",
        "candidates": [
            "[0.16, 0.19, 0.43, 0.92]",
            "[0.49, 0.11, 0.65, 0.98]",
            "[0.34, 0.02, 0.38, 0.70]",
            "[0.79, 0.17, 0.66, 0.81]"
        ],
        "start": 0.0,
        "end": 519.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1434.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.02, 0.20, 0.26, 0.95]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "_eBah6c5kyA",
        "candidates": [
            "[0.02, 0.20, 0.26, 0.95]",
            "[0.00, 0.00, 0.00, 1.00]",
            "[0.20, 0.05, 0.98, 0.99]",
            "[0.00, 0.38, 0.00, 1.00]"
        ],
        "start": 0.0,
        "end": 539.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1559.0,
        "question": "What action is the person currently in the [0.16, 0.33, 0.38, 0.99] location likely to do next?",
        "answer": "carry/hold (an object) and touch (an object)",
        "sub_answer_type": "FuturePrediction-1",
        "answer_type": "FuturePrediction",
        "video": "_eBah6c5kyA",
        "candidates": [
            "walk and carry/hold (an object)",
            "carry/hold (an object) and touch (an object)",
            "fall down",
            "martial art"
        ],
        "start": 0.0,
        "end": 664.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1561.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.17, 0.32, 0.38, 0.99] location?",
        "answer": "talk to (e.g., self, a person, a group) [0.16, 0.33, 0.38, 0.99] -> carry/hold (an object) [0.17, 0.32, 0.38, 0.99] -> touch (an object) [0.17, 0.32, 0.38, 0.99]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "_eBah6c5kyA",
        "candidates": [
            "talk to (e.g., self, a person, a group) [0.16, 0.33, 0.38, 0.99] -> carry/hold (an object) [0.17, 0.32, 0.38, 0.99] -> touch (an object) [0.17, 0.32, 0.38, 0.99]",
            "touch (an object) [0.16, 0.18, 0.57, 1.00] -> talk to (e.g., self, a person, a group) [0.33, 0.23, 0.30, 0.87] -> touch (an object) [0.14, 0.46, 0.46, 0.79]",
            "carry/hold (an object) [0.07, 0.40, 0.53, 1.00] -> fight/hit (a person) [0.14, 0.38, 0.30, 1.00] -> touch (an object) [0.36, 0.19, 0.29, 0.93]",
            "touch (an object) [0.26, 0.21, 0.55, 1.00] -> push (another person) [0.25, 0.18, 0.55, 1.00] -> talk to (e.g., self, a person, a group) [0.14, 0.36, 0.32, 1.00]"
        ],
        "start": 0.0,
        "end": 666.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1562.0,
        "question": "Is the person currently in the [0.06, 0.03, 0.90, 0.98] location in the current frame performing the touch (an object)?",
        "answer": "No",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "_eBah6c5kyA",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 667.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1585.0,
        "question": "Where is the person currently performing the carry/hold (an object) located in the picture?",
        "answer": "[0.27, 0.18, 0.78, 0.99]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "_eBah6c5kyA",
        "candidates": [
            "[0.06, 0.04, 0.69, 0.99]",
            "[0.03, 0.00, 0.55, 0.76]",
            "[0.52, 0.12, 0.91, 1.00]",
            "[0.27, 0.18, 0.78, 0.99]"
        ],
        "start": 0.0,
        "end": 690.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1618.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "carry/hold (an object) -> lie/sleep",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "_eBah6c5kyA",
        "candidates": [
            "carry/hold (an object) -> lie/sleep",
            "stir -> lie/sleep",
            "pull (an object) -> lie/sleep",
            "lie/sleep -> text on/look at a cellphone"
        ],
        "start": 0.0,
        "end": 723.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1703.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.19, 0.54, 0.46, 0.99]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "_eBah6c5kyA",
        "candidates": [
            "[0.40, 0.26, 0.68, 0.89]",
            "[0.02, 0.01, 0.47, 0.98]",
            "[0.37, 0.53, 0.67, 1.00]",
            "[0.19, 0.54, 0.46, 0.99]"
        ],
        "start": 0.0,
        "end": 808.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1726.0,
        "question": "Where is the person currently performing the walk located in the picture?",
        "answer": "[0.00, 0.04, 0.77, 1.00]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "_eBah6c5kyA",
        "candidates": [
            "[0.00, 0.32, 0.53, 1.00]",
            "[0.00, 0.43, 0.88, 0.99]",
            "[0.00, 0.04, 0.77, 1.00]",
            "[0.29, 0.00, 0.65, 0.72]"
        ],
        "start": 0.0,
        "end": 831.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1769.0,
        "question": "Are there still 1 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "_eBah6c5kyA",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 874.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 917.0,
        "question": "Where is the person currently performing the talk to (e.g., self, a person, a group) located in the picture?",
        "answer": "[0.29, 0.00, 0.98, 0.97]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "ayAMdYfJJLk",
        "candidates": [
            "[0.04, 0.00, 0.84, 0.99]",
            "[0.59, 0.00, 1.00, 1.00]",
            "[0.29, 0.00, 0.98, 0.97]",
            "[0.40, 0.29, 1.00, 1.00]"
        ],
        "start": 0.0,
        "end": 22.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 966.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "carry/hold (an object) -> talk to (e.g., self, a person, a group)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "ayAMdYfJJLk",
        "candidates": [
            "talk to (e.g., self, a person, a group) -> walk",
            "carry/hold (an object) -> talk to (e.g., self, a person, a group)",
            "talk to (e.g., self, a person, a group) -> dance",
            "talk to (e.g., self, a person, a group) -> shoot"
        ],
        "start": 0.0,
        "end": 71.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1008.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "read -> talk to (e.g., self, a person, a group)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "ayAMdYfJJLk",
        "candidates": [
            "martial art -> read",
            "lie/sleep -> read",
            "read -> talk to (e.g., self, a person, a group)",
            "exit -> read"
        ],
        "start": 0.0,
        "end": 113.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1031.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "talk to (e.g., self, a person, a group) -> read",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "ayAMdYfJJLk",
        "candidates": [
            "talk to (e.g., self, a person, a group) -> read",
            "dance -> talk to (e.g., self, a person, a group)",
            "dig -> talk to (e.g., self, a person, a group)",
            "hand wave -> read"
        ],
        "start": 0.0,
        "end": 136.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1074.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.35, 0.29, 0.71, 1.00]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "ayAMdYfJJLk",
        "candidates": [
            "[0.59, 0.11, 0.84, 1.00]",
            "[0.35, 0.29, 0.71, 1.00]",
            "[0.00, 0.00, 0.59, 1.00]",
            "[0.09, 0.53, 0.42, 1.00]"
        ],
        "start": 0.0,
        "end": 179.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1083.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.21, 0.23, 0.64, 0.99]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "ayAMdYfJJLk",
        "candidates": [
            "[0.21, 0.09, 0.57, 0.80]",
            "[0.45, 0.04, 0.90, 1.00]",
            "[0.21, 0.23, 0.64, 0.99]",
            "[0.39, 0.65, 0.54, 0.98]"
        ],
        "start": 0.0,
        "end": 188.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1102.0,
        "question": "Where is the person currently performing the talk to (e.g., self, a person, a group) located in the picture?",
        "answer": "[0.35, 0.06, 0.94, 0.98]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "ayAMdYfJJLk",
        "candidates": [
            "[0.35, 0.06, 0.94, 0.98]",
            "[0.55, 0.00, 0.97, 0.69]",
            "[0.05, 0.01, 0.69, 1.00]",
            "[0.37, 0.00, 0.69, 0.80]"
        ],
        "start": 0.0,
        "end": 207.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1232.0,
        "question": "Where is the person currently performing the carry/hold (an object) located in the picture?",
        "answer": "[0.07, 0.04, 0.56, 0.98]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "ayAMdYfJJLk",
        "candidates": [
            "[0.07, 0.04, 0.56, 0.98]",
            "[0.00, 0.06, 0.38, 0.71]",
            "[0.36, 0.03, 0.99, 0.99]",
            "[0.00, 0.34, 0.36, 0.86]"
        ],
        "start": 0.0,
        "end": 337.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1330.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "carry/hold (an object) -> talk to (e.g., self, a person, a group)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "ayAMdYfJJLk",
        "candidates": [
            "carry/hold (an object) -> talk to (e.g., self, a person, a group)",
            "paint -> talk to (e.g., self, a person, a group)",
            "put down -> carry/hold (an object)",
            "talk to (e.g., self, a person, a group) -> crawl"
        ],
        "start": 0.0,
        "end": 435.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1370.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "walk -> carry/hold (an object)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "ayAMdYfJJLk",
        "candidates": [
            "walk -> carry/hold (an object)",
            "carry/hold (an object) -> drink",
            "walk -> crawl",
            "lie/sleep -> carry/hold (an object)"
        ],
        "start": 0.0,
        "end": 475.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1419.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.63, 0.21, 0.97, 0.97]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "ayAMdYfJJLk",
        "candidates": [
            "[0.35, 0.01, 0.76, 1.00]",
            "[0.63, 0.21, 0.97, 0.97]",
            "[0.36, 0.35, 0.46, 0.85]",
            "[0.37, 0.42, 1.00, 0.99]"
        ],
        "start": 0.0,
        "end": 524.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1419.0,
        "question": "What action is the person at the location [0.04, 0.04, 0.53, 0.84] in the image performing?",
        "answer": "stand, carry/hold (an object), listen to (a person), watch (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "ayAMdYfJJLk",
        "candidates": [
            "sit, talk to (e.g., self, a person, a group)",
            "stand, carry/hold (an object), listen to (a person), watch (a person)",
            "stand, listen to (a person)",
            "stand, watch (a person)"
        ],
        "start": 0.0,
        "end": 524.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1435.0,
        "question": "What action is the person currently in the [0.01, 0.06, 0.52, 0.91] location likely to do next?",
        "answer": "carry/hold (an object) and talk to (e.g., self, a person, a group)",
        "sub_answer_type": "FuturePrediction-1",
        "answer_type": "FuturePrediction",
        "video": "ayAMdYfJJLk",
        "candidates": [
            "close (e.g., a door, a box)",
            "push (another person)",
            "walk and carry/hold (an object)",
            "carry/hold (an object) and talk to (e.g., self, a person, a group)"
        ],
        "start": 0.0,
        "end": 540.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1543.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.37, 0.10, 0.95, 0.93]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "ayAMdYfJJLk",
        "candidates": [
            "[0.64, 0.21, 0.96, 0.99]",
            "[0.16, 0.34, 0.97, 0.98]",
            "[0.37, 0.10, 0.95, 0.93]",
            "[0.15, 0.00, 0.85, 1.00]"
        ],
        "start": 0.0,
        "end": 648.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1600.0,
        "question": "What action is the person at the location [0.01, 0.02, 0.45, 0.98] in the image performing?",
        "answer": "stand, talk to (e.g., self, a person, a group), watch (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "ayAMdYfJJLk",
        "candidates": [
            "stand, talk to (e.g., self, a person, a group), watch (a person)",
            "stand, carry/hold (an object), touch (an object), talk to (e.g., self, a person, a group)",
            "stand, listen to (a person)",
            "sit, listen to (a person), watch (a person)"
        ],
        "start": 0.0,
        "end": 705.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1691.0,
        "question": "Is the person currently in the [0.76, 0.00, 1.00, 0.98] location in the current frame performing the talk to (e.g., self, a person, a group)?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "ayAMdYfJJLk",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 796.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1766.0,
        "question": "What location in the frame is the person currently in the [0.20, 0.10, 0.52, 0.94] location likely to move to next?",
        "answer": "[0.37, 0.00, 0.97, 0.94]",
        "sub_answer_type": "FuturePrediction-2",
        "answer_type": "FuturePrediction",
        "video": "ayAMdYfJJLk",
        "candidates": [
            "[0.00, 0.16, 0.16, 1.00]",
            "[0.45, 0.24, 1.00, 1.00]",
            "[0.37, 0.00, 0.97, 0.94]",
            "[0.07, 0.18, 1.00, 1.00]"
        ],
        "start": 0.0,
        "end": 871.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1774.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.20, 0.10, 0.52, 0.94]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "ayAMdYfJJLk",
        "candidates": [
            "[0.20, 0.10, 0.52, 0.94]",
            "[0.05, 0.15, 0.31, 1.00]",
            "[0.31, 0.04, 0.79, 0.96]",
            "[0.41, 0.00, 0.31, 0.66]"
        ],
        "start": 0.0,
        "end": 879.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 905.0,
        "question": "Is the person currently in the [0.54, 0.21, 0.64, 0.57] location in the current frame performing the walk?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "b-YoBU0XT90",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 10.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 933.0,
        "question": "What action is the person currently in the [0.39, 0.20, 0.58, 0.71] location likely to do next?",
        "answer": "bend/bow (at the waist)",
        "sub_answer_type": "FuturePrediction-1",
        "answer_type": "FuturePrediction",
        "video": "b-YoBU0XT90",
        "candidates": [
            "walk and carry/hold (an object)",
            "point to (an object)",
            "cut",
            "bend/bow (at the waist)"
        ],
        "start": 0.0,
        "end": 38.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 934.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.30, 0.04, 0.60, 0.87] location?",
        "answer": "bend/bow (at the waist) [0.30, 0.04, 0.60, 0.87] -> dig [0.30, 0.04, 0.60, 0.87] -> shovel [0.30, 0.04, 0.60, 0.87]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "b-YoBU0XT90",
        "candidates": [
            "bend/bow (at the waist) [0.30, 0.04, 0.60, 0.87] -> dig [0.30, 0.04, 0.60, 0.87] -> shovel [0.30, 0.04, 0.60, 0.87]",
            "bend/bow (at the waist) [0.36, 0.22, 0.53, 0.88] -> smoke [0.13, 0.00, 0.64, 0.89] -> dig [0.25, 0.08, 0.44, 1.00]",
            "dig [0.35, 0.00, 0.66, 0.93] -> shovel [0.13, 0.23, 0.68, 0.78] -> lift/pick up [0.31, 0.19, 0.75, 0.91]",
            "shovel [0.20, 0.19, 0.44, 0.79] -> close (e.g., a door, a box) [0.24, 0.09, 0.49, 0.87] -> dig [0.43, 0.00, 0.43, 1.00]"
        ],
        "start": 0.0,
        "end": 39.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 946.0,
        "question": "Where was the person currently performing the climb (e.g., a mountain) in the scene 8 seconds ago?",
        "answer": "[0.31, 0.20, 0.50, 0.88]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "b-YoBU0XT90",
        "candidates": [
            "[0.29, 0.49, 0.74, 1.00]",
            "[0.31, 0.20, 0.50, 0.88]",
            "[0.48, 0.21, 0.66, 0.69]",
            "[0.33, 0.36, 0.36, 1.00]"
        ],
        "start": 0.0,
        "end": 51.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1003.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "carry/hold (an object) -> walk",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "b-YoBU0XT90",
        "candidates": [
            "walk -> eat",
            "kiss (a person) -> carry/hold (an object)",
            "carry/hold (an object) -> walk",
            "carry/hold (an object) -> take a photo"
        ],
        "start": 0.0,
        "end": 108.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1110.0,
        "question": "Where is the person currently performing the carry/hold (an object) located in the picture?",
        "answer": "[0.34, 0.11, 0.53, 0.94]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "b-YoBU0XT90",
        "candidates": [
            "[0.10, 0.19, 0.47, 0.70]",
            "[0.34, 0.11, 0.53, 0.94]",
            "[0.54, 0.23, 0.61, 1.00]",
            "[0.61, 0.20, 0.77, 0.80]"
        ],
        "start": 0.0,
        "end": 215.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1132.0,
        "question": "Where was the person currently performing the lie/sleep in the scene 8 seconds ago?",
        "answer": "[0.10, 0.10, 1.00, 0.98]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "b-YoBU0XT90",
        "candidates": [
            "[0.17, 0.31, 0.71, 1.00]",
            "[0.08, 0.13, 0.56, 1.00]",
            "[0.05, 0.00, 1.00, 0.75]",
            "[0.10, 0.10, 1.00, 0.98]"
        ],
        "start": 0.0,
        "end": 237.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1172.0,
        "question": "Is the person currently in the [0.00, 0.05, 0.97, 0.89] location in the current frame performing the talk to (e.g., self, a person, a group)?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "b-YoBU0XT90",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 277.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1173.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "talk to (e.g., self, a person, a group) -> lie/sleep",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "b-YoBU0XT90",
        "candidates": [
            "throw -> talk to (e.g., self, a person, a group)",
            "lie/sleep -> take a photo",
            "talk to (e.g., self, a person, a group) -> lie/sleep",
            "lie/sleep -> carry/hold (an object)"
        ],
        "start": 0.0,
        "end": 278.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1219.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.32, 0.04, 0.81, 0.97] location?",
        "answer": "carry/hold (an object) [0.32, 0.04, 0.81, 0.97] -> smoke [0.32, 0.04, 0.81, 0.97] -> talk to (e.g., self, a person, a group) [0.32, 0.04, 0.81, 0.97]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "b-YoBU0XT90",
        "candidates": [
            "carry/hold (an object) [0.32, 0.04, 0.81, 0.97] -> smoke [0.32, 0.04, 0.81, 0.97] -> talk to (e.g., self, a person, a group) [0.32, 0.04, 0.81, 0.97]",
            "talk to (e.g., self, a person, a group) [0.40, 0.20, 0.71, 0.96] -> climb (e.g., a mountain) [0.14, 0.00, 0.71, 0.95] -> smoke [0.19, 0.10, 0.85, 0.86]",
            "carry/hold (an object) [0.31, 0.00, 0.95, 0.95] -> crawl [0.30, 0.15, 0.99, 0.88] -> smoke [0.38, 0.06, 0.76, 0.97]",
            "talk to (e.g., self, a person, a group) [0.41, 0.00, 0.94, 0.84] -> carry/hold (an object) [0.23, 0.06, 0.83, 0.98] -> take (an object) from (a person) [0.47, 0.22, 0.93, 0.95]"
        ],
        "start": 0.0,
        "end": 324.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1238.0,
        "question": "Where is the person currently performing the carry/hold (an object) located in the picture?",
        "answer": "[0.41, 0.20, 0.58, 0.94]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "b-YoBU0XT90",
        "candidates": [
            "[0.55, 0.26, 0.77, 0.62]",
            "[0.18, 0.49, 0.35, 0.80]",
            "[0.41, 0.20, 0.58, 0.94]",
            "[0.43, 0.42, 0.82, 1.00]"
        ],
        "start": 0.0,
        "end": 343.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1241.0,
        "question": "Is the person currently in the [0.38, 0.11, 0.59, 0.92] location in the current frame performing the talk to (e.g., self, a person, a group)?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "b-YoBU0XT90",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 346.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1279.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "carry/hold (an object) -> bend/bow (at the waist)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "b-YoBU0XT90",
        "candidates": [
            "carry/hold (an object) -> turn (e.g., a screwdriver)",
            "bend/bow (at the waist) -> chop",
            "carry/hold (an object) -> watch (e.g., TV)",
            "carry/hold (an object) -> bend/bow (at the waist)"
        ],
        "start": 0.0,
        "end": 384.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1373.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "touch (an object) -> carry/hold (an object)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "b-YoBU0XT90",
        "candidates": [
            "kiss (a person) -> touch (an object)",
            "martial art -> touch (an object)",
            "turn (e.g., a screwdriver) -> touch (an object)",
            "touch (an object) -> carry/hold (an object)"
        ],
        "start": 0.0,
        "end": 478.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1398.0,
        "question": "Where is the person currently performing the walk located in the picture?",
        "answer": "[0.39, 0.14, 0.61, 0.98]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "b-YoBU0XT90",
        "candidates": [
            "[0.58, 0.30, 0.84, 1.00]",
            "[0.66, 0.00, 0.87, 0.73]",
            "[0.04, 0.13, 0.59, 1.00]",
            "[0.39, 0.14, 0.61, 0.98]"
        ],
        "start": 0.0,
        "end": 503.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1421.0,
        "question": "Is the person currently in the [0.21, 0.04, 0.78, 0.94] location in the current frame performing the touch (an object)?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "b-YoBU0XT90",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 526.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1421.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.15, 0.03, 0.78, 0.93] location?",
        "answer": "carry/hold (an object) [0.15, 0.03, 0.78, 0.93] -> read [0.15, 0.03, 0.78, 0.93] -> touch (an object) [0.15, 0.03, 0.78, 0.93]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "b-YoBU0XT90",
        "candidates": [
            "carry/hold (an object) [0.09, 0.10, 0.77, 0.80] -> touch (an object) [0.15, 0.17, 0.70, 0.81] -> push (another person) [0.16, 0.00, 0.64, 0.92]",
            "carry/hold (an object) [0.15, 0.03, 0.78, 0.93] -> read [0.15, 0.03, 0.78, 0.93] -> touch (an object) [0.15, 0.03, 0.78, 0.93]",
            "dress/put on clothing [0.31, 0.02, 0.96, 0.99] -> touch (an object) [0.17, 0.19, 0.83, 1.00] -> read [0.22, 0.17, 0.64, 1.00]",
            "carry/hold (an object) [0.20, 0.00, 0.74, 0.86] -> answer phone [0.09, 0.07, 0.73, 0.82] -> touch (an object) [0.20, 0.04, 0.95, 0.77]"
        ],
        "start": 0.0,
        "end": 526.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1449.0,
        "question": "Where was the person currently performing the read in the scene 8 seconds ago?",
        "answer": "[0.27, 0.02, 1.00, 1.00]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "b-YoBU0XT90",
        "candidates": [
            "[0.00, 0.00, 0.78, 0.88]",
            "[0.13, 0.02, 1.00, 0.71]",
            "[0.28, 0.36, 0.48, 0.85]",
            "[0.27, 0.02, 1.00, 1.00]"
        ],
        "start": 0.0,
        "end": 554.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1463.0,
        "question": "Where is the person currently performing the cut located in the picture?",
        "answer": "[0.06, 0.17, 0.63, 0.99]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "b-YoBU0XT90",
        "candidates": [
            "[0.16, 0.11, 0.96, 0.96]",
            "[0.06, 0.17, 0.63, 0.99]",
            "[0.26, 0.43, 0.83, 1.00]",
            "[0.06, 0.42, 0.43, 1.00]"
        ],
        "start": 0.0,
        "end": 568.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1483.0,
        "question": "Where was the person currently performing the carry/hold (an object) in the scene 8 seconds ago?",
        "answer": "[0.25, 0.08, 0.62, 0.83]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "b-YoBU0XT90",
        "candidates": [
            "[0.25, 0.08, 0.62, 0.83]",
            "[0.10, 0.00, 0.47, 0.65]",
            "[0.48, 0.22, 0.68, 0.86]",
            "[0.20, 0.33, 0.37, 0.98]"
        ],
        "start": 0.0,
        "end": 588.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1612.0,
        "question": "Where was the person currently performing the walk in the scene 8 seconds ago?",
        "answer": "[0.34, 0.26, 0.64, 0.95]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "b-YoBU0XT90",
        "candidates": [
            "[0.34, 0.26, 0.64, 0.95]",
            "[0.39, 0.42, 0.89, 1.00]",
            "[0.11, 0.23, 0.62, 0.69]",
            "[0.25, 0.02, 1.00, 0.96]"
        ],
        "start": 0.0,
        "end": 717.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1662.0,
        "question": "Where is the person currently performing the walk located in the picture?",
        "answer": "[0.56, 0.75, 0.61, 0.93]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "b-YoBU0XT90",
        "candidates": [
            "[0.56, 0.75, 0.61, 0.93]",
            "[0.64, 0.79, 0.86, 0.71]",
            "[0.20, 0.10, 0.79, 0.92]",
            "[0.29, 0.57, 0.53, 0.90]"
        ],
        "start": 0.0,
        "end": 767.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1697.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.13, 0.13, 0.71, 0.96] location?",
        "answer": "talk to (e.g., self, a person, a group) [0.15, 0.16, 0.75, 0.94] -> carry/hold (an object) [0.13, 0.13, 0.71, 0.96] -> touch (an object) [0.13, 0.13, 0.71, 0.96]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "b-YoBU0XT90",
        "candidates": [
            "talk to (e.g., self, a person, a group) [0.15, 0.16, 0.75, 0.94] -> carry/hold (an object) [0.13, 0.13, 0.71, 0.96] -> touch (an object) [0.13, 0.13, 0.71, 0.96]",
            "ride (e.g., a bike, a car, a horse) [0.30, 0.08, 0.92, 1.00] -> carry/hold (an object) [0.17, 0.19, 0.54, 0.77] -> touch (an object) [0.14, 0.23, 0.89, 1.00]",
            "carry/hold (an object) [0.00, 0.12, 0.89, 0.95] -> talk to (e.g., self, a person, a group) [0.29, 0.00, 0.74, 1.00] -> ride (e.g., a bike, a car, a horse) [0.13, 0.00, 0.74, 1.00]",
            "get up [0.27, 0.31, 0.72, 0.91] -> talk to (e.g., self, a person, a group) [0.15, 0.07, 0.89, 1.00] -> touch (an object) [0.09, 0.10, 0.54, 1.00]"
        ],
        "start": 0.0,
        "end": 802.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1699.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.16, 0.21, 0.60, 0.97] location?",
        "answer": "touch (an object) [0.18, 0.16, 0.79, 0.98] -> talk to (e.g., self, a person, a group) [0.18, 0.16, 0.79, 0.98] -> carry/hold (an object) [0.16, 0.21, 0.60, 0.97] -> play with pets [0.16, 0.21, 0.60, 0.97]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "b-YoBU0XT90",
        "candidates": [
            "touch (an object) [0.12, 0.14, 0.97, 0.88] -> talk to (e.g., self, a person, a group) [0.29, 0.28, 0.62, 1.00] -> open (e.g., a window, a car door) [0.18, 0.15, 0.54, 1.00] -> play with pets [0.27, 0.36, 0.41, 0.91]",
            "touch (an object) [0.18, 0.16, 0.79, 0.98] -> talk to (e.g., self, a person, a group) [0.18, 0.16, 0.79, 0.98] -> carry/hold (an object) [0.16, 0.21, 0.60, 0.97] -> play with pets [0.16, 0.21, 0.60, 0.97]",
            "play with pets [0.21, 0.33, 0.74, 0.81] -> touch (an object) [0.28, 0.28, 0.69, 1.00] -> shoot [0.35, 0.28, 0.68, 0.86] -> talk to (e.g., self, a person, a group) [0.21, 0.17, 0.80, 1.00]",
            "sing to (e.g., self, a person, a group) [0.01, 0.11, 0.95, 0.82] -> talk to (e.g., self, a person, a group) [0.18, 0.21, 0.80, 1.00] -> carry/hold (an object) [0.10, 0.27, 0.73, 1.00] -> play with pets [0.03, 0.15, 0.48, 1.00]"
        ],
        "start": 0.0,
        "end": 804.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1715.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "carry/hold (an object) -> talk to (e.g., self, a person, a group) -> touch (an object) -> play with pets -> walk -> bend/bow (at the waist) -> crouch/kneel",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "b-YoBU0XT90",
        "candidates": [
            "talk to (e.g., self, a person, a group) -> walk -> crouch/kneel -> touch (an object) -> play with pets -> sing to (e.g., self, a person, a group) -> carry/hold (an object)",
            "carry/hold (an object) -> talk to (e.g., self, a person, a group) -> touch (an object) -> play with pets -> walk -> bend/bow (at the waist) -> crouch/kneel",
            "carry/hold (an object) -> bend/bow (at the waist) -> talk to (e.g., self, a person, a group) -> crouch/kneel -> touch (an object) -> crouch/kneel -> play with pets",
            "dress/put on clothing -> touch (an object) -> walk -> bend/bow (at the waist) -> play with pets -> talk to (e.g., self, a person, a group) -> carry/hold (an object)"
        ],
        "start": 0.0,
        "end": 820.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1760.0,
        "question": "Is the person currently in the [0.24, 0.08, 0.89, 0.97] location in the current frame performing the carry/hold (an object)?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "b-YoBU0XT90",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 865.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 932.0,
        "question": "Where is the person currently performing the carry/hold (an object) located in the picture?",
        "answer": "[0.38, 0.12, 0.86, 0.99]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "bePts02nIY8",
        "candidates": [
            "[0.02, 0.19, 0.57, 1.00]",
            "[0.17, 0.00, 0.75, 0.73]",
            "[0.60, 0.00, 1.00, 0.97]",
            "[0.38, 0.12, 0.86, 0.99]"
        ],
        "start": 0.0,
        "end": 37.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 950.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.42, 0.15, 0.64, 0.97] location?",
        "answer": "talk to (e.g., self, a person, a group) [0.48, 0.12, 0.68, 0.85] -> walk [0.42, 0.15, 0.64, 0.97] -> carry/hold (an object) [0.42, 0.15, 0.64, 0.97]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "bePts02nIY8",
        "candidates": [
            "talk to (e.g., self, a person, a group) [0.48, 0.12, 0.68, 0.85] -> walk [0.42, 0.15, 0.64, 0.97] -> carry/hold (an object) [0.42, 0.15, 0.64, 0.97]",
            "walk [0.45, 0.01, 0.54, 1.00] -> talk to (e.g., self, a person, a group) [0.33, 0.00, 0.67, 0.92] -> play board game [0.26, 0.29, 0.47, 0.77]",
            "put down [0.24, 0.13, 0.59, 0.80] -> talk to (e.g., self, a person, a group) [0.51, 0.25, 0.80, 0.65] -> walk [0.41, 0.02, 0.47, 1.00]",
            "talk to (e.g., self, a person, a group) [0.54, 0.20, 0.56, 0.84] -> carry/hold (an object) [0.45, 0.13, 0.72, 0.81] -> take a photo [0.57, 0.00, 0.78, 1.00]"
        ],
        "start": 0.0,
        "end": 55.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 951.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.42, 0.15, 0.64, 0.97] location?",
        "answer": "talk to (e.g., self, a person, a group) [0.48, 0.12, 0.68, 0.85] -> walk [0.42, 0.15, 0.64, 0.97] -> carry/hold (an object) [0.42, 0.15, 0.64, 0.97]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "bePts02nIY8",
        "candidates": [
            "sail boat [0.60, 0.07, 0.81, 0.96] -> walk [0.39, 0.27, 0.64, 0.90] -> talk to (e.g., self, a person, a group) [0.36, 0.00, 0.62, 1.00]",
            "work on a computer [0.31, 0.04, 0.72, 0.78] -> talk to (e.g., self, a person, a group) [0.59, 0.00, 0.87, 0.95] -> carry/hold (an object) [0.52, 0.10, 0.45, 0.78]",
            "walk [0.23, 0.23, 0.59, 1.00] -> turn (e.g., a screwdriver) [0.63, 0.14, 0.51, 0.67] -> carry/hold (an object) [0.49, 0.00, 0.79, 0.93]",
            "talk to (e.g., self, a person, a group) [0.48, 0.12, 0.68, 0.85] -> walk [0.42, 0.15, 0.64, 0.97] -> carry/hold (an object) [0.42, 0.15, 0.64, 0.97]"
        ],
        "start": 0.0,
        "end": 56.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 957.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.48, 0.12, 0.68, 0.85]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "bePts02nIY8",
        "candidates": [
            "[0.74, 0.39, 0.57, 1.00]",
            "[0.63, 0.14, 0.91, 0.91]",
            "[0.05, 0.13, 0.48, 0.99]",
            "[0.48, 0.12, 0.68, 0.85]"
        ],
        "start": 0.0,
        "end": 62.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 966.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.76, 0.05, 0.89, 0.73] location?",
        "answer": "talk to (e.g., self, a person, a group) [0.72, 0.05, 0.89, 0.86] -> walk [0.76, 0.05, 0.89, 0.73] -> carry/hold (an object) [0.76, 0.05, 0.89, 0.73] -> hand wave [0.76, 0.05, 0.89, 0.73]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "bePts02nIY8",
        "candidates": [
            "talk to (e.g., self, a person, a group) [0.72, 0.05, 0.89, 0.86] -> walk [0.76, 0.05, 0.89, 0.73] -> carry/hold (an object) [0.76, 0.05, 0.89, 0.73] -> hand wave [0.76, 0.05, 0.89, 0.73]",
            "talk to (e.g., self, a person, a group) [0.74, 0.19, 0.91, 0.86] -> hug (a person) [0.67, 0.00, 0.85, 0.81] -> hand wave [0.63, 0.09, 1.00, 0.59] -> walk [0.89, 0.04, 0.96, 0.81]",
            "talk to (e.g., self, a person, a group) [0.72, 0.00, 0.78, 0.71] -> carry/hold (an object) [0.80, 0.00, 0.93, 0.68] -> hand wave [0.77, 0.21, 1.00, 0.68] -> grab (a person) [0.66, 0.08, 0.72, 0.57]",
            "run/jog [0.83, 0.02, 0.88, 0.74] -> talk to (e.g., self, a person, a group) [0.59, 0.04, 0.83, 0.73] -> hand wave [0.88, 0.15, 1.00, 0.61] -> walk [0.57, 0.14, 0.91, 0.72]"
        ],
        "start": 0.0,
        "end": 71.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1024.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.00, 0.25, 0.33, 1.00] location?",
        "answer": "talk to (e.g., self, a person, a group) [0.00, 0.25, 0.32, 0.99] -> eat [0.00, 0.25, 0.33, 1.00] -> touch (an object) [0.00, 0.25, 0.33, 1.00]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "bePts02nIY8",
        "candidates": [
            "read [0.00, 0.15, 0.13, 1.00] -> talk to (e.g., self, a person, a group) [0.20, 0.15, 0.22, 1.00] -> touch (an object) [0.02, 0.34, 0.38, 0.86]",
            "enter [0.00, 0.20, 0.21, 0.92] -> eat [0.06, 0.24, 0.47, 1.00] -> talk to (e.g., self, a person, a group) [0.00, 0.07, 0.12, 1.00]",
            "talk to (e.g., self, a person, a group) [0.04, 0.29, 0.31, 1.00] -> touch (an object) [0.03, 0.12, 0.47, 0.85] -> chop [0.00, 0.37, 0.48, 0.88]",
            "talk to (e.g., self, a person, a group) [0.00, 0.25, 0.32, 0.99] -> eat [0.00, 0.25, 0.33, 1.00] -> touch (an object) [0.00, 0.25, 0.33, 1.00]"
        ],
        "start": 0.0,
        "end": 129.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1028.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.38, 0.10, 0.58, 0.97] location?",
        "answer": "walk [0.38, 0.10, 0.58, 0.97] -> carry/hold (an object) [0.38, 0.10, 0.58, 0.97] -> talk to (e.g., self, a person, a group) [0.38, 0.10, 0.58, 0.97]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "bePts02nIY8",
        "candidates": [
            "walk [0.41, 0.14, 0.47, 1.00] -> fall down [0.50, 0.00, 0.76, 1.00] -> talk to (e.g., self, a person, a group) [0.39, 0.14, 0.73, 0.91]",
            "talk to (e.g., self, a person, a group) [0.51, 0.03, 0.60, 0.78] -> stir [0.37, 0.03, 0.44, 0.86] -> carry/hold (an object) [0.32, 0.07, 0.60, 0.99]",
            "walk [0.38, 0.10, 0.58, 0.97] -> carry/hold (an object) [0.38, 0.10, 0.58, 0.97] -> talk to (e.g., self, a person, a group) [0.38, 0.10, 0.58, 0.97]",
            "lie/sleep [0.22, 0.05, 0.52, 1.00] -> walk [0.57, 0.00, 0.57, 1.00] -> carry/hold (an object) [0.19, 0.00, 0.64, 1.00]"
        ],
        "start": 0.0,
        "end": 133.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1081.0,
        "question": "Is the person currently in the [0.81, 0.21, 0.93, 0.57] location in the current frame performing the touch (an object)?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "bePts02nIY8",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 186.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1150.0,
        "question": "What action is the person at the location [0.02, 0.03, 0.59, 1.00] in the image performing?",
        "answer": "sit, touch (an object), watch (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "bePts02nIY8",
        "candidates": [
            "sit, touch (an object)",
            "sit, touch (an object), watch (a person)",
            "sit, listen to (a person), watch (a person)",
            "sit, touch (an object), talk to (e.g., self, a person, a group), watch (a person)"
        ],
        "start": 0.0,
        "end": 255.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1207.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.23, 0.05, 0.77, 0.98]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "bePts02nIY8",
        "candidates": [
            "[0.23, 0.05, 0.77, 0.98]",
            "[0.01, 0.22, 0.47, 0.86]",
            "[0.58, 0.10, 0.70, 0.53]",
            "[0.49, 0.24, 0.82, 1.00]"
        ],
        "start": 0.0,
        "end": 312.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1255.0,
        "question": "Are there still 3 people in the current frame now?",
        "answer": "No",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "bePts02nIY8",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 360.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1352.0,
        "question": "How many people were performing the touch (an object) in the scene 240 seconds ago?",
        "answer": "4",
        "sub_answer_type": "PastMemory-5",
        "answer_type": "PastMemory",
        "video": "bePts02nIY8",
        "candidates": [
            "3",
            "4",
            "5",
            "7"
        ],
        "start": 0.0,
        "end": 457.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1470.0,
        "question": "Where was the person currently performing the walk in the scene 8 seconds ago?",
        "answer": "[0.51, 0.24, 0.57, 0.56]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "bePts02nIY8",
        "candidates": [
            "[0.80, 0.18, 0.83, 0.76]",
            "[0.31, 0.20, 0.54, 0.98]",
            "[0.51, 0.24, 0.57, 0.56]",
            "[0.75, 0.46, 0.68, 0.77]"
        ],
        "start": 0.0,
        "end": 575.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1515.0,
        "question": "Where is the person currently performing the talk to (e.g., self, a person, a group) located in the picture?",
        "answer": "[0.37, 0.15, 0.93, 0.99]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "bePts02nIY8",
        "candidates": [
            "[0.01, 0.15, 0.56, 1.00]",
            "[0.17, 0.41, 0.71, 0.73]",
            "[0.37, 0.15, 0.93, 0.99]",
            "[0.63, 0.00, 1.00, 1.00]"
        ],
        "start": 0.0,
        "end": 620.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1572.0,
        "question": "Where is the person currently performing the talk to (e.g., self, a person, a group) located in the picture?",
        "answer": "[0.02, 0.14, 0.54, 1.00]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "bePts02nIY8",
        "candidates": [
            "[0.02, 0.14, 0.54, 1.00]",
            "[0.00, 0.38, 0.77, 1.00]",
            "[0.00, 0.00, 0.82, 0.98]",
            "[0.00, 0.00, 0.64, 0.74]"
        ],
        "start": 0.0,
        "end": 677.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1646.0,
        "question": "What action is the person currently in the [0.41, 0.21, 0.67, 0.63] location likely to do next?",
        "answer": "text on/look at a cellphone",
        "sub_answer_type": "FuturePrediction-1",
        "answer_type": "FuturePrediction",
        "video": "bePts02nIY8",
        "candidates": [
            "touch (an object)",
            "text on/look at a cellphone",
            "eat",
            "take a photo"
        ],
        "start": 0.0,
        "end": 751.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1648.0,
        "question": "What action is the person at the location [0.08, 0.26, 0.29, 0.92] in the image performing?",
        "answer": "sit, watch (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "bePts02nIY8",
        "candidates": [
            "sit, touch (an object), listen to (a person)",
            "sit, watch (a person)",
            "stand, carry/hold (an object)",
            "sit, listen to (a person), watch (a person)"
        ],
        "start": 0.0,
        "end": 753.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1685.0,
        "question": "How many people were performing the sit in the scene 180 seconds ago?",
        "answer": "4",
        "sub_answer_type": "PastMemory-5",
        "answer_type": "PastMemory",
        "video": "bePts02nIY8",
        "candidates": [
            "5",
            "3",
            "4",
            "6"
        ],
        "start": 0.0,
        "end": 790.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1793.0,
        "question": "Are there still 2 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "bePts02nIY8",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 898.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 946.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "carry/hold (an object) -> talk to (e.g., self, a person, a group)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "covMYDBa5dk",
        "candidates": [
            "carry/hold (an object) -> talk to (e.g., self, a person, a group)",
            "talk to (e.g., self, a person, a group) -> talk to (e.g., self, a person, a group)",
            "close (e.g., a door, a box) -> carry/hold (an object)",
            "talk to (e.g., self, a person, a group) -> play with kids"
        ],
        "start": 0.0,
        "end": 51.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 971.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "carry/hold (an object) -> talk to (e.g., self, a person, a group)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "covMYDBa5dk",
        "candidates": [
            "carry/hold (an object) -> talk to (e.g., self, a person, a group)",
            "enter -> carry/hold (an object)",
            "get up -> talk to (e.g., self, a person, a group)",
            "talk to (e.g., self, a person, a group) -> touch (an object)"
        ],
        "start": 0.0,
        "end": 76.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 993.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.21, 0.01, 0.86, 0.98]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "covMYDBa5dk",
        "candidates": [
            "[0.21, 0.01, 0.86, 0.98]",
            "[0.34, 0.04, 1.00, 0.78]",
            "[0.57, 0.42, 0.82, 1.00]",
            "[0.14, 0.30, 0.64, 1.00]"
        ],
        "start": 0.0,
        "end": 98.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 996.0,
        "question": "Where was the person currently performing the crouch/kneel in the scene 8 seconds ago?",
        "answer": "[0.34, 0.53, 0.43, 0.89]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "covMYDBa5dk",
        "candidates": [
            "[0.74, 0.14, 0.88, 0.97]",
            "[0.09, 0.26, 0.38, 0.95]",
            "[0.34, 0.53, 0.43, 0.89]",
            "[0.16, 0.79, 0.14, 0.70]"
        ],
        "start": 0.0,
        "end": 101.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 996.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.53, 0.36, 0.66, 0.99] location?",
        "answer": "bend/bow (at the waist) [0.53, 0.36, 0.66, 0.99] -> carry/hold (an object) [0.53, 0.36, 0.66, 0.99] -> talk to (e.g., self, a person, a group) [0.53, 0.36, 0.66, 0.99]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "covMYDBa5dk",
        "candidates": [
            "bend/bow (at the waist) [0.53, 0.36, 0.66, 0.99] -> carry/hold (an object) [0.53, 0.36, 0.66, 0.99] -> talk to (e.g., self, a person, a group) [0.53, 0.36, 0.66, 0.99]",
            "bend/bow (at the waist) [0.72, 0.38, 0.68, 0.98] -> dance [0.55, 0.35, 0.56, 0.87] -> talk to (e.g., self, a person, a group) [0.53, 0.36, 0.76, 1.00]",
            "clink glass [0.66, 0.52, 0.68, 1.00] -> talk to (e.g., self, a person, a group) [0.58, 0.31, 0.59, 1.00] -> carry/hold (an object) [0.65, 0.17, 0.47, 0.90]",
            "bend/bow (at the waist) [0.62, 0.38, 0.51, 0.86] -> carry/hold (an object) [0.33, 0.35, 0.54, 0.85] -> kick (an object) [0.38, 0.42, 0.62, 0.83]"
        ],
        "start": 0.0,
        "end": 101.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1006.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.12, 0.31, 0.34, 1.00] location?",
        "answer": "walk [0.12, 0.31, 0.34, 1.00] -> carry/hold (an object) [0.12, 0.31, 0.34, 1.00] -> talk to (e.g., self, a person, a group) [0.12, 0.31, 0.34, 1.00]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "covMYDBa5dk",
        "candidates": [
            "talk to (e.g., self, a person, a group) [0.03, 0.11, 0.46, 1.00] -> ride (e.g., a bike, a car, a horse) [0.17, 0.16, 0.47, 1.00] -> carry/hold (an object) [0.23, 0.49, 0.17, 1.00]",
            "talk to (e.g., self, a person, a group) [0.00, 0.42, 0.44, 0.94] -> walk [0.15, 0.19, 0.46, 1.00] -> put down [0.17, 0.26, 0.20, 0.87]",
            "walk [0.12, 0.31, 0.34, 1.00] -> carry/hold (an object) [0.12, 0.31, 0.34, 1.00] -> talk to (e.g., self, a person, a group) [0.12, 0.31, 0.34, 1.00]",
            "carry/hold (an object) [0.00, 0.42, 0.37, 1.00] -> swim [0.17, 0.49, 0.48, 1.00] -> walk [0.19, 0.14, 0.15, 0.89]"
        ],
        "start": 0.0,
        "end": 111.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1029.0,
        "question": "What action is the person at the location [0.12, 0.00, 0.41, 1.00] in the image performing?",
        "answer": "stand, carry/hold (an object), listen to (a person), watch (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "covMYDBa5dk",
        "candidates": [
            "sit, carry/hold (an object), listen to (a person)",
            "stand, watch (a person)",
            "stand, carry/hold (an object), listen to (a person), watch (a person)",
            "stand, talk to (e.g., self, a person, a group), watch (a person)"
        ],
        "start": 0.0,
        "end": 134.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1181.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.23, 0.11, 0.62, 1.00]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "covMYDBa5dk",
        "candidates": [
            "[0.23, 0.11, 0.62, 1.00]",
            "[0.12, 0.00, 0.44, 1.00]",
            "[0.34, 0.53, 0.43, 0.89]",
            "[0.40, 0.33, 0.72, 1.00]"
        ],
        "start": 0.0,
        "end": 286.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1190.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.55, 0.00, 0.88, 0.99]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "covMYDBa5dk",
        "candidates": [
            "[0.55, 0.00, 0.88, 0.99]",
            "[0.25, 0.00, 0.86, 0.99]",
            "[0.77, 0.20, 1.00, 1.00]",
            "[0.40, 0.29, 0.89, 1.00]"
        ],
        "start": 0.0,
        "end": 295.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1202.0,
        "question": "What action is the person at the location [0.54, 0.45, 0.69, 0.99] in the image performing?",
        "answer": "sit, carry/hold (an object), watch (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "covMYDBa5dk",
        "candidates": [
            "carry/hold (an object), crouch/kneel",
            "stand, talk to (e.g., self, a person, a group), watch (a person)",
            "sit, carry/hold (an object), watch (a person)",
            "stand, watch (a person)"
        ],
        "start": 0.0,
        "end": 307.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1277.0,
        "question": "What location in the frame is the person currently in the [0.13, 0.23, 0.23, 0.82] location likely to move to next?",
        "answer": "[0.65, 0.10, 0.69, 0.30]",
        "sub_answer_type": "FuturePrediction-2",
        "answer_type": "FuturePrediction",
        "video": "covMYDBa5dk",
        "candidates": [
            "[0.47, 0.00, 0.62, 0.05]",
            "[0.16, 0.20, 0.24, 0.49]",
            "[0.65, 0.10, 0.69, 0.30]",
            "[0.52, 0.00, 0.47, 0.38]"
        ],
        "start": 0.0,
        "end": 382.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1287.0,
        "question": "Where was the person currently performing the walk in the scene 8 seconds ago?",
        "answer": "[0.63, 0.10, 0.68, 0.35]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "covMYDBa5dk",
        "candidates": [
            "[0.90, 0.31, 0.67, 0.39]",
            "[0.39, 0.00, 0.57, 0.29]",
            "[0.63, 0.10, 0.68, 0.35]",
            "[0.38, 0.30, 0.64, 0.99]"
        ],
        "start": 0.0,
        "end": 392.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1351.0,
        "question": "What action is the person at the location [0.31, 0.01, 0.48, 0.98] in the image performing?",
        "answer": "stand, catch (an object)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "covMYDBa5dk",
        "candidates": [
            "stand, listen to (a person), watch (a person)",
            "walk, watch (a person)",
            "stand, listen to (a person)",
            "stand, catch (an object)"
        ],
        "start": 0.0,
        "end": 456.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1357.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.38, 0.30, 0.64, 0.99] location?",
        "answer": "bend/bow (at the waist) [0.38, 0.30, 0.64, 0.99] -> carry/hold (an object) [0.38, 0.30, 0.64, 0.99] -> talk to (e.g., self, a person, a group) [0.38, 0.30, 0.64, 0.99]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "covMYDBa5dk",
        "candidates": [
            "bend/bow (at the waist) [0.39, 0.27, 0.51, 0.85] -> play with pets [0.49, 0.38, 0.60, 1.00] -> carry/hold (an object) [0.26, 0.23, 0.45, 1.00]",
            "carry/hold (an object) [0.43, 0.12, 0.82, 1.00] -> bend/bow (at the waist) [0.53, 0.34, 0.82, 0.90] -> lift (a person) [0.30, 0.41, 0.78, 1.00]",
            "bend/bow (at the waist) [0.38, 0.16, 0.62, 0.87] -> carry/hold (an object) [0.43, 0.47, 0.48, 1.00] -> point to (an object) [0.18, 0.48, 0.56, 1.00]",
            "bend/bow (at the waist) [0.38, 0.30, 0.64, 0.99] -> carry/hold (an object) [0.38, 0.30, 0.64, 0.99] -> talk to (e.g., self, a person, a group) [0.38, 0.30, 0.64, 0.99]"
        ],
        "start": 0.0,
        "end": 462.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1361.0,
        "question": "What action is the person currently in the [0.49, 0.01, 0.88, 0.99] location likely to do next?",
        "answer": "bend/bow (at the waist) and talk to (e.g., self, a person, a group)",
        "sub_answer_type": "FuturePrediction-1",
        "answer_type": "FuturePrediction",
        "video": "covMYDBa5dk",
        "candidates": [
            "row boat",
            "bend/bow (at the waist) and talk to (e.g., self, a person, a group)",
            "clink glass",
            "carry/hold (an object) and talk to (e.g., self, a person, a group)"
        ],
        "start": 0.0,
        "end": 466.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1363.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.46, 0.01, 0.88, 1.00] location?",
        "answer": "bend/bow (at the waist) [0.46, 0.01, 0.88, 1.00] -> carry/hold (an object) [0.46, 0.01, 0.88, 1.00] -> talk to (e.g., self, a person, a group) [0.46, 0.01, 0.88, 1.00]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "covMYDBa5dk",
        "candidates": [
            "talk to (e.g., self, a person, a group) [0.55, 0.14, 0.71, 0.99] -> drink [0.49, 0.09, 0.88, 0.93] -> bend/bow (at the waist) [0.62, 0.14, 0.73, 1.00]",
            "read [0.30, 0.03, 0.93, 1.00] -> carry/hold (an object) [0.31, 0.19, 0.94, 1.00] -> talk to (e.g., self, a person, a group) [0.34, 0.04, 0.97, 0.82]",
            "talk to (e.g., self, a person, a group) [0.62, 0.00, 0.81, 1.00] -> hand shake [0.60, 0.04, 1.00, 1.00] -> bend/bow (at the waist) [0.42, 0.00, 1.00, 1.00]",
            "bend/bow (at the waist) [0.46, 0.01, 0.88, 1.00] -> carry/hold (an object) [0.46, 0.01, 0.88, 1.00] -> talk to (e.g., self, a person, a group) [0.46, 0.01, 0.88, 1.00]"
        ],
        "start": 0.0,
        "end": 468.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1368.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.26, 0.00, 0.85, 1.00] location?",
        "answer": "bend/bow (at the waist) [0.26, 0.00, 0.85, 1.00] -> carry/hold (an object) [0.26, 0.00, 0.85, 1.00] -> talk to (e.g., self, a person, a group) [0.26, 0.00, 0.85, 1.00]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "covMYDBa5dk",
        "candidates": [
            "talk to (e.g., self, a person, a group) [0.31, 0.00, 1.00, 0.80] -> bend/bow (at the waist) [0.18, 0.00, 0.99, 1.00] -> shoot [0.15, 0.00, 0.97, 0.91]",
            "read [0.11, 0.12, 0.83, 1.00] -> carry/hold (an object) [0.42, 0.18, 0.77, 1.00] -> talk to (e.g., self, a person, a group) [0.41, 0.00, 0.89, 0.83]",
            "talk to (e.g., self, a person, a group) [0.24, 0.00, 0.96, 1.00] -> bend/bow (at the waist) [0.16, 0.16, 0.98, 1.00] -> paint [0.20, 0.07, 1.00, 0.98]",
            "bend/bow (at the waist) [0.26, 0.00, 0.85, 1.00] -> carry/hold (an object) [0.26, 0.00, 0.85, 1.00] -> talk to (e.g., self, a person, a group) [0.26, 0.00, 0.85, 1.00]"
        ],
        "start": 0.0,
        "end": 473.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1419.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "bend/bow (at the waist) -> talk to (e.g., self, a person, a group)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "covMYDBa5dk",
        "candidates": [
            "talk to (e.g., self, a person, a group) -> eat",
            "stir -> talk to (e.g., self, a person, a group)",
            "bend/bow (at the waist) -> talk to (e.g., self, a person, a group)",
            "bend/bow (at the waist) -> catch (an object)"
        ],
        "start": 0.0,
        "end": 524.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1506.0,
        "question": "Where is the person currently performing the hug (a person) located in the picture?",
        "answer": "[0.27, 0.02, 0.88, 1.00]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "covMYDBa5dk",
        "candidates": [
            "[0.27, 0.02, 0.88, 1.00]",
            "[0.51, 0.04, 1.00, 1.00]",
            "[0.31, 0.34, 0.54, 1.00]",
            "[0.01, 0.00, 0.75, 0.98]"
        ],
        "start": 0.0,
        "end": 611.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1507.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "hug (a person) -> talk to (e.g., self, a person, a group)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "covMYDBa5dk",
        "candidates": [
            "exit -> talk to (e.g., self, a person, a group)",
            "lift/pick up -> hug (a person)",
            "hug (a person) -> talk to (e.g., self, a person, a group)",
            "turn (e.g., a screwdriver) -> talk to (e.g., self, a person, a group)"
        ],
        "start": 0.0,
        "end": 612.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1610.0,
        "question": "Are there still 1 people in the current frame now?",
        "answer": "No",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "covMYDBa5dk",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 715.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1666.0,
        "question": "What action is the person at the location [0.12, 0.43, 0.31, 1.00] in the image performing?",
        "answer": "sit, listen to (a person), watch (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "covMYDBa5dk",
        "candidates": [
            "stand, listen to (a person), watch (a person)",
            "sit, listen to (a person), watch (a person)",
            "stand, watch (a person)",
            "stand, give/serve (an object) to (a person), talk to (e.g., self, a person, a group)"
        ],
        "start": 0.0,
        "end": 771.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1773.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "carry/hold (an object) -> talk to (e.g., self, a person, a group)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "covMYDBa5dk",
        "candidates": [
            "sing to (e.g., self, a person, a group) -> talk to (e.g., self, a person, a group)",
            "lie/sleep -> talk to (e.g., self, a person, a group)",
            "carry/hold (an object) -> talk to (e.g., self, a person, a group)",
            "carry/hold (an object) -> fight/hit (a person)"
        ],
        "start": 0.0,
        "end": 878.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 921.0,
        "question": "What action is the person currently in the [0.13, 0.15, 0.41, 0.74] location likely to do next?",
        "answer": "jump/leap and talk to (e.g., self, a person, a group)",
        "sub_answer_type": "FuturePrediction-1",
        "answer_type": "FuturePrediction",
        "video": "er7eeiJB6dI",
        "candidates": [
            "jump/leap and talk to (e.g., self, a person, a group)",
            "text on/look at a cellphone",
            "answer phone",
            "paint"
        ],
        "start": 0.0,
        "end": 26.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 948.0,
        "question": "Where is the person currently performing the talk to (e.g., self, a person, a group) located in the picture?",
        "answer": "[0.20, 0.14, 0.93, 0.89]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "er7eeiJB6dI",
        "candidates": [
            "[0.07, 0.44, 0.41, 0.89]",
            "[0.06, 0.00, 1.00, 0.68]",
            "[0.00, 0.12, 0.80, 1.00]",
            "[0.20, 0.14, 0.93, 0.89]"
        ],
        "start": 0.0,
        "end": 53.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 981.0,
        "question": "Is the person currently in the [0.30, 0.22, 0.59, 0.91] location in the current frame performing the talk to (e.g., self, a person, a group)?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "er7eeiJB6dI",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 86.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1060.0,
        "question": "Where was the person currently performing the answer phone in the scene 8 seconds ago?",
        "answer": "[0.58, 0.13, 0.94, 0.89]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "er7eeiJB6dI",
        "candidates": [
            "[0.29, 0.00, 0.92, 0.63]",
            "[0.15, 0.21, 0.88, 0.88]",
            "[0.58, 0.13, 0.94, 0.89]",
            "[0.82, 0.18, 1.00, 1.00]"
        ],
        "start": 0.0,
        "end": 165.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1068.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "carry/hold (an object) -> text on/look at a cellphone -> answer phone",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "er7eeiJB6dI",
        "candidates": [
            "play board game -> answer phone -> text on/look at a cellphone",
            "answer phone -> paint -> text on/look at a cellphone",
            "carry/hold (an object) -> text on/look at a cellphone -> answer phone",
            "swim -> text on/look at a cellphone -> carry/hold (an object)"
        ],
        "start": 0.0,
        "end": 173.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1090.0,
        "question": "Where is the person currently performing the answer phone located in the picture?",
        "answer": "[0.16, 0.16, 0.64, 0.89]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "er7eeiJB6dI",
        "candidates": [
            "[0.49, 0.24, 0.85, 0.88]",
            "[0.00, 0.38, 0.81, 1.00]",
            "[0.16, 0.16, 0.64, 0.89]",
            "[0.17, 0.00, 0.54, 0.61]"
        ],
        "start": 0.0,
        "end": 195.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1133.0,
        "question": "Are there still 1 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "er7eeiJB6dI",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 238.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1197.0,
        "question": "Are there still 1 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "er7eeiJB6dI",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 302.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1208.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "carry/hold (an object) -> walk",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "er7eeiJB6dI",
        "candidates": [
            "sing to (e.g., self, a person, a group) -> walk",
            "talk to (e.g., self, a person, a group) -> walk",
            "lift (a person) -> walk",
            "carry/hold (an object) -> walk"
        ],
        "start": 0.0,
        "end": 313.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1276.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.26, 0.14, 0.82, 0.86]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "er7eeiJB6dI",
        "candidates": [
            "[0.50, 0.28, 0.96, 0.88]",
            "[0.00, 0.39, 0.77, 0.79]",
            "[0.03, 0.00, 1.00, 0.57]",
            "[0.26, 0.14, 0.82, 0.86]"
        ],
        "start": 0.0,
        "end": 381.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1335.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "carry/hold (an object) -> cut -> eat -> walk",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "er7eeiJB6dI",
        "candidates": [
            "turn (e.g., a screwdriver) -> eat -> carry/hold (an object) -> walk",
            "carry/hold (an object) -> cut -> eat -> walk",
            "walk -> carry/hold (an object) -> eat -> climb (e.g., a mountain)",
            "eat -> talk to (e.g., self, a person, a group) -> cut -> carry/hold (an object)"
        ],
        "start": 0.0,
        "end": 440.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1339.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "carry/hold (an object) -> cut",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "er7eeiJB6dI",
        "candidates": [
            "fight/hit (a person) -> cut",
            "sing to (e.g., self, a person, a group) -> carry/hold (an object)",
            "carry/hold (an object) -> cut",
            "lift (a person) -> cut"
        ],
        "start": 0.0,
        "end": 444.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1348.0,
        "question": "Where was the person currently performing the carry/hold (an object) in the scene 8 seconds ago?",
        "answer": "[0.48, 0.16, 0.80, 0.88]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "er7eeiJB6dI",
        "candidates": [
            "[0.17, 0.15, 0.66, 0.88]",
            "[0.28, 0.34, 0.56, 1.00]",
            "[0.27, 0.46, 0.89, 1.00]",
            "[0.48, 0.16, 0.80, 0.88]"
        ],
        "start": 0.0,
        "end": 453.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1352.0,
        "question": "Where is the person currently performing the bend/bow (at the waist) located in the picture?",
        "answer": "[0.38, 0.14, 0.92, 0.87]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "er7eeiJB6dI",
        "candidates": [
            "[0.65, 0.00, 1.00, 0.75]",
            "[0.07, 0.24, 0.47, 0.87]",
            "[0.09, 0.38, 1.00, 1.00]",
            "[0.38, 0.14, 0.92, 0.87]"
        ],
        "start": 0.0,
        "end": 457.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1400.0,
        "question": "Where is the person currently performing the talk to (e.g., self, a person, a group) located in the picture?",
        "answer": "[0.34, 0.15, 0.96, 0.87]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "er7eeiJB6dI",
        "candidates": [
            "[0.02, 0.12, 0.64, 0.87]",
            "[0.34, 0.15, 0.96, 0.87]",
            "[0.17, 0.21, 0.79, 0.63]",
            "[0.52, 0.34, 0.91, 1.00]"
        ],
        "start": 0.0,
        "end": 505.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1483.0,
        "question": "Are there still 1 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "er7eeiJB6dI",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 588.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1518.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.41, 0.24, 0.87, 0.87]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "er7eeiJB6dI",
        "candidates": [
            "[0.42, 0.45, 0.56, 0.87]",
            "[0.44, 0.00, 1.00, 0.84]",
            "[0.41, 0.24, 0.87, 0.87]",
            "[0.13, 0.12, 0.71, 0.57]"
        ],
        "start": 0.0,
        "end": 623.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1736.0,
        "question": "Where was the person currently performing the lie/sleep in the scene 8 seconds ago?",
        "answer": "[0.22, 0.22, 0.96, 0.88]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "er7eeiJB6dI",
        "candidates": [
            "[0.22, 0.22, 0.96, 0.88]",
            "[0.18, 0.20, 0.60, 0.86]",
            "[0.49, 0.48, 0.95, 0.92]",
            "[0.00, 0.09, 0.96, 0.70]"
        ],
        "start": 0.0,
        "end": 841.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1749.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "carry/hold (an object) -> lie/sleep",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "er7eeiJB6dI",
        "candidates": [
            "carry/hold (an object) -> lie/sleep",
            "take (an object) from (a person) -> carry/hold (an object)",
            "eat -> carry/hold (an object)",
            "lie/sleep -> exit"
        ],
        "start": 0.0,
        "end": 854.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1790.0,
        "question": "What action is the person at the location [0.06, 0.18, 0.65, 0.89] in the image performing?",
        "answer": "stand, listen to (a person), watch (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "er7eeiJB6dI",
        "candidates": [
            "stand, listen to (a person), watch (a person)",
            "stand, hand clap, watch (a person)",
            "sit, listen to (a person)",
            "sit, talk to (e.g., self, a person, a group), watch (a person)"
        ],
        "start": 0.0,
        "end": 895.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1011.0,
        "question": "What action is the person at the location [0.28, 0.10, 0.43, 0.58] in the image performing?",
        "answer": "dance, play musical instrument, listen to (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "fpprSy6AzKk",
        "candidates": [
            "dance, play musical instrument, listen to (a person)",
            "stand, talk to (e.g., self, a person, a group)",
            "stand, watch (a person)",
            "sit, watch (a person)"
        ],
        "start": 0.0,
        "end": 116.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1048.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.28, 0.16, 0.61, 0.76]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "fpprSy6AzKk",
        "candidates": [
            "[0.28, 0.16, 0.61, 0.76]",
            "[0.51, 0.23, 0.84, 0.52]",
            "[0.57, 0.09, 0.46, 0.48]",
            "[0.66, 0.23, 1.00, 0.75]"
        ],
        "start": 0.0,
        "end": 153.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1060.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.58, 0.23, 0.96, 0.76] location?",
        "answer": "talk to (e.g., self, a person, a group) [0.61, 0.23, 1.00, 0.73] -> carry/hold (an object) [0.58, 0.23, 0.96, 0.76] -> give/serve (an object) to (a person) [0.58, 0.23, 0.96, 0.76]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "fpprSy6AzKk",
        "candidates": [
            "talk to (e.g., self, a person, a group) [0.61, 0.23, 1.00, 0.73] -> carry/hold (an object) [0.58, 0.23, 0.96, 0.76] -> give/serve (an object) to (a person) [0.58, 0.23, 0.96, 0.76]",
            "carry/hold (an object) [0.60, 0.28, 1.00, 0.62] -> talk to (e.g., self, a person, a group) [0.68, 0.06, 0.94, 0.64] -> talk to (e.g., self, a person, a group) [0.48, 0.04, 0.87, 0.69]",
            "give/serve (an object) to (a person) [0.76, 0.13, 0.89, 0.74] -> row boat [0.49, 0.34, 0.85, 0.79] -> talk to (e.g., self, a person, a group) [0.69, 0.22, 0.97, 0.61]",
            "talk to (e.g., self, a person, a group) [0.74, 0.04, 0.90, 0.81] -> hand wave [0.73, 0.10, 0.79, 0.67] -> give/serve (an object) to (a person) [0.72, 0.17, 0.84, 0.93]"
        ],
        "start": 0.0,
        "end": 165.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1075.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.16, 0.12, 0.76, 0.98] location?",
        "answer": "sing to (e.g., self, a person, a group) [0.09, 0.15, 0.80, 0.96] -> carry/hold (an object) [0.16, 0.12, 0.76, 0.98] -> dance [0.16, 0.12, 0.76, 0.98]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "fpprSy6AzKk",
        "candidates": [
            "push (another person) [0.30, 0.10, 0.69, 0.85] -> sing to (e.g., self, a person, a group) [0.00, 0.04, 0.91, 1.00] -> carry/hold (an object) [0.13, 0.00, 0.81, 1.00]",
            "sing to (e.g., self, a person, a group) [0.09, 0.15, 0.80, 0.96] -> carry/hold (an object) [0.16, 0.12, 0.76, 0.98] -> dance [0.16, 0.12, 0.76, 0.98]",
            "dance [0.00, 0.00, 0.72, 0.88] -> carry/hold (an object) [0.30, 0.00, 0.94, 1.00] -> hand wave [0.15, 0.17, 0.64, 1.00]",
            "carry/hold (an object) [0.06, 0.04, 0.77, 1.00] -> close (e.g., a door, a box) [0.29, 0.09, 0.68, 0.97] -> sing to (e.g., self, a person, a group) [0.26, 0.20, 0.81, 1.00]"
        ],
        "start": 0.0,
        "end": 180.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1107.0,
        "question": "Are there still 1 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "fpprSy6AzKk",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 212.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1115.0,
        "question": "What action is the person currently in the [0.09, 0.25, 0.33, 0.61] location likely to do next?",
        "answer": "bend/bow (at the waist) and carry/hold (an object)",
        "sub_answer_type": "FuturePrediction-1",
        "answer_type": "FuturePrediction",
        "video": "fpprSy6AzKk",
        "candidates": [
            "play musical instrument and sing to (e.g., self, a person, a group)",
            "walk",
            "bend/bow (at the waist) and carry/hold (an object)",
            "carry/hold (an object)"
        ],
        "start": 0.0,
        "end": 220.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1117.0,
        "question": "What action is the person at the location [0.09, 0.24, 0.33, 0.59] in the image performing?",
        "answer": "stand, talk to (e.g., self, a person, a group), watch (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "fpprSy6AzKk",
        "candidates": [
            "stand, talk to (e.g., self, a person, a group), watch (a person)",
            "stand, watch (a person)",
            "stand, play musical instrument, listen to (a person)",
            "stand, talk to (e.g., self, a person, a group)"
        ],
        "start": 0.0,
        "end": 222.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1120.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.71, 0.24, 0.98, 0.75] location?",
        "answer": "bend/bow (at the waist) [0.71, 0.24, 0.98, 0.75] -> carry/hold (an object) [0.71, 0.24, 0.98, 0.75] -> talk to (e.g., self, a person, a group) [0.71, 0.24, 0.98, 0.75]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "fpprSy6AzKk",
        "candidates": [
            "talk to (e.g., self, a person, a group) [0.74, 0.18, 1.00, 0.75] -> bend/bow (at the waist) [0.83, 0.29, 0.85, 0.55] -> clink glass [0.52, 0.31, 0.89, 0.87]",
            "jump/leap [0.53, 0.15, 1.00, 0.60] -> bend/bow (at the waist) [0.80, 0.29, 0.93, 0.79] -> talk to (e.g., self, a person, a group) [0.79, 0.12, 1.00, 0.84]",
            "drive (e.g., a car, a truck) [0.52, 0.36, 0.89, 0.56] -> bend/bow (at the waist) [0.86, 0.28, 0.99, 0.68] -> talk to (e.g., self, a person, a group) [0.52, 0.17, 0.87, 0.83]",
            "bend/bow (at the waist) [0.71, 0.24, 0.98, 0.75] -> carry/hold (an object) [0.71, 0.24, 0.98, 0.75] -> talk to (e.g., self, a person, a group) [0.71, 0.24, 0.98, 0.75]"
        ],
        "start": 0.0,
        "end": 225.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1158.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.23, 0.31, 0.58, 0.81] location?",
        "answer": "bend/bow (at the waist) [0.23, 0.31, 0.58, 0.81] -> carry/hold (an object) [0.23, 0.31, 0.58, 0.81] -> cook [0.23, 0.31, 0.58, 0.81]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "fpprSy6AzKk",
        "candidates": [
            "cook [0.20, 0.46, 0.63, 0.96] -> carry/hold (an object) [0.38, 0.24, 0.64, 0.77] -> stir [0.31, 0.35, 0.44, 0.91]",
            "bend/bow (at the waist) [0.23, 0.31, 0.58, 0.81] -> carry/hold (an object) [0.23, 0.31, 0.58, 0.81] -> cook [0.23, 0.31, 0.58, 0.81]",
            "bend/bow (at the waist) [0.05, 0.41, 0.77, 0.86] -> carry/hold (an object) [0.14, 0.26, 0.76, 1.00] -> open (e.g., a window, a car door) [0.22, 0.36, 0.38, 0.92]",
            "cook [0.07, 0.27, 0.43, 0.93] -> carry/hold (an object) [0.21, 0.17, 0.52, 0.94] -> play musical instrument [0.24, 0.37, 0.39, 0.93]"
        ],
        "start": 0.0,
        "end": 263.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1214.0,
        "question": "Where was the person currently performing the sing to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.28, 0.11, 0.53, 1.00]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "fpprSy6AzKk",
        "candidates": [
            "[0.72, 0.45, 0.93, 0.96]",
            "[0.56, 0.00, 0.49, 0.76]",
            "[0.13, 0.00, 0.49, 0.85]",
            "[0.28, 0.11, 0.53, 1.00]"
        ],
        "start": 0.0,
        "end": 319.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1318.0,
        "question": "Where is the person currently performing the talk to (e.g., self, a person, a group) located in the picture?",
        "answer": "[0.05, 0.03, 0.87, 1.00]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "fpprSy6AzKk",
        "candidates": [
            "[0.07, 0.14, 0.50, 0.93]",
            "[0.26, 0.13, 1.00, 1.00]",
            "[0.31, 0.00, 0.84, 0.77]",
            "[0.05, 0.03, 0.87, 1.00]"
        ],
        "start": 0.0,
        "end": 423.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1384.0,
        "question": "Are there still 1 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "fpprSy6AzKk",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 489.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1409.0,
        "question": "Where was the person currently performing the play musical instrument in the scene 8 seconds ago?",
        "answer": "[0.07, 0.14, 0.57, 0.96]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "fpprSy6AzKk",
        "candidates": [
            "[0.07, 0.14, 0.57, 0.96]",
            "[0.73, 0.51, 0.95, 0.88]",
            "[0.36, 0.00, 0.62, 1.00]",
            "[0.03, 0.06, 0.41, 0.79]"
        ],
        "start": 0.0,
        "end": 514.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1468.0,
        "question": "Where is the person currently performing the sing to (e.g., self, a person, a group) located in the picture?",
        "answer": "[0.00, 0.10, 0.89, 0.99]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "fpprSy6AzKk",
        "candidates": [
            "[0.00, 0.10, 0.89, 0.99]",
            "[0.00, 0.32, 0.62, 1.00]",
            "[0.41, 0.04, 0.95, 0.93]",
            "[0.07, 0.00, 0.97, 0.82]"
        ],
        "start": 0.0,
        "end": 573.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1494.0,
        "question": "Where was the person currently performing the play musical instrument in the scene 8 seconds ago?",
        "answer": "[0.27, 0.07, 0.68, 0.77]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "fpprSy6AzKk",
        "candidates": [
            "[0.44, 0.30, 0.84, 0.94]",
            "[0.27, 0.07, 0.68, 0.77]",
            "[0.06, 0.08, 0.56, 0.98]",
            "[0.05, 0.04, 0.95, 0.47]"
        ],
        "start": 0.0,
        "end": 599.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1547.0,
        "question": "Where was the person currently performing the walk in the scene 8 seconds ago?",
        "answer": "[0.17, 0.32, 0.25, 0.62]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "fpprSy6AzKk",
        "candidates": [
            "[0.17, 0.32, 0.25, 0.62]",
            "[0.40, 0.50, 0.42, 0.74]",
            "[0.23, 0.13, 0.89, 0.97]",
            "[0.08, 0.45, 0.23, 0.81]"
        ],
        "start": 0.0,
        "end": 652.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1677.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.41, 0.15, 0.82, 0.89] location?",
        "answer": "carry/hold (an object) [0.41, 0.15, 0.82, 0.89] -> give/serve (an object) to (a person) [0.41, 0.15, 0.82, 0.89] -> talk to (e.g., self, a person, a group) [0.41, 0.15, 0.82, 0.89]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "fpprSy6AzKk",
        "candidates": [
            "watch (e.g., TV) [0.33, 0.17, 1.00, 0.80] -> talk to (e.g., self, a person, a group) [0.28, 0.03, 0.66, 0.74] -> carry/hold (an object) [0.39, 0.29, 0.66, 0.93]",
            "give/serve (an object) to (a person) [0.42, 0.28, 0.84, 0.80] -> martial art [0.59, 0.02, 0.81, 0.71] -> carry/hold (an object) [0.52, 0.18, 0.76, 0.84]",
            "carry/hold (an object) [0.53, 0.24, 0.76, 0.99] -> talk to (e.g., self, a person, a group) [0.59, 0.11, 0.91, 0.85] -> sail boat [0.28, 0.31, 0.87, 1.00]",
            "carry/hold (an object) [0.41, 0.15, 0.82, 0.89] -> give/serve (an object) to (a person) [0.41, 0.15, 0.82, 0.89] -> talk to (e.g., self, a person, a group) [0.41, 0.15, 0.82, 0.89]"
        ],
        "start": 0.0,
        "end": 782.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1707.0,
        "question": "Where is the person currently performing the talk to (e.g., self, a person, a group) located in the picture?",
        "answer": "[0.10, 0.11, 0.97, 0.99]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "fpprSy6AzKk",
        "candidates": [
            "[0.20, 0.00, 1.00, 0.78]",
            "[0.28, 0.16, 0.54, 0.57]",
            "[0.06, 0.25, 0.68, 0.93]",
            "[0.10, 0.11, 0.97, 0.99]"
        ],
        "start": 0.0,
        "end": 812.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1798.0,
        "question": "Are there still 1 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "fpprSy6AzKk",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 903.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 956.0,
        "question": "Are there still 1 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "hHgg9WI8dTk",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 61.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 960.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "talk to (e.g., self, a person, a group) -> bend/bow (at the waist)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "hHgg9WI8dTk",
        "candidates": [
            "bend/bow (at the waist) -> smoke",
            "talk to (e.g., self, a person, a group) -> bend/bow (at the waist)",
            "talk to (e.g., self, a person, a group) -> pull (an object)",
            "talk to (e.g., self, a person, a group) -> kick (an object)"
        ],
        "start": 0.0,
        "end": 65.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 962.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.33, 0.00, 0.99, 0.99]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "hHgg9WI8dTk",
        "candidates": [
            "[0.19, 0.00, 0.80, 1.00]",
            "[0.46, 0.28, 1.00, 1.00]",
            "[0.17, 0.00, 1.00, 0.72]",
            "[0.33, 0.00, 0.99, 0.99]"
        ],
        "start": 0.0,
        "end": 67.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1008.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "walk -> carry/hold (an object)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "hHgg9WI8dTk",
        "candidates": [
            "walk -> carry/hold (an object)",
            "carry/hold (an object) -> dig",
            "walk -> lift/pick up",
            "dress/put on clothing -> carry/hold (an object)"
        ],
        "start": 0.0,
        "end": 113.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1031.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "carry/hold (an object) -> talk to (e.g., self, a person, a group)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "hHgg9WI8dTk",
        "candidates": [
            "talk to (e.g., self, a person, a group) -> throw",
            "play board game -> carry/hold (an object)",
            "carry/hold (an object) -> stir",
            "carry/hold (an object) -> talk to (e.g., self, a person, a group)"
        ],
        "start": 0.0,
        "end": 136.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1062.0,
        "question": "Where is the person currently performing the carry/hold (an object) located in the picture?",
        "answer": "[0.48, 0.06, 0.57, 0.46]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "hHgg9WI8dTk",
        "candidates": [
            "[0.77, 0.34, 0.42, 0.76]",
            "[0.58, 0.00, 0.79, 0.76]",
            "[0.48, 0.06, 0.57, 0.46]",
            "[0.03, 0.01, 0.87, 0.98]"
        ],
        "start": 0.0,
        "end": 167.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1084.0,
        "question": "What action is the person currently in the [0.51, 0.03, 0.63, 0.41] location likely to do next?",
        "answer": "walk and carry/hold (an object)",
        "sub_answer_type": "FuturePrediction-1",
        "answer_type": "FuturePrediction",
        "video": "hHgg9WI8dTk",
        "candidates": [
            "walk and carry/hold (an object) and talk to (e.g., self, a person, a group)",
            "walk and carry/hold (an object)",
            "shoot",
            "hand wave"
        ],
        "start": 0.0,
        "end": 189.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1129.0,
        "question": "Are there still 1 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "hHgg9WI8dTk",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 234.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1207.0,
        "question": "Where is the person currently performing the talk to (e.g., self, a person, a group) located in the picture?",
        "answer": "[0.08, 0.00, 0.95, 0.99]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "hHgg9WI8dTk",
        "candidates": [
            "[0.08, 0.00, 0.95, 0.99]",
            "[0.00, 0.27, 0.68, 0.79]",
            "[0.19, 0.00, 0.65, 0.72]",
            "[0.37, 0.01, 0.98, 1.00]"
        ],
        "start": 0.0,
        "end": 312.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1284.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.46, 0.00, 0.66, 0.94]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "hHgg9WI8dTk",
        "candidates": [
            "[0.03, 0.02, 0.70, 1.00]",
            "[0.46, 0.00, 0.66, 0.94]",
            "[0.30, 0.01, 0.58, 0.69]",
            "[0.18, 0.06, 0.39, 0.64]"
        ],
        "start": 0.0,
        "end": 389.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1341.0,
        "question": "Are there still 1 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "hHgg9WI8dTk",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 446.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1347.0,
        "question": "Are there still 2 people in the current frame now?",
        "answer": "No",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "hHgg9WI8dTk",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 452.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1382.0,
        "question": "Where is the person currently performing the talk to (e.g., self, a person, a group) located in the picture?",
        "answer": "[0.20, 0.03, 0.95, 0.97]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "hHgg9WI8dTk",
        "candidates": [
            "[0.48, 0.00, 1.00, 0.86]",
            "[0.01, 0.00, 0.55, 0.98]",
            "[0.46, 0.32, 0.83, 1.00]",
            "[0.20, 0.03, 0.95, 0.97]"
        ],
        "start": 0.0,
        "end": 487.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1501.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.19, 0.00, 0.80, 1.00]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "hHgg9WI8dTk",
        "candidates": [
            "[0.01, 0.00, 0.52, 0.98]",
            "[0.34, 0.00, 1.00, 0.95]",
            "[0.36, 0.28, 0.88, 1.00]",
            "[0.19, 0.00, 0.80, 1.00]"
        ],
        "start": 0.0,
        "end": 606.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1512.0,
        "question": "Are there still 1 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "hHgg9WI8dTk",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 617.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1527.0,
        "question": "Where is the person currently performing the talk to (e.g., self, a person, a group) located in the picture?",
        "answer": "[0.06, 0.00, 0.69, 0.99]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "hHgg9WI8dTk",
        "candidates": [
            "[0.06, 0.00, 0.69, 0.99]",
            "[0.00, 0.30, 0.48, 0.95]",
            "[0.00, 0.00, 0.44, 0.85]",
            "[0.22, 0.04, 0.83, 1.00]"
        ],
        "start": 0.0,
        "end": 632.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1596.0,
        "question": "Where was the person currently performing the walk in the scene 8 seconds ago?",
        "answer": "[0.06, 0.01, 0.74, 1.00]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "hHgg9WI8dTk",
        "candidates": [
            "[0.07, 0.00, 0.92, 0.70]",
            "[0.00, 0.00, 0.48, 0.72]",
            "[0.47, 0.00, 0.70, 0.95]",
            "[0.06, 0.01, 0.74, 1.00]"
        ],
        "start": 0.0,
        "end": 701.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1627.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.11, 0.04, 0.67, 1.00]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "hHgg9WI8dTk",
        "candidates": [
            "[0.00, 0.28, 0.38, 1.00]",
            "[0.32, 0.34, 0.75, 1.00]",
            "[0.47, 0.00, 0.67, 0.95]",
            "[0.11, 0.04, 0.67, 1.00]"
        ],
        "start": 0.0,
        "end": 732.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1676.0,
        "question": "What action is the person at the location [0.19, 0.01, 0.50, 0.99] in the image performing?",
        "answer": "stand, talk to (e.g., self, a person, a group), watch (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "hHgg9WI8dTk",
        "candidates": [
            "walk, listen to (a person)",
            "stand, talk to (e.g., self, a person, a group), watch (a person)",
            "sit, listen to (a person), watch (a person)",
            "carry/hold (an object), get up, listen to (a person)"
        ],
        "start": 0.0,
        "end": 781.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1712.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "walk -> talk to (e.g., self, a person, a group)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "hHgg9WI8dTk",
        "candidates": [
            "open (e.g., a window, a car door) -> walk",
            "walk -> talk to (e.g., self, a person, a group)",
            "walk -> play board game",
            "talk to (e.g., self, a person, a group) -> talk to (e.g., self, a person, a group)"
        ],
        "start": 0.0,
        "end": 817.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1793.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "walk -> carry/hold (an object)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "hHgg9WI8dTk",
        "candidates": [
            "walk -> carry/hold (an object)",
            "play musical instrument -> walk",
            "carry/hold (an object) -> get up",
            "ride (e.g., a bike, a car, a horse) -> walk"
        ],
        "start": 0.0,
        "end": 898.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 925.0,
        "question": "Is the person currently in the [0.13, 0.15, 0.86, 0.96] location in the current frame performing the walk?",
        "answer": "No",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "j5jmjhGBW44",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 30.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 993.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "talk to (e.g., self, a person, a group) -> lie/sleep",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "j5jmjhGBW44",
        "candidates": [
            "dance -> lie/sleep",
            "ride (e.g., a bike, a car, a horse) -> talk to (e.g., self, a person, a group)",
            "talk to (e.g., self, a person, a group) -> lie/sleep",
            "talk to (e.g., self, a person, a group) -> run/jog"
        ],
        "start": 0.0,
        "end": 98.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1046.0,
        "question": "What action is the person at the location [0.13, 0.30, 0.53, 0.99] in the image performing?",
        "answer": "stand, listen to (a person), watch (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "j5jmjhGBW44",
        "candidates": [
            "stand, talk to (e.g., self, a person, a group)",
            "stand, watch (a person)",
            "stand, touch (an object), listen to (a person), watch (a person)",
            "stand, listen to (a person), watch (a person)"
        ],
        "start": 0.0,
        "end": 151.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1062.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.13, 0.19, 0.67, 0.96]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "j5jmjhGBW44",
        "candidates": [
            "[0.00, 0.47, 0.43, 0.89]",
            "[0.60, 0.22, 0.77, 0.97]",
            "[0.13, 0.19, 0.67, 0.96]",
            "[0.23, 0.01, 0.61, 0.78]"
        ],
        "start": 0.0,
        "end": 167.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1103.0,
        "question": "How many people were performing the stand in the scene 180 seconds ago?",
        "answer": "3",
        "sub_answer_type": "PastMemory-5",
        "answer_type": "PastMemory",
        "video": "j5jmjhGBW44",
        "candidates": [
            "6",
            "4",
            "3",
            "5"
        ],
        "start": 0.0,
        "end": 208.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1140.0,
        "question": "What action is the person at the location [0.12, 0.01, 0.54, 0.97] in the image performing?",
        "answer": "walk, listen to (a person), watch (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "j5jmjhGBW44",
        "candidates": [
            "stand, carry/hold (an object), watch (a person)",
            "walk, listen to (a person), watch (a person)",
            "stand, watch (a person)",
            "stand, talk to (e.g., self, a person, a group)"
        ],
        "start": 0.0,
        "end": 245.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1174.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.17, 0.10, 0.49, 0.97] location?",
        "answer": "carry/hold (an object) [0.17, 0.10, 0.49, 0.97] -> smoke [0.17, 0.10, 0.49, 0.97] -> talk to (e.g., self, a person, a group) [0.17, 0.10, 0.49, 0.97]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "j5jmjhGBW44",
        "candidates": [
            "run/jog [0.16, 0.18, 0.47, 0.86] -> talk to (e.g., self, a person, a group) [0.05, 0.16, 0.68, 0.95] -> carry/hold (an object) [0.02, 0.18, 0.55, 0.88]",
            "talk to (e.g., self, a person, a group) [0.02, 0.00, 0.50, 1.00] -> carry/hold (an object) [0.19, 0.30, 0.41, 0.82] -> grab (a person) [0.12, 0.00, 0.50, 1.00]",
            "chop [0.30, 0.02, 0.40, 0.80] -> carry/hold (an object) [0.01, 0.22, 0.41, 0.90] -> talk to (e.g., self, a person, a group) [0.09, 0.03, 0.41, 0.91]",
            "carry/hold (an object) [0.17, 0.10, 0.49, 0.97] -> smoke [0.17, 0.10, 0.49, 0.97] -> talk to (e.g., self, a person, a group) [0.17, 0.10, 0.49, 0.97]"
        ],
        "start": 0.0,
        "end": 279.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1176.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.17, 0.10, 0.49, 0.97] location?",
        "answer": "carry/hold (an object) [0.17, 0.10, 0.49, 0.97] -> smoke [0.17, 0.10, 0.49, 0.97] -> talk to (e.g., self, a person, a group) [0.17, 0.10, 0.49, 0.97]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "j5jmjhGBW44",
        "candidates": [
            "carry/hold (an object) [0.17, 0.10, 0.49, 0.97] -> smoke [0.17, 0.10, 0.49, 0.97] -> talk to (e.g., self, a person, a group) [0.17, 0.10, 0.49, 0.97]",
            "hand clap [0.03, 0.18, 0.50, 0.90] -> smoke [0.12, 0.22, 0.55, 0.87] -> talk to (e.g., self, a person, a group) [0.18, 0.20, 0.38, 0.98]",
            "smoke [0.30, 0.16, 0.52, 1.00] -> talk to (e.g., self, a person, a group) [0.14, 0.00, 0.49, 1.00] -> hug (a person) [0.21, 0.08, 0.47, 0.97]",
            "kick (an object) [0.21, 0.25, 0.58, 1.00] -> smoke [0.18, 0.07, 0.56, 1.00] -> talk to (e.g., self, a person, a group) [0.09, 0.12, 0.38, 0.90]"
        ],
        "start": 0.0,
        "end": 281.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1238.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "talk to (e.g., self, a person, a group) -> lie/sleep",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "j5jmjhGBW44",
        "candidates": [
            "lie/sleep -> walk",
            "talk to (e.g., self, a person, a group) -> lie/sleep",
            "talk to (e.g., self, a person, a group) -> smoke",
            "touch (an object) -> talk to (e.g., self, a person, a group)"
        ],
        "start": 0.0,
        "end": 343.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1266.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "carry/hold (an object) -> smoke",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "j5jmjhGBW44",
        "candidates": [
            "clink glass -> carry/hold (an object)",
            "row boat -> carry/hold (an object)",
            "carry/hold (an object) -> smoke",
            "smoke -> play with pets"
        ],
        "start": 0.0,
        "end": 371.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1269.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "talk to (e.g., self, a person, a group) -> lie/sleep",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "j5jmjhGBW44",
        "candidates": [
            "lie/sleep -> crouch/kneel",
            "talk to (e.g., self, a person, a group) -> lie/sleep",
            "talk to (e.g., self, a person, a group) -> take (an object) from (a person)",
            "lie/sleep -> catch (an object)"
        ],
        "start": 0.0,
        "end": 374.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1273.0,
        "question": "How many people were performing the stand in the scene 240 seconds ago?",
        "answer": "4",
        "sub_answer_type": "PastMemory-5",
        "answer_type": "PastMemory",
        "video": "j5jmjhGBW44",
        "candidates": [
            "3",
            "6",
            "4",
            "5"
        ],
        "start": 0.0,
        "end": 378.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1277.0,
        "question": "Where is the person currently performing the talk to (e.g., self, a person, a group) located in the picture?",
        "answer": "[0.23, 0.00, 0.85, 0.97]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "j5jmjhGBW44",
        "candidates": [
            "[0.38, 0.58, 0.52, 0.84]",
            "[0.47, 0.03, 1.00, 1.00]",
            "[0.23, 0.00, 0.85, 0.97]",
            "[0.07, 0.00, 0.68, 1.00]"
        ],
        "start": 0.0,
        "end": 382.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1354.0,
        "question": "Are there still 1 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "j5jmjhGBW44",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 459.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1409.0,
        "question": "What action is the person currently in the [0.33, 0.21, 0.44, 0.81] location likely to do next?",
        "answer": "carry/hold (an object) and close (e.g., a door, a box)",
        "sub_answer_type": "FuturePrediction-1",
        "answer_type": "FuturePrediction",
        "video": "j5jmjhGBW44",
        "candidates": [
            "carry/hold (an object) and close (e.g., a door, a box)",
            "lie/sleep",
            "cook",
            "push (an object)"
        ],
        "start": 0.0,
        "end": 514.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1418.0,
        "question": "Where was the person currently performing the carry/hold (an object) in the scene 8 seconds ago?",
        "answer": "[0.32, 0.20, 0.43, 0.81]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "j5jmjhGBW44",
        "candidates": [
            "[0.43, 0.33, 0.70, 0.97]",
            "[0.16, 0.00, 0.51, 0.59]",
            "[0.07, 0.37, 0.47, 1.00]",
            "[0.32, 0.20, 0.43, 0.81]"
        ],
        "start": 0.0,
        "end": 523.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1420.0,
        "question": "Are there still 2 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "j5jmjhGBW44",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 525.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1589.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.32, 0.30, 0.40, 0.70] location?",
        "answer": "play board game [0.34, 0.33, 0.40, 0.70] -> walk [0.32, 0.30, 0.40, 0.70] -> carry/hold (an object) [0.32, 0.30, 0.40, 0.70]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "j5jmjhGBW44",
        "candidates": [
            "play board game [0.34, 0.33, 0.40, 0.70] -> walk [0.32, 0.30, 0.40, 0.70] -> carry/hold (an object) [0.32, 0.30, 0.40, 0.70]",
            "walk [0.31, 0.23, 0.45, 0.74] -> carry/hold (an object) [0.37, 0.36, 0.22, 0.79] -> throw [0.17, 0.20, 0.30, 0.74]",
            "hand shake [0.39, 0.42, 0.39, 0.52] -> walk [0.40, 0.28, 0.55, 0.71] -> carry/hold (an object) [0.15, 0.39, 0.22, 0.70]",
            "play board game [0.36, 0.21, 0.48, 0.67] -> jump/leap [0.48, 0.33, 0.25, 0.63] -> walk [0.27, 0.29, 0.35, 0.65]"
        ],
        "start": 0.0,
        "end": 694.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1606.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.37, 0.23, 0.82, 0.90] location?",
        "answer": "bend/bow (at the waist) [0.37, 0.23, 0.82, 0.90] -> carry/hold (an object) [0.37, 0.23, 0.82, 0.90] -> play board game [0.37, 0.23, 0.82, 0.90]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "j5jmjhGBW44",
        "candidates": [
            "carry/hold (an object) [0.46, 0.21, 0.62, 1.00] -> crouch/kneel [0.29, 0.04, 0.70, 1.00] -> bend/bow (at the waist) [0.29, 0.19, 0.98, 0.73]",
            "bend/bow (at the waist) [0.37, 0.23, 0.82, 0.90] -> carry/hold (an object) [0.37, 0.23, 0.82, 0.90] -> play board game [0.37, 0.23, 0.82, 0.90]",
            "play board game [0.27, 0.04, 0.84, 0.84] -> carry/hold (an object) [0.40, 0.09, 0.69, 1.00] -> bend/bow (at the waist) [0.24, 0.30, 0.67, 0.95]",
            "play board game [0.38, 0.20, 0.79, 0.96] -> bend/bow (at the waist) [0.54, 0.10, 0.75, 0.93] -> fight/hit (a person) [0.55, 0.23, 0.85, 1.00]"
        ],
        "start": 0.0,
        "end": 711.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1631.0,
        "question": "What action is the person at the location [0.21, 0.28, 0.36, 0.96] in the image performing?",
        "answer": "stand, touch (an object)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "j5jmjhGBW44",
        "candidates": [
            "stand, carry/hold (an object)",
            "sit, carry/hold (an object), talk to (e.g., self, a person, a group)",
            "stand, watch (a person)",
            "stand, touch (an object)"
        ],
        "start": 0.0,
        "end": 736.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1652.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "walk -> carry/hold (an object)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "j5jmjhGBW44",
        "candidates": [
            "ride (e.g., a bike, a car, a horse) -> walk",
            "walk -> carry/hold (an object)",
            "dance -> walk",
            "carry/hold (an object) -> shovel"
        ],
        "start": 0.0,
        "end": 757.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1707.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.24, 0.10, 0.62, 0.84]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "j5jmjhGBW44",
        "candidates": [
            "[0.24, 0.10, 0.62, 0.84]",
            "[0.31, 0.13, 0.87, 0.94]",
            "[0.07, 0.00, 0.77, 0.60]",
            "[0.00, 0.16, 0.34, 0.73]"
        ],
        "start": 0.0,
        "end": 812.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1759.0,
        "question": "Where is the person currently performing the talk to (e.g., self, a person, a group) located in the picture?",
        "answer": "[0.38, 0.11, 0.69, 0.93]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "j5jmjhGBW44",
        "candidates": [
            "[0.29, 0.00, 0.66, 0.73]",
            "[0.38, 0.11, 0.69, 0.93]",
            "[0.31, 0.23, 0.39, 0.78]",
            "[0.62, 0.18, 0.91, 0.88]"
        ],
        "start": 0.0,
        "end": 864.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1772.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.22, 0.16, 0.45, 0.80] location?",
        "answer": "carry/hold (an object) [0.22, 0.16, 0.45, 0.80] -> touch (an object) [0.22, 0.16, 0.45, 0.80] -> talk to (e.g., self, a person, a group) [0.22, 0.16, 0.45, 0.80]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "j5jmjhGBW44",
        "candidates": [
            "talk to (e.g., self, a person, a group) [0.20, 0.25, 0.28, 0.68] -> push (another person) [0.18, 0.35, 0.26, 0.64] -> touch (an object) [0.10, 0.27, 0.53, 0.67]",
            "talk to (e.g., self, a person, a group) [0.23, 0.29, 0.60, 1.00] -> carry/hold (an object) [0.26, 0.34, 0.35, 0.93] -> drive (e.g., a car, a truck) [0.04, 0.04, 0.64, 0.74]",
            "carry/hold (an object) [0.22, 0.16, 0.45, 0.80] -> touch (an object) [0.22, 0.16, 0.45, 0.80] -> talk to (e.g., self, a person, a group) [0.22, 0.16, 0.45, 0.80]",
            "carry/hold (an object) [0.41, 0.16, 0.49, 0.83] -> run/jog [0.15, 0.26, 0.40, 0.82] -> touch (an object) [0.11, 0.14, 0.26, 0.79]"
        ],
        "start": 0.0,
        "end": 877.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 914.0,
        "question": "What action is the person at the location [0.01, 0.13, 0.14, 0.98] in the image performing?",
        "answer": "stand, listen to (a person), watch (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "jE0S8gYWftE",
        "candidates": [
            "stand, listen to (a person), watch (a person)",
            "stand, talk to (e.g., self, a person, a group), watch (a person)",
            "sit, carry/hold (an object), talk to (e.g., self, a person, a group), watch (a person)",
            "stand, listen to (a person)"
        ],
        "start": 0.0,
        "end": 19.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1147.0,
        "question": "How many people were performing the listen to (a person) in the scene 60 seconds ago?",
        "answer": "5",
        "sub_answer_type": "PastMemory-5",
        "answer_type": "PastMemory",
        "video": "jE0S8gYWftE",
        "candidates": [
            "5",
            "8",
            "4",
            "3"
        ],
        "start": 0.0,
        "end": 252.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1214.0,
        "question": "What action is the person currently in the [0.28, 0.01, 0.98, 0.99] location likely to do next?",
        "answer": "carry/hold (an object) and smoke",
        "sub_answer_type": "FuturePrediction-1",
        "answer_type": "FuturePrediction",
        "video": "jE0S8gYWftE",
        "candidates": [
            "stir",
            "smoke",
            "walk and carry/hold (an object)",
            "carry/hold (an object) and smoke"
        ],
        "start": 0.0,
        "end": 319.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1260.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.67, 0.25, 1.00, 0.87] location?",
        "answer": "touch (an object) [0.67, 0.25, 1.00, 0.87] -> write [0.67, 0.25, 1.00, 0.87] -> talk to (e.g., self, a person, a group) [0.67, 0.25, 1.00, 0.87]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "jE0S8gYWftE",
        "candidates": [
            "crawl [0.83, 0.15, 0.83, 0.82] -> talk to (e.g., self, a person, a group) [0.49, 0.27, 1.00, 0.73] -> write [0.82, 0.24, 0.97, 1.00]",
            "touch (an object) [0.69, 0.35, 1.00, 1.00] -> write [0.59, 0.36, 1.00, 0.72] -> talk to (e.g., self, a person, a group) [0.86, 0.26, 0.84, 0.74]",
            "touch (an object) [0.59, 0.11, 1.00, 0.70] -> talk to (e.g., self, a person, a group) [0.83, 0.41, 0.80, 0.91] -> dress/put on clothing [0.62, 0.21, 0.85, 0.95]",
            "touch (an object) [0.67, 0.25, 1.00, 0.87] -> write [0.67, 0.25, 1.00, 0.87] -> talk to (e.g., self, a person, a group) [0.67, 0.25, 1.00, 0.87]"
        ],
        "start": 0.0,
        "end": 365.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1270.0,
        "question": "How many people in the current frame are performing the action:  carry/hold (an object)?",
        "answer": "2",
        "sub_answer_type": "SpatialPerception-2",
        "answer_type": "SpatialPerception",
        "video": "jE0S8gYWftE",
        "candidates": [
            "2",
            "3",
            "4",
            "5"
        ],
        "start": 0.0,
        "end": 375.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1285.0,
        "question": "What location in the frame is the person currently in the [0.00, 0.20, 0.38, 0.99] location likely to move to next?",
        "answer": "[0.26, 0.00, 0.82, 1.00]",
        "sub_answer_type": "FuturePrediction-2",
        "answer_type": "FuturePrediction",
        "video": "jE0S8gYWftE",
        "candidates": [
            "[0.20, 0.15, 0.60, 1.00]",
            "[0.33, 0.00, 0.53, 0.70]",
            "[0.26, 0.00, 0.82, 1.00]",
            "[0.40, 0.00, 1.00, 0.75]"
        ],
        "start": 0.0,
        "end": 390.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1305.0,
        "question": "How many people were performing the stand in the scene 180 seconds ago?",
        "answer": "7",
        "sub_answer_type": "PastMemory-5",
        "answer_type": "PastMemory",
        "video": "jE0S8gYWftE",
        "candidates": [
            "5",
            "7",
            "3",
            "4"
        ],
        "start": 0.0,
        "end": 410.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1377.0,
        "question": "Are there still 4 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "jE0S8gYWftE",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 482.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1407.0,
        "question": "How many people in the current frame are performing the action:  eat?",
        "answer": "4",
        "sub_answer_type": "SpatialPerception-2",
        "answer_type": "SpatialPerception",
        "video": "jE0S8gYWftE",
        "candidates": [
            "3",
            "6",
            "4",
            "2"
        ],
        "start": 0.0,
        "end": 512.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1464.0,
        "question": "Are there still 1 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "jE0S8gYWftE",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 569.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1528.0,
        "question": "How many people were performing the eat in the scene 120 seconds ago?",
        "answer": "4",
        "sub_answer_type": "PastMemory-5",
        "answer_type": "PastMemory",
        "video": "jE0S8gYWftE",
        "candidates": [
            "8",
            "5",
            "4",
            "3"
        ],
        "start": 0.0,
        "end": 633.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1607.0,
        "question": "How many people were performing the listen to (a person) in the scene 180 seconds ago?",
        "answer": "6",
        "sub_answer_type": "PastMemory-5",
        "answer_type": "PastMemory",
        "video": "jE0S8gYWftE",
        "candidates": [
            "4",
            "6",
            "3",
            "5"
        ],
        "start": 0.0,
        "end": 712.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1663.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.00, 0.07, 0.60, 0.99]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "jE0S8gYWftE",
        "candidates": [
            "[0.09, 0.02, 0.88, 0.99]",
            "[0.01, 0.00, 0.56, 0.75]",
            "[0.22, 0.35, 0.78, 1.00]",
            "[0.00, 0.07, 0.60, 0.99]"
        ],
        "start": 0.0,
        "end": 768.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1663.0,
        "question": "How many people in the current frame are performing the action:  carry/hold (an object)?",
        "answer": "2",
        "sub_answer_type": "SpatialPerception-2",
        "answer_type": "SpatialPerception",
        "video": "jE0S8gYWftE",
        "candidates": [
            "2",
            "3",
            "4",
            "6"
        ],
        "start": 0.0,
        "end": 768.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1671.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.01, 0.23, 0.63, 0.98] location?",
        "answer": "carry/hold (an object) [0.01, 0.23, 0.63, 0.98] -> touch (an object) [0.01, 0.23, 0.63, 0.98] -> talk to (e.g., self, a person, a group) [0.01, 0.23, 0.63, 0.98]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "jE0S8gYWftE",
        "candidates": [
            "carry/hold (an object) [0.01, 0.23, 0.63, 0.98] -> touch (an object) [0.01, 0.23, 0.63, 0.98] -> talk to (e.g., self, a person, a group) [0.01, 0.23, 0.63, 0.98]",
            "touch (an object) [0.00, 0.34, 0.70, 0.94] -> cut [0.00, 0.35, 0.82, 1.00] -> talk to (e.g., self, a person, a group) [0.00, 0.19, 0.51, 1.00]",
            "touch (an object) [0.00, 0.16, 0.71, 1.00] -> sail boat [0.12, 0.37, 0.72, 1.00] -> talk to (e.g., self, a person, a group) [0.00, 0.25, 0.57, 0.87]",
            "talk to (e.g., self, a person, a group) [0.00, 0.10, 0.60, 1.00] -> touch (an object) [0.00, 0.23, 0.81, 0.86] -> fall down [0.19, 0.06, 0.65, 1.00]"
        ],
        "start": 0.0,
        "end": 776.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1673.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.03, 0.20, 0.66, 1.00] location?",
        "answer": "touch (an object) [0.00, 0.21, 0.64, 0.97] -> talk to (e.g., self, a person, a group) [0.00, 0.21, 0.64, 0.97] -> carry/hold (an object) [0.03, 0.20, 0.66, 1.00]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "jE0S8gYWftE",
        "candidates": [
            "touch (an object) [0.00, 0.21, 0.64, 0.97] -> talk to (e.g., self, a person, a group) [0.00, 0.21, 0.64, 0.97] -> carry/hold (an object) [0.03, 0.20, 0.66, 1.00]",
            "talk to (e.g., self, a person, a group) [0.00, 0.37, 0.45, 0.86] -> take a photo [0.00, 0.31, 0.51, 0.94] -> carry/hold (an object) [0.12, 0.25, 0.67, 0.99]",
            "talk to (e.g., self, a person, a group) [0.14, 0.27, 0.53, 1.00] -> talk to (e.g., self, a person, a group) [0.07, 0.15, 0.52, 1.00] -> touch (an object) [0.00, 0.07, 0.59, 0.97]",
            "give/serve (an object) to (a person) [0.00, 0.07, 0.46, 0.88] -> touch (an object) [0.09, 0.06, 0.83, 0.88] -> carry/hold (an object) [0.00, 0.07, 0.69, 0.86]"
        ],
        "start": 0.0,
        "end": 778.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1686.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.13, 0.18, 0.65, 0.90] location?",
        "answer": "carry/hold (an object) [0.13, 0.18, 0.65, 0.90] -> touch (an object) [0.13, 0.18, 0.65, 0.90] -> talk to (e.g., self, a person, a group) [0.13, 0.18, 0.65, 0.90]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "jE0S8gYWftE",
        "candidates": [
            "kick (an object) [0.00, 0.20, 0.66, 0.89] -> talk to (e.g., self, a person, a group) [0.12, 0.11, 0.79, 0.96] -> carry/hold (an object) [0.32, 0.27, 0.69, 0.87]",
            "talk to (e.g., self, a person, a group) [0.31, 0.27, 0.61, 0.99] -> dig [0.03, 0.25, 0.78, 1.00] -> touch (an object) [0.02, 0.09, 0.82, 0.97]",
            "carry/hold (an object) [0.13, 0.18, 0.65, 0.90] -> touch (an object) [0.13, 0.18, 0.65, 0.90] -> talk to (e.g., self, a person, a group) [0.13, 0.18, 0.65, 0.90]",
            "carry/hold (an object) [0.00, 0.04, 0.61, 1.00] -> eat [0.05, 0.01, 0.70, 0.90] -> touch (an object) [0.12, 0.25, 0.83, 0.84]"
        ],
        "start": 0.0,
        "end": 791.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1697.0,
        "question": "Is the person currently in the [0.00, 0.06, 0.24, 0.86] location in the current frame performing the touch (an object)?",
        "answer": "No",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "jE0S8gYWftE",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 802.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1726.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.22, 0.35, 0.74, 0.94] location?",
        "answer": "carry/hold (an object) [0.22, 0.35, 0.74, 0.94] -> touch (an object) [0.22, 0.35, 0.74, 0.94] -> talk to (e.g., self, a person, a group) [0.22, 0.35, 0.74, 0.94]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "jE0S8gYWftE",
        "candidates": [
            "catch (an object) [0.13, 0.19, 0.90, 1.00] -> talk to (e.g., self, a person, a group) [0.15, 0.53, 0.72, 1.00] -> carry/hold (an object) [0.40, 0.47, 0.66, 1.00]",
            "carry/hold (an object) [0.22, 0.35, 0.74, 0.94] -> touch (an object) [0.22, 0.35, 0.74, 0.94] -> talk to (e.g., self, a person, a group) [0.22, 0.35, 0.74, 0.94]",
            "carry/hold (an object) [0.31, 0.33, 0.69, 0.94] -> pull (an object) [0.37, 0.45, 0.57, 1.00] -> talk to (e.g., self, a person, a group) [0.26, 0.44, 0.68, 0.82]",
            "dig [0.13, 0.23, 0.82, 0.97] -> talk to (e.g., self, a person, a group) [0.06, 0.45, 0.56, 0.88] -> touch (an object) [0.09, 0.34, 0.63, 0.75]"
        ],
        "start": 0.0,
        "end": 831.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1783.0,
        "question": "What action is the person at the location [0.22, 0.39, 0.36, 1.00] in the image performing?",
        "answer": "stand, talk to (e.g., self, a person, a group), watch (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "jE0S8gYWftE",
        "candidates": [
            "sit, carry/hold (an object), touch (an object), listen to (a person), watch (a person)",
            "stand, talk to (e.g., self, a person, a group), watch (a person)",
            "sit, carry/hold (an object), talk to (e.g., self, a person, a group), watch (a person)",
            "walk, carry/hold (an object), listen to (a person)"
        ],
        "start": 0.0,
        "end": 888.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 982.0,
        "question": "What action is the person at the location [0.30, 0.27, 0.43, 0.60] in the image performing?",
        "answer": "stand, carry/hold (an object)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "l2XO3tQk8lI",
        "candidates": [
            "stand, watch (a person)",
            "stand, talk to (e.g., self, a person, a group), watch (a person)",
            "stand, carry/hold (an object)",
            "stand, carry/hold (an object), listen to (a person)"
        ],
        "start": 0.0,
        "end": 87.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1085.0,
        "question": "Are there still 1 people in the current frame now?",
        "answer": "No",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "l2XO3tQk8lI",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 190.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1085.0,
        "question": "How many people were performing the stand in the scene 120 seconds ago?",
        "answer": "5",
        "sub_answer_type": "PastMemory-5",
        "answer_type": "PastMemory",
        "video": "l2XO3tQk8lI",
        "candidates": [
            "7",
            "5",
            "3",
            "4"
        ],
        "start": 0.0,
        "end": 190.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1087.0,
        "question": "What action is the person currently in the [0.12, 0.01, 0.62, 0.99] location likely to do next?",
        "answer": "carry/hold (an object) and talk to (e.g., self, a person, a group)",
        "sub_answer_type": "FuturePrediction-1",
        "answer_type": "FuturePrediction",
        "video": "l2XO3tQk8lI",
        "candidates": [
            "close (e.g., a door, a box)",
            "carry/hold (an object) and talk to (e.g., self, a person, a group)",
            "sing to (e.g., self, a person, a group)",
            "walk and talk to (e.g., self, a person, a group)"
        ],
        "start": 0.0,
        "end": 192.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1144.0,
        "question": "Is the person currently in the [0.20, 0.36, 0.44, 0.98] location in the current frame performing the talk to (e.g., self, a person, a group)?",
        "answer": "No",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "l2XO3tQk8lI",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 249.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1165.0,
        "question": "What action is the person at the location [0.10, 0.12, 0.45, 0.98] in the image performing?",
        "answer": "stand, listen to (a person), talk to (e.g., self, a person, a group), watch (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "l2XO3tQk8lI",
        "candidates": [
            "stand, talk to (e.g., self, a person, a group)",
            "stand, listen to (a person), talk to (e.g., self, a person, a group), watch (a person)",
            "stand, carry/hold (an object), talk to (e.g., self, a person, a group), watch (a person)",
            "sit, listen to (a person)"
        ],
        "start": 0.0,
        "end": 270.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1171.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.08, 0.30, 0.29, 0.99]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "l2XO3tQk8lI",
        "candidates": [
            "[0.30, 0.27, 0.44, 0.80]",
            "[0.08, 0.30, 0.29, 0.99]",
            "[0.48, 0.22, 0.60, 0.84]",
            "[0.04, 0.57, 0.16, 1.00]"
        ],
        "start": 0.0,
        "end": 276.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1320.0,
        "question": "Where was the person currently performing the carry/hold (an object) in the scene 8 seconds ago?",
        "answer": "[0.58, 0.15, 0.85, 0.76]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "l2XO3tQk8lI",
        "candidates": [
            "[0.30, 0.34, 0.80, 0.46]",
            "[0.02, 0.21, 0.25, 0.97]",
            "[0.82, 0.10, 0.92, 0.74]",
            "[0.58, 0.15, 0.85, 0.76]"
        ],
        "start": 0.0,
        "end": 425.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1344.0,
        "question": "What action is the person at the location [0.03, 0.01, 0.57, 0.97] in the image performing?",
        "answer": "stand, listen to (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "l2XO3tQk8lI",
        "candidates": [
            "stand, touch (an object), talk to (e.g., self, a person, a group)",
            "stand, listen to (a person)",
            "stand, listen to (a person), watch (a person)",
            "stand, talk to (e.g., self, a person, a group), watch (a person)"
        ],
        "start": 0.0,
        "end": 449.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1348.0,
        "question": "Are there still 2 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "l2XO3tQk8lI",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 453.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1485.0,
        "question": "Where is the person currently performing the walk located in the picture?",
        "answer": "[0.41, 0.12, 0.81, 0.95]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "l2XO3tQk8lI",
        "candidates": [
            "[0.34, 0.40, 0.87, 1.00]",
            "[0.41, 0.12, 0.81, 0.95]",
            "[0.35, 0.00, 1.00, 0.74]",
            "[0.09, 0.01, 0.58, 0.97]"
        ],
        "start": 0.0,
        "end": 590.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1506.0,
        "question": "Are there still 2 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "l2XO3tQk8lI",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 611.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1667.0,
        "question": "What action is the person at the location [0.30, 0.28, 0.63, 0.99] in the image performing?",
        "answer": "walk, carry/hold (an object), talk to (e.g., self, a person, a group), watch (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "l2XO3tQk8lI",
        "candidates": [
            "stand, talk to (e.g., self, a person, a group), watch (a person)",
            "walk, carry/hold (an object), talk to (e.g., self, a person, a group), watch (a person)",
            "stand, watch (a person)",
            "stand, carry/hold (an object), talk to (e.g., self, a person, a group)"
        ],
        "start": 0.0,
        "end": 772.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1669.0,
        "question": "Where was the person currently performing the carry/hold (an object) in the scene 8 seconds ago?",
        "answer": "[0.35, 0.03, 0.74, 0.96]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "l2XO3tQk8lI",
        "candidates": [
            "[0.60, 0.30, 0.68, 1.00]",
            "[0.44, 0.00, 0.89, 0.80]",
            "[0.35, 0.03, 0.74, 0.96]",
            "[0.35, 0.31, 0.43, 0.78]"
        ],
        "start": 0.0,
        "end": 774.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1792.0,
        "question": "How many people were performing the stand in the scene 180 seconds ago?",
        "answer": "5",
        "sub_answer_type": "PastMemory-5",
        "answer_type": "PastMemory",
        "video": "l2XO3tQk8lI",
        "candidates": [
            "4",
            "3",
            "6",
            "5"
        ],
        "start": 0.0,
        "end": 897.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 946.0,
        "question": "Is the person currently in the [0.43, 0.62, 0.51, 0.94] location in the current frame performing the close (e.g., a door, a box)?",
        "answer": "No",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "lDmLcWWBp1E",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 51.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 946.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.43, 0.62, 0.51, 0.94] location?",
        "answer": "carry/hold (an object) [0.39, 0.64, 0.45, 0.91] -> close (e.g., a door, a box) [0.39, 0.64, 0.45, 0.91] -> walk [0.43, 0.62, 0.51, 0.94]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "lDmLcWWBp1E",
        "candidates": [
            "walk [0.27, 0.57, 0.66, 1.00] -> sing to (e.g., self, a person, a group) [0.36, 0.68, 0.44, 0.90] -> close (e.g., a door, a box) [0.26, 0.82, 0.60, 0.78]",
            "carry/hold (an object) [0.39, 0.64, 0.45, 0.91] -> close (e.g., a door, a box) [0.39, 0.64, 0.45, 0.91] -> walk [0.43, 0.62, 0.51, 0.94]",
            "jump/leap [0.49, 0.48, 0.48, 0.76] -> walk [0.54, 0.74, 0.48, 0.92] -> carry/hold (an object) [0.32, 0.51, 0.40, 0.84]",
            "walk [0.61, 0.45, 0.48, 0.93] -> close (e.g., a door, a box) [0.59, 0.54, 0.58, 0.90] -> talk to (e.g., self, a person, a group) [0.42, 0.50, 0.52, 0.86]"
        ],
        "start": 0.0,
        "end": 51.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 990.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "touch (an object) -> lie/sleep",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "lDmLcWWBp1E",
        "candidates": [
            "touch (an object) -> crouch/kneel",
            "touch (an object) -> exit",
            "kick (an object) -> lie/sleep",
            "touch (an object) -> lie/sleep"
        ],
        "start": 0.0,
        "end": 95.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 992.0,
        "question": "Where is the person currently performing the touch (an object) located in the picture?",
        "answer": "[0.06, 0.09, 0.93, 0.88]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "lDmLcWWBp1E",
        "candidates": [
            "[0.54, 0.15, 0.83, 0.70]",
            "[0.06, 0.09, 0.93, 0.88]",
            "[0.04, 0.00, 0.66, 0.80]",
            "[0.00, 0.15, 0.65, 1.00]"
        ],
        "start": 0.0,
        "end": 97.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1110.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.32, 0.62, 0.39, 0.93] location?",
        "answer": "walk [0.32, 0.62, 0.39, 0.93] -> carry/hold (an object) [0.32, 0.62, 0.39, 0.93] -> talk to (e.g., self, a person, a group) [0.32, 0.62, 0.39, 0.93]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "lDmLcWWBp1E",
        "candidates": [
            "talk to (e.g., self, a person, a group) [0.32, 0.48, 0.20, 0.81] -> walk [0.27, 0.65, 0.59, 0.84] -> press [0.52, 0.68, 0.23, 0.74]",
            "extract [0.22, 0.78, 0.40, 1.00] -> carry/hold (an object) [0.44, 0.56, 0.46, 0.78] -> talk to (e.g., self, a person, a group) [0.33, 0.67, 0.27, 1.00]",
            "walk [0.32, 0.62, 0.39, 0.93] -> carry/hold (an object) [0.32, 0.62, 0.39, 0.93] -> talk to (e.g., self, a person, a group) [0.32, 0.62, 0.39, 0.93]",
            "carry/hold (an object) [0.12, 0.75, 0.24, 0.87] -> talk to (e.g., self, a person, a group) [0.12, 0.65, 0.28, 0.77] -> cut [0.33, 0.42, 0.46, 0.80]"
        ],
        "start": 0.0,
        "end": 215.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1122.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "bend/bow (at the waist) -> lift (a person)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "lDmLcWWBp1E",
        "candidates": [
            "catch (an object) -> bend/bow (at the waist)",
            "bend/bow (at the waist) -> lift (a person)",
            "press -> lift (a person)",
            "lift/pick up -> bend/bow (at the waist)"
        ],
        "start": 0.0,
        "end": 227.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1132.0,
        "question": "How many people in the current frame are performing the action:  watch (e.g., TV)?",
        "answer": "4",
        "sub_answer_type": "SpatialPerception-2",
        "answer_type": "SpatialPerception",
        "video": "lDmLcWWBp1E",
        "candidates": [
            "4",
            "6",
            "3",
            "2"
        ],
        "start": 0.0,
        "end": 237.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1196.0,
        "question": "How many people were performing the sit in the scene 60 seconds ago?",
        "answer": "5",
        "sub_answer_type": "PastMemory-5",
        "answer_type": "PastMemory",
        "video": "lDmLcWWBp1E",
        "candidates": [
            "3",
            "4",
            "6",
            "5"
        ],
        "start": 0.0,
        "end": 301.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1217.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.31, 0.14, 0.74, 0.97] location?",
        "answer": "walk [0.31, 0.14, 0.74, 0.97] -> carry/hold (an object) [0.31, 0.14, 0.74, 0.97] -> push (another person) [0.31, 0.14, 0.74, 0.97]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "lDmLcWWBp1E",
        "candidates": [
            "carry/hold (an object) [0.17, 0.00, 0.64, 1.00] -> fight/hit (a person) [0.15, 0.09, 0.76, 1.00] -> push (another person) [0.48, 0.33, 0.70, 1.00]",
            "walk [0.31, 0.14, 0.74, 0.97] -> carry/hold (an object) [0.31, 0.14, 0.74, 0.97] -> push (another person) [0.31, 0.14, 0.74, 0.97]",
            "stir [0.36, 0.07, 0.65, 1.00] -> walk [0.15, 0.10, 0.91, 1.00] -> push (another person) [0.38, 0.00, 0.58, 0.82]",
            "walk [0.22, 0.15, 0.87, 1.00] -> press [0.21, 0.30, 0.56, 0.90] -> carry/hold (an object) [0.43, 0.00, 0.68, 1.00]"
        ],
        "start": 0.0,
        "end": 322.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1302.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "carry/hold (an object) -> lie/sleep",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "lDmLcWWBp1E",
        "candidates": [
            "hit (an object) -> lie/sleep",
            "lie/sleep -> catch (an object)",
            "carry/hold (an object) -> paint",
            "carry/hold (an object) -> lie/sleep"
        ],
        "start": 0.0,
        "end": 407.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1306.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.17, 0.36, 0.46, 0.77] location?",
        "answer": "carry/hold (an object) [0.17, 0.36, 0.46, 0.77] -> talk to (e.g., self, a person, a group) [0.17, 0.36, 0.46, 0.77] -> lie/sleep [0.17, 0.36, 0.46, 0.77]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "lDmLcWWBp1E",
        "candidates": [
            "lie/sleep [0.34, 0.54, 0.63, 0.60] -> exit [0.29, 0.39, 0.52, 0.59] -> carry/hold (an object) [0.17, 0.26, 0.27, 0.70]",
            "shovel [0.37, 0.25, 0.60, 0.63] -> carry/hold (an object) [0.00, 0.50, 0.60, 0.96] -> lie/sleep [0.00, 0.20, 0.60, 0.90]",
            "talk to (e.g., self, a person, a group) [0.25, 0.40, 0.31, 0.91] -> open (e.g., a window, a car door) [0.02, 0.50, 0.53, 0.86] -> lie/sleep [0.37, 0.28, 0.32, 0.86]",
            "carry/hold (an object) [0.17, 0.36, 0.46, 0.77] -> talk to (e.g., self, a person, a group) [0.17, 0.36, 0.46, 0.77] -> lie/sleep [0.17, 0.36, 0.46, 0.77]"
        ],
        "start": 0.0,
        "end": 411.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1311.0,
        "question": "How many people were performing the sit in the scene 120 seconds ago?",
        "answer": "4",
        "sub_answer_type": "PastMemory-5",
        "answer_type": "PastMemory",
        "video": "lDmLcWWBp1E",
        "candidates": [
            "4",
            "6",
            "8",
            "3"
        ],
        "start": 0.0,
        "end": 416.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1333.0,
        "question": "Where is the person currently performing the talk to (e.g., self, a person, a group) located in the picture?",
        "answer": "[0.23, 0.03, 0.98, 0.98]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "lDmLcWWBp1E",
        "candidates": [
            "[0.23, 0.03, 0.98, 0.98]",
            "[0.00, 0.11, 0.68, 1.00]",
            "[0.00, 0.00, 0.97, 0.75]",
            "[0.70, 0.01, 0.99, 0.53]"
        ],
        "start": 0.0,
        "end": 438.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1372.0,
        "question": "Is the person currently in the [0.46, 0.31, 0.70, 0.98] location in the current frame performing the walk?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "lDmLcWWBp1E",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 477.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1388.0,
        "question": "How many people were performing the sit in the scene 180 seconds ago?",
        "answer": "5",
        "sub_answer_type": "PastMemory-5",
        "answer_type": "PastMemory",
        "video": "lDmLcWWBp1E",
        "candidates": [
            "4",
            "3",
            "6",
            "5"
        ],
        "start": 0.0,
        "end": 493.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1405.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "carry/hold (an object) -> crouch/kneel",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "lDmLcWWBp1E",
        "candidates": [
            "carry/hold (an object) -> crouch/kneel",
            "crouch/kneel -> fall down",
            "fishing -> crouch/kneel",
            "crouch/kneel -> swim"
        ],
        "start": 0.0,
        "end": 510.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1482.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.00, 0.02, 0.68, 0.99]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "lDmLcWWBp1E",
        "candidates": [
            "[0.22, 0.00, 0.71, 0.79]",
            "[0.56, 0.71, 0.59, 0.89]",
            "[0.00, 0.02, 0.68, 0.99]",
            "[0.00, 0.21, 0.95, 1.00]"
        ],
        "start": 0.0,
        "end": 587.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1543.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "bend/bow (at the waist) -> talk to (e.g., self, a person, a group)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "lDmLcWWBp1E",
        "candidates": [
            "bend/bow (at the waist) -> talk to (e.g., self, a person, a group)",
            "talk to (e.g., self, a person, a group) -> hug (a person)",
            "take (an object) from (a person) -> bend/bow (at the waist)",
            "talk to (e.g., self, a person, a group) -> fall down"
        ],
        "start": 0.0,
        "end": 648.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1550.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.71, 0.32, 0.78, 0.82] location?",
        "answer": "walk [0.71, 0.32, 0.78, 0.82] -> carry/hold (an object) [0.71, 0.32, 0.78, 0.82] -> grab (a person) [0.71, 0.32, 0.78, 0.82]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "lDmLcWWBp1E",
        "candidates": [
            "carry/hold (an object) [0.55, 0.20, 0.66, 0.72] -> work on a computer [0.81, 0.39, 0.89, 0.96] -> grab (a person) [0.90, 0.18, 0.62, 0.92]",
            "walk [0.71, 0.32, 0.78, 0.82] -> carry/hold (an object) [0.71, 0.32, 0.78, 0.82] -> grab (a person) [0.71, 0.32, 0.78, 0.82]",
            "grab (a person) [0.83, 0.14, 0.79, 1.00] -> extract [0.74, 0.29, 0.98, 0.73] -> walk [0.67, 0.21, 0.88, 0.88]",
            "grab (a person) [0.66, 0.26, 0.64, 0.69] -> walk [0.63, 0.27, 0.64, 0.79] -> crawl [0.57, 0.15, 0.91, 0.86]"
        ],
        "start": 0.0,
        "end": 655.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1603.0,
        "question": "What action is the person at the location [0.07, 0.15, 0.82, 0.97] in the image performing?",
        "answer": "sit, ride (e.g., a bike, a car, a horse), talk to (e.g., self, a person, a group)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "lDmLcWWBp1E",
        "candidates": [
            "sit, ride (e.g., a bike, a car, a horse), listen to (a person)",
            "sit, ride (e.g., a bike, a car, a horse), talk to (e.g., self, a person, a group)",
            "stand, watch (a person)",
            "sit, carry/hold (an object)"
        ],
        "start": 0.0,
        "end": 708.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1710.0,
        "question": "What action is the person currently in the [0.26, 0.31, 0.38, 0.69] location likely to do next?",
        "answer": "play musical instrument",
        "sub_answer_type": "FuturePrediction-1",
        "answer_type": "FuturePrediction",
        "video": "lDmLcWWBp1E",
        "candidates": [
            "swim",
            "play musical instrument",
            "crouch/kneel",
            "bend/bow (at the waist)"
        ],
        "start": 0.0,
        "end": 815.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1711.0,
        "question": "What action is the person at the location [0.07, 0.31, 0.22, 0.74] in the image performing?",
        "answer": "sit, play musical instrument, watch (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "lDmLcWWBp1E",
        "candidates": [
            "sit, ride (e.g., a bike, a car, a horse), listen to (a person)",
            "sit, ride (e.g., a bike, a car, a horse)",
            "stand, listen to (a person), watch (a person)",
            "sit, play musical instrument, watch (a person)"
        ],
        "start": 0.0,
        "end": 816.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1730.0,
        "question": "How many people were performing the walk in the scene 180 seconds ago?",
        "answer": "6",
        "sub_answer_type": "PastMemory-5",
        "answer_type": "PastMemory",
        "video": "lDmLcWWBp1E",
        "candidates": [
            "4",
            "5",
            "6",
            "3"
        ],
        "start": 0.0,
        "end": 835.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1764.0,
        "question": "Are there still 1 people in the current frame now?",
        "answer": "No",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "lDmLcWWBp1E",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 869.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 918.0,
        "question": "Are there still 1 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "nlinqZPgvVk",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 23.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 920.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "carry/hold (an object) -> talk to (e.g., self, a person, a group)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "nlinqZPgvVk",
        "candidates": [
            "get up -> carry/hold (an object)",
            "carry/hold (an object) -> put down",
            "hand clap -> carry/hold (an object)",
            "carry/hold (an object) -> talk to (e.g., self, a person, a group)"
        ],
        "start": 0.0,
        "end": 25.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 928.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "carry/hold (an object) -> talk to (e.g., self, a person, a group)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "nlinqZPgvVk",
        "candidates": [
            "carry/hold (an object) -> talk to (e.g., self, a person, a group)",
            "carry/hold (an object) -> answer phone",
            "talk to (e.g., self, a person, a group) -> cut",
            "talk to (e.g., self, a person, a group) -> clink glass"
        ],
        "start": 0.0,
        "end": 33.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 984.0,
        "question": "Where is the person currently performing the walk located in the picture?",
        "answer": "[0.20, 0.09, 0.69, 0.97]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "nlinqZPgvVk",
        "candidates": [
            "[0.02, 0.37, 0.68, 0.96]",
            "[0.20, 0.09, 0.69, 0.97]",
            "[0.15, 0.00, 0.43, 1.00]",
            "[0.45, 0.00, 0.78, 1.00]"
        ],
        "start": 0.0,
        "end": 89.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1002.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.35, 0.16, 0.95, 0.99]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "nlinqZPgvVk",
        "candidates": [
            "[0.35, 0.16, 0.95, 0.99]",
            "[0.28, 0.44, 0.69, 0.82]",
            "[0.38, 0.00, 0.84, 0.80]",
            "[0.08, 0.05, 0.47, 1.00]"
        ],
        "start": 0.0,
        "end": 107.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1085.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.15, 0.05, 0.52, 0.97]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "nlinqZPgvVk",
        "candidates": [
            "[0.48, 0.15, 0.61, 0.48]",
            "[0.15, 0.05, 0.52, 0.97]",
            "[0.00, 0.29, 0.49, 1.00]",
            "[0.05, 0.00, 0.31, 1.00]"
        ],
        "start": 0.0,
        "end": 190.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1280.0,
        "question": "Where is the person currently performing the talk to (e.g., self, a person, a group) located in the picture?",
        "answer": "[0.13, 0.01, 0.86, 0.99]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "nlinqZPgvVk",
        "candidates": [
            "[0.00, 0.00, 0.69, 0.82]",
            "[0.10, 0.00, 1.00, 0.71]",
            "[0.34, 0.01, 0.97, 0.99]",
            "[0.13, 0.01, 0.86, 0.99]"
        ],
        "start": 0.0,
        "end": 385.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1361.0,
        "question": "What action is the person currently in the [0.17, 0.00, 0.99, 0.99] location likely to do next?",
        "answer": "talk to (e.g., self, a person, a group)",
        "sub_answer_type": "FuturePrediction-1",
        "answer_type": "FuturePrediction",
        "video": "nlinqZPgvVk",
        "candidates": [
            "walk",
            "lie/sleep",
            "row boat",
            "talk to (e.g., self, a person, a group)"
        ],
        "start": 0.0,
        "end": 466.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1440.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "walk -> carry/hold (an object)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "nlinqZPgvVk",
        "candidates": [
            "enter -> carry/hold (an object)",
            "walk -> carry/hold (an object)",
            "carry/hold (an object) -> play with kids",
            "carry/hold (an object) -> cut"
        ],
        "start": 0.0,
        "end": 545.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1469.0,
        "question": "Is the person currently in the [0.03, 0.05, 0.68, 0.94] location in the current frame performing the talk to (e.g., self, a person, a group)?",
        "answer": "No",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "nlinqZPgvVk",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 574.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1471.0,
        "question": "Where was the person currently performing the touch (an object) in the scene 8 seconds ago?",
        "answer": "[0.30, 0.08, 0.95, 0.95]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "nlinqZPgvVk",
        "candidates": [
            "[0.29, 0.38, 1.00, 1.00]",
            "[0.56, 0.03, 0.67, 0.68]",
            "[0.30, 0.08, 0.95, 0.95]",
            "[0.02, 0.00, 0.52, 0.97]"
        ],
        "start": 0.0,
        "end": 576.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1481.0,
        "question": "What action is the person at the location [0.00, 0.01, 0.62, 1.00] in the image performing?",
        "answer": "sit, listen to (a person), watch (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "nlinqZPgvVk",
        "candidates": [
            "stand, talk to (e.g., self, a person, a group), watch (a person)",
            "walk, talk to (e.g., self, a person, a group)",
            "sit, listen to (a person), watch (a person)",
            "stand, talk to (e.g., self, a person, a group)"
        ],
        "start": 0.0,
        "end": 586.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1500.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "carry/hold (an object) -> talk to (e.g., self, a person, a group)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "nlinqZPgvVk",
        "candidates": [
            "carry/hold (an object) -> turn (e.g., a screwdriver)",
            "carry/hold (an object) -> talk to (e.g., self, a person, a group)",
            "talk to (e.g., self, a person, a group) -> walk",
            "talk to (e.g., self, a person, a group) -> crawl"
        ],
        "start": 0.0,
        "end": 605.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1557.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "talk to (e.g., self, a person, a group) -> walk",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "nlinqZPgvVk",
        "candidates": [
            "walk -> brush teeth",
            "talk to (e.g., self, a person, a group) -> paint",
            "talk to (e.g., self, a person, a group) -> walk",
            "talk to (e.g., self, a person, a group) -> write"
        ],
        "start": 0.0,
        "end": 662.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1565.0,
        "question": "What action is the person at the location [0.13, 0.07, 0.41, 0.99] in the image performing?",
        "answer": "walk, talk to (e.g., self, a person, a group)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "nlinqZPgvVk",
        "candidates": [
            "stand, talk to (e.g., self, a person, a group)",
            "stand, carry/hold (an object)",
            "sit, listen to (a person), watch (a person)",
            "walk, talk to (e.g., self, a person, a group)"
        ],
        "start": 0.0,
        "end": 670.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1576.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.15, 0.07, 0.43, 0.98]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "nlinqZPgvVk",
        "candidates": [
            "[0.06, 0.00, 0.48, 0.74]",
            "[0.15, 0.07, 0.43, 0.98]",
            "[0.00, 0.15, 0.15, 0.75]",
            "[0.27, 0.11, 0.96, 0.91]"
        ],
        "start": 0.0,
        "end": 681.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1617.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.46, 0.24, 0.71, 0.97]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "nlinqZPgvVk",
        "candidates": [
            "[0.69, 0.23, 0.73, 0.77]",
            "[0.75, 0.37, 0.89, 1.00]",
            "[0.46, 0.24, 0.71, 0.97]",
            "[0.01, 0.03, 0.47, 0.99]"
        ],
        "start": 0.0,
        "end": 722.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1648.0,
        "question": "Are there still 2 people in the current frame now?",
        "answer": "No",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "nlinqZPgvVk",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 753.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1667.0,
        "question": "What action is the person at the location [0.00, 0.00, 0.64, 0.97] in the image performing?",
        "answer": "stand, carry/hold (an object), talk to (e.g., self, a person, a group)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "nlinqZPgvVk",
        "candidates": [
            "walk, talk to (e.g., self, a person, a group)",
            "stand, carry/hold (an object), talk to (e.g., self, a person, a group)",
            "stand, talk to (e.g., self, a person, a group)",
            "sit, talk to (e.g., self, a person, a group), watch (a person)"
        ],
        "start": 0.0,
        "end": 772.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 911.0,
        "question": "What action is the person at the location [0.14, 0.13, 0.60, 0.98] in the image performing?",
        "answer": "stand, watch (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "o4xQ-BEa3Ss",
        "candidates": [
            "bend/bow (at the waist), watch (a person)",
            "sit, listen to (a person), watch (a person)",
            "stand, watch (a person)",
            "stand, listen to (a person)"
        ],
        "start": 0.0,
        "end": 16.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1123.0,
        "question": "Where was the person currently performing the kiss (a person) in the scene 8 seconds ago?",
        "answer": "[0.13, 0.09, 0.62, 0.98]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "o4xQ-BEa3Ss",
        "candidates": [
            "[0.45, 0.30, 0.73, 0.85]",
            "[0.13, 0.09, 0.62, 0.98]",
            "[0.37, 0.14, 0.67, 0.70]",
            "[0.00, 0.00, 0.46, 1.00]"
        ],
        "start": 0.0,
        "end": 228.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1170.0,
        "question": "What action is the person currently in the [0.59, 0.15, 0.87, 0.96] location likely to do next?",
        "answer": "carry/hold (an object) and talk to (e.g., self, a person, a group)",
        "sub_answer_type": "FuturePrediction-1",
        "answer_type": "FuturePrediction",
        "video": "o4xQ-BEa3Ss",
        "candidates": [
            "carry/hold (an object) and talk to (e.g., self, a person, a group)",
            "walk",
            "cut",
            "shoot"
        ],
        "start": 0.0,
        "end": 275.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1214.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.40, 0.05, 0.70, 0.55] location?",
        "answer": "bend/bow (at the waist) [0.40, 0.05, 0.70, 0.55] -> carry/hold (an object) [0.40, 0.05, 0.70, 0.55] -> talk to (e.g., self, a person, a group) [0.40, 0.05, 0.70, 0.55]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "o4xQ-BEa3Ss",
        "candidates": [
            "talk to (e.g., self, a person, a group) [0.46, 0.00, 0.51, 0.72] -> carry/hold (an object) [0.38, 0.04, 0.73, 0.74] -> throw [0.37, 0.21, 0.66, 0.48]",
            "play with pets [0.58, 0.00, 0.67, 0.49] -> talk to (e.g., self, a person, a group) [0.43, 0.07, 0.79, 0.64] -> bend/bow (at the waist) [0.48, 0.10, 0.71, 0.52]",
            "bend/bow (at the waist) [0.40, 0.05, 0.70, 0.55] -> carry/hold (an object) [0.40, 0.05, 0.70, 0.55] -> talk to (e.g., self, a person, a group) [0.40, 0.05, 0.70, 0.55]",
            "text on/look at a cellphone [0.27, 0.17, 0.79, 0.46] -> carry/hold (an object) [0.26, 0.00, 0.67, 0.39] -> talk to (e.g., self, a person, a group) [0.31, 0.04, 0.89, 0.61]"
        ],
        "start": 0.0,
        "end": 319.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1221.0,
        "question": "Where is the person currently performing the talk to (e.g., self, a person, a group) located in the picture?",
        "answer": "[0.30, 0.07, 0.65, 0.98]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "o4xQ-BEa3Ss",
        "candidates": [
            "[0.54, 0.00, 0.89, 0.82]",
            "[0.13, 0.20, 0.40, 0.99]",
            "[0.03, 0.12, 0.52, 0.71]",
            "[0.30, 0.07, 0.65, 0.98]"
        ],
        "start": 0.0,
        "end": 326.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1232.0,
        "question": "Where was the person currently performing the touch (an object) in the scene 8 seconds ago?",
        "answer": "[0.39, 0.07, 0.77, 0.66]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "o4xQ-BEa3Ss",
        "candidates": [
            "[0.47, 0.06, 0.92, 0.43]",
            "[0.39, 0.07, 0.77, 0.66]",
            "[0.49, 0.25, 0.94, 0.90]",
            "[0.30, 0.07, 0.64, 0.98]"
        ],
        "start": 0.0,
        "end": 337.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1244.0,
        "question": "Where was the person currently performing the eat in the scene 8 seconds ago?",
        "answer": "[0.59, 0.45, 0.85, 1.00]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "o4xQ-BEa3Ss",
        "candidates": [
            "[0.59, 0.45, 0.85, 1.00]",
            "[0.81, 0.22, 0.96, 1.00]",
            "[0.36, 0.30, 0.63, 0.82]",
            "[0.86, 0.64, 0.86, 1.00]"
        ],
        "start": 0.0,
        "end": 349.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1253.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.40, 0.11, 0.72, 0.66] location?",
        "answer": "bend/bow (at the waist) [0.40, 0.11, 0.72, 0.66] -> carry/hold (an object) [0.40, 0.11, 0.72, 0.66] -> talk to (e.g., self, a person, a group) [0.40, 0.11, 0.72, 0.66]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "o4xQ-BEa3Ss",
        "candidates": [
            "carry/hold (an object) [0.35, 0.00, 0.65, 0.54] -> play with kids [0.54, 0.00, 0.70, 0.77] -> talk to (e.g., self, a person, a group) [0.45, 0.00, 0.81, 0.46]",
            "bend/bow (at the waist) [0.40, 0.11, 0.72, 0.66] -> carry/hold (an object) [0.40, 0.11, 0.72, 0.66] -> talk to (e.g., self, a person, a group) [0.40, 0.11, 0.72, 0.66]",
            "carry/hold (an object) [0.51, 0.06, 0.77, 0.68] -> lie/sleep [0.56, 0.16, 0.53, 0.73] -> bend/bow (at the waist) [0.34, 0.21, 0.63, 0.73]",
            "talk to (e.g., self, a person, a group) [0.51, 0.30, 0.58, 0.72] -> carry/hold (an object) [0.45, 0.00, 0.73, 0.48] -> cut [0.53, 0.00, 0.89, 0.70]"
        ],
        "start": 0.0,
        "end": 358.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1352.0,
        "question": "Are there still 5 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "o4xQ-BEa3Ss",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 457.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1406.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.59, 0.22, 0.77, 0.99] location?",
        "answer": "walk [0.59, 0.22, 0.77, 0.99] -> carry/hold (an object) [0.59, 0.22, 0.77, 0.99] -> talk to (e.g., self, a person, a group) [0.59, 0.22, 0.77, 0.99]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "o4xQ-BEa3Ss",
        "candidates": [
            "carry/hold (an object) [0.76, 0.37, 0.74, 1.00] -> walk [0.71, 0.22, 0.66, 0.98] -> exit [0.74, 0.22, 0.72, 1.00]",
            "walk [0.59, 0.22, 0.77, 0.99] -> carry/hold (an object) [0.59, 0.22, 0.77, 0.99] -> talk to (e.g., self, a person, a group) [0.59, 0.22, 0.77, 0.99]",
            "hug (a person) [0.52, 0.03, 0.95, 0.84] -> walk [0.58, 0.29, 0.59, 1.00] -> talk to (e.g., self, a person, a group) [0.59, 0.36, 0.91, 0.81]",
            "carry/hold (an object) [0.77, 0.29, 0.67, 1.00] -> walk [0.45, 0.33, 0.90, 1.00] -> smoke [0.57, 0.08, 0.95, 0.86]"
        ],
        "start": 0.0,
        "end": 511.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1431.0,
        "question": "What action is the person at the location [0.13, 0.08, 0.47, 1.00] in the image performing?",
        "answer": "walk, listen to (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "o4xQ-BEa3Ss",
        "candidates": [
            "stand, carry/hold (an object), watch (a person)",
            "sit, listen to (a person), watch (a person)",
            "stand, listen to (a person)",
            "walk, listen to (a person)"
        ],
        "start": 0.0,
        "end": 536.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1541.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.17, 0.05, 0.55, 0.96]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "o4xQ-BEa3Ss",
        "candidates": [
            "[0.17, 0.05, 0.55, 0.96]",
            "[0.23, 0.00, 0.82, 0.80]",
            "[0.38, 0.30, 0.64, 0.98]",
            "[0.00, 0.24, 0.38, 1.00]"
        ],
        "start": 0.0,
        "end": 646.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1556.0,
        "question": "Are there still 2 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "o4xQ-BEa3Ss",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 661.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1607.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.13, 0.12, 0.36, 0.97] location?",
        "answer": "walk [0.13, 0.12, 0.36, 0.97] -> carry/hold (an object) [0.13, 0.12, 0.36, 0.97] -> talk to (e.g., self, a person, a group) [0.13, 0.12, 0.36, 0.97]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "o4xQ-BEa3Ss",
        "candidates": [
            "carry/hold (an object) [0.00, 0.00, 0.21, 0.81] -> walk [0.31, 0.23, 0.40, 0.79] -> turn (e.g., a screwdriver) [0.17, 0.03, 0.24, 0.92]",
            "answer phone [0.28, 0.02, 0.45, 0.99] -> walk [0.05, 0.02, 0.39, 0.88] -> carry/hold (an object) [0.32, 0.00, 0.35, 0.79]",
            "walk [0.06, 0.24, 0.25, 0.77] -> carry/hold (an object) [0.07, 0.24, 0.53, 1.00] -> hand wave [0.25, 0.24, 0.27, 1.00]",
            "walk [0.13, 0.12, 0.36, 0.97] -> carry/hold (an object) [0.13, 0.12, 0.36, 0.97] -> talk to (e.g., self, a person, a group) [0.13, 0.12, 0.36, 0.97]"
        ],
        "start": 0.0,
        "end": 712.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1649.0,
        "question": "What action is the person at the location [0.26, 0.10, 0.51, 0.97] in the image performing?",
        "answer": "stand, carry/hold (an object), listen to (a person), watch (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "o4xQ-BEa3Ss",
        "candidates": [
            "stand, carry/hold (an object), talk to (e.g., self, a person, a group)",
            "stand, carry/hold (an object), listen to (a person), watch (a person)",
            "stand, listen to (a person), watch (a person)",
            "stand, talk to (e.g., self, a person, a group)"
        ],
        "start": 0.0,
        "end": 754.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1665.0,
        "question": "Where is the person currently performing the carry/hold (an object) located in the picture?",
        "answer": "[0.15, 0.06, 0.52, 1.00]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "o4xQ-BEa3Ss",
        "candidates": [
            "[0.29, 0.00, 0.72, 0.93]",
            "[0.15, 0.06, 0.52, 1.00]",
            "[0.00, 0.29, 0.35, 0.83]",
            "[0.41, 0.46, 0.51, 0.83]"
        ],
        "start": 0.0,
        "end": 770.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1703.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.46, 0.45, 0.87, 0.99]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "o4xQ-BEa3Ss",
        "candidates": [
            "[0.74, 0.35, 1.00, 0.72]",
            "[0.46, 0.45, 0.87, 0.99]",
            "[0.29, 0.74, 1.00, 1.00]",
            "[0.14, 0.17, 0.33, 0.92]"
        ],
        "start": 0.0,
        "end": 808.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1756.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.12, 0.24, 0.55, 0.99] location?",
        "answer": "talk to (e.g., self, a person, a group) [0.15, 0.24, 0.56, 0.97] -> lie/sleep [0.15, 0.24, 0.56, 0.97] -> hug (a person) [0.12, 0.24, 0.55, 0.99]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "o4xQ-BEa3Ss",
        "candidates": [
            "exit [0.03, 0.31, 0.44, 0.87] -> hug (a person) [0.03, 0.06, 0.70, 1.00] -> lie/sleep [0.31, 0.23, 0.53, 1.00]",
            "talk to (e.g., self, a person, a group) [0.15, 0.24, 0.56, 0.97] -> lie/sleep [0.15, 0.24, 0.56, 0.97] -> hug (a person) [0.12, 0.24, 0.55, 0.99]",
            "talk to (e.g., self, a person, a group) [0.06, 0.31, 0.65, 0.87] -> exit [0.20, 0.39, 0.48, 1.00] -> lie/sleep [0.19, 0.32, 0.44, 1.00]",
            "talk to (e.g., self, a person, a group) [0.00, 0.39, 0.56, 0.96] -> lie/sleep [0.16, 0.12, 0.66, 1.00] -> cook [0.21, 0.16, 0.74, 0.99]"
        ],
        "start": 0.0,
        "end": 861.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 916.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.24, 0.25, 0.61, 0.88] location?",
        "answer": "talk to (e.g., self, a person, a group) [0.28, 0.20, 0.86, 0.97] -> carry/hold (an object) [0.24, 0.25, 0.61, 0.88] -> close (e.g., a door, a box) [0.24, 0.25, 0.61, 0.88]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "oifTDWZvOhY",
        "candidates": [
            "carry/hold (an object) [0.33, 0.11, 0.49, 0.91] -> hand clap [0.10, 0.43, 0.65, 0.84] -> talk to (e.g., self, a person, a group) [0.41, 0.11, 0.88, 0.88]",
            "sing to (e.g., self, a person, a group) [0.16, 0.27, 0.71, 1.00] -> close (e.g., a door, a box) [0.19, 0.20, 0.80, 0.83] -> carry/hold (an object) [0.20, 0.07, 0.71, 0.92]",
            "talk to (e.g., self, a person, a group) [0.28, 0.20, 0.86, 0.97] -> carry/hold (an object) [0.24, 0.25, 0.61, 0.88] -> close (e.g., a door, a box) [0.24, 0.25, 0.61, 0.88]",
            "carry/hold (an object) [0.31, 0.28, 0.71, 0.91] -> kiss (a person) [0.05, 0.45, 0.49, 1.00] -> talk to (e.g., self, a person, a group) [0.39, 0.35, 0.69, 1.00]"
        ],
        "start": 0.0,
        "end": 21.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 917.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "carry/hold (an object) -> open (e.g., a window, a car door) -> talk to (e.g., self, a person, a group) -> close (e.g., a door, a box)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "oifTDWZvOhY",
        "candidates": [
            "open (e.g., a window, a car door) -> talk to (e.g., self, a person, a group) -> carry/hold (an object) -> grab (a person)",
            "carry/hold (an object) -> open (e.g., a window, a car door) -> talk to (e.g., self, a person, a group) -> close (e.g., a door, a box)",
            "close (e.g., a door, a box) -> martial art -> open (e.g., a window, a car door) -> talk to (e.g., self, a person, a group)",
            "talk to (e.g., self, a person, a group) -> carry/hold (an object) -> grab (a person) -> close (e.g., a door, a box)"
        ],
        "start": 0.0,
        "end": 22.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 992.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.02, 0.08, 0.52, 0.96] location?",
        "answer": "carry/hold (an object) [0.02, 0.08, 0.52, 0.96] -> give/serve (an object) to (a person) [0.02, 0.08, 0.52, 0.96] -> talk to (e.g., self, a person, a group) [0.02, 0.08, 0.52, 0.96]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "oifTDWZvOhY",
        "candidates": [
            "talk to (e.g., self, a person, a group) [0.14, 0.00, 0.38, 0.85] -> give/serve (an object) to (a person) [0.04, 0.24, 0.50, 0.87] -> turn (e.g., a screwdriver) [0.06, 0.22, 0.45, 1.00]",
            "talk to (e.g., self, a person, a group) [0.01, 0.00, 0.46, 1.00] -> throw [0.00, 0.00, 0.44, 0.78] -> give/serve (an object) to (a person) [0.00, 0.00, 0.46, 0.90]",
            "carry/hold (an object) [0.02, 0.08, 0.52, 0.96] -> give/serve (an object) to (a person) [0.02, 0.08, 0.52, 0.96] -> talk to (e.g., self, a person, a group) [0.02, 0.08, 0.52, 0.96]",
            "dress/put on clothing [0.13, 0.15, 0.37, 0.78] -> carry/hold (an object) [0.00, 0.24, 0.70, 0.92] -> give/serve (an object) to (a person) [0.11, 0.01, 0.57, 1.00]"
        ],
        "start": 0.0,
        "end": 97.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 997.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.41, 0.21, 0.96, 0.87] location?",
        "answer": "carry/hold (an object) [0.41, 0.21, 0.96, 0.87] -> read [0.41, 0.21, 0.96, 0.87] -> talk to (e.g., self, a person, a group) [0.41, 0.21, 0.96, 0.87]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "oifTDWZvOhY",
        "candidates": [
            "read [0.48, 0.35, 0.92, 0.77] -> talk to (e.g., self, a person, a group) [0.26, 0.21, 1.00, 1.00] -> text on/look at a cellphone [0.28, 0.14, 0.88, 0.78]",
            "talk to (e.g., self, a person, a group) [0.61, 0.18, 1.00, 0.88] -> carry/hold (an object) [0.55, 0.12, 1.00, 1.00] -> eat [0.36, 0.04, 1.00, 0.84]",
            "enter [0.22, 0.34, 0.93, 1.00] -> read [0.38, 0.22, 1.00, 0.91] -> carry/hold (an object) [0.35, 0.36, 1.00, 0.95]",
            "carry/hold (an object) [0.41, 0.21, 0.96, 0.87] -> read [0.41, 0.21, 0.96, 0.87] -> talk to (e.g., self, a person, a group) [0.41, 0.21, 0.96, 0.87]"
        ],
        "start": 0.0,
        "end": 102.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1001.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.39, 0.20, 0.94, 0.85] location?",
        "answer": "read [0.43, 0.19, 0.95, 0.86] -> talk to (e.g., self, a person, a group) [0.43, 0.19, 0.95, 0.86] -> carry/hold (an object) [0.39, 0.20, 0.94, 0.85]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "oifTDWZvOhY",
        "candidates": [
            "carry/hold (an object) [0.43, 0.13, 1.00, 0.71] -> talk to (e.g., self, a person, a group) [0.29, 0.37, 1.00, 0.87] -> crouch/kneel [0.34, 0.36, 1.00, 0.93]",
            "carry/hold (an object) [0.32, 0.03, 0.96, 0.75] -> kick (an object) [0.36, 0.05, 0.90, 1.00] -> read [0.60, 0.36, 1.00, 0.96]",
            "read [0.43, 0.19, 0.95, 0.86] -> talk to (e.g., self, a person, a group) [0.43, 0.19, 0.95, 0.86] -> carry/hold (an object) [0.39, 0.20, 0.94, 0.85]",
            "sail boat [0.29, 0.18, 1.00, 1.00] -> talk to (e.g., self, a person, a group) [0.59, 0.19, 1.00, 0.99] -> carry/hold (an object) [0.52, 0.33, 1.00, 0.73]"
        ],
        "start": 0.0,
        "end": 106.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1012.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.03, 0.08, 0.34, 0.97]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "oifTDWZvOhY",
        "candidates": [
            "[0.00, 0.22, 0.05, 0.81]",
            "[0.03, 0.08, 0.34, 0.97]",
            "[0.41, 0.21, 0.96, 0.87]",
            "[0.32, 0.00, 0.16, 0.71]"
        ],
        "start": 0.0,
        "end": 117.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1022.0,
        "question": "Where is the person currently performing the talk to (e.g., self, a person, a group) located in the picture?",
        "answer": "[0.30, 0.24, 0.76, 1.00]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "oifTDWZvOhY",
        "candidates": [
            "[0.25, 0.28, 0.29, 0.41]",
            "[0.55, 0.02, 0.49, 0.71]",
            "[0.30, 0.24, 0.76, 1.00]",
            "[0.21, 0.39, 0.52, 1.00]"
        ],
        "start": 0.0,
        "end": 127.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1036.0,
        "question": "Are there still 1 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "oifTDWZvOhY",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 141.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1044.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "talk to (e.g., self, a person, a group) -> read",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "oifTDWZvOhY",
        "candidates": [
            "lift/pick up -> read",
            "talk to (e.g., self, a person, a group) -> extract",
            "take (an object) from (a person) -> read",
            "talk to (e.g., self, a person, a group) -> read"
        ],
        "start": 0.0,
        "end": 149.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1053.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "touch (an object) -> carry/hold (an object)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "oifTDWZvOhY",
        "candidates": [
            "push (another person) -> touch (an object)",
            "touch (an object) -> carry/hold (an object)",
            "smoke -> touch (an object)",
            "touch (an object) -> enter"
        ],
        "start": 0.0,
        "end": 158.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1058.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "carry/hold (an object) -> talk to (e.g., self, a person, a group)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "oifTDWZvOhY",
        "candidates": [
            "talk to (e.g., self, a person, a group) -> pull (an object)",
            "carry/hold (an object) -> enter",
            "talk to (e.g., self, a person, a group) -> brush teeth",
            "carry/hold (an object) -> talk to (e.g., self, a person, a group)"
        ],
        "start": 0.0,
        "end": 163.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1164.0,
        "question": "Where is the person currently performing the carry/hold (an object) located in the picture?",
        "answer": "[0.72, 0.42, 0.84, 0.96]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "oifTDWZvOhY",
        "candidates": [
            "[0.58, 0.62, 0.70, 1.00]",
            "[0.72, 0.42, 0.84, 0.96]",
            "[0.43, 0.43, 0.69, 0.94]",
            "[0.33, 0.08, 0.86, 1.00]"
        ],
        "start": 0.0,
        "end": 269.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1235.0,
        "question": "Is the person currently in the [0.39, 0.33, 0.71, 0.98] location in the current frame performing the walk?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "oifTDWZvOhY",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 340.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1278.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.07, 0.12, 0.41, 0.95]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "oifTDWZvOhY",
        "candidates": [
            "[0.03, 0.10, 0.13, 0.78]",
            "[0.14, 0.03, 0.92, 1.00]",
            "[0.07, 0.12, 0.41, 0.95]",
            "[0.00, 0.00, 0.60, 0.75]"
        ],
        "start": 0.0,
        "end": 383.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1299.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.03, 0.15, 0.55, 0.99]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "oifTDWZvOhY",
        "candidates": [
            "[0.03, 0.15, 0.55, 0.99]",
            "[0.14, 0.41, 0.84, 1.00]",
            "[0.00, 0.12, 0.64, 0.69]",
            "[0.51, 0.17, 0.82, 0.98]"
        ],
        "start": 0.0,
        "end": 404.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1308.0,
        "question": "What action is the person at the location [0.02, 0.08, 0.44, 1.00] in the image performing?",
        "answer": "stand, listen to (a person), watch (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "oifTDWZvOhY",
        "candidates": [
            "stand, carry/hold (an object), watch (a person)",
            "stand, carry/hold (an object), ride (e.g., a bike, a car, a horse)",
            "stand, carry/hold (an object), talk to (e.g., self, a person, a group), watch (a person)",
            "stand, listen to (a person), watch (a person)"
        ],
        "start": 0.0,
        "end": 413.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1366.0,
        "question": "Is the person currently in the [0.64, 0.23, 0.76, 0.70] location in the current frame performing the walk?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "oifTDWZvOhY",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 471.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1442.0,
        "question": "Is the person currently in the [0.46, 0.15, 0.60, 0.65] location in the current frame performing the carry/hold (an object)?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "oifTDWZvOhY",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 547.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1443.0,
        "question": "How many people in the current frame are performing the action:  carry/hold (an object)?",
        "answer": "3",
        "sub_answer_type": "SpatialPerception-2",
        "answer_type": "SpatialPerception",
        "video": "oifTDWZvOhY",
        "candidates": [
            "8",
            "4",
            "2",
            "3"
        ],
        "start": 0.0,
        "end": 548.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1528.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.33, 0.19, 0.72, 0.98] location?",
        "answer": "talk to (e.g., self, a person, a group) [0.41, 0.17, 0.93, 0.99] -> carry/hold (an object) [0.33, 0.19, 0.72, 0.98] -> give/serve (an object) to (a person) [0.33, 0.19, 0.72, 0.98]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "oifTDWZvOhY",
        "candidates": [
            "sail boat [0.49, 0.33, 0.88, 1.00] -> carry/hold (an object) [0.32, 0.10, 0.73, 1.00] -> talk to (e.g., self, a person, a group) [0.57, 0.27, 0.87, 1.00]",
            "talk to (e.g., self, a person, a group) [0.41, 0.17, 0.93, 0.99] -> carry/hold (an object) [0.33, 0.19, 0.72, 0.98] -> give/serve (an object) to (a person) [0.33, 0.19, 0.72, 0.98]",
            "give/serve (an object) to (a person) [0.50, 0.35, 0.80, 0.86] -> carry/hold (an object) [0.39, 0.13, 0.80, 1.00] -> dig [0.49, 0.32, 1.00, 0.89]",
            "cut [0.33, 0.02, 0.81, 0.87] -> carry/hold (an object) [0.49, 0.14, 0.78, 0.84] -> give/serve (an object) to (a person) [0.41, 0.17, 0.83, 0.90]"
        ],
        "start": 0.0,
        "end": 633.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1560.0,
        "question": "How many people were performing the watch (a person) in the scene 180 seconds ago?",
        "answer": "5",
        "sub_answer_type": "PastMemory-5",
        "answer_type": "PastMemory",
        "video": "oifTDWZvOhY",
        "candidates": [
            "3",
            "5",
            "4",
            "7"
        ],
        "start": 0.0,
        "end": 665.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1592.0,
        "question": "What action is the person currently in the [0.19, 0.11, 0.70, 1.00] location likely to do next?",
        "answer": "carry/hold (an object)",
        "sub_answer_type": "FuturePrediction-1",
        "answer_type": "FuturePrediction",
        "video": "oifTDWZvOhY",
        "candidates": [
            "kick (an object)",
            "carry/hold (an object) and ride (e.g., a bike, a car, a horse)",
            "carry/hold (an object)",
            "swim"
        ],
        "start": 0.0,
        "end": 697.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1593.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "walk -> carry/hold (an object) -> hit (an object)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "oifTDWZvOhY",
        "candidates": [
            "answer phone -> hit (an object) -> carry/hold (an object)",
            "walk -> carry/hold (an object) -> hit (an object)",
            "hit (an object) -> carry/hold (an object) -> crouch/kneel",
            "carry/hold (an object) -> hit (an object) -> grab (a person)"
        ],
        "start": 0.0,
        "end": 698.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1627.0,
        "question": "How many people were performing the watch (a person) in the scene 60 seconds ago?",
        "answer": "3",
        "sub_answer_type": "PastMemory-5",
        "answer_type": "PastMemory",
        "video": "oifTDWZvOhY",
        "candidates": [
            "3",
            "9",
            "7",
            "4"
        ],
        "start": 0.0,
        "end": 732.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1678.0,
        "question": "Are there still 4 people in the current frame now?",
        "answer": "No",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "oifTDWZvOhY",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 783.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1715.0,
        "question": "How many people in the current frame are performing the action:  carry/hold (an object)?",
        "answer": "3",
        "sub_answer_type": "SpatialPerception-2",
        "answer_type": "SpatialPerception",
        "video": "oifTDWZvOhY",
        "candidates": [
            "3",
            "5",
            "4",
            "2"
        ],
        "start": 0.0,
        "end": 820.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 971.0,
        "question": "Where is the person currently performing the talk to (e.g., self, a person, a group) located in the picture?",
        "answer": "[0.03, 0.11, 0.98, 0.96]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "om_83F5VwTQ",
        "candidates": [
            "[0.26, 0.00, 0.68, 0.69]",
            "[0.26, 0.00, 1.00, 0.90]",
            "[0.03, 0.11, 0.98, 0.96]",
            "[0.23, 0.32, 0.53, 0.95]"
        ],
        "start": 0.0,
        "end": 76.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 988.0,
        "question": "Are there still 1 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "om_83F5VwTQ",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 93.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1038.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.34, 0.09, 0.70, 0.97]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "om_83F5VwTQ",
        "candidates": [
            "[0.34, 0.09, 0.70, 0.97]",
            "[0.12, 0.00, 0.45, 0.79]",
            "[0.54, 0.00, 0.85, 0.75]",
            "[0.04, 0.20, 0.52, 0.97]"
        ],
        "start": 0.0,
        "end": 143.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1071.0,
        "question": "Where is the person currently performing the talk to (e.g., self, a person, a group) located in the picture?",
        "answer": "[0.11, 0.20, 0.91, 0.96]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "om_83F5VwTQ",
        "candidates": [
            "[0.30, 0.03, 0.96, 0.97]",
            "[0.26, 0.36, 1.00, 1.00]",
            "[0.19, 0.49, 0.62, 1.00]",
            "[0.11, 0.20, 0.91, 0.96]"
        ],
        "start": 0.0,
        "end": 176.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1188.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.42, 0.18, 0.66, 0.80] location?",
        "answer": "carry/hold (an object) [0.42, 0.16, 0.65, 0.80] -> smoke [0.42, 0.16, 0.65, 0.80] -> bend/bow (at the waist) [0.42, 0.18, 0.66, 0.80]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "om_83F5VwTQ",
        "candidates": [
            "put down [0.48, 0.05, 0.69, 0.87] -> bend/bow (at the waist) [0.52, 0.02, 0.55, 0.69] -> carry/hold (an object) [0.33, 0.30, 0.53, 0.70]",
            "carry/hold (an object) [0.51, 0.07, 0.65, 0.62] -> bend/bow (at the waist) [0.62, 0.25, 0.59, 0.77] -> push (an object) [0.54, 0.08, 0.67, 0.96]",
            "carry/hold (an object) [0.42, 0.16, 0.65, 0.80] -> smoke [0.42, 0.16, 0.65, 0.80] -> bend/bow (at the waist) [0.42, 0.18, 0.66, 0.80]",
            "bend/bow (at the waist) [0.62, 0.36, 0.51, 0.75] -> close (e.g., a door, a box) [0.49, 0.27, 0.84, 0.69] -> carry/hold (an object) [0.38, 0.30, 0.75, 0.80]"
        ],
        "start": 0.0,
        "end": 293.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1200.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.58, 0.29, 0.98, 0.96] location?",
        "answer": "talk to (e.g., self, a person, a group) [0.57, 0.28, 0.98, 0.96] -> carry/hold (an object) [0.58, 0.29, 0.98, 0.96] -> touch (an object) [0.58, 0.29, 0.98, 0.96]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "om_83F5VwTQ",
        "candidates": [
            "ride (e.g., a bike, a car, a horse) [0.60, 0.23, 0.96, 0.88] -> touch (an object) [0.61, 0.37, 0.96, 1.00] -> talk to (e.g., self, a person, a group) [0.66, 0.17, 0.88, 1.00]",
            "carry/hold (an object) [0.67, 0.21, 0.99, 0.85] -> touch (an object) [0.72, 0.39, 0.89, 0.99] -> sing to (e.g., self, a person, a group) [0.40, 0.48, 1.00, 0.95]",
            "talk to (e.g., self, a person, a group) [0.63, 0.20, 1.00, 1.00] -> touch (an object) [0.49, 0.42, 0.99, 0.99] -> crouch/kneel [0.59, 0.20, 1.00, 1.00]",
            "talk to (e.g., self, a person, a group) [0.57, 0.28, 0.98, 0.96] -> carry/hold (an object) [0.58, 0.29, 0.98, 0.96] -> touch (an object) [0.58, 0.29, 0.98, 0.96]"
        ],
        "start": 0.0,
        "end": 305.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1206.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.00, 0.29, 0.41, 1.00]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "om_83F5VwTQ",
        "candidates": [
            "[0.00, 0.29, 0.41, 1.00]",
            "[0.24, 0.18, 0.55, 0.85]",
            "[0.00, 0.15, 0.44, 0.73]",
            "[0.17, 0.34, 0.61, 1.00]"
        ],
        "start": 0.0,
        "end": 311.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1214.0,
        "question": "Is the person currently in the [0.02, 0.24, 0.73, 0.96] location in the current frame performing the talk to (e.g., self, a person, a group)?",
        "answer": "No",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "om_83F5VwTQ",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 319.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1231.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.03, 0.29, 0.53, 0.99] location?",
        "answer": "talk to (e.g., self, a person, a group) [0.01, 0.26, 0.54, 0.98] -> smoke [0.03, 0.29, 0.53, 0.99] -> touch (an object) [0.03, 0.29, 0.53, 0.99]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "om_83F5VwTQ",
        "candidates": [
            "talk to (e.g., self, a person, a group) [0.01, 0.26, 0.54, 0.98] -> smoke [0.03, 0.29, 0.53, 0.99] -> touch (an object) [0.03, 0.29, 0.53, 0.99]",
            "talk to (e.g., self, a person, a group) [0.18, 0.42, 0.44, 1.00] -> smoke [0.00, 0.44, 0.65, 0.94] -> shoot [0.17, 0.18, 0.43, 0.86]",
            "smoke [0.00, 0.32, 0.63, 1.00] -> lie/sleep [0.12, 0.18, 0.47, 0.87] -> touch (an object) [0.00, 0.23, 0.46, 0.92]",
            "smoke [0.16, 0.21, 0.70, 1.00] -> crawl [0.17, 0.22, 0.56, 1.00] -> talk to (e.g., self, a person, a group) [0.00, 0.33, 0.53, 1.00]"
        ],
        "start": 0.0,
        "end": 336.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1254.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.27, 0.31, 0.66, 0.98]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "om_83F5VwTQ",
        "candidates": [
            "[0.49, 0.48, 0.90, 1.00]",
            "[0.57, 0.15, 0.91, 0.97]",
            "[0.15, 0.58, 0.49, 0.98]",
            "[0.27, 0.31, 0.66, 0.98]"
        ],
        "start": 0.0,
        "end": 359.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1333.0,
        "question": "What action is the person at the location [0.02, 0.20, 0.18, 0.61] in the image performing?",
        "answer": "stand, listen to (a person), watch (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "om_83F5VwTQ",
        "candidates": [
            "stand, talk to (e.g., self, a person, a group), watch (a person)",
            "sit, touch (an object), listen to (a person), watch (a person)",
            "stand, listen to (a person), watch (a person)",
            "stand, watch (a person)"
        ],
        "start": 0.0,
        "end": 438.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1407.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.35, 0.39, 0.70, 0.91] location?",
        "answer": "carry/hold (an object) [0.35, 0.39, 0.70, 0.91] -> touch (an object) [0.35, 0.39, 0.70, 0.91] -> talk to (e.g., self, a person, a group) [0.35, 0.39, 0.70, 0.91]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "om_83F5VwTQ",
        "candidates": [
            "talk to (e.g., self, a person, a group) [0.39, 0.31, 0.74, 1.00] -> touch (an object) [0.38, 0.33, 0.79, 0.87] -> run/jog [0.33, 0.36, 0.81, 0.85]",
            "grab (a person) [0.17, 0.41, 0.70, 0.76] -> touch (an object) [0.24, 0.23, 0.70, 0.74] -> carry/hold (an object) [0.19, 0.50, 0.71, 0.81]",
            "carry/hold (an object) [0.49, 0.23, 0.83, 0.90] -> shoot [0.27, 0.19, 0.51, 0.78] -> talk to (e.g., self, a person, a group) [0.35, 0.21, 0.88, 0.98]",
            "carry/hold (an object) [0.35, 0.39, 0.70, 0.91] -> touch (an object) [0.35, 0.39, 0.70, 0.91] -> talk to (e.g., self, a person, a group) [0.35, 0.39, 0.70, 0.91]"
        ],
        "start": 0.0,
        "end": 512.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1417.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.35, 0.38, 0.71, 0.89]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "om_83F5VwTQ",
        "candidates": [
            "[0.17, 0.47, 0.57, 1.00]",
            "[0.62, 0.21, 0.63, 0.69]",
            "[0.52, 0.24, 0.98, 0.95]",
            "[0.35, 0.38, 0.71, 0.89]"
        ],
        "start": 0.0,
        "end": 522.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1420.0,
        "question": "What action is the person at the location [0.00, 0.10, 0.14, 0.96] in the image performing?",
        "answer": "sit, touch (an object), listen to (a person), watch (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "om_83F5VwTQ",
        "candidates": [
            "sit, carry/hold (an object), touch (an object), listen to (a person)",
            "sit, touch (an object), watch (a person)",
            "sit, smoke, touch (an object), listen to (a person)",
            "sit, touch (an object), listen to (a person), watch (a person)"
        ],
        "start": 0.0,
        "end": 525.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1545.0,
        "question": "Are there still 3 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "om_83F5VwTQ",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 650.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1586.0,
        "question": "What action is the person at the location [0.01, 0.14, 0.60, 0.96] in the image performing?",
        "answer": "sit, carry/hold (an object), touch (an object), listen to (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "om_83F5VwTQ",
        "candidates": [
            "walk, listen to (a person), watch (a person)",
            "sit, carry/hold (an object), touch (an object), listen to (a person)",
            "sit, touch (an object), watch (a person)",
            "sit, touch (an object), listen to (a person), watch (a person)"
        ],
        "start": 0.0,
        "end": 691.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1594.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.01, 0.13, 0.56, 0.95] location?",
        "answer": "talk to (e.g., self, a person, a group) [0.03, 0.10, 0.55, 0.95] -> carry/hold (an object) [0.01, 0.13, 0.56, 0.95] -> touch (an object) [0.01, 0.13, 0.56, 0.95]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "om_83F5VwTQ",
        "candidates": [
            "play musical instrument [0.21, 0.24, 0.64, 0.94] -> carry/hold (an object) [0.00, 0.02, 0.41, 1.00] -> talk to (e.g., self, a person, a group) [0.15, 0.22, 0.57, 1.00]",
            "touch (an object) [0.00, 0.29, 0.53, 1.00] -> carry/hold (an object) [0.13, 0.14, 0.58, 0.87] -> play with pets [0.02, 0.17, 0.69, 0.86]",
            "talk to (e.g., self, a person, a group) [0.03, 0.10, 0.55, 0.95] -> carry/hold (an object) [0.01, 0.13, 0.56, 0.95] -> touch (an object) [0.01, 0.13, 0.56, 0.95]",
            "carry/hold (an object) [0.00, 0.27, 0.73, 1.00] -> talk to (e.g., self, a person, a group) [0.03, 0.09, 0.46, 0.83] -> hand wave [0.00, 0.07, 0.71, 1.00]"
        ],
        "start": 0.0,
        "end": 699.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1727.0,
        "question": "Are there still 3 people in the current frame now?",
        "answer": "No",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "om_83F5VwTQ",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 832.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1781.0,
        "question": "What action is the person currently in the [0.59, 0.14, 0.90, 0.96] location likely to do next?",
        "answer": "walk",
        "sub_answer_type": "FuturePrediction-1",
        "answer_type": "FuturePrediction",
        "video": "om_83F5VwTQ",
        "candidates": [
            "dig",
            "touch (an object)",
            "drink",
            "walk"
        ],
        "start": 0.0,
        "end": 886.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1782.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.71, 0.25, 0.88, 0.95]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "om_83F5VwTQ",
        "candidates": [
            "[0.01, 0.13, 0.56, 0.95]",
            "[0.56, 0.06, 0.73, 1.00]",
            "[0.71, 0.25, 0.88, 0.95]",
            "[0.69, 0.46, 0.62, 1.00]"
        ],
        "start": 0.0,
        "end": 887.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 907.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "bend/bow (at the waist) -> carry/hold (an object)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "qx2vAO5ofmo",
        "candidates": [
            "dress/put on clothing -> carry/hold (an object)",
            "carry/hold (an object) -> play with kids",
            "answer phone -> carry/hold (an object)",
            "bend/bow (at the waist) -> carry/hold (an object)"
        ],
        "start": 0.0,
        "end": 12.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 961.0,
        "question": "Where is the person currently performing the walk located in the picture?",
        "answer": "[0.42, 0.13, 0.75, 0.87]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "qx2vAO5ofmo",
        "candidates": [
            "[0.43, 0.31, 0.98, 0.98]",
            "[0.21, 0.07, 0.46, 0.58]",
            "[0.42, 0.13, 0.75, 0.87]",
            "[0.57, 0.11, 0.96, 0.87]"
        ],
        "start": 0.0,
        "end": 66.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 973.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.54, 0.15, 0.97, 0.85] location?",
        "answer": "walk [0.54, 0.15, 0.97, 0.85] -> carry/hold (an object) [0.54, 0.15, 0.97, 0.85] -> talk to (e.g., self, a person, a group) [0.54, 0.15, 0.97, 0.85]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "qx2vAO5ofmo",
        "candidates": [
            "walk [0.40, 0.23, 1.00, 1.00] -> exit [0.61, 0.13, 1.00, 0.69] -> talk to (e.g., self, a person, a group) [0.68, 0.00, 0.85, 0.80]",
            "fishing [0.51, 0.05, 0.88, 0.91] -> walk [0.64, 0.31, 1.00, 0.95] -> carry/hold (an object) [0.46, 0.00, 1.00, 1.00]",
            "walk [0.54, 0.15, 0.97, 0.85] -> carry/hold (an object) [0.54, 0.15, 0.97, 0.85] -> talk to (e.g., self, a person, a group) [0.54, 0.15, 0.97, 0.85]",
            "carry/hold (an object) [0.67, 0.22, 0.78, 0.74] -> put down [0.66, 0.32, 1.00, 0.80] -> talk to (e.g., self, a person, a group) [0.52, 0.00, 1.00, 0.82]"
        ],
        "start": 0.0,
        "end": 78.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 983.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.68, 0.12, 0.99, 0.86] location?",
        "answer": "carry/hold (an object) [0.37, 0.14, 0.79, 0.88] -> talk to (e.g., self, a person, a group) [0.37, 0.14, 0.79, 0.88] -> walk [0.68, 0.12, 0.99, 0.86]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "qx2vAO5ofmo",
        "candidates": [
            "carry/hold (an object) [0.47, 0.14, 0.91, 0.80] -> hug (a person) [0.79, 0.10, 1.00, 0.78] -> talk to (e.g., self, a person, a group) [0.29, 0.02, 0.94, 0.83]",
            "carry/hold (an object) [0.37, 0.14, 0.79, 0.88] -> talk to (e.g., self, a person, a group) [0.37, 0.14, 0.79, 0.88] -> walk [0.68, 0.12, 0.99, 0.86]",
            "walk [0.65, 0.15, 1.00, 1.00] -> talk to (e.g., self, a person, a group) [0.49, 0.10, 0.80, 1.00] -> fall down [0.32, 0.05, 0.77, 0.71]",
            "talk to (e.g., self, a person, a group) [0.47, 0.00, 0.69, 0.70] -> text on/look at a cellphone [0.50, 0.17, 0.79, 0.76] -> carry/hold (an object) [0.32, 0.29, 0.60, 0.94]"
        ],
        "start": 0.0,
        "end": 88.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1045.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.05, 0.14, 0.51, 0.79] location?",
        "answer": "talk to (e.g., self, a person, a group) [0.08, 0.13, 0.50, 0.77] -> carry/hold (an object) [0.05, 0.14, 0.51, 0.79] -> touch (an object) [0.05, 0.14, 0.51, 0.79]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "qx2vAO5ofmo",
        "candidates": [
            "fall down [0.00, 0.10, 0.38, 0.75] -> carry/hold (an object) [0.00, 0.09, 0.53, 0.87] -> talk to (e.g., self, a person, a group) [0.07, 0.22, 0.57, 0.77]",
            "talk to (e.g., self, a person, a group) [0.08, 0.13, 0.50, 0.77] -> carry/hold (an object) [0.05, 0.14, 0.51, 0.79] -> touch (an object) [0.05, 0.14, 0.51, 0.79]",
            "touch (an object) [0.00, 0.04, 0.36, 0.71] -> stir [0.00, 0.08, 0.45, 0.62] -> carry/hold (an object) [0.09, 0.00, 0.49, 0.68]",
            "talk to (e.g., self, a person, a group) [0.15, 0.29, 0.46, 0.72] -> bend/bow (at the waist) [0.13, 0.03, 0.58, 0.89] -> touch (an object) [0.20, 0.17, 0.65, 0.65]"
        ],
        "start": 0.0,
        "end": 150.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1047.0,
        "question": "Where was the person currently performing the touch (an object) in the scene 8 seconds ago?",
        "answer": "[0.16, 0.14, 0.52, 0.77]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "qx2vAO5ofmo",
        "candidates": [
            "[0.75, 0.28, 0.98, 0.87]",
            "[0.42, 0.00, 0.81, 0.63]",
            "[0.18, 0.43, 0.30, 0.72]",
            "[0.16, 0.14, 0.52, 0.77]"
        ],
        "start": 0.0,
        "end": 152.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1064.0,
        "question": "Are there still 4 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "qx2vAO5ofmo",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 169.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1161.0,
        "question": "How many people in the current frame are performing the action:  dance?",
        "answer": "4",
        "sub_answer_type": "SpatialPerception-2",
        "answer_type": "SpatialPerception",
        "video": "qx2vAO5ofmo",
        "candidates": [
            "4",
            "2",
            "3",
            "5"
        ],
        "start": 0.0,
        "end": 266.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1164.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.37, 0.32, 0.70, 0.89] location?",
        "answer": "carry/hold (an object) [0.37, 0.32, 0.70, 0.89] -> dance [0.37, 0.32, 0.70, 0.89] -> talk to (e.g., self, a person, a group) [0.37, 0.32, 0.70, 0.89]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "qx2vAO5ofmo",
        "candidates": [
            "dance [0.53, 0.16, 0.62, 0.78] -> write [0.28, 0.19, 0.57, 0.76] -> talk to (e.g., self, a person, a group) [0.50, 0.23, 0.51, 0.88]",
            "kick (an object) [0.17, 0.44, 0.51, 1.00] -> carry/hold (an object) [0.42, 0.14, 0.61, 0.87] -> talk to (e.g., self, a person, a group) [0.33, 0.27, 0.85, 0.85]",
            "carry/hold (an object) [0.37, 0.32, 0.70, 0.89] -> dance [0.37, 0.32, 0.70, 0.89] -> talk to (e.g., self, a person, a group) [0.37, 0.32, 0.70, 0.89]",
            "talk to (e.g., self, a person, a group) [0.42, 0.45, 0.78, 0.74] -> chop [0.45, 0.35, 0.79, 1.00] -> carry/hold (an object) [0.29, 0.20, 0.88, 0.71]"
        ],
        "start": 0.0,
        "end": 269.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1207.0,
        "question": "Is the person currently in the [0.27, 0.20, 0.51, 0.87] location in the current frame performing the touch (an object)?",
        "answer": "No",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "qx2vAO5ofmo",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 312.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1227.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "ride (e.g., a bike, a car, a horse) -> talk to (e.g., self, a person, a group)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "qx2vAO5ofmo",
        "candidates": [
            "ride (e.g., a bike, a car, a horse) -> talk to (e.g., self, a person, a group)",
            "talk to (e.g., self, a person, a group) -> talk to (e.g., self, a person, a group)",
            "chop -> ride (e.g., a bike, a car, a horse)",
            "ride (e.g., a bike, a car, a horse) -> touch (an object)"
        ],
        "start": 0.0,
        "end": 332.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1262.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.43, 0.27, 0.75, 0.87]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "qx2vAO5ofmo",
        "candidates": [
            "[0.43, 0.27, 0.75, 0.87]",
            "[0.54, 0.09, 0.95, 1.00]",
            "[0.19, 0.20, 0.51, 0.87]",
            "[0.44, 0.13, 0.63, 0.60]"
        ],
        "start": 0.0,
        "end": 367.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1294.0,
        "question": "Is the person currently in the [0.43, 0.24, 0.71, 0.86] location in the current frame performing the walk?",
        "answer": "No",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "qx2vAO5ofmo",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 399.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1311.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "close (e.g., a door, a box) -> walk -> carry/hold (an object)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "qx2vAO5ofmo",
        "candidates": [
            "enter -> carry/hold (an object) -> close (e.g., a door, a box)",
            "close (e.g., a door, a box) -> walk -> carry/hold (an object)",
            "press -> carry/hold (an object) -> close (e.g., a door, a box)",
            "close (e.g., a door, a box) -> bend/bow (at the waist) -> carry/hold (an object)"
        ],
        "start": 0.0,
        "end": 416.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1316.0,
        "question": "What action is the person currently in the [0.23, 0.20, 0.44, 0.87] location likely to do next?",
        "answer": "carry/hold (an object) and talk to (e.g., self, a person, a group)",
        "sub_answer_type": "FuturePrediction-1",
        "answer_type": "FuturePrediction",
        "video": "qx2vAO5ofmo",
        "candidates": [
            "fight/hit (a person)",
            "walk and carry/hold (an object)",
            "carry/hold (an object) and talk to (e.g., self, a person, a group)",
            "sing to (e.g., self, a person, a group)"
        ],
        "start": 0.0,
        "end": 421.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1319.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.24, 0.19, 0.41, 0.87] location?",
        "answer": "carry/hold (an object) [0.25, 0.19, 0.46, 0.88] -> talk to (e.g., self, a person, a group) [0.25, 0.19, 0.46, 0.88] -> walk [0.24, 0.19, 0.41, 0.87]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "qx2vAO5ofmo",
        "candidates": [
            "talk to (e.g., self, a person, a group) [0.41, 0.11, 0.33, 0.80] -> push (an object) [0.21, 0.18, 0.33, 0.78] -> carry/hold (an object) [0.11, 0.28, 0.59, 0.72]",
            "carry/hold (an object) [0.25, 0.19, 0.46, 0.88] -> talk to (e.g., self, a person, a group) [0.25, 0.19, 0.46, 0.88] -> walk [0.24, 0.19, 0.41, 0.87]",
            "walk [0.18, 0.12, 0.54, 0.90] -> eat [0.24, 0.35, 0.31, 0.93] -> carry/hold (an object) [0.26, 0.10, 0.32, 0.75]",
            "carry/hold (an object) [0.39, 0.30, 0.60, 0.95] -> walk [0.38, 0.22, 0.54, 1.00] -> push (another person) [0.15, 0.06, 0.57, 1.00]"
        ],
        "start": 0.0,
        "end": 424.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1328.0,
        "question": "What location in the frame is the person currently in the [0.42, 0.45, 0.62, 0.86] location likely to move to next?",
        "answer": "[0.72, 0.67, 0.91, 0.87]",
        "sub_answer_type": "FuturePrediction-2",
        "answer_type": "FuturePrediction",
        "video": "qx2vAO5ofmo",
        "candidates": [
            "[0.60, 0.93, 0.72, 0.84]",
            "[0.72, 0.67, 0.91, 0.87]",
            "[0.00, 0.22, 0.33, 0.87]",
            "[0.81, 0.48, 0.62, 0.81]"
        ],
        "start": 0.0,
        "end": 433.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1336.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "talk to (e.g., self, a person, a group) -> run/jog",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "qx2vAO5ofmo",
        "candidates": [
            "dress/put on clothing -> run/jog",
            "talk to (e.g., self, a person, a group) -> run/jog",
            "run/jog -> sing to (e.g., self, a person, a group)",
            "run/jog -> write"
        ],
        "start": 0.0,
        "end": 441.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1363.0,
        "question": "Where is the person currently performing the walk located in the picture?",
        "answer": "[0.41, 0.36, 0.55, 0.87]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "qx2vAO5ofmo",
        "candidates": [
            "[0.15, 0.19, 0.54, 0.78]",
            "[0.11, 0.51, 0.43, 0.83]",
            "[0.46, 0.16, 0.98, 0.91]",
            "[0.41, 0.36, 0.55, 0.87]"
        ],
        "start": 0.0,
        "end": 468.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1461.0,
        "question": "How many people were performing the stand in the scene 60 seconds ago?",
        "answer": "7",
        "sub_answer_type": "PastMemory-5",
        "answer_type": "PastMemory",
        "video": "qx2vAO5ofmo",
        "candidates": [
            "5",
            "4",
            "3",
            "7"
        ],
        "start": 0.0,
        "end": 566.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1506.0,
        "question": "Are there still 1 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "qx2vAO5ofmo",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 611.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1561.0,
        "question": "Where is the person currently performing the talk to (e.g., self, a person, a group) located in the picture?",
        "answer": "[0.26, 0.24, 0.82, 0.86]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "qx2vAO5ofmo",
        "candidates": [
            "[0.47, 0.00, 0.97, 0.70]",
            "[0.26, 0.24, 0.82, 0.86]",
            "[0.17, 0.27, 0.50, 0.87]",
            "[0.19, 0.44, 0.91, 1.00]"
        ],
        "start": 0.0,
        "end": 666.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1641.0,
        "question": "How many people were performing the listen to (a person) in the scene 240 seconds ago?",
        "answer": "6",
        "sub_answer_type": "PastMemory-5",
        "answer_type": "PastMemory",
        "video": "qx2vAO5ofmo",
        "candidates": [
            "4",
            "3",
            "6",
            "5"
        ],
        "start": 0.0,
        "end": 746.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1692.0,
        "question": "Where is the person currently performing the carry/hold (an object) located in the picture?",
        "answer": "[0.56, 0.31, 0.69, 0.77]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "qx2vAO5ofmo",
        "candidates": [
            "[0.81, 0.30, 0.98, 0.72]",
            "[0.06, 0.23, 0.80, 0.85]",
            "[0.74, 0.59, 0.88, 0.76]",
            "[0.56, 0.31, 0.69, 0.77]"
        ],
        "start": 0.0,
        "end": 797.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1703.0,
        "question": "How many people were performing the stand in the scene 300 seconds ago?",
        "answer": "7",
        "sub_answer_type": "PastMemory-5",
        "answer_type": "PastMemory",
        "video": "qx2vAO5ofmo",
        "candidates": [
            "6",
            "7",
            "3",
            "5"
        ],
        "start": 0.0,
        "end": 808.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1751.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "carry/hold (an object) -> read -> talk to (e.g., self, a person, a group)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "qx2vAO5ofmo",
        "candidates": [
            "talk to (e.g., self, a person, a group) -> climb (e.g., a mountain) -> carry/hold (an object)",
            "talk to (e.g., self, a person, a group) -> carry/hold (an object) -> lift/pick up",
            "carry/hold (an object) -> read -> talk to (e.g., self, a person, a group)",
            "carry/hold (an object) -> dress/put on clothing -> talk to (e.g., self, a person, a group)"
        ],
        "start": 0.0,
        "end": 856.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1006.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.21, 0.28, 0.48, 0.89] location?",
        "answer": "read [0.21, 0.28, 0.50, 0.90] -> talk to (e.g., self, a person, a group) [0.21, 0.28, 0.50, 0.90] -> carry/hold (an object) [0.21, 0.28, 0.48, 0.89]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "rXFlJbXyZyc",
        "candidates": [
            "read [0.13, 0.47, 0.53, 0.84] -> talk to (e.g., self, a person, a group) [0.23, 0.24, 0.50, 1.00] -> touch (an object) [0.15, 0.27, 0.37, 0.70]",
            "talk to (e.g., self, a person, a group) [0.36, 0.28, 0.52, 0.88] -> swim [0.17, 0.18, 0.60, 0.97] -> read [0.39, 0.28, 0.43, 1.00]",
            "carry/hold (an object) [0.14, 0.29, 0.61, 0.81] -> sail boat [0.39, 0.13, 0.41, 1.00] -> read [0.08, 0.10, 0.49, 1.00]",
            "read [0.21, 0.28, 0.50, 0.90] -> talk to (e.g., self, a person, a group) [0.21, 0.28, 0.50, 0.90] -> carry/hold (an object) [0.21, 0.28, 0.48, 0.89]"
        ],
        "start": 0.0,
        "end": 111.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1009.0,
        "question": "Are there still 2 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "rXFlJbXyZyc",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 114.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1016.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.10, 0.14, 0.44, 1.00] location?",
        "answer": "read [0.10, 0.18, 0.42, 0.99] -> walk [0.10, 0.14, 0.44, 1.00] -> carry/hold (an object) [0.10, 0.14, 0.44, 1.00]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "rXFlJbXyZyc",
        "candidates": [
            "take a photo [0.25, 0.13, 0.50, 0.93] -> walk [0.03, 0.30, 0.34, 0.83] -> read [0.28, 0.25, 0.39, 0.88]",
            "play board game [0.08, 0.29, 0.59, 0.97] -> carry/hold (an object) [0.28, 0.13, 0.35, 1.00] -> walk [0.18, 0.24, 0.58, 0.80]",
            "read [0.10, 0.18, 0.42, 0.99] -> walk [0.10, 0.14, 0.44, 1.00] -> carry/hold (an object) [0.10, 0.14, 0.44, 1.00]",
            "walk [0.17, 0.00, 0.46, 1.00] -> brush teeth [0.00, 0.09, 0.23, 0.84] -> carry/hold (an object) [0.08, 0.02, 0.28, 1.00]"
        ],
        "start": 0.0,
        "end": 121.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1030.0,
        "question": "What was the minimum number of people in the scene over the past 15 seconds?",
        "answer": "2",
        "sub_answer_type": "PastMemory-3",
        "answer_type": "PastMemory",
        "video": "rXFlJbXyZyc",
        "candidates": [
            "4",
            "2",
            "3",
            "1"
        ],
        "start": 0.0,
        "end": 135.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1031.0,
        "question": "What action is the person at the location [0.06, 0.12, 0.40, 0.99] in the image performing?",
        "answer": "walk, carry/hold (an object), listen to (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "rXFlJbXyZyc",
        "candidates": [
            "sit, listen to (a person)",
            "sit, talk to (e.g., self, a person, a group), watch (a person)",
            "walk, carry/hold (an object), listen to (a person)",
            "sit, listen to (a person), watch (a person)"
        ],
        "start": 0.0,
        "end": 136.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1034.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.00, 0.12, 0.38, 1.00] location?",
        "answer": "talk to (e.g., self, a person, a group) [0.02, 0.12, 0.37, 1.00] -> walk [0.00, 0.12, 0.38, 1.00] -> carry/hold (an object) [0.00, 0.12, 0.38, 1.00] -> read [0.00, 0.12, 0.38, 1.00]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "rXFlJbXyZyc",
        "candidates": [
            "kiss (a person) [0.00, 0.02, 0.46, 0.87] -> carry/hold (an object) [0.03, 0.20, 0.53, 0.96] -> read [0.00, 0.27, 0.36, 0.80] -> talk to (e.g., self, a person, a group) [0.07, 0.17, 0.56, 1.00]",
            "talk to (e.g., self, a person, a group) [0.02, 0.12, 0.37, 1.00] -> walk [0.00, 0.12, 0.38, 1.00] -> carry/hold (an object) [0.00, 0.12, 0.38, 1.00] -> read [0.00, 0.12, 0.38, 1.00]",
            "walk [0.00, 0.28, 0.55, 1.00] -> open (e.g., a window, a car door) [0.13, 0.16, 0.56, 0.89] -> talk to (e.g., self, a person, a group) [0.00, 0.02, 0.52, 1.00] -> carry/hold (an object) [0.00, 0.00, 0.57, 1.00]",
            "talk to (e.g., self, a person, a group) [0.00, 0.29, 0.50, 1.00] -> give/serve (an object) to (a person) [0.09, 0.00, 0.19, 1.00] -> read [0.00, 0.02, 0.39, 1.00] -> walk [0.01, 0.02, 0.49, 1.00]"
        ],
        "start": 0.0,
        "end": 139.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1075.0,
        "question": "What was the minimum number of people in the scene over the past 15 seconds?",
        "answer": "2",
        "sub_answer_type": "PastMemory-3",
        "answer_type": "PastMemory",
        "video": "rXFlJbXyZyc",
        "candidates": [
            "4",
            "1",
            "3",
            "2"
        ],
        "start": 0.0,
        "end": 180.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1125.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "walk -> carry/hold (an object)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "rXFlJbXyZyc",
        "candidates": [
            "walk -> carry/hold (an object)",
            "play with kids -> walk",
            "carry/hold (an object) -> ride (e.g., a bike, a car, a horse)",
            "carry/hold (an object) -> exit"
        ],
        "start": 0.0,
        "end": 230.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1164.0,
        "question": "Where is the person currently performing the walk located in the picture?",
        "answer": "[0.37, 0.12, 0.76, 0.87]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "rXFlJbXyZyc",
        "candidates": [
            "[0.37, 0.12, 0.76, 0.87]",
            "[0.28, 0.35, 0.98, 1.00]",
            "[0.59, 0.00, 1.00, 0.72]",
            "[0.03, 0.01, 0.72, 1.00]"
        ],
        "start": 0.0,
        "end": 269.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1268.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "walk -> talk to (e.g., self, a person, a group)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "rXFlJbXyZyc",
        "candidates": [
            "give/serve (an object) to (a person) -> walk",
            "walk -> talk to (e.g., self, a person, a group)",
            "walk -> row boat",
            "walk -> throw"
        ],
        "start": 0.0,
        "end": 373.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1297.0,
        "question": "Are there still 1 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "rXFlJbXyZyc",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 402.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1303.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "carry/hold (an object) -> talk to (e.g., self, a person, a group)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "rXFlJbXyZyc",
        "candidates": [
            "carry/hold (an object) -> watch (e.g., TV)",
            "carry/hold (an object) -> talk to (e.g., self, a person, a group)",
            "talk to (e.g., self, a person, a group) -> answer phone",
            "talk to (e.g., self, a person, a group) -> cook"
        ],
        "start": 0.0,
        "end": 408.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1317.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.59, 0.43, 0.87, 0.81] location?",
        "answer": "talk to (e.g., self, a person, a group) [0.59, 0.42, 0.88, 0.80] -> carry/hold (an object) [0.59, 0.43, 0.87, 0.81] -> sail boat [0.59, 0.43, 0.87, 0.81]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "rXFlJbXyZyc",
        "candidates": [
            "sail boat [0.54, 0.46, 1.00, 0.89] -> talk to (e.g., self, a person, a group) [0.50, 0.27, 0.83, 0.96] -> talk to (e.g., self, a person, a group) [0.50, 0.26, 1.00, 0.66]",
            "catch (an object) [0.55, 0.28, 1.00, 0.62] -> sail boat [0.74, 0.35, 0.85, 0.62] -> carry/hold (an object) [0.65, 0.37, 0.71, 0.66]",
            "catch (an object) [0.73, 0.55, 0.71, 0.98] -> talk to (e.g., self, a person, a group) [0.51, 0.24, 0.76, 0.65] -> carry/hold (an object) [0.58, 0.43, 0.68, 0.64]",
            "talk to (e.g., self, a person, a group) [0.59, 0.42, 0.88, 0.80] -> carry/hold (an object) [0.59, 0.43, 0.87, 0.81] -> sail boat [0.59, 0.43, 0.87, 0.81]"
        ],
        "start": 0.0,
        "end": 422.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1332.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.02, 0.09, 0.67, 0.99] location?",
        "answer": "carry/hold (an object) [0.02, 0.09, 0.67, 0.99] -> give/serve (an object) to (a person) [0.02, 0.09, 0.67, 0.99] -> talk to (e.g., self, a person, a group) [0.02, 0.09, 0.67, 0.99]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "rXFlJbXyZyc",
        "candidates": [
            "give/serve (an object) to (a person) [0.04, 0.00, 0.68, 0.89] -> talk to (e.g., self, a person, a group) [0.07, 0.15, 0.86, 1.00] -> cut [0.00, 0.22, 0.73, 1.00]",
            "give/serve (an object) to (a person) [0.09, 0.07, 0.49, 1.00] -> talk to (e.g., self, a person, a group) [0.18, 0.00, 0.70, 0.96] -> read [0.00, 0.08, 0.59, 0.88]",
            "row boat [0.15, 0.09, 0.60, 0.81] -> carry/hold (an object) [0.00, 0.07, 0.56, 0.87] -> talk to (e.g., self, a person, a group) [0.08, 0.08, 0.53, 0.99]",
            "carry/hold (an object) [0.02, 0.09, 0.67, 0.99] -> give/serve (an object) to (a person) [0.02, 0.09, 0.67, 0.99] -> talk to (e.g., self, a person, a group) [0.02, 0.09, 0.67, 0.99]"
        ],
        "start": 0.0,
        "end": 437.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1348.0,
        "question": "Where is the person currently performing the carry/hold (an object) located in the picture?",
        "answer": "[0.30, 0.15, 1.00, 0.99]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "rXFlJbXyZyc",
        "candidates": [
            "[0.09, 0.12, 0.89, 0.97]",
            "[0.30, 0.15, 1.00, 0.99]",
            "[0.47, 0.43, 1.00, 0.96]",
            "[0.20, 0.01, 1.00, 0.69]"
        ],
        "start": 0.0,
        "end": 453.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1355.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "talk to (e.g., self, a person, a group) -> carry/hold (an object)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "rXFlJbXyZyc",
        "candidates": [
            "carry/hold (an object) -> play musical instrument",
            "bend/bow (at the waist) -> talk to (e.g., self, a person, a group)",
            "talk to (e.g., self, a person, a group) -> carry/hold (an object)",
            "talk to (e.g., self, a person, a group) -> play musical instrument"
        ],
        "start": 0.0,
        "end": 460.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1382.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "carry/hold (an object) -> talk to (e.g., self, a person, a group)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "rXFlJbXyZyc",
        "candidates": [
            "talk to (e.g., self, a person, a group) -> point to (an object)",
            "talk to (e.g., self, a person, a group) -> dress/put on clothing",
            "talk to (e.g., self, a person, a group) -> cut",
            "carry/hold (an object) -> talk to (e.g., self, a person, a group)"
        ],
        "start": 0.0,
        "end": 487.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1444.0,
        "question": "What action is the person at the location [0.01, 0.19, 0.30, 0.98] in the image performing?",
        "answer": "walk, carry/hold (an object)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "rXFlJbXyZyc",
        "candidates": [
            "sit, listen to (a person)",
            "walk, carry/hold (an object)",
            "sit, carry/hold (an object), listen to (a person), watch (a person)",
            "stand, listen to (a person), watch (a person)"
        ],
        "start": 0.0,
        "end": 549.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1462.0,
        "question": "What was the minimum number of people in the scene over the past 15 seconds?",
        "answer": "4",
        "sub_answer_type": "PastMemory-3",
        "answer_type": "PastMemory",
        "video": "rXFlJbXyZyc",
        "candidates": [
            "2",
            "3",
            "1",
            "4"
        ],
        "start": 0.0,
        "end": 567.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1527.0,
        "question": "Is the person currently in the [0.35, 0.12, 0.68, 0.61] location in the current frame performing the carry/hold (an object)?",
        "answer": "No",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "rXFlJbXyZyc",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 632.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1598.0,
        "question": "Are there still 2 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "rXFlJbXyZyc",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 703.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1614.0,
        "question": "What action is the person currently in the [0.32, 0.01, 1.00, 1.00] location likely to do next?",
        "answer": "smoke",
        "sub_answer_type": "FuturePrediction-1",
        "answer_type": "FuturePrediction",
        "video": "rXFlJbXyZyc",
        "candidates": [
            "play musical instrument",
            "smoke",
            "dig",
            "talk to (e.g., self, a person, a group)"
        ],
        "start": 0.0,
        "end": 719.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1623.0,
        "question": "What was the minimum number of people in the scene over the past 30 seconds?",
        "answer": "1",
        "sub_answer_type": "PastMemory-3",
        "answer_type": "PastMemory",
        "video": "rXFlJbXyZyc",
        "candidates": [
            "2",
            "1",
            "3",
            "4"
        ],
        "start": 0.0,
        "end": 728.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1671.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.00, 0.09, 0.64, 0.99]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "rXFlJbXyZyc",
        "candidates": [
            "[0.33, 0.23, 0.66, 0.97]",
            "[0.25, 0.18, 0.91, 0.77]",
            "[0.00, 0.09, 0.64, 0.99]",
            "[0.00, 0.00, 0.37, 0.90]"
        ],
        "start": 0.0,
        "end": 776.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1686.0,
        "question": "Where is the person currently performing the carry/hold (an object) located in the picture?",
        "answer": "[0.28, 0.20, 0.70, 0.79]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "rXFlJbXyZyc",
        "candidates": [
            "[0.28, 0.20, 0.70, 0.79]",
            "[0.56, 0.48, 0.70, 0.65]",
            "[0.04, 0.16, 0.62, 1.00]",
            "[0.26, 0.00, 0.96, 0.50]"
        ],
        "start": 0.0,
        "end": 791.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 951.0,
        "question": "Where was the person currently performing the touch (an object) in the scene 8 seconds ago?",
        "answer": "[0.56, 0.18, 0.84, 0.95]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "sNQJfYvhcPk",
        "candidates": [
            "[0.03, 0.00, 0.83, 1.00]",
            "[0.83, 0.09, 0.81, 0.70]",
            "[0.67, 0.35, 0.94, 1.00]",
            "[0.56, 0.18, 0.84, 0.95]"
        ],
        "start": 0.0,
        "end": 56.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1017.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "walk -> carry/hold (an object)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "sNQJfYvhcPk",
        "candidates": [
            "walk -> work on a computer",
            "carry/hold (an object) -> write",
            "walk -> kick (an object)",
            "walk -> carry/hold (an object)"
        ],
        "start": 0.0,
        "end": 122.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1061.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.60, 0.24, 0.96, 0.92] location?",
        "answer": "touch (an object) [0.07, 0.03, 0.96, 1.00] -> talk to (e.g., self, a person, a group) [0.07, 0.03, 0.96, 1.00] -> drink [0.60, 0.24, 0.96, 0.92]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "sNQJfYvhcPk",
        "candidates": [
            "touch (an object) [0.07, 0.03, 0.96, 1.00] -> talk to (e.g., self, a person, a group) [0.07, 0.03, 0.96, 1.00] -> drink [0.60, 0.24, 0.96, 0.92]",
            "catch (an object) [0.07, 0.06, 1.00, 1.00] -> talk to (e.g., self, a person, a group) [0.24, 0.00, 1.00, 0.86] -> drink [0.64, 0.37, 0.89, 0.90]",
            "touch (an object) [0.00, 0.00, 1.00, 0.84] -> run/jog [0.10, 0.00, 1.00, 0.81] -> drink [0.50, 0.33, 0.96, 0.79]",
            "lift (a person) [0.68, 0.06, 1.00, 0.98] -> touch (an object) [0.18, 0.00, 0.77, 0.86] -> talk to (e.g., self, a person, a group) [0.00, 0.00, 0.79, 0.93]"
        ],
        "start": 0.0,
        "end": 166.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1064.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.56, 0.29, 0.96, 0.93] location?",
        "answer": "touch (an object) [0.56, 0.25, 0.97, 0.94] -> talk to (e.g., self, a person, a group) [0.56, 0.25, 0.97, 0.94] -> drink [0.56, 0.29, 0.96, 0.93]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "sNQJfYvhcPk",
        "candidates": [
            "watch (e.g., TV) [0.59, 0.15, 0.82, 0.74] -> touch (an object) [0.67, 0.28, 0.78, 0.76] -> drink [0.39, 0.21, 0.83, 0.88]",
            "talk to (e.g., self, a person, a group) [0.74, 0.10, 0.87, 0.74] -> drink [0.71, 0.25, 0.97, 0.85] -> shovel [0.65, 0.17, 1.00, 0.89]",
            "touch (an object) [0.61, 0.15, 0.93, 0.96] -> swim [0.68, 0.31, 0.80, 0.74] -> drink [0.51, 0.47, 0.77, 0.97]",
            "touch (an object) [0.56, 0.25, 0.97, 0.94] -> talk to (e.g., self, a person, a group) [0.56, 0.25, 0.97, 0.94] -> drink [0.56, 0.29, 0.96, 0.93]"
        ],
        "start": 0.0,
        "end": 169.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1068.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.57, 0.25, 0.97, 0.94] location?",
        "answer": "drink [0.57, 0.25, 0.97, 0.94] -> touch (an object) [0.57, 0.25, 0.97, 0.94] -> talk to (e.g., self, a person, a group) [0.57, 0.25, 0.97, 0.94]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "sNQJfYvhcPk",
        "candidates": [
            "drink [0.57, 0.25, 0.97, 0.94] -> touch (an object) [0.57, 0.25, 0.97, 0.94] -> talk to (e.g., self, a person, a group) [0.57, 0.25, 0.97, 0.94]",
            "drink [0.73, 0.30, 1.00, 1.00] -> talk to (e.g., self, a person, a group) [0.72, 0.25, 0.98, 0.88] -> turn (e.g., a screwdriver) [0.71, 0.30, 1.00, 0.91]",
            "drink [0.38, 0.25, 0.93, 1.00] -> touch (an object) [0.62, 0.38, 0.77, 1.00] -> hand wave [0.57, 0.22, 1.00, 0.92]",
            "talk to (e.g., self, a person, a group) [0.62, 0.22, 1.00, 1.00] -> touch (an object) [0.47, 0.16, 1.00, 0.87] -> give/serve (an object) to (a person) [0.51, 0.20, 0.94, 0.90]"
        ],
        "start": 0.0,
        "end": 173.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1072.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "touch (an object) -> talk to (e.g., self, a person, a group)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "sNQJfYvhcPk",
        "candidates": [
            "touch (an object) -> talk to (e.g., self, a person, a group)",
            "talk to (e.g., self, a person, a group) -> clink glass",
            "push (an object) -> touch (an object)",
            "smoke -> talk to (e.g., self, a person, a group)"
        ],
        "start": 0.0,
        "end": 177.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1079.0,
        "question": "Are there still 2 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "sNQJfYvhcPk",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 184.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1081.0,
        "question": "What action is the person at the location [0.02, 0.21, 0.48, 0.98] in the image performing?",
        "answer": "sit, answer phone, carry/hold (an object), touch (an object), talk to (e.g., self, a person, a group)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "sNQJfYvhcPk",
        "candidates": [
            "sit, answer phone",
            "stand, talk to (e.g., self, a person, a group), watch (a person)",
            "sit, answer phone, carry/hold (an object), touch (an object), talk to (e.g., self, a person, a group)",
            "sit, talk to (e.g., self, a person, a group), watch (a person)"
        ],
        "start": 0.0,
        "end": 186.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1136.0,
        "question": "What action is the person at the location [0.00, 0.11, 0.46, 0.98] in the image performing?",
        "answer": "sit, answer phone, touch (an object)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "sNQJfYvhcPk",
        "candidates": [
            "sit, answer phone, talk to (e.g., self, a person, a group)",
            "sit, answer phone, touch (an object)",
            "sit, answer phone",
            "sit, touch (an object), listen to (a person), watch (a person)"
        ],
        "start": 0.0,
        "end": 241.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1154.0,
        "question": "Where was the person currently performing the answer phone in the scene 8 seconds ago?",
        "answer": "[0.00, 0.12, 0.49, 0.98]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "sNQJfYvhcPk",
        "candidates": [
            "[0.00, 0.12, 0.49, 0.98]",
            "[0.56, 0.24, 0.68, 0.66]",
            "[0.00, 0.03, 0.73, 0.71]",
            "[0.04, 0.00, 0.37, 0.71]"
        ],
        "start": 0.0,
        "end": 259.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1166.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "talk to (e.g., self, a person, a group) -> carry/hold (an object)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "sNQJfYvhcPk",
        "candidates": [
            "talk to (e.g., self, a person, a group) -> carry/hold (an object)",
            "put down -> talk to (e.g., self, a person, a group)",
            "carry/hold (an object) -> hit (an object)",
            "hit (an object) -> carry/hold (an object)"
        ],
        "start": 0.0,
        "end": 271.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1183.0,
        "question": "Are there still 1 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "sNQJfYvhcPk",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 288.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1250.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.00, 0.02, 0.82, 0.99]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "sNQJfYvhcPk",
        "candidates": [
            "[0.03, 0.18, 0.42, 0.98]",
            "[0.15, 0.00, 1.00, 1.00]",
            "[0.00, 0.02, 0.82, 0.99]",
            "[0.00, 0.00, 0.66, 0.73]"
        ],
        "start": 0.0,
        "end": 355.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1274.0,
        "question": "Is the person currently in the [0.00, 0.02, 0.88, 0.99] location in the current frame performing the talk to (e.g., self, a person, a group)?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "sNQJfYvhcPk",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 379.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1298.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "touch (an object) -> talk to (e.g., self, a person, a group) -> get up -> bend/bow (at the waist) -> carry/hold (an object)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "sNQJfYvhcPk",
        "candidates": [
            "push (an object) -> touch (an object) -> get up -> talk to (e.g., self, a person, a group) -> bend/bow (at the waist)",
            "talk to (e.g., self, a person, a group) -> touch (an object) -> bend/bow (at the waist) -> get up -> lift/pick up",
            "carry/hold (an object) -> get up -> touch (an object) -> talk to (e.g., self, a person, a group) -> throw",
            "touch (an object) -> talk to (e.g., self, a person, a group) -> get up -> bend/bow (at the waist) -> carry/hold (an object)"
        ],
        "start": 0.0,
        "end": 403.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1343.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.69, 0.12, 0.94, 0.96] location?",
        "answer": "carry/hold (an object) [0.69, 0.12, 0.94, 0.96] -> touch (an object) [0.69, 0.12, 0.94, 0.96] -> talk to (e.g., self, a person, a group) [0.69, 0.12, 0.94, 0.96]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "sNQJfYvhcPk",
        "candidates": [
            "talk to (e.g., self, a person, a group) [0.59, 0.18, 0.99, 0.84] -> fishing [0.56, 0.21, 1.00, 0.86] -> touch (an object) [0.53, 0.00, 0.76, 1.00]",
            "eat [0.49, 0.29, 1.00, 0.89] -> carry/hold (an object) [0.72, 0.15, 1.00, 0.78] -> touch (an object) [0.85, 0.27, 1.00, 0.93]",
            "carry/hold (an object) [0.69, 0.12, 0.94, 0.96] -> touch (an object) [0.69, 0.12, 0.94, 0.96] -> talk to (e.g., self, a person, a group) [0.69, 0.12, 0.94, 0.96]",
            "touch (an object) [0.75, 0.28, 0.96, 0.86] -> carry/hold (an object) [0.71, 0.18, 0.85, 0.97] -> chop [0.60, 0.19, 1.00, 1.00]"
        ],
        "start": 0.0,
        "end": 448.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1346.0,
        "question": "What action is the person at the location [0.19, 0.47, 0.29, 0.87] in the image performing?",
        "answer": "walk, carry/hold (an object)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "sNQJfYvhcPk",
        "candidates": [
            "sit, read, touch (an object)",
            "sit, touch (an object), listen to (a person), watch (a person)",
            "walk, carry/hold (an object)",
            "sit, talk to (e.g., self, a person, a group), watch (a person)"
        ],
        "start": 0.0,
        "end": 451.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1353.0,
        "question": "What action is the person currently in the [0.03, 0.29, 0.41, 0.98] location likely to do next?",
        "answer": "work on a computer",
        "sub_answer_type": "FuturePrediction-1",
        "answer_type": "FuturePrediction",
        "video": "sNQJfYvhcPk",
        "candidates": [
            "talk to (e.g., self, a person, a group)",
            "walk",
            "play with pets",
            "work on a computer"
        ],
        "start": 0.0,
        "end": 458.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1438.0,
        "question": "What action is the person at the location [0.14, 0.31, 0.45, 0.78] in the image performing?",
        "answer": "sit, touch (an object), talk to (e.g., self, a person, a group), watch (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "sNQJfYvhcPk",
        "candidates": [
            "sit, answer phone",
            "sit, touch (an object), talk to (e.g., self, a person, a group), watch (a person)",
            "stand, listen to (a person), watch (a person)",
            "sit, touch (an object), listen to (a person), watch (a person)"
        ],
        "start": 0.0,
        "end": 543.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1440.0,
        "question": "Are there still 2 people in the current frame now?",
        "answer": "No",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "sNQJfYvhcPk",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 545.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1450.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.28, 0.11, 0.98, 0.95] location?",
        "answer": "read [0.28, 0.11, 0.98, 0.95] -> touch (an object) [0.28, 0.11, 0.98, 0.95] -> talk to (e.g., self, a person, a group) [0.28, 0.11, 0.98, 0.95]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "sNQJfYvhcPk",
        "candidates": [
            "climb (e.g., a mountain) [0.25, 0.14, 1.00, 0.80] -> read [0.47, 0.00, 0.79, 1.00] -> touch (an object) [0.26, 0.00, 0.85, 1.00]",
            "read [0.28, 0.11, 0.98, 0.95] -> touch (an object) [0.28, 0.11, 0.98, 0.95] -> talk to (e.g., self, a person, a group) [0.28, 0.11, 0.98, 0.95]",
            "close (e.g., a door, a box) [0.16, 0.08, 0.97, 0.95] -> read [0.08, 0.00, 1.00, 0.88] -> touch (an object) [0.14, 0.00, 0.90, 0.84]",
            "read [0.10, 0.26, 1.00, 1.00] -> read [0.30, 0.20, 0.84, 1.00] -> touch (an object) [0.08, 0.28, 0.92, 0.92]"
        ],
        "start": 0.0,
        "end": 555.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1592.0,
        "question": "Where was the person currently performing the touch (an object) in the scene 8 seconds ago?",
        "answer": "[0.36, 0.16, 0.59, 0.76]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "sNQJfYvhcPk",
        "candidates": [
            "[0.41, 0.00, 0.30, 0.46]",
            "[0.26, 0.00, 0.78, 0.58]",
            "[0.36, 0.16, 0.59, 0.76]",
            "[0.00, 0.12, 0.49, 0.98]"
        ],
        "start": 0.0,
        "end": 697.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1658.0,
        "question": "What action is the person at the location [0.08, 0.29, 0.33, 0.98] in the image performing?",
        "answer": "sit, talk to (e.g., self, a person, a group), watch (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "sNQJfYvhcPk",
        "candidates": [
            "sit, answer phone, touch (an object)",
            "sit, talk to (e.g., self, a person, a group), watch (a person)",
            "sit, answer phone",
            "stand, listen to (a person), watch (a person)"
        ],
        "start": 0.0,
        "end": 763.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1708.0,
        "question": "Are there still 1 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "sNQJfYvhcPk",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 813.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1749.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "walk -> carry/hold (an object)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "sNQJfYvhcPk",
        "candidates": [
            "walk -> brush teeth",
            "walk -> work on a computer",
            "walk -> carry/hold (an object)",
            "walk -> answer phone"
        ],
        "start": 0.0,
        "end": 854.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1781.0,
        "question": "Where was the person currently performing the walk in the scene 8 seconds ago?",
        "answer": "[0.31, 0.08, 0.99, 0.97]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "sNQJfYvhcPk",
        "candidates": [
            "[0.31, 0.08, 0.99, 0.97]",
            "[0.19, 0.38, 0.78, 1.00]",
            "[0.08, 0.14, 0.48, 0.98]",
            "[0.12, 0.00, 0.76, 0.81]"
        ],
        "start": 0.0,
        "end": 886.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 909.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "carry/hold (an object) -> talk to (e.g., self, a person, a group)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "tghXjom3120",
        "candidates": [
            "carry/hold (an object) -> point to (an object)",
            "eat -> carry/hold (an object)",
            "hand clap -> talk to (e.g., self, a person, a group)",
            "carry/hold (an object) -> talk to (e.g., self, a person, a group)"
        ],
        "start": 0.0,
        "end": 14.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 938.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.14, 0.59, 0.45, 0.98] location?",
        "answer": "carry/hold (an object) [0.16, 0.49, 0.46, 1.00] -> talk to (e.g., self, a person, a group) [0.16, 0.49, 0.46, 1.00] -> walk [0.14, 0.59, 0.45, 0.98]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "tghXjom3120",
        "candidates": [
            "paint [0.23, 0.55, 0.62, 0.97] -> talk to (e.g., self, a person, a group) [0.05, 0.57, 0.32, 1.00] -> walk [0.18, 0.47, 0.36, 0.95]",
            "push (an object) [0.07, 0.40, 0.63, 1.00] -> talk to (e.g., self, a person, a group) [0.24, 0.48, 0.65, 0.82] -> walk [0.03, 0.55, 0.47, 0.99]",
            "carry/hold (an object) [0.16, 0.49, 0.46, 1.00] -> talk to (e.g., self, a person, a group) [0.16, 0.49, 0.46, 1.00] -> walk [0.14, 0.59, 0.45, 0.98]",
            "walk [0.12, 0.42, 0.60, 1.00] -> hug (a person) [0.25, 0.52, 0.60, 1.00] -> carry/hold (an object) [0.03, 0.59, 0.37, 1.00]"
        ],
        "start": 0.0,
        "end": 43.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 957.0,
        "question": "Are there still 1 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "tghXjom3120",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 62.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1007.0,
        "question": "How many people in the current frame are performing the action:  carry/hold (an object)?",
        "answer": "4",
        "sub_answer_type": "SpatialPerception-2",
        "answer_type": "SpatialPerception",
        "video": "tghXjom3120",
        "candidates": [
            "5",
            "2",
            "4",
            "3"
        ],
        "start": 0.0,
        "end": 112.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1025.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "carry/hold (an object) -> talk to (e.g., self, a person, a group)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "tghXjom3120",
        "candidates": [
            "dress/put on clothing -> carry/hold (an object)",
            "touch (an object) -> carry/hold (an object)",
            "carry/hold (an object) -> talk to (e.g., self, a person, a group)",
            "carry/hold (an object) -> text on/look at a cellphone"
        ],
        "start": 0.0,
        "end": 130.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1045.0,
        "question": "How many people were performing the stand in the scene 120 seconds ago?",
        "answer": "7",
        "sub_answer_type": "PastMemory-5",
        "answer_type": "PastMemory",
        "video": "tghXjom3120",
        "candidates": [
            "7",
            "6",
            "5",
            "4"
        ],
        "start": 0.0,
        "end": 150.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1063.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "text on/look at a cellphone -> touch (an object) -> answer phone -> talk to (e.g., self, a person, a group)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "tghXjom3120",
        "candidates": [
            "text on/look at a cellphone -> touch (an object) -> answer phone -> talk to (e.g., self, a person, a group)",
            "text on/look at a cellphone -> touch (an object) -> answer phone -> bend/bow (at the waist)",
            "touch (an object) -> talk to (e.g., self, a person, a group) -> hug (a person) -> text on/look at a cellphone",
            "answer phone -> touch (an object) -> push (an object) -> talk to (e.g., self, a person, a group)"
        ],
        "start": 0.0,
        "end": 168.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1106.0,
        "question": "How many people in the current frame are performing the action:  carry/hold (an object)?",
        "answer": "2",
        "sub_answer_type": "SpatialPerception-2",
        "answer_type": "SpatialPerception",
        "video": "tghXjom3120",
        "candidates": [
            "5",
            "3",
            "2",
            "4"
        ],
        "start": 0.0,
        "end": 211.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1190.0,
        "question": "How many people were performing the dance in the scene 60 seconds ago?",
        "answer": "4",
        "sub_answer_type": "PastMemory-5",
        "answer_type": "PastMemory",
        "video": "tghXjom3120",
        "candidates": [
            "5",
            "6",
            "3",
            "4"
        ],
        "start": 0.0,
        "end": 295.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1225.0,
        "question": "How many people were performing the watch (a person) in the scene 60 seconds ago?",
        "answer": "5",
        "sub_answer_type": "PastMemory-5",
        "answer_type": "PastMemory",
        "video": "tghXjom3120",
        "candidates": [
            "6",
            "4",
            "5",
            "3"
        ],
        "start": 0.0,
        "end": 330.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1301.0,
        "question": "Are there still 1 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "tghXjom3120",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 406.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1327.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.54, 0.35, 0.72, 0.98] location?",
        "answer": "run/jog [0.54, 0.35, 0.72, 0.98] -> carry/hold (an object) [0.54, 0.35, 0.72, 0.98] -> talk to (e.g., self, a person, a group) [0.54, 0.35, 0.72, 0.98]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "tghXjom3120",
        "candidates": [
            "talk to (e.g., self, a person, a group) [0.56, 0.37, 0.54, 0.93] -> run/jog [0.48, 0.25, 0.72, 0.82] -> work on a computer [0.68, 0.17, 0.65, 1.00]",
            "give/serve (an object) to (a person) [0.73, 0.30, 0.73, 0.80] -> run/jog [0.42, 0.50, 0.70, 1.00] -> talk to (e.g., self, a person, a group) [0.56, 0.40, 0.76, 0.94]",
            "run/jog [0.73, 0.49, 0.63, 1.00] -> drive (e.g., a car, a truck) [0.46, 0.46, 0.81, 1.00] -> carry/hold (an object) [0.50, 0.34, 0.53, 1.00]",
            "run/jog [0.54, 0.35, 0.72, 0.98] -> carry/hold (an object) [0.54, 0.35, 0.72, 0.98] -> talk to (e.g., self, a person, a group) [0.54, 0.35, 0.72, 0.98]"
        ],
        "start": 0.0,
        "end": 432.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1378.0,
        "question": "How many people in the current frame are performing the action:  carry/hold (an object)?",
        "answer": "3",
        "sub_answer_type": "SpatialPerception-2",
        "answer_type": "SpatialPerception",
        "video": "tghXjom3120",
        "candidates": [
            "3",
            "6",
            "4",
            "2"
        ],
        "start": 0.0,
        "end": 483.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1413.0,
        "question": "How many people were performing the watch (a person) in the scene 300 seconds ago?",
        "answer": "6",
        "sub_answer_type": "PastMemory-5",
        "answer_type": "PastMemory",
        "video": "tghXjom3120",
        "candidates": [
            "7",
            "3",
            "5",
            "6"
        ],
        "start": 0.0,
        "end": 518.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1497.0,
        "question": "What action is the person currently in the [0.15, 0.06, 0.78, 0.98] location likely to do next?",
        "answer": "talk to (e.g., self, a person, a group)",
        "sub_answer_type": "FuturePrediction-1",
        "answer_type": "FuturePrediction",
        "video": "tghXjom3120",
        "candidates": [
            "climb (e.g., a mountain)",
            "fall down",
            "run/jog",
            "talk to (e.g., self, a person, a group)"
        ],
        "start": 0.0,
        "end": 602.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1499.0,
        "question": "Are there still 1 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "tghXjom3120",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 604.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1545.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "walk -> carry/hold (an object)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "tghXjom3120",
        "candidates": [
            "walk -> eat",
            "carry/hold (an object) -> kiss (a person)",
            "walk -> carry/hold (an object)",
            "walk -> turn (e.g., a screwdriver)"
        ],
        "start": 0.0,
        "end": 650.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1563.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.41, 0.08, 0.75, 0.99] location?",
        "answer": "carry/hold (an object) [0.50, 0.07, 0.80, 0.97] -> talk to (e.g., self, a person, a group) [0.50, 0.07, 0.80, 0.97] -> walk [0.41, 0.08, 0.75, 0.99]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "tghXjom3120",
        "candidates": [
            "fishing [0.30, 0.00, 0.94, 1.00] -> walk [0.58, 0.00, 0.61, 1.00] -> talk to (e.g., self, a person, a group) [0.43, 0.08, 0.96, 0.98]",
            "carry/hold (an object) [0.50, 0.07, 0.80, 0.97] -> talk to (e.g., self, a person, a group) [0.50, 0.07, 0.80, 0.97] -> walk [0.41, 0.08, 0.75, 0.99]",
            "walk [0.38, 0.27, 0.89, 1.00] -> talk to (e.g., self, a person, a group) [0.55, 0.24, 0.63, 0.88] -> stir [0.45, 0.26, 0.87, 0.89]",
            "enter [0.43, 0.10, 0.89, 0.91] -> walk [0.54, 0.12, 0.73, 1.00] -> carry/hold (an object) [0.55, 0.12, 0.92, 1.00]"
        ],
        "start": 0.0,
        "end": 668.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1566.0,
        "question": "Where was the person currently performing the grab (a person) in the scene 8 seconds ago?",
        "answer": "[0.52, 0.06, 0.87, 0.98]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "tghXjom3120",
        "candidates": [
            "[0.22, 0.17, 0.32, 0.58]",
            "[0.42, 0.13, 0.69, 0.70]",
            "[0.23, 0.00, 0.60, 1.00]",
            "[0.52, 0.06, 0.87, 0.98]"
        ],
        "start": 0.0,
        "end": 671.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1571.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "carry/hold (an object) -> talk to (e.g., self, a person, a group)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "tghXjom3120",
        "candidates": [
            "talk to (e.g., self, a person, a group) -> kick (an object)",
            "hug (a person) -> talk to (e.g., self, a person, a group)",
            "carry/hold (an object) -> talk to (e.g., self, a person, a group)",
            "talk to (e.g., self, a person, a group) -> shovel"
        ],
        "start": 0.0,
        "end": 676.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1606.0,
        "question": "Where is the person currently performing the carry/hold (an object) located in the picture?",
        "answer": "[0.25, 0.08, 0.89, 0.99]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "tghXjom3120",
        "candidates": [
            "[0.25, 0.08, 0.89, 0.99]",
            "[0.09, 0.26, 0.68, 0.74]",
            "[0.27, 0.35, 0.72, 1.00]",
            "[0.67, 0.44, 0.79, 0.70]"
        ],
        "start": 0.0,
        "end": 711.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1719.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.24, 0.29, 0.54, 0.99] location?",
        "answer": "walk [0.24, 0.29, 0.54, 0.99] -> grab (a person) [0.24, 0.29, 0.54, 0.99] -> talk to (e.g., self, a person, a group) [0.24, 0.29, 0.54, 0.99]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "tghXjom3120",
        "candidates": [
            "walk [0.24, 0.29, 0.54, 0.99] -> grab (a person) [0.24, 0.29, 0.54, 0.99] -> talk to (e.g., self, a person, a group) [0.24, 0.29, 0.54, 0.99]",
            "play with pets [0.32, 0.34, 0.57, 1.00] -> walk [0.34, 0.39, 0.64, 0.86] -> talk to (e.g., self, a person, a group) [0.40, 0.27, 0.35, 1.00]",
            "talk to (e.g., self, a person, a group) [0.21, 0.46, 0.73, 1.00] -> carry/hold (an object) [0.33, 0.12, 0.57, 1.00] -> walk [0.43, 0.13, 0.38, 1.00]",
            "grab (a person) [0.31, 0.16, 0.66, 0.97] -> take (an object) from (a person) [0.28, 0.39, 0.54, 0.81] -> walk [0.08, 0.28, 0.45, 1.00]"
        ],
        "start": 0.0,
        "end": 824.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1773.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.50, 0.56, 0.58, 0.68] location?",
        "answer": "lift/pick up [0.46, 0.55, 0.53, 0.69] -> bend/bow (at the waist) [0.50, 0.56, 0.58, 0.68] -> carry/hold (an object) [0.50, 0.56, 0.58, 0.68]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "tghXjom3120",
        "candidates": [
            "bend/bow (at the waist) [0.32, 0.50, 0.58, 0.64] -> push (another person) [0.28, 0.53, 0.61, 0.57] -> carry/hold (an object) [0.61, 0.61, 0.64, 0.56]",
            "lift/pick up [0.54, 0.69, 0.57, 0.75] -> dig [0.66, 0.66, 0.48, 0.60] -> bend/bow (at the waist) [0.33, 0.71, 0.68, 0.70]",
            "lift/pick up [0.34, 0.52, 0.56, 0.65] -> carry/hold (an object) [0.43, 0.54, 0.72, 0.59] -> martial art [0.50, 0.72, 0.39, 0.57]",
            "lift/pick up [0.46, 0.55, 0.53, 0.69] -> bend/bow (at the waist) [0.50, 0.56, 0.58, 0.68] -> carry/hold (an object) [0.50, 0.56, 0.58, 0.68]"
        ],
        "start": 0.0,
        "end": 878.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1793.0,
        "question": "What action is the person at the location [0.24, 0.24, 0.45, 1.00] in the image performing?",
        "answer": "stand, talk to (e.g., self, a person, a group), watch (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "tghXjom3120",
        "candidates": [
            "stand, listen to (a person), watch (a person)",
            "stand, talk to (e.g., self, a person, a group), watch (a person)",
            "stand, carry/hold (an object)",
            "walk, listen to (a person), watch (a person)"
        ],
        "start": 0.0,
        "end": 898.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 919.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.52, 0.06, 0.96, 0.98]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "u1ltv6r14KQ",
        "candidates": [
            "[0.24, 0.22, 1.00, 1.00]",
            "[0.78, 0.24, 1.00, 0.72]",
            "[0.52, 0.06, 0.96, 0.98]",
            "[0.11, 0.48, 0.32, 0.95]"
        ],
        "start": 0.0,
        "end": 24.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 978.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.48, 0.30, 0.57, 0.67]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "u1ltv6r14KQ",
        "candidates": [
            "[0.52, 0.06, 0.96, 0.98]",
            "[0.48, 0.30, 0.57, 0.67]",
            "[0.46, 0.53, 0.69, 0.84]",
            "[0.30, 0.16, 0.42, 0.90]"
        ],
        "start": 0.0,
        "end": 83.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1012.0,
        "question": "Where is the person currently performing the talk to (e.g., self, a person, a group) located in the picture?",
        "answer": "[0.16, 0.06, 0.99, 1.00]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "u1ltv6r14KQ",
        "candidates": [
            "[0.32, 0.27, 0.50, 0.50]",
            "[0.40, 0.32, 1.00, 0.91]",
            "[0.16, 0.06, 0.99, 1.00]",
            "[0.00, 0.32, 0.98, 1.00]"
        ],
        "start": 0.0,
        "end": 117.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1023.0,
        "question": "Are there still 1 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "u1ltv6r14KQ",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 128.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1030.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "carry/hold (an object) -> talk to (e.g., self, a person, a group)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "u1ltv6r14KQ",
        "candidates": [
            "text on/look at a cellphone -> talk to (e.g., self, a person, a group)",
            "carry/hold (an object) -> clink glass",
            "carry/hold (an object) -> talk to (e.g., self, a person, a group)",
            "run/jog -> carry/hold (an object)"
        ],
        "start": 0.0,
        "end": 135.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1043.0,
        "question": "Where was the person currently performing the carry/hold (an object) in the scene 8 seconds ago?",
        "answer": "[0.49, 0.31, 0.62, 0.77]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "u1ltv6r14KQ",
        "candidates": [
            "[0.15, 0.33, 0.66, 0.96]",
            "[0.62, 0.09, 0.88, 0.93]",
            "[0.35, 0.20, 0.89, 0.57]",
            "[0.49, 0.31, 0.62, 0.77]"
        ],
        "start": 0.0,
        "end": 148.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1046.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "open (e.g., a window, a car door) -> bend/bow (at the waist) -> carry/hold (an object)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "u1ltv6r14KQ",
        "candidates": [
            "open (e.g., a window, a car door) -> bend/bow (at the waist) -> carry/hold (an object)",
            "bend/bow (at the waist) -> throw -> open (e.g., a window, a car door)",
            "carry/hold (an object) -> crawl -> bend/bow (at the waist)",
            "open (e.g., a window, a car door) -> bend/bow (at the waist) -> sail boat"
        ],
        "start": 0.0,
        "end": 151.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1212.0,
        "question": "Is the person currently in the [0.36, 0.19, 0.72, 1.00] location in the current frame performing the talk to (e.g., self, a person, a group)?",
        "answer": "No",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "u1ltv6r14KQ",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 317.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1229.0,
        "question": "Where is the person currently performing the carry/hold (an object) located in the picture?",
        "answer": "[0.46, 0.23, 0.67, 0.94]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "u1ltv6r14KQ",
        "candidates": [
            "[0.78, 0.23, 0.97, 0.98]",
            "[0.46, 0.23, 0.67, 0.94]",
            "[0.59, 0.08, 0.69, 0.79]",
            "[0.29, 0.00, 0.52, 0.79]"
        ],
        "start": 0.0,
        "end": 334.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1308.0,
        "question": "What action is the person at the location [0.03, 0.10, 0.49, 0.89] in the image performing?",
        "answer": "sit, listen to (a person), talk to (e.g., self, a person, a group), watch (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "u1ltv6r14KQ",
        "candidates": [
            "sit, listen to (a person), talk to (e.g., self, a person, a group), watch (a person)",
            "sit, talk to (e.g., self, a person, a group), watch (a person)",
            "sit, talk to (e.g., self, a person, a group)",
            "stand, talk to (e.g., self, a person, a group)"
        ],
        "start": 0.0,
        "end": 413.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1325.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "carry/hold (an object) -> eat",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "u1ltv6r14KQ",
        "candidates": [
            "carry/hold (an object) -> cook",
            "eat -> extract",
            "swim -> eat",
            "carry/hold (an object) -> eat"
        ],
        "start": 0.0,
        "end": 430.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1367.0,
        "question": "Is the person currently in the [0.66, 0.11, 0.84, 0.94] location in the current frame performing the carry/hold (an object)?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "u1ltv6r14KQ",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 472.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1447.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.24, 0.19, 0.49, 0.99]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "u1ltv6r14KQ",
        "candidates": [
            "[0.18, 0.44, 0.29, 1.00]",
            "[0.24, 0.19, 0.49, 0.99]",
            "[0.39, 0.17, 0.98, 0.97]",
            "[0.41, 0.00, 0.69, 0.86]"
        ],
        "start": 0.0,
        "end": 552.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1550.0,
        "question": "What action is the person currently in the [0.14, 0.31, 0.64, 0.97] location likely to do next?",
        "answer": "carry/hold (an object) and talk to (e.g., self, a person, a group)",
        "sub_answer_type": "FuturePrediction-1",
        "answer_type": "FuturePrediction",
        "video": "u1ltv6r14KQ",
        "candidates": [
            "carry/hold (an object) and talk to (e.g., self, a person, a group)",
            "get up",
            "open (e.g., a window, a car door)",
            "pull (an object)"
        ],
        "start": 0.0,
        "end": 655.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1552.0,
        "question": "What action is the person at the location [0.20, 0.43, 0.60, 0.98] in the image performing?",
        "answer": "sit, lift/pick up, talk to (e.g., self, a person, a group)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "u1ltv6r14KQ",
        "candidates": [
            "stand, talk to (e.g., self, a person, a group), watch (a person)",
            "sit, talk to (e.g., self, a person, a group)",
            "sit, listen to (a person), watch (a person)",
            "sit, lift/pick up, talk to (e.g., self, a person, a group)"
        ],
        "start": 0.0,
        "end": 657.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1638.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "carry/hold (an object) -> touch (an object)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "u1ltv6r14KQ",
        "candidates": [
            "touch (an object) -> carry/hold (an object)",
            "fishing -> carry/hold (an object)",
            "carry/hold (an object) -> cut",
            "carry/hold (an object) -> touch (an object)"
        ],
        "start": 0.0,
        "end": 743.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1688.0,
        "question": "Are there still 1 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "u1ltv6r14KQ",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 793.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1734.0,
        "question": "What action is the person at the location [0.07, 0.31, 0.45, 0.98] in the image performing?",
        "answer": "sit, touch (an object), listen to (a person), watch (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "u1ltv6r14KQ",
        "candidates": [
            "sit, listen to (a person), watch (a person)",
            "stand, listen to (a person), watch (a person)",
            "stand, talk to (e.g., self, a person, a group), watch (a person)",
            "sit, touch (an object), listen to (a person), watch (a person)"
        ],
        "start": 0.0,
        "end": 839.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1758.0,
        "question": "Where was the person currently performing the carry/hold (an object) in the scene 8 seconds ago?",
        "answer": "[0.29, 0.03, 1.00, 1.00]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "u1ltv6r14KQ",
        "candidates": [
            "[0.29, 0.03, 1.00, 1.00]",
            "[0.52, 0.05, 1.00, 0.78]",
            "[0.56, 0.31, 1.00, 0.96]",
            "[0.00, 0.07, 0.93, 0.99]"
        ],
        "start": 0.0,
        "end": 863.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1788.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "carry/hold (an object) -> talk to (e.g., self, a person, a group)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "u1ltv6r14KQ",
        "candidates": [
            "stir -> talk to (e.g., self, a person, a group)",
            "carry/hold (an object) -> enter",
            "bend/bow (at the waist) -> talk to (e.g., self, a person, a group)",
            "carry/hold (an object) -> talk to (e.g., self, a person, a group)"
        ],
        "start": 0.0,
        "end": 893.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 948.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.39, 0.07, 0.98, 0.98]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "uNT6HrrnqPU",
        "candidates": [
            "[0.17, 0.05, 0.70, 0.82]",
            "[0.33, 0.00, 0.85, 0.79]",
            "[0.39, 0.48, 0.56, 0.99]",
            "[0.39, 0.07, 0.98, 0.98]"
        ],
        "start": 0.0,
        "end": 53.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 961.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "talk to (e.g., self, a person, a group) -> walk",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "uNT6HrrnqPU",
        "candidates": [
            "talk to (e.g., self, a person, a group) -> pull (an object)",
            "talk to (e.g., self, a person, a group) -> walk",
            "walk -> brush teeth",
            "push (another person) -> walk"
        ],
        "start": 0.0,
        "end": 66.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 970.0,
        "question": "Where is the person currently performing the walk located in the picture?",
        "answer": "[0.19, 0.07, 0.59, 0.98]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "uNT6HrrnqPU",
        "candidates": [
            "[0.33, 0.33, 0.86, 1.00]",
            "[0.54, 0.34, 0.62, 0.59]",
            "[0.00, 0.00, 0.48, 0.72]",
            "[0.19, 0.07, 0.59, 0.98]"
        ],
        "start": 0.0,
        "end": 75.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 974.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "carry/hold (an object) -> talk to (e.g., self, a person, a group)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "uNT6HrrnqPU",
        "candidates": [
            "cook -> talk to (e.g., self, a person, a group)",
            "carry/hold (an object) -> talk to (e.g., self, a person, a group)",
            "row boat -> talk to (e.g., self, a person, a group)",
            "carry/hold (an object) -> chop"
        ],
        "start": 0.0,
        "end": 79.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1053.0,
        "question": "Are there still 2 people in the current frame now?",
        "answer": "No",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "uNT6HrrnqPU",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 158.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1091.0,
        "question": "What action is the person currently in the [0.20, 0.44, 0.30, 0.96] location likely to do next?",
        "answer": "walk",
        "sub_answer_type": "FuturePrediction-1",
        "answer_type": "FuturePrediction",
        "video": "uNT6HrrnqPU",
        "candidates": [
            "walk",
            "jump/leap",
            "hand clap",
            "carry/hold (an object)"
        ],
        "start": 0.0,
        "end": 196.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1200.0,
        "question": "Where is the person currently performing the talk to (e.g., self, a person, a group) located in the picture?",
        "answer": "[0.05, 0.14, 0.93, 0.94]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "uNT6HrrnqPU",
        "candidates": [
            "[0.11, 0.14, 0.47, 0.98]",
            "[0.11, 0.00, 0.87, 0.72]",
            "[0.21, 0.43, 1.00, 1.00]",
            "[0.05, 0.14, 0.93, 0.94]"
        ],
        "start": 0.0,
        "end": 305.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1221.0,
        "question": "Are there still 1 people in the current frame now?",
        "answer": "No",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "uNT6HrrnqPU",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 326.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1239.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "bend/bow (at the waist) -> kiss (a person)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "uNT6HrrnqPU",
        "candidates": [
            "bend/bow (at the waist) -> write",
            "martial art -> bend/bow (at the waist)",
            "bend/bow (at the waist) -> kiss (a person)",
            "dress/put on clothing -> kiss (a person)"
        ],
        "start": 0.0,
        "end": 344.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1246.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.44, 0.56, 0.50, 0.72] location?",
        "answer": "carry/hold (an object) [0.44, 0.56, 0.50, 0.72] -> crouch/kneel [0.44, 0.56, 0.50, 0.72] -> fishing [0.44, 0.56, 0.50, 0.72]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "uNT6HrrnqPU",
        "candidates": [
            "carry/hold (an object) [0.44, 0.56, 0.50, 0.72] -> crouch/kneel [0.44, 0.56, 0.50, 0.72] -> fishing [0.44, 0.56, 0.50, 0.72]",
            "fishing [0.31, 0.73, 0.58, 0.62] -> touch (an object) [0.55, 0.50, 0.59, 0.84] -> carry/hold (an object) [0.31, 0.48, 0.32, 0.65]",
            "carry/hold (an object) [0.59, 0.74, 0.38, 0.58] -> crouch/kneel [0.37, 0.72, 0.57, 0.80] -> read [0.25, 0.68, 0.69, 0.66]",
            "carry/hold (an object) [0.40, 0.38, 0.63, 0.63] -> crouch/kneel [0.56, 0.56, 0.32, 0.86] -> cut [0.30, 0.54, 0.66, 0.64]"
        ],
        "start": 0.0,
        "end": 351.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1269.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.41, 0.17, 0.70, 0.99] location?",
        "answer": "carry/hold (an object) [0.40, 0.12, 0.66, 0.98] -> talk to (e.g., self, a person, a group) [0.40, 0.12, 0.66, 0.98] -> walk [0.41, 0.17, 0.70, 0.99]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "uNT6HrrnqPU",
        "candidates": [
            "carry/hold (an object) [0.40, 0.12, 0.66, 0.98] -> talk to (e.g., self, a person, a group) [0.40, 0.12, 0.66, 0.98] -> walk [0.41, 0.17, 0.70, 0.99]",
            "carry/hold (an object) [0.29, 0.14, 0.81, 0.85] -> talk to (e.g., self, a person, a group) [0.55, 0.00, 0.62, 0.86] -> fall down [0.58, 0.23, 0.53, 0.80]",
            "walk [0.39, 0.22, 0.67, 1.00] -> carry/hold (an object) [0.45, 0.00, 0.61, 0.79] -> shoot [0.39, 0.27, 0.78, 0.88]",
            "walk [0.41, 0.27, 0.75, 0.91] -> kiss (a person) [0.36, 0.17, 0.60, 1.00] -> carry/hold (an object) [0.42, 0.27, 0.64, 0.98]"
        ],
        "start": 0.0,
        "end": 374.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1271.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "carry/hold (an object) -> talk to (e.g., self, a person, a group)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "uNT6HrrnqPU",
        "candidates": [
            "carry/hold (an object) -> talk to (e.g., self, a person, a group)",
            "play musical instrument -> carry/hold (an object)",
            "talk to (e.g., self, a person, a group) -> shoot",
            "carry/hold (an object) -> catch (an object)"
        ],
        "start": 0.0,
        "end": 376.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1276.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "carry/hold (an object) -> crouch/kneel",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "uNT6HrrnqPU",
        "candidates": [
            "fall down -> crouch/kneel",
            "work on a computer -> carry/hold (an object)",
            "carry/hold (an object) -> crouch/kneel",
            "carry/hold (an object) -> shovel"
        ],
        "start": 0.0,
        "end": 381.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1356.0,
        "question": "Where was the person currently performing the walk in the scene 8 seconds ago?",
        "answer": "[0.00, 0.18, 0.28, 0.98]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "uNT6HrrnqPU",
        "candidates": [
            "[0.00, 0.17, 0.56, 0.69]",
            "[0.00, 0.44, 0.10, 1.00]",
            "[0.16, 0.02, 0.71, 0.98]",
            "[0.00, 0.18, 0.28, 0.98]"
        ],
        "start": 0.0,
        "end": 461.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1356.0,
        "question": "What action is the person at the location [0.39, 0.23, 0.59, 0.85] in the image performing?",
        "answer": "stand, carry/hold (an object), cook, watch (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "uNT6HrrnqPU",
        "candidates": [
            "stand, carry/hold (an object), listen to (a person), watch (a person)",
            "stand, carry/hold (an object)",
            "stand, carry/hold (an object), cook, watch (a person)",
            "dance, watch (a person)"
        ],
        "start": 0.0,
        "end": 461.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1415.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.26, 0.18, 0.61, 0.99] location?",
        "answer": "talk to (e.g., self, a person, a group) [0.31, 0.20, 0.62, 0.99] -> walk [0.26, 0.18, 0.61, 0.99] -> carry/hold (an object) [0.26, 0.18, 0.61, 0.99] -> grab (a person) [0.26, 0.18, 0.61, 0.99]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "uNT6HrrnqPU",
        "candidates": [
            "jump/leap [0.33, 0.26, 0.66, 0.83] -> talk to (e.g., self, a person, a group) [0.51, 0.08, 0.54, 1.00] -> walk [0.40, 0.19, 0.61, 1.00] -> grab (a person) [0.07, 0.31, 0.76, 0.89]",
            "talk to (e.g., self, a person, a group) [0.31, 0.20, 0.62, 0.99] -> walk [0.26, 0.18, 0.61, 0.99] -> carry/hold (an object) [0.26, 0.18, 0.61, 0.99] -> grab (a person) [0.26, 0.18, 0.61, 0.99]",
            "talk to (e.g., self, a person, a group) [0.41, 0.22, 0.62, 1.00] -> grab (a person) [0.31, 0.02, 0.61, 1.00] -> walk [0.32, 0.36, 0.60, 1.00] -> swim [0.10, 0.10, 0.76, 1.00]",
            "grab (a person) [0.33, 0.10, 0.79, 1.00] -> smoke [0.21, 0.20, 0.76, 1.00] -> carry/hold (an object) [0.14, 0.36, 0.74, 1.00] -> walk [0.40, 0.28, 0.76, 0.85]"
        ],
        "start": 0.0,
        "end": 520.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1547.0,
        "question": "How many people were performing the stand in the scene 120 seconds ago?",
        "answer": "6",
        "sub_answer_type": "PastMemory-5",
        "answer_type": "PastMemory",
        "video": "uNT6HrrnqPU",
        "candidates": [
            "6",
            "4",
            "3",
            "5"
        ],
        "start": 0.0,
        "end": 652.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1553.0,
        "question": "Are there still 3 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "uNT6HrrnqPU",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 658.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1573.0,
        "question": "What action is the person at the location [0.05, 0.41, 0.30, 0.94] in the image performing?",
        "answer": "sit, carry/hold (an object), eat",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "uNT6HrrnqPU",
        "candidates": [
            "sit, carry/hold (an object), eat",
            "stand, talk to (e.g., self, a person, a group), watch (a person)",
            "dance, watch (a person)",
            "stand, carry/hold (an object), talk to (e.g., self, a person, a group), watch (a person)"
        ],
        "start": 0.0,
        "end": 678.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1612.0,
        "question": "How many people were performing the stand in the scene 180 seconds ago?",
        "answer": "7",
        "sub_answer_type": "PastMemory-5",
        "answer_type": "PastMemory",
        "video": "uNT6HrrnqPU",
        "candidates": [
            "4",
            "7",
            "5",
            "3"
        ],
        "start": 0.0,
        "end": 717.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1681.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.36, 0.19, 0.59, 0.99] location?",
        "answer": "walk [0.36, 0.19, 0.59, 0.99] -> carry/hold (an object) [0.36, 0.19, 0.59, 0.99] -> talk to (e.g., self, a person, a group) [0.36, 0.19, 0.59, 0.99]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "uNT6HrrnqPU",
        "candidates": [
            "carry/hold (an object) [0.33, 0.12, 0.42, 0.92] -> swim [0.40, 0.33, 0.41, 1.00] -> walk [0.25, 0.27, 0.60, 1.00]",
            "walk [0.35, 0.20, 0.56, 1.00] -> lift/pick up [0.46, 0.10, 0.63, 1.00] -> talk to (e.g., self, a person, a group) [0.35, 0.11, 0.41, 1.00]",
            "kick (a person) [0.44, 0.38, 0.55, 0.85] -> carry/hold (an object) [0.41, 0.02, 0.76, 1.00] -> walk [0.48, 0.00, 0.50, 0.85]",
            "walk [0.36, 0.19, 0.59, 0.99] -> carry/hold (an object) [0.36, 0.19, 0.59, 0.99] -> talk to (e.g., self, a person, a group) [0.36, 0.19, 0.59, 0.99]"
        ],
        "start": 0.0,
        "end": 786.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1685.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.03, 0.37, 0.54, 0.99] location?",
        "answer": "walk [0.03, 0.37, 0.54, 0.99] -> carry/hold (an object) [0.03, 0.37, 0.54, 0.99] -> talk to (e.g., self, a person, a group) [0.03, 0.37, 0.54, 0.99]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "uNT6HrrnqPU",
        "candidates": [
            "walk [0.04, 0.44, 0.61, 1.00] -> dress/put on clothing [0.00, 0.52, 0.72, 1.00] -> carry/hold (an object) [0.18, 0.53, 0.39, 1.00]",
            "enter [0.00, 0.35, 0.48, 0.80] -> walk [0.21, 0.42, 0.56, 0.90] -> carry/hold (an object) [0.00, 0.34, 0.42, 0.85]",
            "walk [0.03, 0.37, 0.54, 0.99] -> carry/hold (an object) [0.03, 0.37, 0.54, 0.99] -> talk to (e.g., self, a person, a group) [0.03, 0.37, 0.54, 0.99]",
            "talk to (e.g., self, a person, a group) [0.16, 0.43, 0.59, 0.83] -> walk [0.08, 0.35, 0.62, 0.94] -> hand clap [0.04, 0.30, 0.51, 1.00]"
        ],
        "start": 0.0,
        "end": 790.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1693.0,
        "question": "How many people in the current frame are performing the action:  carry/hold (an object)?",
        "answer": "3",
        "sub_answer_type": "SpatialPerception-2",
        "answer_type": "SpatialPerception",
        "video": "uNT6HrrnqPU",
        "candidates": [
            "2",
            "4",
            "5",
            "3"
        ],
        "start": 0.0,
        "end": 798.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1709.0,
        "question": "Is the person currently in the [0.36, 0.34, 0.95, 1.00] location in the current frame performing the talk to (e.g., self, a person, a group)?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "uNT6HrrnqPU",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 814.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1718.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.00, 0.01, 0.56, 0.99]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "uNT6HrrnqPU",
        "candidates": [
            "[0.00, 0.01, 0.56, 0.99]",
            "[0.29, 0.26, 0.54, 0.98]",
            "[0.06, 0.00, 0.76, 0.72]",
            "[0.03, 0.00, 0.27, 0.81]"
        ],
        "start": 0.0,
        "end": 823.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 977.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "carry/hold (an object) -> talk to (e.g., self, a person, a group)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "wONG7Vh87B4",
        "candidates": [
            "carry/hold (an object) -> talk to (e.g., self, a person, a group)",
            "talk to (e.g., self, a person, a group) -> sing to (e.g., self, a person, a group)",
            "talk to (e.g., self, a person, a group) -> kick (a person)",
            "talk to (e.g., self, a person, a group) -> lie/sleep"
        ],
        "start": 0.0,
        "end": 82.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 988.0,
        "question": "Are there still 2 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "wONG7Vh87B4",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 93.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1026.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "talk to (e.g., self, a person, a group) -> lie/sleep",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "wONG7Vh87B4",
        "candidates": [
            "lie/sleep -> climb (e.g., a mountain)",
            "hit (an object) -> talk to (e.g., self, a person, a group)",
            "talk to (e.g., self, a person, a group) -> lie/sleep",
            "run/jog -> talk to (e.g., self, a person, a group)"
        ],
        "start": 0.0,
        "end": 131.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1059.0,
        "question": "Where was the person currently performing the touch (an object) in the scene 8 seconds ago?",
        "answer": "[0.26, 0.32, 0.42, 0.98]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "wONG7Vh87B4",
        "candidates": [
            "[0.48, 0.19, 0.73, 0.87]",
            "[0.52, 0.06, 0.43, 0.74]",
            "[0.26, 0.32, 0.42, 0.98]",
            "[0.25, 0.05, 0.15, 1.00]"
        ],
        "start": 0.0,
        "end": 164.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1068.0,
        "question": "Where is the person currently performing the touch (an object) located in the picture?",
        "answer": "[0.01, 0.00, 0.77, 0.99]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "wONG7Vh87B4",
        "candidates": [
            "[0.01, 0.00, 0.77, 0.99]",
            "[0.00, 0.26, 0.48, 0.79]",
            "[0.11, 0.26, 0.91, 1.00]",
            "[0.22, 0.04, 0.94, 0.89]"
        ],
        "start": 0.0,
        "end": 173.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1129.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.54, 0.40, 0.67, 0.90] location?",
        "answer": "walk [0.54, 0.40, 0.67, 0.90] -> carry/hold (an object) [0.54, 0.40, 0.67, 0.90] -> talk to (e.g., self, a person, a group) [0.54, 0.40, 0.67, 0.90]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "wONG7Vh87B4",
        "candidates": [
            "walk [0.54, 0.40, 0.67, 0.90] -> carry/hold (an object) [0.54, 0.40, 0.67, 0.90] -> talk to (e.g., self, a person, a group) [0.54, 0.40, 0.67, 0.90]",
            "talk to (e.g., self, a person, a group) [0.44, 0.49, 0.57, 0.73] -> sail boat [0.39, 0.59, 0.78, 0.81] -> carry/hold (an object) [0.74, 0.59, 0.83, 1.00]",
            "walk [0.68, 0.33, 0.81, 0.95] -> fight/hit (a person) [0.38, 0.25, 0.62, 0.82] -> carry/hold (an object) [0.51, 0.28, 0.68, 0.88]",
            "carry/hold (an object) [0.49, 0.41, 0.75, 0.94] -> exit [0.73, 0.60, 0.61, 1.00] -> walk [0.64, 0.39, 0.61, 0.94]"
        ],
        "start": 0.0,
        "end": 234.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1136.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.48, 0.34, 0.64, 0.98] location?",
        "answer": "walk [0.48, 0.34, 0.64, 0.98] -> carry/hold (an object) [0.48, 0.34, 0.64, 0.98] -> talk to (e.g., self, a person, a group) [0.48, 0.34, 0.64, 0.98]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "wONG7Vh87B4",
        "candidates": [
            "play with kids [0.32, 0.46, 0.47, 0.85] -> carry/hold (an object) [0.31, 0.20, 0.79, 1.00] -> talk to (e.g., self, a person, a group) [0.48, 0.44, 0.52, 0.81]",
            "bend/bow (at the waist) [0.45, 0.32, 0.55, 0.80] -> walk [0.49, 0.45, 0.80, 1.00] -> carry/hold (an object) [0.65, 0.14, 0.76, 0.93]",
            "talk to (e.g., self, a person, a group) [0.56, 0.30, 0.56, 0.93] -> put down [0.65, 0.50, 0.81, 1.00] -> carry/hold (an object) [0.47, 0.39, 0.81, 0.96]",
            "walk [0.48, 0.34, 0.64, 0.98] -> carry/hold (an object) [0.48, 0.34, 0.64, 0.98] -> talk to (e.g., self, a person, a group) [0.48, 0.34, 0.64, 0.98]"
        ],
        "start": 0.0,
        "end": 241.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1166.0,
        "question": "Where is the person currently performing the open (e.g., a window, a car door) located in the picture?",
        "answer": "[0.18, 0.08, 0.59, 0.95]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "wONG7Vh87B4",
        "candidates": [
            "[0.00, 0.00, 0.39, 1.00]",
            "[0.38, 0.11, 0.77, 0.99]",
            "[0.18, 0.08, 0.59, 0.95]",
            "[0.36, 0.00, 0.46, 0.72]"
        ],
        "start": 0.0,
        "end": 271.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1311.0,
        "question": "Are there still 1 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "wONG7Vh87B4",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 416.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1347.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.22, 0.19, 0.40, 0.99]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "wONG7Vh87B4",
        "candidates": [
            "[0.22, 0.19, 0.40, 0.99]",
            "[0.03, 0.07, 0.94, 0.97]",
            "[0.00, 0.00, 0.24, 1.00]",
            "[0.19, 0.46, 0.26, 1.00]"
        ],
        "start": 0.0,
        "end": 452.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1361.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "walk -> carry/hold (an object)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "wONG7Vh87B4",
        "candidates": [
            "carry/hold (an object) -> fall down",
            "walk -> carry/hold (an object)",
            "shovel -> carry/hold (an object)",
            "walk -> exit"
        ],
        "start": 0.0,
        "end": 466.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1369.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "walk -> carry/hold (an object)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "wONG7Vh87B4",
        "candidates": [
            "walk -> carry/hold (an object)",
            "carry/hold (an object) -> enter",
            "kiss (a person) -> walk",
            "drink -> carry/hold (an object)"
        ],
        "start": 0.0,
        "end": 474.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1436.0,
        "question": "What action is the person at the location [0.00, 0.00, 0.27, 1.00] in the image performing?",
        "answer": "stand, carry/hold (an object), watch (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "wONG7Vh87B4",
        "candidates": [
            "stand, talk to (e.g., self, a person, a group), watch (a person)",
            "stand, listen to (a person), watch (a person)",
            "stand, carry/hold (an object), watch (a person)",
            "stand, talk to (e.g., self, a person, a group)"
        ],
        "start": 0.0,
        "end": 541.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1456.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.49, 0.23, 0.58, 0.64] location?",
        "answer": "walk [0.49, 0.23, 0.58, 0.64] -> carry/hold (an object) [0.49, 0.23, 0.58, 0.64] -> pull (an object) [0.49, 0.23, 0.58, 0.64]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "wONG7Vh87B4",
        "candidates": [
            "crouch/kneel [0.68, 0.22, 0.68, 0.68] -> carry/hold (an object) [0.44, 0.19, 0.52, 0.61] -> pull (an object) [0.52, 0.13, 0.51, 0.71]",
            "carry/hold (an object) [0.32, 0.21, 0.43, 0.80] -> walk [0.59, 0.39, 0.65, 0.64] -> take (an object) from (a person) [0.62, 0.40, 0.65, 0.63]",
            "walk [0.49, 0.23, 0.58, 0.64] -> carry/hold (an object) [0.49, 0.23, 0.58, 0.64] -> pull (an object) [0.49, 0.23, 0.58, 0.64]",
            "swim [0.31, 0.14, 0.67, 0.84] -> pull (an object) [0.38, 0.28, 0.77, 0.79] -> walk [0.36, 0.25, 0.70, 0.57]"
        ],
        "start": 0.0,
        "end": 561.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1492.0,
        "question": "What action is the person currently in the [0.00, 0.07, 0.99, 1.00] location likely to do next?",
        "answer": "carry/hold (an object) and lie/sleep",
        "sub_answer_type": "FuturePrediction-1",
        "answer_type": "FuturePrediction",
        "video": "wONG7Vh87B4",
        "candidates": [
            "carry/hold (an object) and lie/sleep",
            "smoke",
            "touch (an object)",
            "hand shake"
        ],
        "start": 0.0,
        "end": 597.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1494.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "carry/hold (an object) -> lie/sleep",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "wONG7Vh87B4",
        "candidates": [
            "hand shake -> lie/sleep",
            "fishing -> lie/sleep",
            "carry/hold (an object) -> lie/sleep",
            "lift/pick up -> lie/sleep"
        ],
        "start": 0.0,
        "end": 599.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1538.0,
        "question": "Are there still 2 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "wONG7Vh87B4",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 643.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1571.0,
        "question": "Where is the person currently performing the talk to (e.g., self, a person, a group) located in the picture?",
        "answer": "[0.37, 0.10, 0.72, 0.98]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "wONG7Vh87B4",
        "candidates": [
            "[0.07, 0.04, 0.70, 0.99]",
            "[0.36, 0.40, 0.98, 1.00]",
            "[0.37, 0.10, 0.72, 0.98]",
            "[0.63, 0.00, 0.70, 0.74]"
        ],
        "start": 0.0,
        "end": 676.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1605.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.46, 0.10, 0.66, 0.99]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "wONG7Vh87B4",
        "candidates": [
            "[0.30, 0.00, 0.36, 1.00]",
            "[0.66, 0.00, 0.94, 0.99]",
            "[0.33, 0.34, 0.54, 0.99]",
            "[0.46, 0.10, 0.66, 0.99]"
        ],
        "start": 0.0,
        "end": 710.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1620.0,
        "question": "Where was the person currently performing the walk in the scene 8 seconds ago?",
        "answer": "[0.43, 0.05, 0.96, 0.99]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "wONG7Vh87B4",
        "candidates": [
            "[0.65, 0.32, 1.00, 1.00]",
            "[0.20, 0.34, 0.87, 1.00]",
            "[0.43, 0.05, 0.96, 0.99]",
            "[0.05, 0.02, 0.90, 1.00]"
        ],
        "start": 0.0,
        "end": 725.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1633.0,
        "question": "What action is the person at the location [0.08, 0.04, 0.43, 0.99] in the image performing?",
        "answer": "stand, listen to (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "wONG7Vh87B4",
        "candidates": [
            "stand, watch (a person)",
            "stand, carry/hold (an object), talk to (e.g., self, a person, a group), watch (a person)",
            "stand, listen to (a person)",
            "stand, carry/hold (an object), talk to (e.g., self, a person, a group)"
        ],
        "start": 0.0,
        "end": 738.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1644.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.46, 0.20, 0.61, 0.95] location?",
        "answer": "talk to (e.g., self, a person, a group) [0.45, 0.16, 0.64, 0.97] -> carry/hold (an object) [0.46, 0.20, 0.61, 0.95] -> touch (an object) [0.46, 0.20, 0.61, 0.95]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "wONG7Vh87B4",
        "candidates": [
            "touch (an object) [0.66, 0.33, 0.64, 0.85] -> cut [0.41, 0.25, 0.50, 0.76] -> talk to (e.g., self, a person, a group) [0.58, 0.35, 0.44, 1.00]",
            "touch (an object) [0.37, 0.15, 0.48, 1.00] -> talk to (e.g., self, a person, a group) [0.35, 0.29, 0.57, 1.00] -> ride (e.g., a bike, a car, a horse) [0.52, 0.31, 0.51, 1.00]",
            "carry/hold (an object) [0.42, 0.06, 0.46, 1.00] -> hand clap [0.31, 0.29, 0.79, 1.00] -> talk to (e.g., self, a person, a group) [0.37, 0.31, 0.72, 0.90]",
            "talk to (e.g., self, a person, a group) [0.45, 0.16, 0.64, 0.97] -> carry/hold (an object) [0.46, 0.20, 0.61, 0.95] -> touch (an object) [0.46, 0.20, 0.61, 0.95]"
        ],
        "start": 0.0,
        "end": 749.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1731.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.45, 0.16, 0.95, 0.98]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "wONG7Vh87B4",
        "candidates": [
            "[0.33, 0.34, 0.54, 0.99]",
            "[0.60, 0.04, 1.00, 0.83]",
            "[0.20, 0.00, 1.00, 0.73]",
            "[0.45, 0.16, 0.95, 0.98]"
        ],
        "start": 0.0,
        "end": 836.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1762.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.50, 0.07, 0.67, 0.99] location?",
        "answer": "walk [0.50, 0.07, 0.67, 0.99] -> carry/hold (an object) [0.50, 0.07, 0.67, 0.99] -> talk to (e.g., self, a person, a group) [0.50, 0.07, 0.67, 0.99]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "wONG7Vh87B4",
        "candidates": [
            "swim [0.51, 0.17, 0.77, 0.90] -> walk [0.64, 0.18, 0.52, 1.00] -> talk to (e.g., self, a person, a group) [0.51, 0.00, 0.86, 0.85]",
            "cut [0.60, 0.00, 0.53, 1.00] -> carry/hold (an object) [0.53, 0.08, 0.51, 0.86] -> walk [0.42, 0.00, 0.51, 0.86]",
            "walk [0.50, 0.07, 0.67, 0.99] -> carry/hold (an object) [0.50, 0.07, 0.67, 0.99] -> talk to (e.g., self, a person, a group) [0.50, 0.07, 0.67, 0.99]",
            "carry/hold (an object) [0.40, 0.06, 0.58, 0.80] -> carry/hold (an object) [0.67, 0.06, 0.81, 1.00] -> walk [0.61, 0.14, 0.65, 0.96]"
        ],
        "start": 0.0,
        "end": 867.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1786.0,
        "question": "Are there still 6 people in the current frame now?",
        "answer": "No",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "wONG7Vh87B4",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 891.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 914.0,
        "question": "Where was the person currently performing the smoke in the scene 8 seconds ago?",
        "answer": "[0.25, 0.00, 0.98, 0.97]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "xeGWXqSvC-8",
        "candidates": [
            "[0.17, 0.00, 0.74, 0.99]",
            "[0.25, 0.00, 0.98, 0.97]",
            "[0.09, 0.00, 0.72, 0.70]",
            "[0.03, 0.04, 0.54, 1.00]"
        ],
        "start": 0.0,
        "end": 19.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 929.0,
        "question": "Are there still 1 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "xeGWXqSvC-8",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 34.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 947.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "smoke -> talk to (e.g., self, a person, a group)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "xeGWXqSvC-8",
        "candidates": [
            "smoke -> carry/hold (an object)",
            "hug (a person) -> talk to (e.g., self, a person, a group)",
            "brush teeth -> smoke",
            "smoke -> talk to (e.g., self, a person, a group)"
        ],
        "start": 0.0,
        "end": 52.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 963.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "talk to (e.g., self, a person, a group) -> carry/hold (an object)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "xeGWXqSvC-8",
        "candidates": [
            "talk to (e.g., self, a person, a group) -> ride (e.g., a bike, a car, a horse)",
            "talk to (e.g., self, a person, a group) -> carry/hold (an object)",
            "drive (e.g., a car, a truck) -> carry/hold (an object)",
            "hug (a person) -> carry/hold (an object)"
        ],
        "start": 0.0,
        "end": 68.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1049.0,
        "question": "Where is the person currently performing the sail boat located in the picture?",
        "answer": "[0.50, 0.03, 0.64, 0.26]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "xeGWXqSvC-8",
        "candidates": [
            "[0.50, 0.03, 0.64, 0.26]",
            "[0.79, 0.00, 0.69, 0.32]",
            "[0.28, 0.37, 0.40, 0.80]",
            "[0.72, 0.00, 0.77, 0.00]"
        ],
        "start": 0.0,
        "end": 154.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1104.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "play board game -> talk to (e.g., self, a person, a group)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "xeGWXqSvC-8",
        "candidates": [
            "play board game -> play with pets",
            "play board game -> talk to (e.g., self, a person, a group)",
            "play board game -> press",
            "play board game -> put down"
        ],
        "start": 0.0,
        "end": 209.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1315.0,
        "question": "Where was the person currently performing the walk in the scene 8 seconds ago?",
        "answer": "[0.00, 0.30, 0.40, 0.98]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "xeGWXqSvC-8",
        "candidates": [
            "[0.00, 0.30, 0.40, 0.98]",
            "[0.00, 0.04, 0.33, 0.94]",
            "[0.17, 0.01, 0.48, 0.78]",
            "[0.00, 0.58, 0.67, 1.00]"
        ],
        "start": 0.0,
        "end": 420.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1324.0,
        "question": "Where is the person currently performing the walk located in the picture?",
        "answer": "[0.00, 0.09, 0.30, 1.00]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "xeGWXqSvC-8",
        "candidates": [
            "[0.00, 0.09, 0.30, 1.00]",
            "[0.00, 0.01, 0.27, 0.76]",
            "[0.73, 0.49, 0.84, 0.64]",
            "[0.28, 0.27, 0.41, 1.00]"
        ],
        "start": 0.0,
        "end": 429.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1376.0,
        "question": "Is the person currently in the [0.01, 0.06, 0.37, 0.99] location in the current frame performing the open (e.g., a window, a car door)?",
        "answer": "No",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "xeGWXqSvC-8",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 481.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1382.0,
        "question": "Where was the person currently performing the carry/hold (an object) in the scene 8 seconds ago?",
        "answer": "[0.03, 0.11, 0.57, 0.98]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "xeGWXqSvC-8",
        "candidates": [
            "[0.24, 0.23, 0.70, 1.00]",
            "[0.03, 0.11, 0.57, 0.98]",
            "[0.00, 0.34, 0.32, 0.93]",
            "[0.59, 0.22, 0.99, 1.00]"
        ],
        "start": 0.0,
        "end": 487.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1416.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "touch (an object) -> walk",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "xeGWXqSvC-8",
        "candidates": [
            "hand clap -> walk",
            "touch (an object) -> paint",
            "touch (an object) -> walk",
            "walk -> lie/sleep"
        ],
        "start": 0.0,
        "end": 521.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1487.0,
        "question": "What action is the person at the location [0.13, 0.20, 0.30, 0.83] in the image performing?",
        "answer": "walk, talk to (e.g., self, a person, a group), watch (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "xeGWXqSvC-8",
        "candidates": [
            "walk, talk to (e.g., self, a person, a group)",
            "stand, carry/hold (an object)",
            "walk, talk to (e.g., self, a person, a group), watch (a person)",
            "walk, carry/hold (an object)"
        ],
        "start": 0.0,
        "end": 592.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1496.0,
        "question": "What action is the person currently in the [0.17, 0.07, 0.61, 0.98] location likely to do next?",
        "answer": "walk and talk to (e.g., self, a person, a group)",
        "sub_answer_type": "FuturePrediction-1",
        "answer_type": "FuturePrediction",
        "video": "xeGWXqSvC-8",
        "candidates": [
            "walk and talk to (e.g., self, a person, a group)",
            "put down",
            "carry/hold (an object)",
            "enter"
        ],
        "start": 0.0,
        "end": 601.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1528.0,
        "question": "Where was the person currently performing the walk in the scene 8 seconds ago?",
        "answer": "[0.53, 0.32, 0.68, 0.62]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "xeGWXqSvC-8",
        "candidates": [
            "[0.21, 0.07, 0.60, 0.99]",
            "[0.53, 0.32, 0.68, 0.62]",
            "[0.81, 0.21, 0.74, 0.66]",
            "[0.44, 0.06, 0.41, 0.62]"
        ],
        "start": 0.0,
        "end": 633.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1532.0,
        "question": "Are there still 2 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "xeGWXqSvC-8",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 637.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1578.0,
        "question": "Where was the person currently performing the walk in the scene 8 seconds ago?",
        "answer": "[0.01, 0.01, 0.48, 0.99]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "xeGWXqSvC-8",
        "candidates": [
            "[0.23, 0.00, 0.98, 0.97]",
            "[0.23, 0.24, 0.69, 0.90]",
            "[0.01, 0.01, 0.48, 0.99]",
            "[0.22, 0.00, 0.70, 0.77]"
        ],
        "start": 0.0,
        "end": 683.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1590.0,
        "question": "Is the person currently in the [0.50, 0.09, 0.70, 0.57] location in the current frame performing the walk?",
        "answer": "No",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "xeGWXqSvC-8",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 695.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1597.0,
        "question": "What action is the person at the location [0.01, 0.12, 0.48, 1.00] in the image performing?",
        "answer": "walk, carry/hold (an object)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "xeGWXqSvC-8",
        "candidates": [
            "walk, talk to (e.g., self, a person, a group), watch (a person)",
            "walk, talk to (e.g., self, a person, a group)",
            "walk, carry/hold (an object)",
            "stand, drink, watch (a person)"
        ],
        "start": 0.0,
        "end": 702.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1645.0,
        "question": "Where is the person currently performing the drink located in the picture?",
        "answer": "[0.08, 0.10, 0.94, 0.98]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "xeGWXqSvC-8",
        "candidates": [
            "[0.00, 0.00, 0.64, 1.00]",
            "[0.08, 0.10, 0.94, 0.98]",
            "[0.39, 0.01, 1.00, 1.00]",
            "[0.34, 0.00, 0.68, 0.71]"
        ],
        "start": 0.0,
        "end": 750.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1730.0,
        "question": "Is the person currently in the [0.00, 0.21, 0.19, 0.99] location in the current frame performing the drink?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "xeGWXqSvC-8",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 835.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1765.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "walk -> touch (an object)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "xeGWXqSvC-8",
        "candidates": [
            "throw -> touch (an object)",
            "walk -> touch (an object)",
            "fall down -> touch (an object)",
            "touch (an object) -> fishing"
        ],
        "start": 0.0,
        "end": 870.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 946.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "drive (e.g., a car, a truck) -> talk to (e.g., self, a person, a group)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "yn9WN9lsHRE",
        "candidates": [
            "drive (e.g., a car, a truck) -> talk to (e.g., self, a person, a group)",
            "talk to (e.g., self, a person, a group) -> cook",
            "hand shake -> talk to (e.g., self, a person, a group)",
            "drive (e.g., a car, a truck) -> play with kids"
        ],
        "start": 0.0,
        "end": 51.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 958.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.51, 0.31, 0.64, 0.91] location?",
        "answer": "walk [0.51, 0.31, 0.64, 0.91] -> carry/hold (an object) [0.51, 0.31, 0.64, 0.91] -> talk to (e.g., self, a person, a group) [0.51, 0.31, 0.64, 0.91]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "yn9WN9lsHRE",
        "candidates": [
            "walk [0.68, 0.49, 0.49, 1.00] -> carry/hold (an object) [0.64, 0.33, 0.83, 0.76] -> lift/pick up [0.67, 0.19, 0.56, 0.88]",
            "walk [0.51, 0.31, 0.64, 0.91] -> carry/hold (an object) [0.51, 0.31, 0.64, 0.91] -> talk to (e.g., self, a person, a group) [0.51, 0.31, 0.64, 0.91]",
            "give/serve (an object) to (a person) [0.64, 0.25, 0.73, 0.72] -> talk to (e.g., self, a person, a group) [0.58, 0.33, 0.83, 1.00] -> carry/hold (an object) [0.33, 0.28, 0.64, 0.81]",
            "carry/hold (an object) [0.64, 0.26, 0.64, 0.86] -> answer phone [0.56, 0.23, 0.74, 0.93] -> walk [0.39, 0.38, 0.66, 0.95]"
        ],
        "start": 0.0,
        "end": 63.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 964.0,
        "question": "Are there still 2 people in the current frame now?",
        "answer": "No",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "yn9WN9lsHRE",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 69.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 983.0,
        "question": "Where was the person currently performing the touch (an object) in the scene 8 seconds ago?",
        "answer": "[0.31, 0.25, 0.51, 0.91]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "yn9WN9lsHRE",
        "candidates": [
            "[0.15, 0.11, 0.35, 1.00]",
            "[0.25, 0.24, 0.72, 0.63]",
            "[0.31, 0.25, 0.51, 0.91]",
            "[0.74, 0.42, 0.87, 0.97]"
        ],
        "start": 0.0,
        "end": 88.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1026.0,
        "question": "What action is the person at the location [0.01, 0.10, 0.52, 0.96] in the image performing?",
        "answer": "sit, talk to (e.g., self, a person, a group), watch (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "yn9WN9lsHRE",
        "candidates": [
            "walk, carry/hold (an object)",
            "stand, watch (a person)",
            "stand, carry/hold (an object), listen to (a person)",
            "sit, talk to (e.g., self, a person, a group), watch (a person)"
        ],
        "start": 0.0,
        "end": 131.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1110.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "bend/bow (at the waist) -> carry/hold (an object) -> touch (an object)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "yn9WN9lsHRE",
        "candidates": [
            "bend/bow (at the waist) -> carry/hold (an object) -> touch (an object)",
            "drive (e.g., a car, a truck) -> carry/hold (an object) -> touch (an object)",
            "dress/put on clothing -> carry/hold (an object) -> bend/bow (at the waist)",
            "touch (an object) -> carry/hold (an object) -> chop"
        ],
        "start": 0.0,
        "end": 215.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1164.0,
        "question": "Is the person currently in the [0.30, 0.05, 0.76, 0.91] location in the current frame performing the smoke?",
        "answer": "No",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "yn9WN9lsHRE",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 269.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1186.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.38, 0.10, 0.81, 0.96] location?",
        "answer": "bend/bow (at the waist) [0.38, 0.10, 0.81, 0.96] -> carry/hold (an object) [0.38, 0.10, 0.81, 0.96] -> talk to (e.g., self, a person, a group) [0.38, 0.10, 0.81, 0.96]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "yn9WN9lsHRE",
        "candidates": [
            "get up [0.29, 0.00, 0.82, 0.94] -> talk to (e.g., self, a person, a group) [0.21, 0.29, 0.81, 1.00] -> bend/bow (at the waist) [0.47, 0.28, 0.76, 1.00]",
            "bend/bow (at the waist) [0.38, 0.10, 0.81, 0.96] -> carry/hold (an object) [0.38, 0.10, 0.81, 0.96] -> talk to (e.g., self, a person, a group) [0.38, 0.10, 0.81, 0.96]",
            "smoke [0.34, 0.01, 0.96, 1.00] -> talk to (e.g., self, a person, a group) [0.43, 0.00, 0.71, 1.00] -> carry/hold (an object) [0.21, 0.28, 0.91, 1.00]",
            "read [0.54, 0.00, 0.99, 1.00] -> bend/bow (at the waist) [0.46, 0.00, 0.65, 0.97] -> carry/hold (an object) [0.20, 0.00, 0.75, 0.98]"
        ],
        "start": 0.0,
        "end": 291.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1210.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.40, 0.18, 0.58, 0.68] location?",
        "answer": "carry/hold (an object) [0.47, 0.20, 0.62, 0.76] -> smoke [0.47, 0.20, 0.62, 0.76] -> walk [0.40, 0.18, 0.58, 0.68]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "yn9WN9lsHRE",
        "candidates": [
            "smoke [0.33, 0.36, 0.47, 0.71] -> walk [0.46, 0.26, 0.57, 0.53] -> sing to (e.g., self, a person, a group) [0.51, 0.40, 0.57, 0.61]",
            "answer phone [0.27, 0.10, 0.67, 0.56] -> carry/hold (an object) [0.58, 0.28, 0.58, 0.62] -> smoke [0.40, 0.14, 0.53, 0.65]",
            "walk [0.56, 0.13, 0.58, 0.69] -> smoke [0.27, 0.08, 0.62, 0.91] -> martial art [0.62, 0.24, 0.48, 0.66]",
            "carry/hold (an object) [0.47, 0.20, 0.62, 0.76] -> smoke [0.47, 0.20, 0.62, 0.76] -> walk [0.40, 0.18, 0.58, 0.68]"
        ],
        "start": 0.0,
        "end": 315.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1256.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "carry/hold (an object) -> talk to (e.g., self, a person, a group) -> lie/sleep",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "yn9WN9lsHRE",
        "candidates": [
            "lift (a person) -> lie/sleep -> talk to (e.g., self, a person, a group)",
            "lie/sleep -> hand shake -> carry/hold (an object)",
            "carry/hold (an object) -> lie/sleep -> extract",
            "carry/hold (an object) -> talk to (e.g., self, a person, a group) -> lie/sleep"
        ],
        "start": 0.0,
        "end": 361.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1257.0,
        "question": "Where is the person currently performing the carry/hold (an object) located in the picture?",
        "answer": "[0.35, 0.06, 0.83, 0.98]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "yn9WN9lsHRE",
        "candidates": [
            "[0.06, 0.10, 0.82, 0.99]",
            "[0.43, 0.00, 0.97, 0.74]",
            "[0.35, 0.06, 0.83, 0.98]",
            "[0.64, 0.05, 1.00, 1.00]"
        ],
        "start": 0.0,
        "end": 362.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1348.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.45, 0.02, 0.96, 0.98] location?",
        "answer": "carry/hold (an object) [0.45, 0.02, 0.96, 0.98] -> give/serve (an object) to (a person) [0.45, 0.02, 0.96, 0.98] -> talk to (e.g., self, a person, a group) [0.45, 0.02, 0.96, 0.98]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "yn9WN9lsHRE",
        "candidates": [
            "carry/hold (an object) [0.30, 0.10, 0.78, 0.80] -> cook [0.39, 0.21, 0.86, 0.82] -> talk to (e.g., self, a person, a group) [0.31, 0.18, 0.82, 0.79]",
            "carry/hold (an object) [0.45, 0.02, 0.96, 0.98] -> give/serve (an object) to (a person) [0.45, 0.02, 0.96, 0.98] -> talk to (e.g., self, a person, a group) [0.45, 0.02, 0.96, 0.98]",
            "give/serve (an object) to (a person) [0.54, 0.00, 1.00, 0.85] -> jump/leap [0.48, 0.05, 0.80, 0.94] -> carry/hold (an object) [0.48, 0.20, 1.00, 1.00]",
            "give/serve (an object) to (a person) [0.51, 0.14, 1.00, 0.78] -> hand clap [0.54, 0.00, 1.00, 0.93] -> talk to (e.g., self, a person, a group) [0.57, 0.00, 1.00, 0.90]"
        ],
        "start": 0.0,
        "end": 453.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1349.0,
        "question": "Are there still 2 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "yn9WN9lsHRE",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 454.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1352.0,
        "question": "What action is the person currently in the [0.41, 0.03, 0.98, 0.99] location likely to do next?",
        "answer": "carry/hold (an object) and give/serve (an object) to (a person) and talk to (e.g., self, a person, a group)",
        "sub_answer_type": "FuturePrediction-1",
        "answer_type": "FuturePrediction",
        "video": "yn9WN9lsHRE",
        "candidates": [
            "push (an object)",
            "turn (e.g., a screwdriver)",
            "carry/hold (an object) and talk to (e.g., self, a person, a group)",
            "carry/hold (an object) and give/serve (an object) to (a person) and talk to (e.g., self, a person, a group)"
        ],
        "start": 0.0,
        "end": 457.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1361.0,
        "question": "Where was the person currently performing the drink in the scene 8 seconds ago?",
        "answer": "[0.39, 0.05, 0.99, 0.96]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "yn9WN9lsHRE",
        "candidates": [
            "[0.29, 0.08, 0.67, 0.98]",
            "[0.36, 0.34, 1.00, 1.00]",
            "[0.39, 0.05, 0.99, 0.96]",
            "[0.41, 0.00, 0.78, 0.67]"
        ],
        "start": 0.0,
        "end": 466.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1371.0,
        "question": "Where is the person currently performing the talk to (e.g., self, a person, a group) located in the picture?",
        "answer": "[0.03, 0.06, 0.62, 0.97]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "yn9WN9lsHRE",
        "candidates": [
            "[0.03, 0.06, 0.62, 0.97]",
            "[0.00, 0.13, 0.39, 0.73]",
            "[0.43, 0.68, 0.54, 0.98]",
            "[0.00, 0.33, 0.69, 1.00]"
        ],
        "start": 0.0,
        "end": 476.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1386.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "carry/hold (an object) -> lie/sleep",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "yn9WN9lsHRE",
        "candidates": [
            "lie/sleep -> open (e.g., a window, a car door)",
            "lie/sleep -> walk",
            "carry/hold (an object) -> lie/sleep",
            "carry/hold (an object) -> carry/hold (an object)"
        ],
        "start": 0.0,
        "end": 491.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1454.0,
        "question": "What action is the person at the location [0.16, 0.14, 0.52, 0.96] in the image performing?",
        "answer": "sit, talk to (e.g., self, a person, a group), watch (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "yn9WN9lsHRE",
        "candidates": [
            "sit, talk to (e.g., self, a person, a group), watch (a person)",
            "stand, listen to (a person), watch (a person)",
            "stand, carry/hold (an object), listen to (a person), watch (a person)",
            "sit, stand, carry/hold (an object), talk to (e.g., self, a person, a group)"
        ],
        "start": 0.0,
        "end": 559.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1539.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.07, 0.05, 0.76, 0.98] location?",
        "answer": "carry/hold (an object) [0.07, 0.05, 0.76, 0.98] -> read [0.07, 0.05, 0.76, 0.98] -> talk to (e.g., self, a person, a group) [0.07, 0.05, 0.76, 0.98]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "yn9WN9lsHRE",
        "candidates": [
            "exit [0.25, 0.22, 0.83, 0.86] -> talk to (e.g., self, a person, a group) [0.00, 0.00, 0.61, 1.00] -> read [0.00, 0.12, 0.80, 0.90]",
            "carry/hold (an object) [0.07, 0.05, 0.76, 0.98] -> read [0.07, 0.05, 0.76, 0.98] -> talk to (e.g., self, a person, a group) [0.07, 0.05, 0.76, 0.98]",
            "talk to (e.g., self, a person, a group) [0.00, 0.12, 0.64, 1.00] -> dress/put on clothing [0.00, 0.17, 0.78, 0.97] -> carry/hold (an object) [0.04, 0.00, 0.90, 1.00]",
            "talk to (e.g., self, a person, a group) [0.18, 0.21, 0.76, 0.98] -> read [0.00, 0.10, 0.88, 1.00] -> crouch/kneel [0.04, 0.00, 0.72, 0.99]"
        ],
        "start": 0.0,
        "end": 644.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1542.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "carry/hold (an object) -> read -> talk to (e.g., self, a person, a group)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "yn9WN9lsHRE",
        "candidates": [
            "carry/hold (an object) -> read -> talk to (e.g., self, a person, a group)",
            "carry/hold (an object) -> answer phone -> read",
            "carry/hold (an object) -> talk to (e.g., self, a person, a group) -> kiss (a person)",
            "dress/put on clothing -> carry/hold (an object) -> read"
        ],
        "start": 0.0,
        "end": 647.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1572.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.57, 0.05, 0.99, 0.97]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "yn9WN9lsHRE",
        "candidates": [
            "[0.36, 0.46, 0.56, 0.84]",
            "[0.57, 0.05, 0.99, 0.97]",
            "[0.76, 0.00, 1.00, 0.76]",
            "[0.43, 0.00, 0.79, 0.75]"
        ],
        "start": 0.0,
        "end": 677.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1669.0,
        "question": "How many people were performing the stand in the scene 60 seconds ago?",
        "answer": "5",
        "sub_answer_type": "PastMemory-5",
        "answer_type": "PastMemory",
        "video": "yn9WN9lsHRE",
        "candidates": [
            "5",
            "7",
            "4",
            "3"
        ],
        "start": 0.0,
        "end": 774.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1738.0,
        "question": "How many people were performing the stand in the scene 120 seconds ago?",
        "answer": "6",
        "sub_answer_type": "PastMemory-5",
        "answer_type": "PastMemory",
        "video": "yn9WN9lsHRE",
        "candidates": [
            "4",
            "6",
            "3",
            "5"
        ],
        "start": 0.0,
        "end": 843.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1755.0,
        "question": "Where is the person currently performing the lie/sleep located in the picture?",
        "answer": "[0.00, 0.30, 1.00, 0.99]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "yn9WN9lsHRE",
        "candidates": [
            "[0.59, 0.08, 0.75, 0.89]",
            "[0.29, 0.51, 1.00, 1.00]",
            "[0.00, 0.30, 1.00, 0.99]",
            "[0.00, 0.41, 0.71, 1.00]"
        ],
        "start": 0.0,
        "end": 860.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 917.0,
        "question": "Where is the person currently performing the walk located in the picture?",
        "answer": "[0.00, 0.12, 0.45, 0.92]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "z-fsLpGHq6o",
        "candidates": [
            "[0.00, 0.12, 0.45, 0.92]",
            "[0.00, 0.33, 0.17, 0.83]",
            "[0.28, 0.33, 0.57, 0.71]",
            "[0.50, 0.17, 0.92, 0.91]"
        ],
        "start": 0.0,
        "end": 22.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 920.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.01, 0.16, 0.35, 0.89]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "z-fsLpGHq6o",
        "candidates": [
            "[0.30, 0.00, 0.30, 0.78]",
            "[0.24, 0.36, 0.60, 0.90]",
            "[0.01, 0.16, 0.35, 0.89]",
            "[0.00, 0.03, 0.22, 0.61]"
        ],
        "start": 0.0,
        "end": 25.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1068.0,
        "question": "Are there still 1 people in the current frame now?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-2",
        "answer_type": "Hallucination",
        "video": "z-fsLpGHq6o",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 173.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1175.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.58, 0.27, 0.78, 0.90] location?",
        "answer": "dance [0.58, 0.27, 0.78, 0.90] -> hug (a person) [0.58, 0.27, 0.78, 0.90] -> sing to (e.g., self, a person, a group) [0.58, 0.27, 0.78, 0.90]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "z-fsLpGHq6o",
        "candidates": [
            "dance [0.58, 0.27, 0.78, 0.90] -> hug (a person) [0.58, 0.27, 0.78, 0.90] -> sing to (e.g., self, a person, a group) [0.58, 0.27, 0.78, 0.90]",
            "hug (a person) [0.47, 0.22, 0.59, 0.82] -> dance [0.49, 0.14, 0.84, 0.83] -> swim [0.53, 0.32, 0.66, 1.00]",
            "dance [0.77, 0.27, 0.66, 0.85] -> hug (a person) [0.71, 0.37, 0.93, 1.00] -> talk to (e.g., self, a person, a group) [0.57, 0.29, 0.73, 1.00]",
            "walk [0.47, 0.30, 0.64, 0.77] -> hug (a person) [0.56, 0.40, 0.79, 0.74] -> sing to (e.g., self, a person, a group) [0.60, 0.20, 0.63, 0.94]"
        ],
        "start": 0.0,
        "end": 280.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1210.0,
        "question": "Is the person currently in the [0.54, 0.28, 0.77, 0.90] location in the current frame performing the walk?",
        "answer": "No",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "z-fsLpGHq6o",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 315.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1211.0,
        "question": "How many people in the current frame are performing the action:  dance?",
        "answer": "2",
        "sub_answer_type": "SpatialPerception-2",
        "answer_type": "SpatialPerception",
        "video": "z-fsLpGHq6o",
        "candidates": [
            "3",
            "2",
            "4",
            "5"
        ],
        "start": 0.0,
        "end": 316.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1237.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.22, 0.46, 0.36, 0.86] location?",
        "answer": "carry/hold (an object) [0.22, 0.46, 0.36, 0.86] -> crouch/kneel [0.22, 0.46, 0.36, 0.86] -> give/serve (an object) to (a person) [0.22, 0.46, 0.36, 0.86]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "z-fsLpGHq6o",
        "candidates": [
            "swim [0.23, 0.28, 0.47, 0.90] -> crouch/kneel [0.21, 0.31, 0.56, 0.97] -> carry/hold (an object) [0.19, 0.35, 0.20, 0.89]",
            "carry/hold (an object) [0.22, 0.46, 0.36, 0.86] -> crouch/kneel [0.22, 0.46, 0.36, 0.86] -> give/serve (an object) to (a person) [0.22, 0.46, 0.36, 0.86]",
            "hand shake [0.28, 0.47, 0.33, 0.76] -> carry/hold (an object) [0.37, 0.50, 0.19, 0.99] -> crouch/kneel [0.26, 0.57, 0.23, 0.76]",
            "give/serve (an object) to (a person) [0.03, 0.48, 0.47, 0.84] -> carry/hold (an object) [0.16, 0.38, 0.27, 1.00] -> take (an object) from (a person) [0.22, 0.32, 0.20, 0.90]"
        ],
        "start": 0.0,
        "end": 342.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1292.0,
        "question": "How many people in the current frame are performing the action:  eat?",
        "answer": "3",
        "sub_answer_type": "SpatialPerception-2",
        "answer_type": "SpatialPerception",
        "video": "z-fsLpGHq6o",
        "candidates": [
            "4",
            "2",
            "5",
            "3"
        ],
        "start": 0.0,
        "end": 397.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1332.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.62, 0.19, 0.88, 0.81] location?",
        "answer": "bend/bow (at the waist) [0.62, 0.19, 0.88, 0.81] -> carry/hold (an object) [0.62, 0.19, 0.88, 0.81] -> give/serve (an object) to (a person) [0.62, 0.19, 0.88, 0.81]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "z-fsLpGHq6o",
        "candidates": [
            "walk [0.58, 0.08, 0.90, 0.77] -> give/serve (an object) to (a person) [0.47, 0.29, 1.00, 0.91] -> carry/hold (an object) [0.72, 0.38, 0.83, 0.81]",
            "bend/bow (at the waist) [0.62, 0.19, 0.88, 0.81] -> carry/hold (an object) [0.62, 0.19, 0.88, 0.81] -> give/serve (an object) to (a person) [0.62, 0.19, 0.88, 0.81]",
            "carry/hold (an object) [0.61, 0.04, 0.86, 0.70] -> hug (a person) [0.56, 0.04, 1.00, 0.62] -> bend/bow (at the waist) [0.70, 0.19, 0.83, 0.81]",
            "bend/bow (at the waist) [0.74, 0.28, 0.80, 0.89] -> carry/hold (an object) [0.71, 0.09, 0.94, 0.95] -> lie/sleep [0.63, 0.11, 1.00, 0.72]"
        ],
        "start": 0.0,
        "end": 437.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1333.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.62, 0.19, 0.88, 0.81] location?",
        "answer": "bend/bow (at the waist) [0.62, 0.19, 0.88, 0.81] -> carry/hold (an object) [0.62, 0.19, 0.88, 0.81] -> give/serve (an object) to (a person) [0.62, 0.19, 0.88, 0.81]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "z-fsLpGHq6o",
        "candidates": [
            "give/serve (an object) to (a person) [0.62, 0.17, 0.74, 0.76] -> bend/bow (at the waist) [0.51, 0.24, 1.00, 0.77] -> crouch/kneel [0.58, 0.20, 1.00, 0.84]",
            "bend/bow (at the waist) [0.62, 0.19, 0.88, 0.81] -> carry/hold (an object) [0.62, 0.19, 0.88, 0.81] -> give/serve (an object) to (a person) [0.62, 0.19, 0.88, 0.81]",
            "swim [0.75, 0.23, 1.00, 0.82] -> bend/bow (at the waist) [0.66, 0.05, 0.78, 0.99] -> give/serve (an object) to (a person) [0.78, 0.22, 1.00, 0.62]",
            "carry/hold (an object) [0.57, 0.34, 0.85, 0.93] -> shovel [0.44, 0.24, 0.69, 0.61] -> give/serve (an object) to (a person) [0.79, 0.34, 1.00, 0.91]"
        ],
        "start": 0.0,
        "end": 438.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1365.0,
        "question": "What action is the person currently in the [0.03, 0.12, 0.52, 0.90] location likely to do next?",
        "answer": "ride (e.g., a bike, a car, a horse)",
        "sub_answer_type": "FuturePrediction-1",
        "answer_type": "FuturePrediction",
        "video": "z-fsLpGHq6o",
        "candidates": [
            "clink glass",
            "ride (e.g., a bike, a car, a horse)",
            "crawl",
            "eat"
        ],
        "start": 0.0,
        "end": 470.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1437.0,
        "question": "How many people in the current frame are performing the action:  walk?",
        "answer": "4",
        "sub_answer_type": "SpatialPerception-2",
        "answer_type": "SpatialPerception",
        "video": "z-fsLpGHq6o",
        "candidates": [
            "3",
            "4",
            "5",
            "2"
        ],
        "start": 0.0,
        "end": 542.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1476.0,
        "question": "How many people were performing the listen to (a person) in the scene 60 seconds ago?",
        "answer": "5",
        "sub_answer_type": "PastMemory-5",
        "answer_type": "PastMemory",
        "video": "z-fsLpGHq6o",
        "candidates": [
            "4",
            "3",
            "8",
            "5"
        ],
        "start": 0.0,
        "end": 581.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1569.0,
        "question": "How many people in the current frame are performing the action:  talk to (e.g., self, a person, a group)?",
        "answer": "2",
        "sub_answer_type": "SpatialPerception-2",
        "answer_type": "SpatialPerception",
        "video": "z-fsLpGHq6o",
        "candidates": [
            "4",
            "3",
            "2",
            "5"
        ],
        "start": 0.0,
        "end": 674.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1624.0,
        "question": "How many people were performing the stand in the scene 120 seconds ago?",
        "answer": "9",
        "sub_answer_type": "PastMemory-5",
        "answer_type": "PastMemory",
        "video": "z-fsLpGHq6o",
        "candidates": [
            "6",
            "9",
            "4",
            "3"
        ],
        "start": 0.0,
        "end": 729.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1654.0,
        "question": "How many people were performing the stand in the scene 180 seconds ago?",
        "answer": "9",
        "sub_answer_type": "PastMemory-5",
        "answer_type": "PastMemory",
        "video": "z-fsLpGHq6o",
        "candidates": [
            "4",
            "3",
            "6",
            "9"
        ],
        "start": 0.0,
        "end": 759.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1735.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.29, 0.14, 0.60, 0.90] location?",
        "answer": "talk to (e.g., self, a person, a group) [0.31, 0.12, 0.59, 0.90] -> bend/bow (at the waist) [0.29, 0.14, 0.60, 0.90] -> touch (an object) [0.29, 0.14, 0.60, 0.90]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "z-fsLpGHq6o",
        "candidates": [
            "open (e.g., a window, a car door) [0.26, 0.00, 0.60, 1.00] -> touch (an object) [0.31, 0.21, 0.74, 0.85] -> talk to (e.g., self, a person, a group) [0.31, 0.28, 0.45, 1.00]",
            "talk to (e.g., self, a person, a group) [0.31, 0.12, 0.59, 0.90] -> bend/bow (at the waist) [0.29, 0.14, 0.60, 0.90] -> touch (an object) [0.29, 0.14, 0.60, 0.90]",
            "talk to (e.g., self, a person, a group) [0.46, 0.12, 0.63, 1.00] -> drive (e.g., a car, a truck) [0.27, 0.29, 0.74, 0.88] -> bend/bow (at the waist) [0.36, 0.07, 0.60, 0.87]",
            "drink [0.14, 0.22, 0.41, 1.00] -> talk to (e.g., self, a person, a group) [0.50, 0.14, 0.71, 0.89] -> touch (an object) [0.40, 0.33, 0.51, 0.86]"
        ],
        "start": 0.0,
        "end": 840.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1795.0,
        "question": "Where was the person currently performing the drink in the scene 8 seconds ago?",
        "answer": "[0.04, 0.45, 0.28, 0.89]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "z-fsLpGHq6o",
        "candidates": [
            "[0.45, 0.10, 0.80, 0.94]",
            "[0.31, 0.39, 0.26, 0.64]",
            "[0.04, 0.45, 0.28, 0.89]",
            "[0.00, 0.75, 0.17, 0.91]"
        ],
        "start": 0.0,
        "end": 900.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 937.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "talk to (e.g., self, a person, a group) -> carry/hold (an object) -> walk",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "zC5Fh2tTS1U",
        "candidates": [
            "talk to (e.g., self, a person, a group) -> walk -> paint",
            "touch (an object) -> walk -> talk to (e.g., self, a person, a group)",
            "talk to (e.g., self, a person, a group) -> carry/hold (an object) -> walk",
            "talk to (e.g., self, a person, a group) -> walk -> crouch/kneel"
        ],
        "start": 0.0,
        "end": 42.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 946.0,
        "question": "What action is the person at the location [0.04, 0.25, 0.39, 0.99] in the image performing?",
        "answer": "bend/bow (at the waist), stand, listen to (a person), watch (a person)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "zC5Fh2tTS1U",
        "candidates": [
            "bend/bow (at the waist), stand, listen to (a person), watch (a person)",
            "stand, listen to (a person), watch (a person)",
            "walk, carry/hold (an object)",
            "stand, talk to (e.g., self, a person, a group), watch (a person)"
        ],
        "start": 0.0,
        "end": 51.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 958.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.03, 0.22, 0.42, 0.97] location?",
        "answer": "talk to (e.g., self, a person, a group) [0.00, 0.27, 0.42, 0.99] -> bend/bow (at the waist) [0.03, 0.22, 0.42, 0.97] -> grab (a person) [0.03, 0.22, 0.42, 0.97]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "zC5Fh2tTS1U",
        "candidates": [
            "lie/sleep [0.01, 0.08, 0.24, 0.97] -> talk to (e.g., self, a person, a group) [0.00, 0.08, 0.44, 0.92] -> bend/bow (at the waist) [0.00, 0.30, 0.42, 1.00]",
            "bend/bow (at the waist) [0.23, 0.27, 0.58, 1.00] -> talk to (e.g., self, a person, a group) [0.02, 0.28, 0.31, 0.95] -> grab (a person) [0.00, 0.37, 0.51, 0.98]",
            "talk to (e.g., self, a person, a group) [0.00, 0.27, 0.42, 0.99] -> bend/bow (at the waist) [0.03, 0.22, 0.42, 0.97] -> grab (a person) [0.03, 0.22, 0.42, 0.97]",
            "grab (a person) [0.12, 0.30, 0.32, 1.00] -> cut [0.00, 0.14, 0.37, 0.87] -> talk to (e.g., self, a person, a group) [0.00, 0.08, 0.44, 1.00]"
        ],
        "start": 0.0,
        "end": 63.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1032.0,
        "question": "Is the person currently in the [0.21, 0.12, 0.41, 0.94] location in the current frame performing the carry/hold (an object)?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "zC5Fh2tTS1U",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 137.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1042.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.13, 0.03, 0.96, 0.99] location?",
        "answer": "walk [0.13, 0.03, 0.96, 0.99] -> carry/hold (an object) [0.13, 0.03, 0.96, 0.99] -> talk to (e.g., self, a person, a group) [0.13, 0.03, 0.96, 0.99]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "zC5Fh2tTS1U",
        "candidates": [
            "smoke [0.29, 0.17, 0.97, 0.83] -> walk [0.26, 0.10, 0.85, 1.00] -> carry/hold (an object) [0.00, 0.00, 0.99, 1.00]",
            "walk [0.13, 0.03, 0.96, 0.99] -> carry/hold (an object) [0.13, 0.03, 0.96, 0.99] -> talk to (e.g., self, a person, a group) [0.13, 0.03, 0.96, 0.99]",
            "carry/hold (an object) [0.00, 0.00, 0.91, 1.00] -> lift (a person) [0.02, 0.03, 0.82, 1.00] -> walk [0.16, 0.15, 0.90, 1.00]",
            "carry/hold (an object) [0.00, 0.22, 1.00, 0.94] -> enter [0.21, 0.06, 1.00, 1.00] -> talk to (e.g., self, a person, a group) [0.00, 0.00, 0.81, 0.94]"
        ],
        "start": 0.0,
        "end": 147.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1110.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.55, 0.32, 0.80, 0.98]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "zC5Fh2tTS1U",
        "candidates": [
            "[0.06, 0.09, 0.19, 0.75]",
            "[0.55, 0.32, 0.80, 0.98]",
            "[0.29, 0.38, 0.73, 1.00]",
            "[0.50, 0.07, 0.60, 1.00]"
        ],
        "start": 0.0,
        "end": 215.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1127.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.38, 0.03, 0.74, 0.99]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "zC5Fh2tTS1U",
        "candidates": [
            "[0.21, 0.05, 0.43, 0.95]",
            "[0.30, 0.33, 0.59, 1.00]",
            "[0.38, 0.03, 0.74, 0.99]",
            "[0.55, 0.00, 0.99, 0.91]"
        ],
        "start": 0.0,
        "end": 232.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1170.0,
        "question": "Where is the person currently performing the talk to (e.g., self, a person, a group) located in the picture?",
        "answer": "[0.26, 0.05, 0.99, 0.97]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "zC5Fh2tTS1U",
        "candidates": [
            "[0.26, 0.05, 0.99, 0.97]",
            "[0.00, 0.02, 0.86, 0.96]",
            "[0.53, 0.05, 0.93, 0.69]",
            "[0.54, 0.22, 1.00, 0.99]"
        ],
        "start": 0.0,
        "end": 275.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1365.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.61, 0.04, 0.89, 0.99] location?",
        "answer": "walk [0.61, 0.04, 0.89, 0.99] -> carry/hold (an object) [0.61, 0.04, 0.89, 0.99] -> talk to (e.g., self, a person, a group) [0.61, 0.04, 0.89, 0.99]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "zC5Fh2tTS1U",
        "candidates": [
            "carry/hold (an object) [0.67, 0.23, 0.94, 0.84] -> take (an object) from (a person) [0.69, 0.00, 0.93, 0.88] -> walk [0.66, 0.00, 0.74, 0.83]",
            "walk [0.48, 0.11, 0.79, 0.94] -> carry/hold (an object) [0.42, 0.00, 0.83, 1.00] -> ride (e.g., a bike, a car, a horse) [0.64, 0.20, 0.76, 0.93]",
            "talk to (e.g., self, a person, a group) [0.58, 0.13, 1.00, 0.95] -> carry/hold (an object) [0.54, 0.03, 0.81, 1.00] -> kick (a person) [0.65, 0.17, 1.00, 0.89]",
            "walk [0.61, 0.04, 0.89, 0.99] -> carry/hold (an object) [0.61, 0.04, 0.89, 0.99] -> talk to (e.g., self, a person, a group) [0.61, 0.04, 0.89, 0.99]"
        ],
        "start": 0.0,
        "end": 470.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1377.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "talk to (e.g., self, a person, a group) -> carry/hold (an object)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "zC5Fh2tTS1U",
        "candidates": [
            "write -> carry/hold (an object)",
            "talk to (e.g., self, a person, a group) -> carry/hold (an object)",
            "carry/hold (an object) -> martial art",
            "talk to (e.g., self, a person, a group) -> ride (e.g., a bike, a car, a horse)"
        ],
        "start": 0.0,
        "end": 482.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1390.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.19, 0.06, 0.51, 0.96] location?",
        "answer": "bend/bow (at the waist) [0.19, 0.06, 0.51, 0.96] -> carry/hold (an object) [0.19, 0.06, 0.51, 0.96] -> talk to (e.g., self, a person, a group) [0.19, 0.06, 0.51, 0.96]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "zC5Fh2tTS1U",
        "candidates": [
            "bend/bow (at the waist) [0.29, 0.04, 0.65, 1.00] -> clink glass [0.11, 0.20, 0.55, 0.80] -> carry/hold (an object) [0.28, 0.00, 0.69, 0.89]",
            "carry/hold (an object) [0.14, 0.00, 0.68, 0.91] -> point to (an object) [0.11, 0.00, 0.55, 0.80] -> bend/bow (at the waist) [0.20, 0.15, 0.70, 1.00]",
            "bend/bow (at the waist) [0.05, 0.04, 0.53, 0.76] -> carry/hold (an object) [0.21, 0.16, 0.54, 1.00] -> walk [0.09, 0.00, 0.39, 1.00]",
            "bend/bow (at the waist) [0.19, 0.06, 0.51, 0.96] -> carry/hold (an object) [0.19, 0.06, 0.51, 0.96] -> talk to (e.g., self, a person, a group) [0.19, 0.06, 0.51, 0.96]"
        ],
        "start": 0.0,
        "end": 495.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1430.0,
        "question": "Where is the person currently performing the talk to (e.g., self, a person, a group) located in the picture?",
        "answer": "[0.03, 0.12, 0.89, 0.97]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "zC5Fh2tTS1U",
        "candidates": [
            "[0.00, 0.00, 0.77, 0.68]",
            "[0.32, 0.02, 0.98, 1.00]",
            "[0.23, 0.41, 0.93, 1.00]",
            "[0.03, 0.12, 0.89, 0.97]"
        ],
        "start": 0.0,
        "end": 535.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1445.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.01, 0.03, 0.83, 0.99]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "zC5Fh2tTS1U",
        "candidates": [
            "[0.72, 0.11, 0.87, 0.86]",
            "[0.23, 0.00, 0.93, 0.80]",
            "[0.15, 0.19, 0.97, 1.00]",
            "[0.01, 0.03, 0.83, 0.99]"
        ],
        "start": 0.0,
        "end": 550.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1445.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "talk to (e.g., self, a person, a group) -> crouch/kneel",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "zC5Fh2tTS1U",
        "candidates": [
            "read -> talk to (e.g., self, a person, a group)",
            "open (e.g., a window, a car door) -> crouch/kneel",
            "talk to (e.g., self, a person, a group) -> point to (an object)",
            "talk to (e.g., self, a person, a group) -> crouch/kneel"
        ],
        "start": 0.0,
        "end": 550.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1498.0,
        "question": "What action is the person currently in the [0.14, 0.62, 0.71, 1.00] location likely to do next?",
        "answer": "crouch/kneel and talk to (e.g., self, a person, a group)",
        "sub_answer_type": "FuturePrediction-1",
        "answer_type": "FuturePrediction",
        "video": "zC5Fh2tTS1U",
        "candidates": [
            "crouch/kneel and talk to (e.g., self, a person, a group)",
            "chop",
            "touch (an object)",
            "carry/hold (an object) and talk to (e.g., self, a person, a group)"
        ],
        "start": 0.0,
        "end": 603.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1514.0,
        "question": "Is the person currently in the [0.24, 0.05, 1.00, 1.00] location in the current frame performing the bend/bow (at the waist)?",
        "answer": "No",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "zC5Fh2tTS1U",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 619.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1517.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "crouch/kneel -> talk to (e.g., self, a person, a group) -> bend/bow (at the waist)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "zC5Fh2tTS1U",
        "candidates": [
            "cook -> talk to (e.g., self, a person, a group) -> bend/bow (at the waist)",
            "bend/bow (at the waist) -> talk to (e.g., self, a person, a group) -> walk",
            "crouch/kneel -> talk to (e.g., self, a person, a group) -> bend/bow (at the waist)",
            "hit (an object) -> bend/bow (at the waist) -> talk to (e.g., self, a person, a group)"
        ],
        "start": 0.0,
        "end": 622.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1555.0,
        "question": "What is the sequence of actions the person in the scene has performed recently?",
        "answer": "run/jog -> talk to (e.g., self, a person, a group)",
        "sub_answer_type": "TemporalPerception-2",
        "answer_type": "TemporalPerception",
        "video": "zC5Fh2tTS1U",
        "candidates": [
            "lie/sleep -> run/jog",
            "talk to (e.g., self, a person, a group) -> martial art",
            "press -> run/jog",
            "run/jog -> talk to (e.g., self, a person, a group)"
        ],
        "start": 0.0,
        "end": 660.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1572.0,
        "question": "What action is the person at the location [0.51, 0.19, 0.78, 0.92] in the image performing?",
        "answer": "walk, carry/hold (an object)",
        "sub_answer_type": "SpatialPerception-3",
        "answer_type": "SpatialPerception",
        "video": "zC5Fh2tTS1U",
        "candidates": [
            "stand, listen to (a person), watch (a person)",
            "walk, carry/hold (an object)",
            "stand, talk to (e.g., self, a person, a group), watch (a person)",
            "sit, listen to (a person), watch (a person)"
        ],
        "start": 0.0,
        "end": 677.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1629.0,
        "question": "Is the person currently in the [0.15, 0.12, 0.93, 1.00] location in the current frame performing the talk to (e.g., self, a person, a group)?",
        "answer": "Yes",
        "sub_answer_type": "Hallucination-1",
        "answer_type": "Hallucination",
        "video": "zC5Fh2tTS1U",
        "candidates": [
            "Yes",
            "No"
        ],
        "start": 0.0,
        "end": 734.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1633.0,
        "question": "Where is the person currently performing the talk to (e.g., self, a person, a group) located in the picture?",
        "answer": "[0.12, 0.06, 1.00, 0.99]",
        "sub_answer_type": "SpatialPerception-1",
        "answer_type": "SpatialPerception",
        "video": "zC5Fh2tTS1U",
        "candidates": [
            "[0.02, 0.05, 0.77, 0.97]",
            "[0.00, 0.29, 0.94, 1.00]",
            "[0.12, 0.06, 1.00, 0.99]",
            "[0.15, 0.00, 0.87, 0.70]"
        ],
        "start": 0.0,
        "end": 738.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1644.0,
        "question": "Where was the person currently performing the talk to (e.g., self, a person, a group) in the scene 8 seconds ago?",
        "answer": "[0.32, 0.34, 0.58, 0.89]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "zC5Fh2tTS1U",
        "candidates": [
            "[0.06, 0.43, 0.49, 1.00]",
            "[0.07, 0.08, 0.22, 0.75]",
            "[0.60, 0.56, 0.79, 0.91]",
            "[0.32, 0.34, 0.58, 0.89]"
        ],
        "start": 0.0,
        "end": 749.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1657.0,
        "question": "What is the sequence of actions and the corresponding movement trajectory of the person currently in the [0.33, 0.16, 0.71, 0.98] location?",
        "answer": "carry/hold (an object) [0.33, 0.16, 0.71, 0.98] -> dance [0.33, 0.16, 0.71, 0.98] -> sing to (e.g., self, a person, a group) [0.33, 0.16, 0.71, 0.98]",
        "sub_answer_type": "SpatioTemporalPerception-2",
        "answer_type": "SpatioTemporalPerception",
        "video": "zC5Fh2tTS1U",
        "candidates": [
            "dance [0.35, 0.10, 0.52, 0.87] -> carry/hold (an object) [0.51, 0.28, 0.65, 0.94] -> shoot [0.49, 0.34, 0.75, 0.79]",
            "write [0.28, 0.12, 0.88, 0.86] -> carry/hold (an object) [0.51, 0.13, 0.73, 0.92] -> sing to (e.g., self, a person, a group) [0.41, 0.35, 0.85, 0.88]",
            "carry/hold (an object) [0.33, 0.16, 0.71, 0.98] -> dance [0.33, 0.16, 0.71, 0.98] -> sing to (e.g., self, a person, a group) [0.33, 0.16, 0.71, 0.98]",
            "carry/hold (an object) [0.27, 0.00, 0.68, 0.82] -> close (e.g., a door, a box) [0.43, 0.20, 0.53, 1.00] -> sing to (e.g., self, a person, a group) [0.36, 0.13, 0.62, 0.78]"
        ],
        "start": 0.0,
        "end": 762.0,
        "fps": 1
    },
    {
        "middle_frame_timestamp": 1762.0,
        "question": "Where was the person currently performing the carry/hold (an object) in the scene 8 seconds ago?",
        "answer": "[0.07, 0.08, 0.23, 0.75]",
        "sub_answer_type": "PastMemory-4",
        "answer_type": "PastMemory",
        "video": "zC5Fh2tTS1U",
        "candidates": [
            "[0.07, 0.08, 0.23, 0.75]",
            "[0.26, 0.05, 0.55, 0.97]",
            "[0.00, 0.00, 0.45, 0.53]",
            "[0.00, 0.27, 0.16, 1.00]"
        ],
        "start": 0.0,
        "end": 867.0,
        "fps": 1
    }
]